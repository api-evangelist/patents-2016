---

title: Sharing content
abstract: A user terminal comprising: a network interface; a display; a content sharing module configured to display content shared with a further user terminal on the display, and receive position data from the further user terminal via the network interface, said position data indicating a position within the shared content associated with a user at the further user terminal; and a communications module. The communications module configured to: receive video data from the further user terminal over a communications network during a communication event with at least said further user terminal via the network interface; and control the video data received from said further user terminal to be displayed on said display in dependence on the position within the shared content associated with the user at the further user terminal.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09516266&OS=09516266&RS=09516266
owner: Microsoft Technology Licensing, LLC
number: 09516266
owner_city: Redmond
owner_country: US
publication_date: 20160520
---
This application is a continuation of and claims priority under 35 U.S.C 120 to U.S. patent application Ser. No. 14 617 897 filed Feb. 9 2015 entitled Sharing Content which claims priority under 35 USC 119 or 365 to Great Britain Patent Application No. 1403807.9 entitled Sharing Content filed Mar. 4 2014 the disclosures of which are incorporated by reference herein in their entirety.

Packet based communication systems allow the user of a device such as a personal computer to communicate across the computer network using a packet protocol such as Internet Protocol IP . Packet based communication systems can be used for various types of communication events. Communication events which can be established include voice calls video calls instant messaging voice mail file transfer and others. These systems are beneficial to the user as they are often of significantly lower cost than fixed line or mobile networks. This may particularly be the case for long distance communication. To use a packet based system the user installs and executes client software on their device. The client software provides the packet based connections as well as other functions such as registration and authentication.

Communications systems allow users of devices to communicate across a computer network such as the internet. Communication events which can be established include voice calls video calls instant messaging voice mail file transfer and others. With video calling the callers are able to view video images of the other party in addition to voice information. This enables a much more natural communication between the parties as facial expressions are also communicated thereby making video calls more comparable to a face to face conversation.

Whilst a communication event is being conducted between users known client software allows a user to share the contents of their screen with the other user. That is a first user at a first terminal the sharer can decide to share the contents of his screen with a second user at a second terminal the viewer via the established communication event. As an example screen sharing can be particularly useful when the first user is trying to explain what they are seeing on their screen to the second user because with screen sharing the viewer can see images that are displayed on the sharer s screen.

Additionally collaboration software is known whereby a user of the collaboration software can make modifications to shared content whereby the content and the modifications are displayed to the user and others users of the collaboration software. Often the users of the collaboration software additionally use communication client software to establish a communication event so that the contents and the modifications to the content can be discussed.

The inventors have recognised that in both the screen sharing and collaborative scenarios discussed above when a video call is being conducted between users the shared experience is disrupted by a user having to switch from viewing the shared content to viewing the video data received from another user. This may be a result of the shared content and the received video data being displayed in separate areas of a user s screen or being displayed in separate windows which a user must toggle between.

According to one aspect there is provided a user terminal comprising a network interface a display a content module configured to display content shared with a further user terminal on the display and receive position data from the further user terminal via the network interface said position data indicating a position in the shared content of a user at the further user terminal and a communications module configured to receive video data from the further user terminal over a communications network during a communication event with at least said further user terminal via the network interface control the video data received from said further user terminal to be displayed on said display in dependence on the position in the shared content of the user at the further user terminal

This enables a user of the user terminal to view both the shared media content and the received video data at the same time without having to glance from one part of the display to another or to switch viewing windows.

According to another aspect there is provided a computer program product the computer program product being embodied on a non transient computer readable medium and configured so as when executed on a processor of a user terminal comprising a display to receive video data from a further user terminal over a communications network during a communication event with at least said further user terminal receive position data indicating a position within content shared with the further user terminal displayed on the display said position associated with a user at the further user terminal and control the video data received from said further user terminal to be displayed on said display in dependence on the position within the shared content associated with the user at the further user terminal.

According to a further aspect there is provided a method implemented at a user terminal the method comprising receiving video data from a further user terminal over a communications network during a video call with said further user terminal via a network interface of said user terminal displaying content shared with the further user terminal on the display receiving position data from the further user terminal via the network interface said position data indicating a position within the shared content associated with a user at the further user terminal controlling the video data received from said further user terminal to be displayed on said display to overlay said displayed content in dependence on the position within the shared content associated with the user at the further user terminal.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

The user terminal executes a communication client application provided by a software provider associated with the communication system . The communication client application is a software program executed on a local processor in the user terminal . The communication client application comprises the communications module referred to above. The communication client application performs the processing required at the user terminal in order for the user terminal to transmit and receive data over the communication system . The communication client application executed at the user terminal may be authenticated to communicate over the communication system through the presentation of digital certificates e.g. to prove that user is a genuine subscriber of the communication system described in more detail in WO 2005 009019 .

The user terminal may correspond to the user terminal . The user terminal executes on a local processor a communication client application which corresponds to the communication client application executed at the user terminal . The communication client application at the user terminal performs the processing required to allow the user to communicate over the network in the same way that the communication client application at the user terminal performs the processing required to allow the user to communicate over the network . The user terminals and are end points in the communication system. shows only two users and and two user terminals and for clarity but many more users and user devices may be included in the communication system and may communicate over the communication system using respective communication clients executed on the respective user devices as is known in the art.

Reference is now made to which illustrates a process of a method performed at the user terminal whilst a video call is being conducted between the first user terminal and the second user terminal .

During the video call between the first user terminal and the second user terminal at step S first user terminal receives via the network interface encoded video data transmitted from the second user terminal frames of image data captured by the camera of the second user terminal over the network . The I O layer of the communication client application executed on the first user terminal receives the incoming encoded video stream and decodes the encoded video stream. The client engine controls the client user interface layer to display the decoded video data to the first user via the user interface of the client displayed on display .

During the video call between the first user terminal and the second user terminal the first user terminal may also receive via the network interface encoded audio data transmitted from the second user terminal captured by the microphone of the second user terminal over the network . The I O layer of the communication client application executed on the first user terminal receives the incoming encoded audio data and decodes the encoded audio data for output to speaker .

At step S the content sharing module displays media content that is shared between the first user terminal and the second user terminal on the display of the first user terminal .

At step S the content sharing module receives position data from the second user terminal via the network interface the position data indicating a position within the shared media content associated with the second user at the second user terminal .

At step S the communication client application executed on the first user terminal controls the video data received from the second user terminal to be displayed on the display of the first user terminal in dependence on the position in the shared content of the second user at the second user terminal .

The process is now described in more detail with reference to by way of example a number of illustrative embodiments.

In one embodiment the communication client application executed on the CPU of the first user terminal may comprise the content sharing module . In a screen sharing context the first user terminal may act as a sharer terminal in this example the content sharing module enables an image screen capture of the display of the first user terminal to be transmitted to a viewer terminal i.e. the second user terminal . The first user terminal may alternatively act as a viewer terminal in this example the content sharing module enables an image screen capture of a display at the sharer terminal i.e. second user terminal to be received and displayed on the display of the first user terminal . When the image displayed at the sharer terminal is changed then those changes are received at the viewer terminal and the image displayed on the display at the viewer terminal can be updated accordingly to reflect the changes. When only certain areas of the image are changed at the viewer terminal then screen rectangles representing those areas in need of updating are received at the viewer terminal.

During a video call between the first user terminal and the second user terminal the first user terminal receives via the network interface video data transmitted from the second user terminal step S .

During the video call the second user makes an appropriate selection to display a photograph on the display of the second user terminal and selects to the share the contents of his screen by making an appropriate selection via the user interface of the communication client application executed on the second user terminal . Thus in this example the first user terminal acts as a viewer terminal .

In response to this selection the image of the photograph screen capture of a display at the second user terminal is transmitted to the first user terminal . The photograph may be stored locally in memory on the second user terminal in which case the photograph is transmitted from the second user terminal to the first user terminal . Alternatively the photograph may be stored on a computing device for example a server in the communication network in which case the photograph is transmitted from the computing device to the first user terminal .

At step S the content sharing module displays the photograph on the display of the first user terminal as shown in .

At step S the content sharing module receives position data from either the second user terminal or one or more computing devices in the communication network via the network interface . The position data indicates a position within the photograph that the second user is interacting with i.e. the second user s place in the shared media content . The content sharing module supplies the position data to the communication client application executed on the first user terminal .

A screen image displayed on the display of the second user terminal is made up of a number of pixels the number of pixels used to represent the screen image is dependent on the resolution of the display of the second user terminal the number of pixels in each dimension that can be displayed . Each pixel has an x coordinate and a y coordinate where x refers to the distance along the horizontal axis from a reference point and y refers to the distance along the vertical axis from the reference point.

The interaction with the photograph by the second user may be the second user moving the position of a cursor displayed on the display of the second user terminal over the displayed photograph the position of which is controlled by the second user moving a mouse or other input device such as the keypad . The position of a cursor often termed a cursor hot spot can be expressed by an x coordinate and a y coordinate of a pixel of a screen image that is displayed on a display. Typically the hot spot is the focal point of the cursor. For example typical hot spots are the pixel at the tip of an arrow shaped cursor and the pixel in the middle of a crosshair shaped cursor. In this example the position data comprises an x coordinate and a y coordinate indicating the position of the cursor that is displayed on the display of the second user terminal .

The interaction with the photograph by the second user may be the second user physically touching the display of the second user terminal corresponding to an area of the photograph in the case that the display comprises a touch screen. It will be appreciated that the area of the display touched by the second user will typically correspond to a plurality of pixels of the screen image displayed on the display . In this example the position data may comprise for example x y coordinates of the plurality of pixels or an x coordinate and a y coordinate of a pixel determined to be in the centre of the plurality of pixels.

It will be appreciated by persons skilled that a positioning mechanism based on pixels co ordinates is just one example of how to indicate a position within shared content that a user is interacting with. Embodiments of the present disclosure extend to other positioning mechanisms known in the art which convey positions in content. For example the shared the content might have its own model like a Microsoft Excel spreadsheet where each box has its own reference in this example the position data mat indicate the box which a user is interacting with rather than screen pixels.

If the resolution of the displays of the first user terminal and the second user terminal are different the position data may additionally comprise the resolution of the display of the second user terminal . It will be appreciated that this ensures that the content sharing module is able to accurately determine the position within the photograph that the second user is interacting with.

At step S the communication client application executed on the first user terminal controls the video data received from the second user terminal to be overlaid on top of the photograph displayed on the display of the first user terminal as shown in . The video data received from the second user terminal is displayed using the position data at a position on the display to indicate where the second user is interacting with the photograph i.e. to indicate the second user s place in the shared media content .

If the position within the photograph that the second user is interacting with changes i.e. the second user moves the position of the cursor displayed on the display of the second user terminal or touches a different area of the touch screen then the communication client application executed on the first user terminal moves the displayed video data received from the second user terminal accordingly to indicate this change in the area of the photograph that the second user is interacting with.

Whilst only two user terminals have been shown in for simplicity it will be appreciated that a video call maybe conducted between more than two users using respective user terminals and media content may be shared between these plurality of user terminals and principles of the present disclosure extend to such scenarios. For example if a video call is conducted between the first user at the first user terminal the second user at the second user terminal and two additional users i.e. a third user at a third user terminal and a fourth user at a fourth user terminal . In accordance with principles of the present disclosure as shown in received video data from users and may be displayed on the display of the first user terminal in dependence on the respective positions within the shared media content associated with users and .

In other embodiments a separate application executed on the CPU to the communication client application may comprise the content sharing module . Data is exchanged between the communication client application and the separate application to enable the communication client application and the separate application to communicate with each other. The communication client application and the separate application may each comprise an application programming interface API to facilitate this data exchange.

For example a collaborative workspace application executed on the CPU of the first user terminal may comprise the content sharing module . In this embodiment the content sharing module allows users of the communication system to work together i.e. collaborate on a document or other data structure as part of a collaborative authoring process. The data structure may originate for example from a word processing application a presentation application a spreadsheet application etc. The content sharing module on the first user terminal is configured to display an original data structure on the display . The content sharing module may access the original data structure from local storage on the first user terminal or from one or more computing devices in the communication network or from the second user terminal . Any modification to the original data structure by either the first user at the first user terminal or the second user at the second user terminal is presented by the content sharing module of the first user terminal on the display . The application comprising the content sharing module may be a dedicated collaborative workspace application as described above or may be an application to which collaborative features have been added e.g. a web browser .

During a video call between the first user terminal and the second user terminal the first user terminal receives via the network interface video data transmitted from the second user terminal step S . During the video call the content sharing module on the first user terminal displays the presentation on the display of the first user terminal step S as shown in .

At step S the content sharing module receives position data from either the second user terminal or one or more computing devices in the communication network via the network interface . The position data indicates a position within the presentation that the second user is interacting with. Example types of interaction are described above with reference to . The position data may comprise coordinates of at least one pixel as described above with reference to . The content sharing module supplies the position data to the communication client application executed on the first user terminal .

At step S the communication client application executed on the first user terminal controls the video data received from the second user terminal to be overlaid on top of the presentation displayed on the display of the first user terminal as shown in . The video data received from the second user terminal is displayed using the position data at a position on the display to indicate where the second user is interacting with the presentation i.e. to indicate the second user s place in the shared media content .

Whilst shows the video data received from the second user terminal being displayed above a text cursor where the second user is editing the presentation this is merely example. As the second user edits the presentation using the second user terminal the communication client application executed on the first user terminal moves the displayed video data received from the second user terminal accordingly to indicate the change in the area of the presentation that the second user is interacting with.

In another embodiment a gaming application executed on the CPU of the first user terminal comprises the content sharing module . In this embodiment the gaming application enables users of the communication system to share a gaming experience of a video game. For example the first user at the first user terminal may share a gaming experience of a video game with the second user at the second user terminal . The content sharing module on the first user terminal alters the display of the shared gaming experience on the display of the first user terminal in response to detecting input selections on the keypad of a gaming controller by the first user at the first user terminal . The content sharing module is also configured to receive gaming data from the second user terminal or one or more computing devices gaming servers in the communication network in response to input selections on the keypad of a gaming controller by the second user at the second user terminal . The content sharing module alters the display of the shared gaming experience on the display of the first user terminal in response to receiving this gaming data. That is the shared gaming experience is reflected on the displays of both the first user terminal and the second user terminal .

Whilst the video game content is being displayed on the display of the first user terminal step S a video call between the first user at the first user terminal and the second user at the second user terminal may be conducted. During the video call between the first user terminal and the second user terminal the first user terminal receives via the network interface video data transmitted from the second user terminal step S .

At step S the content sharing module receives position data from either the second user terminal or one or more computing devices in the communication network via the network interface . The position data indicates a position within the video game content that the second user is interacting with. The content sharing module supplies the position data to the communication client application executed on the first user terminal .

Input selections on the keypad of a gaming controller by the second user at the second user terminal may be used to interact with the video game content by for example moving an in game representation of the second user for example a character in the video game. The position data may comprise information pertaining to the position of the in game representation of the second user in the video game.

At step S the communication client application executed on the first user terminal controls the video data received from the second user terminal to be overlaid on top of the video game content displayed on the display of the first user terminal as shown in . The video data received from the second user terminal is displayed using the position data at a position on the display to indicate where the second user is interacting with the video game content i.e. to indicate the second user s place in the shared media content .

For example the communication client application executed on the first user terminal may control the video data received from the second user terminal to be overlaid on top of the video game content in dependence on the position of the in game representation of the second user in the video game this is shown in . As the second user moves the in game representation of the second user in the video game the communication client application executed on the first user terminal moves the displayed video data received from the second user terminal accordingly to indicate the change in the area of the video game content that the second user is interacting with.

In a further embodiment a mapping application executed on the CPU of the first user terminal comprises the content sharing module . In this embodiment the content sharing module is configured to display map data and indicate the geographical position of users of the communication system . The content sharing module on the first user terminal is configured to receive map data and location information of the second user terminal from the second user terminal or one or more computing devices map servers in the communication network . This enables the content sharing module to indicate the geographical position of the second user terminal to the first user at the first user terminal .

During a video call between the first user terminal and the second user terminal the first user terminal receives via the network interface video data transmitted from the second user terminal step S . During the video call the second user may select to send their geographic position to the first user terminal over the communication network during the video call. The second user may make such a selection in the user interface of the communication client executed on the second user terminal using an input device of the second user terminal .

Upon the second user selecting to send their geographic position to participants in the video call i.e. the first user terminal during the video call. The communication client executed on the second user terminal requests location information from a location determination module on the second user terminal . Upon receiving this request the location determination module on the second user terminal determines the location of the second user terminal .

The location determination module on the second user terminal uses geographic location technology for determining the location of the second user terminal in terms of geographic position relative to the surface of the earth for example using a satellite based positioning system such as GPS Global Positioning System including potential variants such as assisted GPS or differential GPS GLONASS Global Navigation Satellite System or Galileo and or trilateration or more generally muiltilateration relative to a plurality of different wireless base stations or access points having known locations and or a technique based on detecting signal strength relative to a known base station or access point or another known method.

The location determination module supplies this location information to a mapping application executed on the second user terminal . The location information may comprise a longitude and latitude of the second user terminal . The location information may additionally comprise an altitude of the second user terminal .

The mapping application executed on the second user terminal transmits the location information with a request for map data via the network interface to a mapping server. The mapping server stores a large set of pre generated map tile images covering the entire globe each map tile has a z coordinate describing its zoom level and x and y co ordinates describing its position. For each zoom level there is a predetermined number of map tile images to cover the entire globe whereby the greater the zoom level the greater the number of predetermined number of map tile images are required to cover the entire globe. A single map tile at a lower zoom level illustrates a larger geographic area than a single map tile at a higher zoom level. The mapping server determines based on the received location information a subset of map tile images of the large set of pre generated map tile images stored by the mapping server.

At step S the content sharing module on the first user terminal receives the map data a subset of map tile images via the network interface and displays the map data on the display of the first user terminal as shown in . At step S the content sharing module receives position data the location information . The position data indicates a geographical position within the map data of the second user terminal . The second user s position within the map data moves as the second user moves their geographical position.

The content sharing module on the first user terminal may receive the map data and the position data from one or more computing devices in the communication network for example the map server or from the second user terminal . The content sharing module supplies the position data to the communication client application executed on the first user terminal .

At step S the communication client application executed on the first user terminal uses the received position data to control the video data received at step S to be displayed in a position of the display to provide a visual indication of the geographical location of the second user terminal with reference to the displayed map . That is by its very nature the map displayed by the content module displays a plurality of geographical locations and the communication client application executed on the first user terminal controls the video data received from the second user terminal to be displayed on the display to provide a visual indication of the location of the second user terminal at one of the plurality of locations.

Thus both geographical location information and video data are simultaneously displayed on the first user terminal to visually indicate the location of the second user terminal from which the video data is received. This embodiment enables all participants in a video call keep eye contact and continue visual communication whilst at the same time clearly communicating each other s geographic location and movements.

In the video data received from the second user terminal is shown in a window . That is window displays the real time video data captured at the second user terminal and transmitted to the first user terminal over the network . Alternatively as shown in the video data received from the second user terminal may be shown enclosed within a border the border comprising a pointer to provide a more accurate indication of the location of the second user terminal .

The camera on the second user terminal may comprise a front facing camera and a rear facing camera. During the video call the second user may select to switch the video capture between the front facing camera and the rear facing camera. Responsive to this camera switch the video data received from the second user terminal may switch from being a view of the second user to a view of the scene surrounding the second user .

It will be appreciated from the above that embodiments of the present disclosure described above let all participants in a video call keep eye contact and continue visual communication whilst at the same time viewing and being deeply immersed in the shared media content. In embodiments of the present disclosure a user can move their location in the shared content and this results in the video data received from that user to move accordingly on the displays of other users in a video call with the user. The user can freely move their position in the shared content in ways that aren t scripted or predetermined thus the video data received from that user also moves accordingly on the displays of other users in a video call with the user in ways that aren t scripted or predetermined.

Whilst show the video data received from the second user terminal being displayed by the communication client application such that it fully overlays i.e. is on top of the displayed shared media content. In other embodiments a portion of or the entire video data received from the second user terminal may not be displayed on top of the displayed shared media content. For example the shared media content may be displayed in the centre of the display and the video data received from the second user terminal may be displayed partially or completely outside the edges of the shared media content and a suitable marker or pointer may be displayed to indicate the position within the shared media content associated with the second user at the second user terminal .

In the embodiments described above the communication client executed on the first user terminal may be configured to control the display of the video data received from the second user terminal based on the audio data received from the second user terminal during the video call.

For example in response to detecting that the second user at the second user terminal has stopped speaking the communication client executed on the first user terminal may reduce the size of the displayed video data received from the second user terminal the representation of the second user is reduced such that the display of the video data received from the second user terminal requires less physical space on the display .

Alternatively or additionally in response to detecting that the second user at the second user terminal has stopped speaking the communication client executed on the first user terminal may increase the transparency of the displayed video data received from the second user terminal the representation of the second user is reduced .

In both examples above the first user is able to view the shared media content more easily when the video data received from the second user terminal is overlayed over the shared media content. This is advantageous when the second user at the second user terminal has stopped speaking and it is more desirable for the first user to view the shared media content rather than the video data received from the second user terminal .

In the embodiments described above the communication client application executed on the first user terminal may display the video data received from other users in the video call in video windows displayed on the display of the first user terminal . In addition to the above examples the communication client application may apply other aesthetic effects to the received video and or video windows. For example the communication client application may blur the boundaries of the displayed video windows to make the video window merge more with the shared content.

In the embodiments described above the communication client application executed on the first user terminal may overlay selectable buttons for the first user to select using an appropriate input device during the video call. The selectable buttons may comprise a button to end the video call to mute audio such that no audio data received during the video call is output from the speaker to control the volume of audio output from the speaker and other functionality related to the video call. By overlaying the selectable buttons on top of the shared media content the size of the displayed shared media content is maximised which is advantageous on mobile devices with limited display size. Alternatively a portion of or all of the selectable buttons may not be displayed on top of the displayed shared media content. For example the selectable buttons may be displayed outside the edges of the displayed shared media content.

The video data displayed by the communication client application on the display may be a selectable input. That is the first user may select the displayed video data using an appropriate input device of the first user terminal .

In response to the first user selecting the displayed video data the communication client application may increase the size of the displayed video data. That is in response to the communication client application detecting selection of the displayed video data the communication client application may utilise a larger physical portion of the display to display the received video data i.e. the communication client application executed on the first user terminal zooms in on the displayed video data. This enables the first user to be provided with a larger view of the received video data. This is advantageous when it is more desirable for the first user to view the received video data received from the second user terminal rather than the shared media content.

In response to the first user selecting the displayed video data the communication client application may provide the user with one or more selectable options pertaining to the functionality provided by the communication client application. The one or more selectable options may be selected by the first user using an appropriate input device on the first user terminal .

The one or more selectable options may include an option to view profile information of the second user to send the second user a Short Message Service SMS message to send the second user an IM message to send the second user a data file to view IM conversation history between the first user and the second user etc. It will be appreciated that these examples are used herein to illustrate the concept and further selectable options may be provided the communication client application that are not described herein.

The steps shown separately in may or may not be implemented as separate steps. Furthermore the steps S S and S may not be necessarily implemented in the order shown in and may be implemented in an alternative order. For example in the embodiment described above with reference to the first user and the second user may be conducting a video call using their respective terminals and then decide to start working collaboratively on some shared media content. Alternatively the first user and the second user may be working collaboratively on some shared media content and then decide to conduct a video call.

Whilst only two user terminals have been shown in for simplicity it will be appreciated that a video call maybe conducted between more than two users using respective user terminals and media content may be shared between these plurality of user terminals and principles of the present disclosure extend to such scenarios. Received video data of a plurality of users may be displayed on the display of the first user terminal in dependence on the respective positions within the shared media content associated with the plurality of users. Whilst this has been explained above with reference to the screen share embodiment shown in this applies to all other embodiments described herein.

The communication client application executed on the first user terminal is configured to transmit captured video data of the first user captured using camera to other user terminals of other users in the video call. In the embodiments described above during the video call the communication client application executed on the first user terminal may display the captured video data of the first user on the display of the first user terminal . Furthermore the content sharing module on the first user terminal may be configured to detect a position within the shared media content associated with the first user and communicate this to the communication client application executed on the first user terminal . The content sharing module supplies this position data to the communication client application executed on the first user terminal .

The communication client application executed on the first user terminal may control the captured video data of the first user to be displayed on the display of the first user terminal in dependence on the position in the shared content of the first user i.e. where the first user is interacting with the shared media content. This is shown for example in in the context of the shared gaming experience wherein the captured video data of the first user is overlaid on top of the video game content in dependence on the position of the in game representation of the first user in the video game. Whilst this has been explained above with reference to the shared video game experience embodiment shown in this applies to all other embodiments described herein.

Generally any of the functions described herein can be implemented using software firmware hardware e.g. fixed logic circuitry or a combination of these implementations. The terms module functionality component application and logic as used herein generally represent software firmware hardware or a combination thereof. In the case of a software implementation the module functionality or logic represents program code that performs specified tasks when executed on a processor e.g. CPU or CPUs . The program code can be stored in one or more computer readable memory devices. The features of the techniques described below are platform independent meaning that the techniques may be implemented on a variety of commercial computing platforms having a variety of processors.

For example the user terminals may also include an entity e.g. software that causes hardware of the user terminals to perform operations e.g. processors functional blocks and so on. For example the user terminals may include a computer readable medium that may be configured to maintain instructions that cause the user terminals and more particularly the operating system and associated hardware of the user terminals to perform operations. Thus the instructions function to configure the operating system and associated hardware to perform the operations and in this way result in transformation of the operating system and associated hardware to perform functions. The instructions may be provided by the computer readable medium to the user terminals through a variety of different configurations.

One such configuration of a computer readable medium is signal bearing medium and thus is configured to transmit the instructions e.g. as a carrier wave to the computing device such as via a network. The computer readable medium may also be configured as a computer readable storage medium and thus is not a signal bearing medium. Examples of a computer readable storage medium include a random access memory RAM read only memory ROM an optical disc flash memory hard disk memory and other memory devices that may use magnetic optical and other techniques to store instructions and other data.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

