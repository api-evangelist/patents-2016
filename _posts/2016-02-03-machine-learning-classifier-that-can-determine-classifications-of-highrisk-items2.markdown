---

title: Machine learning classifier that can determine classifications of high-risk items
abstract: A machine learning classifier system includes a data set processing subsystem to generate a training set and a validation set from multiple data sources. Classifier hardware induces a classifier according to the training set, and tests the classifier according to the validation set. A buffer connected to the classifier hardware stores data objects to be classified, and a register connected to the classifier hardware stores outputs of the classifier, including classified data objects.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09600779&OS=09600779&RS=09600779
owner: ACCENTURE GLOBAL SOLUTIONS LIMITED
number: 09600779
owner_city: Dublin
owner_country: IE
publication_date: 20160203
---
This patent application is a continuation in part of U.S. patent application Ser. No. 13 491 146 filed Jun. 7 2012 which claims priority to U.S. provisional patent application Ser. No. 61 494 839 filed on Jun. 8 2011 which are both incorporated by reference in their entireties. This patent application is also a continuation in part of U.S. patent application Ser. No. 14 989 572 filed Jan. 6 2016 which is a continuation of U.S. patent application Ser. No. 13 491 146 filed Jun. 7 2012 which claims priority to U.S. provisional patent application Ser. No. 61 494 839 all of which are incorporated by reference in their entireties.

This invention was made with government support under contract number SP4701 07 A 001 awarded by the Defense Logistics Agency. The government has certain rights in the invention.

Embodiments of the present application are directed to artificial intelligence type computers and digital data processing systems and corresponding data processing methods and products for emulation of intelligence. The embodiments include supervised machine learning classifiers.

Machine learning evolved from the study of pattern recognition and computational learning theory in artificial intelligence. Machine learning explores the study and construction of algorithms that can learn from and make predictions on data. Such algorithms operate by building a machine implemented model from example inputs in order to make data driven predictions or decisions rather than following strictly static program instructions.

One type of machine learning involves supervised learning based on a training set as part of a classification process. Examples of machine learning algorithms used for classification include the well known Na ve Bayes and C4.5 algorithms or a so called stacked combination of two or more such algorithms. The machine learning algorithm examines the input training set and the computer learns or generates a classifier which is able to classify a new document or another data object under one or more categories. In other words the machine learns to predict whether a document or another type of data object usually provided in the form of a vector of predetermined attributes describing the document or data object belongs to a category. When a classifier is being trained classifier parameters for classifying objects are determined by examining data objects in the training set that have been assigned labels indicating to which category each object in the training set belongs. After the classifier is trained the classifier s goal is to predict to which category an object provided to the classifier for classification belongs.

A technical problem associated with classifiers is that in practice the classifiers that assign objects to categories make mistakes. For example classifiers may generate false positives i.e. instances of mistakenly assigning an object to a category and false negatives i.e. instances of mistakenly failing to assign an object to a category when the object belongs in the category. These mistakes are often caused by deficiencies of the training set. For example typically the larger the training set the better the classification accuracy. In many instances large training sets may be unavailable. Also the accuracy of the labeled data in the training set impacts the classification accuracy. In some cases the data in the training set may not be correctly labeled causing the classification accuracy to be compromised.

For simplicity and illustrative purposes the principles of the embodiments are described by referring mainly to examples thereof. In the following description numerous specific details are set forth in order to provide an understanding of the embodiments. It will be apparent however to one of ordinary skill in the art that the embodiments may be practiced without limitation to these specific details. In some instances well known methods and or structures have not been described in detail so as not to unnecessarily obscure the embodiments.

According to embodiments advanced techniques including data mining and data transformation techniques are used to generate accurate training sets for machine learning operations using data objects provided by multiple data sources. For example the data objects from each of the data sources are analyzed to estimate whether the data objects can be used to make accurate predictions. For example quality of the data objects periodicity of refresh of the data objects data scarcity etc. are evaluated to help determine if data objects are amenable to accurate predictions. In addition these aspects of data objects can be used for creating training sets. Also information from multiple data sources may be used to supplement data in the data objects for the training set. Furthermore embodiments can employ different techniques for creating a training set including techniques that can create a quality training set when data scarcity occurs. Improvements to the quality and accuracy of training sets facilitate improved performance of classifiers generated from the training sets For example a classifier created from a high quality training set may produce more accurate classification of data objects into categories than a classifier created using a lower quality training set.

Also according to an embodiment an ensemble classifier may be generated to classify data objects. The ensemble classifier is generated from multiple machine learning functions and may produce more accurate predictions than using a classifier generated from a single machine learning function.

The information received from the data sources may include data objects. A data object for example may be information to be classified or may be information that can be used for classification such as metadata describing a data object to be classified. A data object may be represented by a vector of variables also referred to as attributes and a value for each variable that describes the data object. Examples of data objects can include but are not limited to numbers files images documents etc. By way of example whereby the data object is a document the document may be classified into a category such as whether the document is a health document or whether the document is a financial document. In another example a data object may comprise a health record for a patient and the health record may be classified as to whether the patient is at risk for a particular disease. In yet another example the data object may be procurement data used for procuring items services etc. For example the data object may represent a bid to supply items and the bid may be classified as to whether the bid is a high risk bid as is further described below. The classifiers may classify whether a bid includes a high risk price a high risk supplier or a high risk item. The examples described above and elsewhere herein are non limiting. For example the classifier generation system may be used to generate classifiers to classify other types of data objects.

The data set processing subsystem generates data sets such as training sets and validation sets . A data set is a set of multiple data objects. A training set is a data set of data objects used for inferring a function for classification i.e. a classifier . The training sets may include supervised training sets that include labeled data objects which are used by one or more machine learning functions to generate the classifiers . Each of the labels for the data objects can indicate whether the respective data object is classified under a particular category. Labels may be manually generated may be specified in historic data or may be generated automatically.

In an example during a training phase the training sets are input into the machine learning functions . A machine learning function being used to train a classifier adjusts parameters in the classifier in order that it makes accurate predictions for the training set . The machine learning functions may include a known induction algorithm such as Naive Bayes C4.5 decision trees Support Vector Machines logistic regression step wise logistic regression chi squared tests for predictive variable selection and others. Accordingly inputting a training set to a machine learning function generates a classifier such as one of the classifiers trained to classify the data objects into a category associated with the labels in the training set. After being trained the classifiers are used to classify data objects without labels such as data objects .

The data set processing subsystem may perform data mining and data transformation techniques on data objects received from the data sources to generate the training sets to induce more accurate classifiers. The data set processing subsystem may generate a data object from data received from multiple data sources. A data object may be comprised of multiple variables which in turn may have been provided by multiple data sources. The data set processing subsystem may collect and store the variables for each data object to build the training data sets and validation data sets . A subset of the variables may be selected as predictive variables to induce a classifier.

According to an example the data set processing subsystem may perform data partitioning filtering data transformation to create data objects from multiple data sources. Staging tables may be used for the data processing performed by the data set processing subsystem . In an example shown in staging tables may be used to create the data objects which are subsequently loaded into database tables which may be used to generate the training and validation data sets and . For example data objects to be classified may represent vendors that supply items for use in satisfying a procurement request. For example a training set of the training sets is generated to train a classifier of the classifiers to classify vendors as high risk or not. High risk may be based on whether a vendor is likely to provide counterfeit or otherwise non conforming items or not. Each data object may be comprised of multiple variables describing the vendors.

In an example data from a reliable data source is loaded into staging tables . For example data source may be associated with an internal procurement system having a data repository of historic procurement data captured for example over several years. Staging tables may include fields from the data repository of historic data including for example vendor name vendor identifier ID etc. Multiple fields of the historic data may be included in the staging tables . These fields may be supplemented by additional fields based on data retrieved from other ones of the data sources as is further described below.

Data partitioner may partition loaded data. For example a date range is selected such as the most recent six years of data and stored in a partition in the staging tables The data may be further partitioned to create validation data sets and to identify a subset of the partitioned data for example the most recent data e.g. data for the last 12 months which may include data objects to be classified.

The data set processing subsystem may include a query generator to generate queries to retrieve related data from other ones of the data sources . Examples of the retrieved related data are described below. For example the query generator may automatically generate a query using fields from the staging tables that are populated with data from the data source e.g. data from an internal system such as a procurement system or another trusted system . For example the query generator generates a query with vendor name and vendor ID for a specific vendor record in the staging tables and executes the query on other ones of the data sources . This may include interfacing with various data sources through an interface such as an application programming interface API to execute the query. The query results are received from the data sources and stored in the staging tables . Retrieved information may include demographic information such as address vendor codes industry codes credit score financial stress score debarment indicator criminal activity indicator compliance risk index number of total payments number of slow late and delinquent payments bankruptcy indicator number of employees lawsuits liens judgments and or other variables and or information describing the vendors. If the received data matches an existing field such as in terms of data type data range etc. the data is stored in an existing field otherwise the data is stored in a new field. Also new fields may be manually analyzed after being populated to determine whether the fields include relevant data and to assign a field name and field constraints to the field. Through the data retrieval process data objects are created for the vendors including multiple variables from multiple data sources and the data objects may be stored in the staging tables .

Filtering module and transformation module can filter and transform data objects in the staging tables for loading into the database tables . Filtering module may perform quality checks and may filter variables that may not be predictive. For example quality checks may be checking for null data or data outside field constraints and evaluating variables in the staging tables for data scarcity. Variables with a high rate of missing data or having no or little variation in value may be filtered e.g. removed and not loaded into the database tables . Next for variables with an acceptable rate of missing values and having an acceptable variation of values missing data may be populated with mean or median values for the variable depending upon the variable under consideration.

Variables from the staging tables may be transformed by the transformation module before loading into the database tables . Transformations may include executing a transformation function on a field before loading operation into the database tables is performed. A transformation function may convert data to be placed in the same field to the same unit such as a same unit of measurement a same currency a same lot size etc. combine fields into a single field create a new field or execute other operations on a field. In an example a variable is created for foreign electronics vendors that have an industry code for electronics and that have an address outside the United States. Another example of a transformation function may include applying an inflation cost adjustment to historic prices for present value calculations.

Also prior to loading the database tables from the staging tables the variables in the staging tables may be evaluated by a factor analysis module to identify relationships between the variables and to identify variables that may be used as predictive variables for a classifier. While strong correlations between predictive variables and a target variable e.g. the category being predicted are desired such high correlations between predictive variables themselves can be undesirable and can greatly affect the accuracy of the final classifier through multicollinearity. For example the factor analysis module determines the predictive variables that are highly correlated and performs a factor analysis process to mitigate their effects. In the process variables that are highly correlated with each other are combined into a single variable which can then be used by one or more of the machine learning functions to train a classifier without the consequences of multicollinearity as long as those factors do not correlate with other variables.

After the factor analysis process is performed by the factor analysis module the data from the staging tables is loaded into the database tables . The data for the data objects that is loaded into the database tables including the variables describing the data objects may be partitioned into the training sets and the validation sets . For example the data is divided into a training set and a validation set. The validation set is used to validate the classifier generated from the training set. For example the validation set includes data objects pre determined to be in particular categories and the trained classifier classifies the data objects in the validation set to determine whether the classifier correctly classifies the data objects into their particular categories. Regarding the training set data objects in the training set are labeled. For example if the data objects represent vendors the labels may indicate whether the vendors are high risk or not high risk. In an example the machine learning function trained according to the training set is step wise logistic regression which can be used to generate one of the classifiers . The step wise regression can determine relationships between predictive variables from the training set and the target variable being predicted such as whether a vendor is a high risk vendor. Following this operation if the classifier is successful at predicting the target variable the training and test sets are combined and the classifier is run again on the entire population of vendors in the combined training and test sets. The final classifier is the classifier that is deemed successful at classifying the combined training and test sets.

Multiple classifiers may be created to classify different data objects into various categories. The staging tables and database tables may include tables to store data for different types of data objects. For example vendor data objects may be stored in one set of tables and data objects representing items to be procured may be stored in another set of tables and so on. Training and validation sets may be generated for each of the classifiers for training and testing. Each of the classifiers may classify data objects into different categories. For example a classifier may classify data objects representing vendors or suppliers where the classifications indicate whether the vendors or suppliers are high risk or not. In another example a classifier may identify items to be procured as high risk or not. Price risk classifiers may also be generated.

Processes described with respect to may be performed to generate training and validation sets for a classifier to classify data objects for items to be procured as high risk or not. For example the data from an initial data set from data source is partitioned. Data objects for general merchandise may be removed since those items may be procured differently than other items such as items prone to being high risk. Data objects may be further filtered and transformed and factor analysis may be performed. Data objects indicative of a high risk item are labeled for the training set. Examples of the variables for the data objects representing items to be procured may include number of instances an item was purchased over the past six years an indicator of an item s criticality and whether the item had a diminishing manufacturing source etc.

As discussed above an ensemble classifier may be generated to classify data objects. The ensemble classifier is a classifier generated from multiple machine learning functions and may obtain more accurate predictions than using a classifier generated from a single machine learning function.

As shown in a decision tree may be generated through supervised learning. For example training set which may be one of the training sets is applied to the decision tree function to generate the decision tree . The training set may include predictive variables and the target variable. The decision tree function may be one of the machine learning functions . Decision trees compatible with embodiments disclosed herein may be generated using known techniques and or software applications such as a commercially available a machine learning software product. For example R is an open source suite of software facilities that include machine learning functions such as one or more of the machine learning functions and tools for performing other machine operations described herein. R is a GNU project which was developed at Bell Laboratories now Lucent Technologies by John Chambers and colleagues. R includes a decision tree library which may be used for the decision tree function . Other machine learning tools may also be used to generate the decision tree . For example open source software by WEKA created by Mark Hall Eibe Frank Geoffrey Holmes Bernhard Pfahringer Peter Reutemann Ian H. Witten 2009 and SAS Enterprise Miner are machine learning software that include machine learning functions and tools for performing other machine operations described herein.

The training set may be a supervised training set including predictive variables and the labeled target variable e.g. an indication of whether the item being procured was a high risk item or not . The training set may be generated from historic procurement data. Some examples of the predictive variables may include an amount of item purchased for each procurement a quantity purchased in each procurement a production lead time for the supplier to provide the item a commonality of a unit in the bid specifying the amount of the item to be supplied the type of item e.g. microprocessors may be considered higher risk than a fastener geographic location of manufacturing of the item the use of the item e.g. military versus civilian past supplier history with respect to providing items etc. Although not shown in the decision tree may be validated with a validation set such as described with respect to .

The decision tree may identify ranges of values for continuous predictive variables e.g. predictive variables which have values that lie on a continuum such as procurement lead time that are predictive of the target variable and the decision tree may identify binary values for categorical predictive variables e.g. predictive variables which have values that are binary such as whether an item was procured for military use or not that are predictive of the target variable. The decision tree maps the identified ranges of values for the continuous predictive variables and the identified binary values for the categorical predictive variables to conclusions about the target variable e.g. high risk or not . Embodiments may be configured to allow the mapping to be logically represented in a tree structure. Also the decision tree function may determine p values for the predictive variables which indicate a level of significance for each predictive variable in predicting the target variable. The p values may be determined by the machine learning software used to determine the decision tree . In an embodiment the decision tree may be generated over multiple iterations whereby different factors are changed such as the predictive variables used in the decision tree number of stages in the decision tree etc.

From the decision tree the predictive variables in the decision tree are analyzed for multicollinearity at . Multicollinearity means that one variable can be linearly predicted from another variable. The multicollinearity analyses performed at identifies collinearity of the predictive variables. The multicollinearity analyses performed at may include the analysis similar to or the same as the factor analysis performed by the factor analysis module described above. Examples of machine learning software described above may include tools for determining multicollinearity of predictive variables. For example R includes a library for identifying collinearity among predictive variables through variance inflation factors VIF . A VIF for a single predictive variable is obtained using the r squared value of the regression of that variable against all other predictive variables. The higher the VIF value the higher the collinearity and a predictive variable with a high VIF value e.g. 5 10 may be removed. Accordingly from the multicollinearity analysis performed at a set of predictive variables is determined that includes predictive variables from the decision tree whereby the collinear predictive variables are removed.

The set of predictive variables may be provided for additional predictive strength analysis at . For example Chi square tests are conducted on categorical predictive variables to assess and reaffirm strength of the categorical predictive variables from the set . T tests may be conducted to assess and reaffirm strength of the continuous predictive variables from the set . These tests may determine the p values of the predictive variables in the set and the predictive variables having p values less than a threshold e.g. 0.05 may be removed from the set to create a set of the predictive variables which may be estimated to have a level of significance e.g. a highest level of significance for predicting the target variable.

Transformations may be performed on the set of the predictive variables at . Transformations may include transforming predictive variables in the set into new predictive variables such as through stepwise regression. For example assume the decision tree identifies ranges of values for the production lead time predictive variable as follows less than 179 days is high risk greater than 179 days but less than 280 days is not high risk and greater than 280 days is high risk. The transformations may assess whether to convert this into two predictive variables such as one predictive variable for less than 179 days or greater than 280 days for high risk and one predictive variable for not high risk between 179 and 280 days or whether to keep it as. Also after the transformations are performed multicollinearity may be analyzed again such as performed at to remove collinear predictive variables and a set of predictive variables may be generated from the set which includes the transformed variables and which does not include predictive variables determined to be collinear.

The ensemble classifier is generated and validated using the predictive variables from the set of predictive variables . For example a training set which may be one of the training sets and a validation set which may be one of the validation sets include the set of predictive variables . The training set is applied to machine learning function which may be one of the machine learning functions to generate the ensemble classifier . The ensemble classifier is tested with the validation set . The generation and testing may be an iterative process. In an example the machine learning function is a logistic regression machine learning function such as a Bernoulli Naive Bayes logistic regression function.

Other types of data objects and classifiers and models may be generated by the system . For example should cost models may be generated to identify costs associated with transactions as is further discussed below. and which is described below are described with respect to using staging and database tables for the dataset processing. In other embodiments other storage structures may be used.

At data is retrieved from other ones of the data sources to supplement the historic data and stored in the staging table. For example a query is generated using data from one or more fields of historic data in the staging table to retrieve data from other data sources to supplement the historic data. At variables from the historic data in the staging table which may be fields in the staging table are filtered based on data scarcity and variation. For example variables with a high rate of missing data or having no or little variation may be removed.

At data in the staging table is transformed. For example one or more fields may be transformed according to predetermined transformation operations. A transformation function may convert to the same unit or combine fields into a single field or create a new field or execute other operations on a field. In an example a variable is created by combining information from other variables. At factor analysis is performed to determine multicollinearity between variables and identify variables that are highly correlated. At variables that are determined to be multicollinear are combined into a single variable or one variable is removed from the staging table.

At the data from the staging table is loaded into the database table. At historic data from the database table is divided into a training set and a validation set. The training set includes labeled data objects for supervised training of a classifier. Labels may be entered manually for each data object in the training set based on expert analysis. A label specifies whether the data object belongs to a particular category or not. The training set is input to one or more of the machine learning functions to train a classifier at . At the classifier is tested using one or more of the validation set and a combination of the validation set and the training set. After the classifier has been determined to be accurate at the classifier classifies data objects . For example the classifier receives data objects to be classified and generates a probability for each data object where the probability value indicates whether the data object is classified in a particular class or category.

The system discussed above may be used to generate classifiers to classify data objects for a variety of different categories. According to an embodiment the system is used to generate classifiers to classify different types of procurement data as high risk or not. For example an entity such as a government agency corporation etc. may acquire goods or services through a procurement process. The procurement process may encompass sending out a request for bids to supply goods or services and receiving bids from vendors or other organizations to supply the goods or services. High risk procurements may potentially represent a risk for fraud e.g. substituting an unauthorized product a counterfeit of a desired product etc. waste and abuse. For example a high risk procurement is a procurement having characteristics that meet certain criteria. The criteria may be related to identifying fraud abuse or general errors. A procurement is the acquisition of items which may include one or more goods or services. A typical procurement process includes accepting bids to supply items from one or more suppliers and selecting one or more bids for the procurement of the items. The procurement process may include posting a request for bids or proposals that provides a description of the items being procured and any constraints on the procurement.

The system may identify characteristics such as predictive variables of high risk procurements and develop classifiers to classify bids or aspects of bids as high risk using the predictive variables and or other information. The characteristics and their relationships can be quantified to generate classifiers for evaluating and grading bids for each procurement in order to identify one or more bids to accept for the procurement. The classifiers and scoring models can be incorporated into or used with a procurement system and ultimately into a computer implemented workflow for procurement that is used by procurement specialists and or leadership of entities making procurements. As a result entities acquiring goods or services through a procurement process can have visibility into high risk procurements early in the procurement process while there is still time to proactively react. Early detection of high risk items allows these bids to be rejected or remediated to significantly reduce or eliminate risk to the procuring entity. Also procurement request risk may be tracked as a metric using computer implemented embodiments disclosed herein. Other metrics may also be captured for each procurement when desired. Embodiments allow metrics and other information related to high risk and non high risk procurements to be archived and used for subsequent procurements. As a result embodiments become more accurate and effective at identifying high risk procurements over time thus allowing procuring entities to lower procurement costs while improving procurement quality and efficiency.

Business rules logistic regression and scoring criteria may be used for developing scoring models and or for scoring procurements. The output of the system may include scoring models including the classifiers a high risk file identifying high risk procurements e.g. high risk vendors high risk items high risk services etc. a procurement score file identifying scores for procurements and business intelligence metrics . The high risk procurements identified in the high risk file sent to the procurement system may continue to be evaluated in a workflow used by the procurement system before the procurement process is closed. For example procurements flagged as high risk may be given further analysis to determine whether they can be accepted or denied. The metrics may be displayed via a dashboard or provided to the procurement system for further evaluation.

Also scores in the procurement score file may include favorable e.g. good scores as well as unfavorable e.g. bad scores. These scores may be used to create or update scoring models or used for additional analytics. The scores may be comprised of multiple elements related to a procurement. Metrics may indicate where and what items are high risk and may include drill downs by item product line drill downs by contracting officers drill downs by contractors etc. to facilitate decision making by system . For example the metrics may be included in daily or periodic reporting of the scores to the user. The metrics may be used to identify trends that warrant further analysis such as whether a particular geographic region or procurement officer is associated with an unusually high number of high risk procurements.

The architecture includes an application service integration and communication layer a core and data repository . Data repository can include data structures storing procurement data on one or more storage devices. The application service integration and communication layer supports data collection from the data sources the procurement system and other systems and applications. The layer may also provide secure access with a customer portal which may allow users to log into the system to view data or perform other operations. The layer may utilize a full featured web services library to provide a connection for the customer portal to the system . Generally the layer provides a mechanism for interfacing with the different systems and web interfaces.

The layer may include APIs to communicate with the data sources the procurement system and other systems and applications. For example the layer receives data from the data sources the procurement system through APIs or other interfaces and may normalize the data for storage in data repository . Normalizing may include formatting according to predetermined schemas. For example the layer may map received data to schemas of data structures which may include tables in the data repository based on determined types and fields. Then the data may be stored in the tables in the data repository . The data repository may include a database comprised of the tables.

The information stored in the data repository may include model building data sets and validation data sets which may be determined from the procurement data or other data received at the system . Other stored information may include models generated by the system business rules for the models bid evaluation results evaluation capacities information describing procurements e.g. items being procured constraints for bids etc. and information from received bids. Data repository can store procurement related information over time to allow system to become more accurate over time. Since system can handle extremely high volumes of procurements the amount of information stored in data repository can become extremely large. As a result data repository can be implemented as a standalone or distributed repository and can used in conjunction with big data frameworks algorithms protocols etc.

The core performs operations and or functions of the system . For example the core may perform the methods described in connection with flowcharts included herein including processes for model building and bid evaluation.

The core may include a characteristics identifier module a model generator module a procurement risk analysis module and a dashboard . The characteristics identifier module identifies characteristics of high risk procurements. Machine learning such as neural networks logistic regression or other functions may be used to identify the characteristics. For example the characteristics may include predictive variables for generating the models including the classifiers . The predictive variables may be related to cost quantity industry specific characteristics etc.

The characteristics may further include should cost data tables that include information identifying how much an item should cost. A should cost table may include information about how much an item similar to an item being procured costs e.g. in ranges from low cost median cost and high cost . This information may be gleaned from the data sources which may include data obtained from other procurement organizations commercial databases historical pricing indices etc. Should cost data can further be organized or limited to regions such as a geographic region e.g. from a domestic organization or from organizations that do strategic sourcing across the globe . Costs may further vary by industry or other categories.

Another characteristic for comparison may be company location and production information for companies that are bidding on a procurement. In one example whereby the United States U.S. government is procuring items company data could be linked to Buy American Act decisions. For example if the company doesn t have primary production facilities in the U.S. then the company would likely have to sub contract out the work to a U.S. company or work the production into their facilities inside the United States. Other procurement rules may be identified to determine whether a company may have the characteristics to meet the criteria specified in the rules.

Network analysis could be used to identify companies that have close associations with companies that either have unscrupulous partner companies or represent potential conflicts of interest or other violations. For example network analysis may be used to identify companies that have violated the Foreign Corrupt Practices Act bribery or corruption or companies that have been accused of providing counterfeit goods. Network analysis may be performed by external providers or internal systems and can be performed using public and or private data. For example social networking data and or social network analytics can be used alone or in combination with other data such as past procurement data from a proprietary database to facilitate identifying vendors items or services that may be high risk.

Former bids and bid rules can also be incorporated as a component. For example rules can be built into the system that indicate that for buys of 20 000 or more if 2 or more bids are not received then it identifies the procurement as a high risk procurement that requires an audit operation before a procurement can be completed. For example a computer implemented audit can be trigger. In another embodiment a manual audit may be triggered. Former bids can be used to indicate another range of plausible dollar values for a procurement.

A review of previously identified high risk procurements produces a domain of potential rule based structures that can be utilized as rules for identifying high risk procurements. In machine learning or database mining activities these rule based structures may be applied in a decision tree based approach. For example these rules may be developed by the characteristics identifier module using one or more of the characteristics described above. The rules may be developed according to a model building data set or one of the training sets which may be received from one or more of the data sources and then tested on one of the validation sets . The scoring model may be generated based on the rules and the procurement risk analysis module uses the scoring model to score procurements and identify high risk procurements.

The model generator module generates the scoring models. Scoring models including the classifiers may be generated for different risk areas. The models may be generated using logistic regression business rules or other ones of the machine learning functions based on variables. The variables may be received from the data sources . For example logistic regression can be performed by a processor to build a multivariate model. For example predictive variables i.e. covariates are selected and a model is generated using the variables. A variable may be removed and the model refitted to determine if the new model differs from the old model. Detection of a difference between the new and old models may indicate the variable is considered important and is kept. This process is repeated until the variables are determined for the model. Embodiments can incorporate thresholds with respect to difference values between a new and old model so that variables are kept when a threshold value is satisfied. Examples of the models are further described below.

The dashboard may facilitate presenting information related to the bid evaluation. For example the procurement risk analysis module evaluates the received bids for a procurement based on the scoring models. Evaluation results and identification of high risk bids may be presented via one or more user interfaces such as dashboard displays provided by the dashboard . For example the dashboard may generate a graphical user interface GUI presented on a computer screen. The computer screen may be a display provided as an input output mechanism used in conjunction with system . The GUI may provide graphical illustrations of price risk supplier risk and item risk for bids based on the evaluation of the bids. Also the GUI may graphically illustrate scores for the bids and present information for the bids. The GUI may represent bid information such that bid information is selectable for drill downs to display additional information describing a risk profile for a given bid.

The computer system includes processor s such as a central processing unit application specific integrated circuit ASIC or other type of processing circuit input output devices such as a display mouse keyboard etc. a network interface such as one or more interfaces for connecting to a Local Area Network LAN a wireless 802.11x LAN a 7G or 4G mobile WAN or a WiMax WAN or other type of network and a computer readable medium . Each of these components may be operatively coupled to a bus . The computer readable medium may be any suitable medium which participates in providing instructions to the processor s for execution. For example the computer readable medium may be non transitory or non volatile media such as a magnetic disk or solid state non volatile memory or volatile media such as RAM. The instructions stored on the computer readable medium may include machine readable instructions executed by the processor s to perform the methods and functions of the system .

The computer readable medium may store an operating system such as MAC OS MS WINDOWS UNIX or LINUX and one or more applications which can include the modules for the system . The operating system may be multiuser multiprocessing multitasking multithreading real time etc.

The computer system may include a data storage which may include non volatile data storage. The data storage stores data used by the system . The data storage may be used for the data repository or the computer system may be connected to a database server not shown for providing the data repository.

The network interface connects the computer system to the procurement system for example via a LAN. End user devices and other computer systems servers may also connect to the computer system via the LAN and network interface . Also the network interface may connect the computer system to the Internet. For example the computer system may connect to customer portal and data sources via the network interface and the Internet.

At data for previous high risk procurements is identified. The identification of these procurements may be done through audits performed through a computer system and or using machine implemented expert analysis. The specific characteristics of procurements are stored in a database along with the timeframe of the procurement action. These characteristics may be the variables used in the scoring models to determine if a bid is high risk. The variables may be related to the price of procuring items the supplier of the items the items themselves etc.

At model building data sets such as training sets and validation data sets such as validation sets are determined from historic procurement data including the identified high risk procurements. Portions of the procurement data may be in both types of data sets to allow for development and confirmation of the models. Data mining techniques that can be used for creating the training sets the validation sets and scoring models may use both procurements that were problematic high risk along with those that were not non high risk or low risk procurements .

At the scoring models are created from the model building data sets. For example machine learning functions use the training sets to train the classifiers . For example logistic regression neural networks analysis decision trees data mining regression gradient boosting bootstrapping and ensemble a method that combines the predictions from the individual models are techniques that can be used to build the scoring models which can include the classifiers . Characteristics e.g. variables that have the greatest predictive power are determined and incorporated into the models and are used to determine a probability that a given procurement would be high risk.

For example one factor that might indicate an increased probability that a high risk procurement has been identified includes a procurement price nomenclature relationship that exceeds the bounds of a commercially available price nomenclature relationship. This factor may be constructed by combining data from an organization s procurement system with data from commercial sourcing pricing nomenclature tables.

Table 1 below illustrates a manner in which the data may be compared. The data gleaned from this comparison could create an index value e.g. Bid Should Cost High Value that is a factor to be considered in the high risk identification process.

The factor data is used to build the scoring model used to identify a high risk procurement. When that operation is complete the model or models chosen can then be adjusted based on how sensitive the prediction of a high risk procurement is selected to be. A more sensitive model may highlight more procurements as high risk including those that might not represent ones that are truly high risk false positives . A less sensitive model may identify fewer procurements as high risk but may run a greater probability that an otherwise high risk procurement won t be identified as such. Embodiments allow tuning models with respect to sensitivity so that a desired degree of accuracy is obtained with respect to identifying potential procurements as high risk.

Multiple scoring models may be created at to accommodate different areas of risk. For example a price risk scoring model a supplier risk scoring model and an item risk scoring model may be generated using a price risk data set a supplier risk data set and an item risk data set respectively. Respective data sets may contain information relevant to particular risk area. The data may include information associated with variables for each risk areas. Also respective models may be generated using different model building techniques. If desired respective models may use a common scoring scale and scoring threshold to identify high risk procurements as is further described below.

The price risk scoring model may be used to identify bids that are over priced or bids that are underpriced. For example an underpricing threshold can be determined and bids below the threshold may be labeled significantly underpriced bids. Significantly underpriced bids may be indicative of the supplier using for example counterfeit goods or goods made with inferior materials and thus may be considered high risk. The price risk scoring model may be comprised of historic price data for a period of time e.g. the last 12 months and beyond for goods or services being procured. The price risk model may also include variables to adjust for economic conditions. For example the variables may include a consumer price index CPI a producer price index PPI for commodities and a PPI for industries and other variables that may account for inflation or other economic conditions. The price risk scoring model identifies the should cost amount for items being procured.

Certain factors may be used to select the variables for the price risk scoring model. For example commodity inflation factor data sources may be evaluated to select the inflation variable that is most relevant to the item being procured. The inflation rate may vary widely depending on the type of item being procured and an inflation rate may be selected that is for a particular type of item being procured. Geographic location and shipping costs are examples of other variables that may be used to adjust prices or costs.

The supplier risk model includes variables that are used to identify high risk suppliers of items being procured. The variables may vary depending on the type of item being procured and the variables may include geographic location out of business indicators legal status e.g. corporation partnership sole proprietor etc. year started number of employees past procurement history with regard to supplying of items etc. In one example cluster analyses is performed to determine the association of each variable against the supplier being evaluated as well as a level of multicollinearity amongst the variables. Through a number of model iterations a set of variables are selected which not only minimize multicollinearity but are also able to accurately distinguish which suppliers are high risk. A logistic regression may be used to identify suppliers that have a high probability of being high risk based on the supplier risk model.

The item risk model includes variables that are used to identify high risk items that may be supplied by a supplier for a procurement. The item risk scoring model may be used to identify bids that are high risk based on the items being supplied by the supplier for the procurement. For example a bid may be considered high risk if the items being supplied by a supplier are expected to have a high probability of being counterfeit. Some examples of variables that may be used in the item risk model may include commonality of a unit in the bid specifying the amount of the item to be supplied the type of item e.g. microprocessors may be considered higher risk than a fastener geographic location of manufacturing of the item the use of the item e.g. military versus civilian past supplier history with respect to providing items etc.

At the scoring models may be validated by evaluating the validation data set using the models to confirm accuracy. Validating models may also protect against model over fit which is a condition where the model places more emphasis on a variable than might be found in the larger population of procurements in which the model could be run. Model validation ensures that the model will operate as desired when run against live data as part of an automated procurement process.

At the scoring models are incorporated into the procurement process to identify high risk procurements. The scoring models for example may be incorporated into an automated daily review of procurements. For example the scoring models are used to evaluate bids that may be high risk and may generate alerts when a bid is determined to be high risk.

Bids may be evaluated using the price risk scoring model the supplier risk scoring model and the item risk scoring model to identify high risk procurements. Also evaluation capacity may be considered when evaluating bids using the models. The evaluation capacity is a number of bids that can be reviewed within a predetermined time period. The evaluation capacity may be based on an operating capacity of a system such as system for selecting one or more bids for procuring one or more items. In situations where an evaluation capacity is anticipated to be inadequate to process in incoming number of bids filtering may be used to reduce the number of bids evaluated by system . Alternatively system capacity can be expanded using for example cloud based deployments to increase system capacity to process an anticipated number of incoming bids.

The evaluation of bids may include determining a price risk score a supplier risk score and an item risk score for each bid based on the models and the evaluation capacity and the information associated with each bid. The same scoring scale e.g. 0 1000 may be used for each type of score e.g. price risk supplier risk and or item risk score. Also the same threshold in the scoring scale may identify a bid as a high risk. For example if the threshold is 800 a price risk score a supplier risk score and or an item risk score greater than or equal to 800 for a bid may indicate the bid is high risk. Use of a single or consistent scoring scale and or scoring threshold for each risk area may facilitate quickly identifying which bids are high risk. Bid evaluations are further described with respect to the methods discussed below.

In order to determine a suitable should cost price for each item adjustments are made to historic procurement data at . For example certain items may not be procured through a procedure where bids are received to supply these items and as a result there may be minimal correlation between predictive variables and target variables for these items. Examples of such items may include general merchandise medical and subsistence procurements. Procurements for these types of items may be removed from the historic procurement data. Also items procured through long term contracts may be removed from the historic procurement data due to the differing procedure for acquiring these items. Following this instances where the net price of a procurement was missing or equal to zero are also removed as well as instances where the net price associated with a procurement represented an extreme outlier. For example in a first pass Pass 1 such outliers were identified as those procurements with a net price greater than four times the median price for a particular item. A second pass Pass 2 of outlier exclusion may also be applied. For example Pass 2 utilizes different thresholds of the historic price coefficient of variation based on the median price of an item. For example if the median price of an item is between 7 and 1000 and the coefficient of variation is above 40 this record would be deemed an outlier and subsequently removed from the should cost calculation.

At the adjusted historic procurement data is partitioned into current and historic data sets. For example the adjusted historic procurement data is split into two datasets representing a current dataset which included all procurements taking place in the most recent twelve months of procurement data and a historic dataset which includes the remaining approximately five years of procurement history. The current dataset is treated as if such procurements are incoming bids and the expected cost savings are calculated against the actual price paid.

At after separating the current and historic datasets the historic dataset is split again. For example a first historic dataset contains items for which only two or fewer procurements occurred within the five year time period contained within the historic data set and a second historic dataset contains items for which greater than two procurements took place over the same period. Due to the scarcity of procurement pricing history for those items with two or fewer purchases the methodology for determining a should cost price differs from those items for which a richer pricing history exists.

At prices in each of the historic datasets of are adjusted for inflation to determine a should cost price for each item and the should cost price may be entered into should cost tables for items. For example in order to account for the effects of inflation on price the Consumer Price Index CPI and the Producer Price Index Industry PPI I are both applied. Since CPI measures the amount of inflation experienced by the consumer for a basket of goods and PPI I measures the amount of inflation experienced by producers in the profits that they gain from the sale of their goods and can be disaggregated by industry using NAICS North American Industry Classification System codes using both indices may provide a better adjustment for inflation than using a single index. More specifically using both CPI and PPI I disaggregated by industry using NAICS codes allowed the Price Risk model to account for the variances in inflation factors that may occur between industries by mapping each item s NIIN National Item Identification Number code to an associated NAICS code.

Application of CPI and PPI I to adjust for inflation may differ between the two historic datasets determined at . For those items procured more than two times CPI and the appropriate industry specific PPI I values for the month in which the procurement took place are averaged. Using the resulting index the net price for each item was inflated to the current month after which all of the inflation adjusted net price values were averaged by NIIN in order to produce a NIIN specific should cost price. For those items with a sparse procurement history e.g. two or less the appropriate CPI and PPI I index values used to inflate the procurement s net price to current values are applied separately. The values for each procurement obtained using this method are then averaged as if they represented their own individual price points in order to produce a NIIN specific should cost price for those items with two or fewer purchases in the five years of historic procurement data. The should cost price represents an estimation of how much should be paid for an item being procured based on historic price data for the item or related items and other variables.

After the should cost item prices are determined the bids may be scored according to the should cost price of the items in the bid as is discussed further below. The price risk scoring model identifies bids that are high risk based on price. A high risk price may represent overpayment for a good or service if accepted. Also a significantly underpriced bid may be considered high risk. For example a bid three times less than an average price may be indicative that the supplier is using counterfeit goods.

At the evaluation capacity is determined. The evaluation capacity may be entered by a user and stored in the data repository and the evaluation capacity may be retrieved as needed.

At a cost savings is determined for each bid. The cost savings may be based on the difference between the should cost and the price specified in the bid to procure an item. If the price is per item and multiple items are being procured then the difference may be multiplied by the number of items being procured.

At the bids are sorted by cost savings for example from highest cost savings to lowest cost savings. At a subset of the bids having the highest cost savings are determined. The number of bids in the subset may be based on the evaluation capacity. For example if the evaluation capacity is 200 then 200 bids with the most cost savings is determined and may be selected based on the determination.

At a score according to the scoring threshold in the scoring scale is assigned to the bid in the subset that is associated with the lowest cost savings. For example if the scoring threshold is 800 then the bid in the subset with the lowest cost savings is assigned a score of 800.

At a score weighting is calculated. For example an embodiment may calculate the score weighting by taking the natural log of the cost savings for the lowest cost savings bid and then dividing it by the threshold e.g. 800.

At the natural log of the cost savings for each bid in the subset is determined. At the weighting determined at is applied to the natural log of the cost savings for each bid determined at to determine each bid s score. For example the natural log determined at is multiplied by the score weighting determined at for each bid.

At the scores may be adjusted if a limit is exceeded. For example any score over an upper limit of the scoring scale e.g. 1000 on a scoring scale of 0 1000 is assigned to the upper limit and any score below the lower limit e.g. 0 is assigned the lower limit for the score.

At the score for each bid is compared to the scoring threshold to determine if the bid is high risk. For example if the bid s score exceeds the threshold it is marked as high risk and a notification may be generated for example via the dashboard or message may be sent to a bid evaluator.

The supplier risk model is designed to identify high risk suppliers submitting bids for a procurement. In this way it can help reduce the quantity of bids awarded to suppliers who may provide counterfeit or non conforming items or that are unlikely to fulfill their contractual obligations. illustrates a method for evaluating bids according to a supplier risk scoring model and may be used to identify bids having a high risk supplier. The supplier risk scoring model may be used to identify bids that are high risk based on the supplier of the items being procured. For example some suppliers may be considered bad actors based on previous procurement actions. For example the supplier may have previously been found to provide counterfeit goods or was accused or indicted for fraud. Bids from these types of suppliers may be considered high risk.

At a historic dataset is generated for use to create the supplier risk model. For example supplier names are extracted from approximately six years of historical procurement data. Those suppliers are matched against information from multiple data sources to collect additional information about the suppliers including demographic information and include the additional information in the historic data set.

At the historic dataset is adjusted. For example a quality check may be applied to sources of the historic data set. Based on the quality check it may be determined that variables are deemed unusable due to a high rate of missing data and or no variation in values. Unusable variables may be removed from consideration as potentially predictive variables. Each variable with an acceptable rate of missing values may be improved for example by replacing the missing values of the variable with either the mean or the median of the values for the variable depending upon the variable under consideration. Also additional variables may be created for example by combining or modifying original variables.

At variables in the adjusted historic dataset are evaluated for multicollinearity. For example a factor analysis can be performed to mitigate effects of highly correlated predictive variables. In the process variables that are highly correlated with each other are combined into a single variable which can then be used by one or more of the machine learning functions to train a classifier without the consequences of multicollinearity as long as those factors do not correlate with other variables.

At for example after performing factor analysis on the adjusted historic dataset the adjusted historic dataset is divided into a training set and a validation set. The training set includes labeled data objects for supervised training of a classifier. Factor analysis may be performed again on the training set.

At the training set is input to one or more of the machine learning functions to train a classifier. In an example a step wise logistic regression function may be used to generate the supplier risk model which may be a classifier. At the supplier risk model is tested using one or more of the validation set and a combination of the validation set and the training set. After proven to be accurate through the testing the supplier risk model may be used to classify data objects such as data objects in the current set as is discussed below. The supplier risk model may be adjusted depending on the type of items being procured. For example the supplier risk model may include a geographic location of the supplier as a variable. The variable may be weighted differently depending on the type of item being procured and or where a supplier is located.

At the evaluation capacity is determined. The evaluation capacity may be received by system on behalf of a user and stored for example in the data repository and retrieved as needed.

At a subset of bids are identified based on the evaluation capacity. For example the subset may be determined based on cost savings and the evaluation capacity as described in the method .

At a supplier score is determined based on the supplier risk model for each bid. For example the supplier risk model determines a probability that a bid includes a high risk supplier. In one example business rules may be used to determine the supplier risk score based on the probability. For example if the supplier is determined to be on a barred list for the procurement the bid is given the maximum score of 1000.

At the supplier risk score for each bid is compared to the scoring threshold to determine if the bid is high risk. For example if the bid s supplier score exceeds the threshold it is marked as high risk and a notification may be generated for example via the dashboard or message may be sent to a bid evaluator.

At a historic dataset is generated to create the item risk model. For example the historic dataset includes approximately six years of historic procurement data. A list of items previously purchased over the last six years is determined from the historic procurement data. The historic dataset may include data from multiple sources.

At the historic dataset is adjusted. For example general merchandise items which may be identified through NIIN codes or other item codes are filtered from the historic data set.

At from the adjusted historic dataset a list of items known to have experienced instances of counterfeit or non conformance is determined. For example failure reports defect codes contractor fault reports and other information may be used to identify the items that were counterfeit or non conforming.

At the list of items from which are determined to have experienced instances of counterfeit or non conformance are used to label data objects in the adjusted historic data set from as high risk items to create a training set. Also predictive variables are determined for the item risk model. For example variables such as the number of instances an item was purchased over the past six years an indicator of an item s criticality and whether the item had a diminishing manufacturing source are selected as predictive variables.

At the item risk model is determined. For example an ensemble classifier is generated for the item risk model. In an embodiment a combination of a decision tree function a correlation analyses function and Chi squared tests are employed to determine variable importance multicollinearity and the weights for each variable to create the ensemble classifier. For the decision tree function variables selected as predictive variables are input to the decision tree. The decision tree output identifies group values of continuous variables that have the greatest predictive power and the groups are transformed into categorical variables and included in further decision tree iterations as well as in Chi squared tests which are performed in to assign weights to the rules relating to the predictive variables used for the final classifier. The item risk model may be stored in data storage and may be retrieved to evaluate bids. The item risk model may be adjusted depending on the type of items being procured.

At the evaluation capacity is determined. The evaluation capacity may be received on behalf of a user and stored. At a subset of bids are identified based on the evaluation capacity. For example the subset may be determined based on cost savings and the evaluation capacity as described above. At a number of true risk conditions is determined for each bid. For example variables in the item risk model may represent risk conditions such as whether the bid contains an uncommon unit whether the bid is for supplying a microprocessor whether manufacturing is performed overseas etc. Examples of assigning true conditions for these variable may include if the unit in the bid is uncommon it is assigned a 1 i.e. a true risk condition otherwise it is assigned a 0 . If the item is a microprocessor the bid is assigned a 1 . If the item is manufactured overseas the bid is assigned a 1 . The total number of true risk conditions are determined for each bid.

At the number of true risk conditions is multiplied by a predetermined value to determine an item risk score in the scoring scale for each bid in the subset. The predetermined value may be based on the scoring scale used. At the item risk score for each bid is compared to the scoring threshold to determine if the bid is high risk. For example if the bid s supplier score exceeds the threshold it is marked as high risk and a notification may be generated for example via the dashboard or message may be sent to a bid evaluator.

The dashboard may generate screenshots of the scores determined by the system . Examples of the screenshots are described with respect to . Also scores may be selected to provide drill downs to display additional information related to the scores. shows an example of a screenshot illustrating scores for bids provided by the fictitious companies James Brother Construction Quincy Engineering and F T Sales and Service. The scores are 967 810 and 930. In this example only the highest score is shown but multiple scores may be generated for each bid such as a price risk score a supplier risk score and an item risk score. As shown 967 and 930 are price risk scores and 810 is a supplier risk score. Also the company the score or the risk factor may be selected by a user for drill downs to get additional information on the selected item.

As shown in and discussed above with respect to a procurement system may interact with the system to identify high risk bids for procurements received through the procurement system . For example bids in a feed of live procurement data are received at the system from the procurement system . The system may score the bids and identify high risk procurements. For example the system generates information such as a high risk file identifying high risk procurements a procurement score file identifying scores for procurements and metrics for the bids and sends the information to the procurement system . The high risk procurements identified in the high risk file may be evaluated in a workflow executed by the procurement system before the procurement process is closed. For example procurements flagged as high risk may be given further analysis using for example an audit workflow to determine whether they can be accepted or denied. The metrics may be displayed via a GUI e.g. a dashboard. describe procedures of the procurement process performed by the procurement system and examples of interactions between the procurement system and the system .

The item risk score displayed by the procurement system may be hyperlinked to provide the end user with access to an item risk report which may be self populated without the user having to enter information e.g. search criteria . The item risk report can display information regarding the item risk score as well as recommendations for actions that could change the workflow for the procurement specialist. Additionally the recommendations may trigger requirements for overview and or audit if there is a high risk determination. The item risk report also provides the user with a detailed report of metrics which combine information from multiple ones of the data sources . If the risk score raises a concern the procurement specialist can view underlying data for the procurement via a drill down to see what metrics may have led to that risk. Additionally by automatically generating the item risk report using data relevant to the specific item being procured the end user does not have to enter lookup information.

The item risk report may include a combination of data fields data tables and data visualizations customized to meet the objectives of the user. While some data will be a replication of relevant fields concatenated into one report data visualization tools provide easy to read displays and visual comparisons of relevant data. Also the data visualization tools can be used to plot relevant item risk data and provide the user with easy to read graphs for quick analyses of key information and enables the user to spot trends more easily. Also new graphs may be created with selectable options e.g. selecting certain time periods to instantly generate a new view.

At shown in a solicitation comprised of procurement request may be generated and posted to solicit bids from suppliers and at bids are received and evaluated including evaluating bids for high risk procurements and evaluating bids to award a contract to one of the bidders at . At steps various reports may be accessed to aid in the evaluation process. The reports may include item risk reports supplier risk reports and price risk reports for different steps such as shown in . Item risk reports are described above. Price risk reports are now described. Price risk scores and accompanying confidence level indicators may be determined by the system and provided to the system for display during bid evaluation. During bid evaluation a price risk score and confidence level indicator is generated for every bid submitted for consideration and an accompanying price risk score and confidence level indicator is automatically generated displayed alongside the bid information. Additionally when a procurement specialist launches a bid evaluation screen in preparation to make an award the price risk scores and confidence level indicators are updated and appear alongside other relevant bid evaluation data.

The price risk score can assist in mitigating the risk of overpayments and identifies and flags bids such that procurement specialist or contracting officer can initiate suitable price negotiation procedures. In an example the workflow of the procurement specialist and contracting officer is automatically modified to invoke price negotiation and other investigative procedures. Also notifications may be generated for low bids such as to alert to potential counterfeit non conforming items and or investigate potential misunderstandings of the requirements. The confidence level indicators provide a single measure of both the availability of recent historical data and the price variance within the data. Having the price risk scores and confidence level indicators on screen together allows for quick risk evaluation. Additionally providing refreshed scores every time the bid evaluation screen is opened ensures the procurement specialist is always viewing scores produced from the most up to date data.

The system may generate a price score hyperlink via a bid evaluation screen and clicking the hyperlink causes a detailed price risk report to be displayed. Similar to the item risk report the price risk report displays detailed information regarding the price risk score and recommendations for actions that could change the workflow for the procurement specialist. Additionally the recommendations may trigger requirements for overview if there is a high risk. The price risk report also provides the user with a detailed report of metrics which combines information from multiple ones of the data sources . If the price risk score raises a concern the procurement specialist can view the underlying data via a drill down to see what metrics may have led to that risk. Additionally by automatically generating the price risk report with data relevant to the specific item being procured the end user does not have to enter lookup information.

Similar to the item risk report the price risk report may include a combination of data fields data tables and data visualizations customized to meet the objectives of the user. While some data will be a replication of relevant fields concatenated into one report data visualization tools provide easy to read displays and visual comparisons of relevant data. Also the data visualization tools can be used to plot relevant price risk data and provide the user with easy to read graphs for quick analyses of key information and enables the user to spot trends more easily. Also new graphs may be created with selectable options e.g. selecting certain time periods to instantly generate a new view.

Supplier risk reports may be generated and accessed at various steps such as shown in . For example during solicitation and bid evaluation and possibly other steps and phases supplier risk scores may be displayed. A supplier risk score may be generated for every supplier that submits a bid for consideration. When each new bid is received an accompanying supplier risk score is generated and appears alongside the bid information. Additionally when a procurement specialist launches their bid evaluation screen in preparation to make an award the supplier risk scores are updated and appear alongside other relevant bid evaluation data. The supplier risk scores can be used to identify potentially high risk suppliers such as during bid evaluation. In this way the supplier risk score can help reduce the number of bids awarded to suppliers who may provide counterfeit or non conforming items or who are unlikely not able to fulfill their contractual obligations.

Similar to the item risk and price risk reports the system may generate a supplier score hyperlink to access supplier risk reports and recommendations for actions that could change the workflow for the procurement specialist. Also similar to the item risk and price risk reports the supplier risk report may include a combination of data fields data tables and data visualizations customized to meet the objectives of the user.

The case management operations may store risk scores and risk alerts along with related metrics so this information can be tracked and reported. Accordingly the system may operate as a central repository for risk scores and alerts and risk trends over time can be identified. In response to identifying trends suppliers may be excluded or other actions may be performed.

Also one or more risk thresholds may be customizable in the system . For example each risk score may have a customizable risk score threshold or tolerance which enables decision makers to set a range of acceptable risk scores. The customizable thresholds also allow for custom categorization of risk scores such as high medium or low risk based on available data and scoring techniques. The thresholds may be customizable by administrators so that they can be modified to adapt to future changes or guidance.

Referring now to the system may interact with a mobile application that executes on a mobile device to perform various operations associated with the workflow steps shown in . The alerts may be sent from the procurement system to mobile devices of supervisors or contracting officers for immediate review and action. The mobile application accompanying this capability allows supervisors to review procurement details approve reject contracting steps and move procurements between automated processes and other processes such as audit processes. For example an automated workflow executed by the system includes performance of steps for solicitation evaluation and contract awarding such as shown at in . In certain instances such as due to item supplier or price risk alerts an interrupt is generated to halt the workflow until audit feedback is received concerning an alert. The alerts may be generated in response to the classifiers identifying high risk suppliers items or prices in bids. For example the automated workflow is halted and the alert is sent to the mobile application . The mobile application may send a command to trigger an audit and or may directly cause the audit to be performed. For example when mobile application triggers an audit one or more of the audit operations shown at may be performed in response to the alert. The mobile application may receive an approval alert or notification in response to sending the command if the bid is approved based on an audit operation performed at . If the audit operation indicates that no adverse action should be taken a command may be sent back to the system to re start the workflow. If the audit operation indicates that an adverse action such as rejecting a bid should be taken then the bid may not be accepted. As seen in the mobile application facilitates transitioning between automated and audit workflows based on item supplier or price risk alerts.

The mobile application also allows supervisors or contracting officers to set custom alerts applicable to specific criteria such as certain items suppliers quantities etc. This allows personnel to remain informed about procurements in real time and to provide them with the ability to react to procurement risks using system before procurement specialists make the award. This mobile application also facilitates performance of operations described with respect to from mobile devices.

While the embodiments have been described with reference to examples those skilled in the art will be able to make various modifications to the described embodiments without departing from the scope of the claimed embodiments.

