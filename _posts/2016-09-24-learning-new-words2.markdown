---

title: Learning new words
abstract: Systems and methods are disclosed for a server learning new words generated by user client devices in a crowdsourced manner while maintaining local differential privacy of client devices. A client device can determine that a word typed on the client device is a new word that is not contained in a dictionary or asset catalog on the client device. New words can be grouped in classifications such as entertainment, health, finance, etc. A differential privacy system on the client device can comprise a privacy budget for each classification of new words. If there is privacy budget available for the classification, then one or more new terms in a classification can be sent to new term learning server, and the privacy budget for the classification reduced. The privacy budget can be periodically replenished.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09645998&OS=09645998&RS=09645998
owner: Apple Inc.
number: 09645998
owner_city: Cupertino
owner_country: US
publication_date: 20160924
---
This application claims priority under 35 U.S.C. 119 e of U.S. Patent Application No. 62 348 988 filed Jun. 12 2016 and entitled LEARNING NEW WORDS and U.S. Patent Application No. 62 371 657 filed Aug. 5 2016 entitled LEARNING NEW WORDS both of which are incorporated herein by reference to the extent that they are consistent with this disclosure.

This application is related to U.S. patent application Ser. No. 15 275 356 filed Sep. 24 2016 and entitled LEARNING NEW WORDS which is incorporated herein by reference to the extent that is it consistent with this disclosure.

A user of a client device relies on one or more dictionaries of words for spell checking suggesting words during typing and other uses of known words. Such client dictionaries are difficult to keep updated with new words that may become popular through crowdsourced usage of words without compromising privacy.

Current servers can learn the words that users are typing by examining clear text that users have typed when utilizing the servers. For example some prior art text message services and email services collectively messages receive messages in clear text. Message servers that route messages to client devices can read the clear text and use the words obtained from the clear text of user messages to present advertising to the users. However the server learned words remain on the server and do not update an on device dictionary to include the new words. Also usage of clear text by servers compromises the privacy of a user. In addition new words generated on a client device such as words that are used within documents on the client device and are not transmitted to a server cannot be learned by the server because the words are localized to the client device. Further if the client device utilizes an end to end encrypted messaging service such as Apple iMessage then a server cannot learn the words contained in the user message at all and thus a server cannot update a user client dictionary using crowdsourced data.

Systems and methods are disclosed for a server learning new words generated by user client devices in a crowdsourced manner while maintaining local differential privacy of client devices. In a crowdsourced client server environment local differential privacy introduces randomness into user data prior to a client sharing the user data with a server. A server can learn from the aggregation of the crowdsourced data of all clients but the server cannot learn the data provided by any particular client.

Local differential privacy introduces in one embodiment randomness to client user data prior to sharing the user data. Instead of having a centralized data source D d1 . . . dn each data entry dbelongs to a separate client i. Given the transcript Tof the interaction with client i it is not possible for an adversary to distinguish Tfrom the transcript that would have been generated if the data element were to be replaced by null. The degree of indistinguishability is parameterized by typically considered to be a small constant. The following is a formal definition of local differential privacy.

Let n be the number of clients in a client server system let be the set of all possible transcripts generated from any single client server interaction and let Tbe the transcript generated by a differential privacy algorithm A while interacting with client i. Let d S be the data element for client i. Algorithm A is locally differentially private if for all subsets T the following holds 

The systems and methods disclosed herein include an local differentially private count median sketch CMS and a Hadamard local differentially private count median sketch CMS that compare favorably to prior art methods with respect to error communication load space used and client and server computation while preserving user privacy as shown in the table below.

In an embodiment a client device can determine that a word typed on the client device is a new word that is not contained in a dictionary or asset catalog on the client device. New words can be associated with classifications such as entertainment health finance etc. A classification is a conglomeration of similar types of information. In an embodiment each classification can be associated with one or more sessions wherein each session can be associated with an application or product type. For example the health classification can be associated with a personal fitness or health application. New words generated by the health or fitness application can be classified as health words. For example zika a trending medical term could be classified as a health word. Similarly the classification can be associated with a finance application or a finance tab of a browser session. New words generated by a finance application or finance tab can be classified in the finance classification. For example corporate inversion a trending financial term could be classified in the financial classification. A differential privacy system on the client device can comprise a privacy budget for each classification of new words. New words generated by a user can be stored in a transmission buffer in preparation for being transmitted to a new word learning server. Words can be stored in the transmission buffer organized by classification. It is possible to store more words in the transmission buffer than there is privacy budget available to transmit the words. To preserve the privacy budget the transmission buffer can be periodically sampled to obtain a word for transmission to the new word learning server. If there is sufficient privacy budget available for the classification the sampled word can be segmented into n grams an n gram can be selected from the n grams and processed using local differential privacy then transmitted to a server. N grams can be selected to be a particular length such as 1 character one gram 2 characters bi gram etc. Throughout the disclosure the term n gram is used to generically refer to a sequence of characters having a specified length for a process. In an embodiment a length of 2 is selected bi gram to reduce search space complexity. Longer or shorter n grams can be used. In an embodiment an n gram length can be selected based upon the language of the words to learn. In an embodiment the client device can use local differential privacy to introduce randomness in the client data prior to sharing the data with a server that will learn the new words. In an embodiment a server can test differentially private data received from a plurality of clients to determine whether the amount of randomization in the differentially private data is sufficient to maintain differential privacy of client data.

In an embodiment a non transitory computer readable medium can store executable instructions that when executed by a processing system can perform any of the functionality described above.

In yet another embodiment a processing system coupled to a memory programmed with executable instructions can when the instructions are executed by the processing system perform any of the functionality described above.

Some embodiments described herein can include one or more application programming interfaces APIs in an environment with calling program code interacting with other program code being called through the one or more interfaces. Various function calls messages or other types of invocations which further may include various kinds of parameters can be transferred via the APIs between the calling program and the code being called. In addition an API may provide the calling program code the ability to use data types or classes defined in the API and implemented in the called program code.

Other features and advantages will be apparent from the accompanying drawings and from the detailed description.

The present disclosure recognizes that the use of personal information data collected from a large population of users in the present technology can be used to the benefit of all or many users. For example the words that are introduced to the popular lexicon can be identified and included in on device dictionaries. Accordingly use of such personal information data enables calculated control of the delivered content. Further other uses for personal information data that benefit the user are also contemplated by the present disclosure.

The present disclosure further contemplates that the entities responsible for the collection analysis disclosure transfer storage or other use of such personal information data will comply with well established privacy policies and or privacy practices. In particular such entities should implement and consistently use privacy policies and practices that are generally recognized as meeting or exceeding industry or governmental requirements for maintaining personal information data private and secure. For example personal information from users should be collected for legitimate and reasonable uses of the entity and not shared or sold outside of those legitimate uses. Further such collection should occur only after receiving the informed consent of the users. Additionally such entities would take any needed steps for safeguarding and securing access to such personal information data and ensuring that others with access to the personal information data adhere to their privacy policies and procedures. Further such entities can subject themselves to evaluation by third parties to certify their adherence to widely accepted privacy policies and practices.

Despite the foregoing the present disclosure also contemplates embodiments in which users selectively block the use of or access to personal information data. That is the present disclosure contemplates that hardware and or software elements can be provided to prevent or block access to such personal information data. For example in the case of advertisement delivery services the present technology can be configured to allow users to select to opt in or opt out of participation in the collection of personal information data during registration for services. In another example users can select not to provide location information for targeted content delivery services. In yet another example users can select to not provide precise location information but permit the transfer of location zone information.

In the following detailed description of embodiments reference is made to the accompanying drawings in which like references indicate similar elements and in which is shown by way of illustration manners in which specific embodiments may be practiced. These embodiments are described in sufficient detail to enable those skilled in the art to practice the invention and it is to be understood that other embodiments may be utilized and that logical mechanical electrical functional and other changes may be made without departing from the scope of the present disclosure. The following detailed description is therefore not to be taken in a limiting sense and the scope of the present invention is defined only by the appended claims.

Client devices each associated with a user in a large plurality of users crowdsource can be coupled to a one or more new term learning server s term learning server via network . Each client device can segment a new word into n grams and send a differentially private sketch of the word and n grams of the word to a term learning server. A sketch of a word is a computed encoded representation of the word. The purpose of the sketch is to transmit the encoded representation of the word sketch to the server rather that the clear text of the word so that the server cannot directly learn the word transmitted by only the one client. In a crowdsourced client server environment a local differential privacy system generates the encoded representation such that randomness is introduced to client data word prior to a client sharing the word with a server. A server can learn the word from the aggregation of the crowdsourced data of all clients but cannot learn the word provided by any particular client. Collectively the differentially private sketches received from the large plurality of client devices comprise crowdsourced data from which term learning server can learn new words used among the large plurality of client devices while maintaining privacy of each of the client devices . Client side local differential privacy implemented in a crowdsourced data environment ensures that the term learning server learns the new words of all client devices without exposing whether any particular client device uses the new words. Client device can comprise any type of computing device such as a desktop computer a tablet computer a smartphone a television set top box or other computing device such as iPhone Apple Watch Apple TV etc. as described below with reference to .

Network can be any type of network such as Ethernet WiFi Token Ring Firewire USB Fiber Channel or other network type.

Term learning server can comprise one or more hardware processors memory storage devices such as one or more hard disks solid state storage devices CD ROM storage DVD ROM storage storage appliances etc. Exemplary components of term learning server are described below with reference to .

Internal components of client device can include a plurality of storages a differential privacy engine DPE that can comprises a differential privacy daemon and a differential privacy framework or application programming interface API and a plurality of applications e.g. App 1 App2 and App 3. APIs are described in detail below with reference to .

Storages can include a blacklist a term learning buffer an asset catalog and private dictionary . Blacklist can be used to determine words that are not to be sent to term learning server . A user may prefer to blacklist certain words as having a high level of privacy to the user such that the user does not want to transmit word to the term learning server no matter how great the guarantee of privacy from the term learning server . Such words may include proper names e.g. family members or surnames proprietary technology words and other words a user may proactively choose to keep private using blacklist .

Blacklist storage can be used to store words that have been previously transmitted by client device to term learning server but the client device has not yet received an updated asset catalog from new term learning server to replace the client device asset catalog . In an embodiment differential privacy engine can check the blacklist storage before processing a word e.g. generating differentially private n grams . In an embodiment differential privacy engine DPE of a client device sends a word to term learning server only once. To preserve a privacy budget of the client device a word that has been added to transmitted words storage may not be re sent to the term learning server . Once the client receives an updated asset catalog words that appear within blacklist storage that are now contained in the updated asset catalog can be deleted from blacklist storage .

Privacy budget is a quantity that ensures the privacy of an individual is not compromised after repeated donation of information to the term learning server . A privacy budget E quantifies the amount of information leaked by a client device to a server by providing the differentially private information to the server. Every submission to a server of differentially private information e.g. a new word consumes a portion of the privacy budget E for the client device . If a client device submits k pieces of information through a privacy channel to a server then E k to ensure that the overall privacy budget E is not violated. A separate privacy budget is allocated to each classification of information. Each time a word is transmitted to term learning server a privacy budget for a classification of the word is charged or reduced by some amount. For example in the keyboard usage classification if a client device transmits the words zika and ebola to the term learning server the client device keyboard classification budget would be charged a portion of the privacy budget E for the keyboard classification for each transmitted word.

When data for a classification is purged from term learning server it is possible to replenish or increase the privacy budget for the classification on a client device . Alternatively the privacy budget for the classification can be replenished periodically on the client device . In an embodiment replenishment of the client device privacy budget for a classification can be synchronized with purging of client device data for one or more client devices on term learning server or purging of all client device data on the term learning server . In an embodiment replenishment of a client device privacy budget for a classification of words can be asynchronous with term learning server purging client device data for a plurality of client devices .

A term learning buffer can comprise a storage that holds candidate words for transmission to term learning server . A user may generate more new words than can be sent within a privacy budget for a classification of words. Thus DPE can store candidate words in term learning buffer then sample the buffer later to determine a random candidate word to send to term learning server . Term learning buffer can also store words that have been sampled from the candidate words and selected for transmission to the term learning server . In an embodiment words are stored in term learning buffer by classification. Each classification can have a privacy budget.

Client device can further include a private dictionary that stores words that a user of a client device may want to consider familiar or frequent i.e. known to the particular client device . In an embodiment the user can designate a word in private dictionary as eligible or ineligible for sending to the term learning server . Differential privacy engine can receive a word from an application and access the private dictionary to determine whether the word is eligible to be sent to term learning server .

Term learning server can comprise a module to receive data a module to classify received data according to a classification system and a job to learn new words from received de identified sketch data. Term learning server can further include one or more storages including an n gram position frequencies storage an asset catalog and an updated asset catalog . A module to update clients can publish the asset catalog update to one or more client devices .

Receive module can asynchronously receive sketches of n grams of new words for a large plurality of client devices crowdsourced data . Receive module can remove from the received sketch data any latent identifiers such as IP address meta data session identifier or other data that might identify a particular client device that sent the sketch data.

Classify received data module can extract classification data from the received sketches and group received sketch data by classification. For example classify received data module can receive sketches for the new words and group these sketches according to the keyboard usage classification.

Learn new terms job can periodically process the received de identified and classify sketch data received from the large plurality of client devices . Learn new terms job can include operations that include accumulating frequencies of received n grams generating permutations of n grams trimming the permutations of n grams and determining candidate new words from the permutations of n grams. Learn new terms job can also update asset catalog to generate asset catalog update with updated frequencies of known words.

In operation differential privacy engine DPE can receive a new word from an application . The application can identify a new word by comparing the new word to dictionaries included on the client device . If a word is not included in the dictionaries then application can determined that the new word is to be sent to the DPE . An application can be an email application a messaging application a word processing application a web browser a client device browser an online store or any other application. An application can determine a classification class for the word. A class can be a language e.g. English or Chinese. In an embodiment a class can be shared by a plurality of applications . In an embodiment a class can be health finance legal terms or other use case classification. As an example DPE can receive the word zika from a messaging application and determine that the word is associated with the keyboard usage classification. As another example the DPE can receive the number of steps a user takes over a period of time from a fitness application and determine that the number of steps is associated with a health classification. Each classification of words can have its own privacy budget.

In operation DPE can access asset catalog to determine whether the word received in operation is already known to term learning server as evidenced by the presence of the word in asset catalog or private dictionary . If the word is in the asset catalog or in the private dictionary then the method ends. Otherwise the method continues at operation .

In operation application or DPE can determine whether the word is stored in blacklist storage . If the word is stored in blacklist storage then method ends. Otherwise method resumes at operation .

In operation DPE can determine whether the word has been previously processed by DPE . A previously processed word can include a term that has been previously transmitted to term learning server by this client device but is not yet found in an updated asset catalog on the client device . A word that has been previously processed can also be a word that is stored in the learning buffer that has not yet been transmitted to term learning server but has been processed by DPE on client device . If the word has been previously processed then the method ends. Otherwise method resumes at operation .

In operation the word can be stored in a sample buffer or queue in learning buffer . After operation method resumes at operation as described below with reference to .

Words can be held in learning buffer such that a batch of words is gathered together for sending to term learning server within a time interval. Each time a word is sent a portion of the privacy budget for a classification is charged. To preserve privacy budget for each classification of words terms are held in a learning buffer then after an interval of time a word is selected from a classification in the learning buffer for processing. In an embodiment the words in the buffer are processed in a queue order. In embodiment a word is selected at random from the buffer in accordance with a policy. This process slows the rate at which new words are sent to the term learning server and extends the life of the privacy budget. In an embodiment DPE can contain logic that determines when a privacy budget for a classification is depleted. DPE can then monitor the elapsed time before the privacy budget is replenished. The time interval between client intervals of processing can be extended or contracted based upon the amount of privacy budget available at any time. Before selecting a word it can be determined whether there is privacy budget available to send the word to the new term learning server . A word may not be processed if there is no privacy budget available for the classification of the word.

In in operation it can be determined whether an update interval has expired. If not then the update interval can be periodically rechecked in operation until the interval has expired. The update interval can be used to meter the donation of information from the client device to the new term frequency server to preserve privacy budget.

In operation a word can be selected from the sample buffer in learning buffer . In an embodiment the sample buffer can hold a plurality of words optionally organized by classification such that a word can be selected at random from the sample buffer for processing in preparation for transmission to term learning server . In an embodiment words can be selected from the sample buffer in a queue order. In an embodiment words can be selected from the sample buffer in a random order. In an embodiment selection of words from the sample buffer can be performed in accordance with a policy. A policy can be determined per application or per classification of words.

In operation the selected word is processed for sending to term learning server . Operation is described in detail below with reference to .

In operation the processed word can be stored in a buffer in learning buffer for transmission to new term learning server .

In operation it can be determined whether there are more words in the sample buffer to consider for processing and transmission to term learning server . If so then method resumes at operation otherwise method resumes at operation .

In operation client device can optionally receive an updated asset catalog from term learning server. The updated asset catalog can have one or more new terms added by the term learning server in response to crowdsourced data received by term learning server .

In an embodiment the words that were processed and transmitted to term learning server in operation can be stored in blacklist storage . In an embodiment application that initially selected the word for processing in operation of can determine whether the word should be added to blacklist storage .

In operation the new word can be segmented into n grams. In an embodiment an n gram can be a single character in length one gram . A single n gram length may be appropriate for a language such as Chinese wherein a single symbol can represent one or more words. In another embodiment n gram length can be two characters bi gram . In an embodiment an n gram can be three or four characters long. Each n gram has a position in a word. For example if a new word is bazinga and the n gram length is two then a first n gram would comprise ba a second n gram would comprise zi a third n gram would comprise ng and a fourth n gram would comprise a. 

In operation a number can be generated that is a hash of the new word and associated with the new word and each n gram of the new word a puzzle piece . In an embodiment the hash can comprise the SHA256 hash algorithm or other hash algorithm. The term learning server can use the number as a puzzle piece to associate n grams together in combinations to identify new words at the new term learning server .

In operation DPE can apply a differential privacy algorithm to the new word and to a selected n gram of the new word. Operation is described in detail with reference to below.

In operation DPE can transmit the differentially private word and selected differentially private n gram of the word to term learning server along with selected n gram position data and class information of the new word.

In operation DPE can charge the client device privacy budget for the classification of the new word transmitted to the term learning server . For example after the DPE transmits the differentially private data to the term learning server the privacy budget for the classification of the new term can be reduced or adjusted to reflect the transmission.

In operation DPE can periodically replenish or increase the privacy budget for the classification on the client device . In an embodiment replenishing or increasing the privacy budget for a classification is asynchronous with the transmission of new term learning information in operation .

A sketch provides a succinct data structure to maintain a frequency of a domain of elements S s . . . s present in a data stream D d . . . . Let H h . . . h be a set of k pair wise independent hash functions such that each h H is h S m . Client and server differential privacy algorithms can agree on a common set of k pair wise independent hash functions H h . . . h which map to 0 . . . m . In an embodiment m can be square root over n wherein n is a number of client samples of data to be collected by the server. The value m can be a nearest power of 2 to the value of square root over n . In an embodiment k can be approximately 8 ln p wherein p is approximately equal to S the count of data items in S for the classification of terms.

A client side local differentially private sketch can be one of two types 1 an local differentially private sketch A or 2 a Hadamard local differentially private sketch A.

In operation DPE can receive the new word and n grams as an ordered set. In an example the candidate new word is bazinga a word made popular by a television show. In the example n grams are length 2 bi grams such that an ordered set of n grams for the word bazinga is ba zi ng and a where null signifies the end of the word bazinga. Bazinga has been determined to be a candidate new word as shown in above. Bazinga was not in the blacklist bazinga was not in the learning buffer storage bazinga was not in the asset catalog and bazinga was not found in the private dictionary .

In operation DPE can convert the word to a numeric value by taking a hash of the string representation of the word d H word e.g. d SHA256 word . The word is encoded as a number d in the range of 0 . . . m using H wherein m is the square root of the estimated size S of the vocabulary S of the classification. In an embodiment d H word modulo m such that d 0 m . The size of a vocabulary for a classification can vary by classification.

Operations and differ slightly as between client side local differentially private sketch algorithms Aand A. The operations and for Awill be described first.

Input for the client side local differentially private algorithm A can include 1 privacy parameter 2 hashing range m 3 k pair wise independent hashing functions H h . . . h with each h S m and 4 data element d S.

If the client instead generates the Hadamard version of the local differentially private sketch using the Aalgorithm the inputs to Acan be 1 privacy parameter 2 hashing range m 3 k pair wise independent hashing functions H h . . . h with each h S m and 4 data element d S.

Operations and below form a part of the operations of the algorithm Athat generates the Hadamard version of the local differentially private sketch.

In operation an n gram is randomly selected of the new word bazinga from the set of n grams ba zi ng a that make up the word. For example n gram ba can be randomly selected from the set of n grams for the new word bazinga. In an embodiment the set of n grams can be an ordered set.

In operation DPE can convert the randomly selected n gram to a numeric value by taking a hash of the string representation of the n gram with the puzzle piece PP prepended d n gram H PP n gram e.g. d n gram SHA256 PP n gram . The n gram and puzzle piece can be encoded as a number d n gram in the range of 0 . . . m using H. In an embodiment d n gram H PP n gram modulo m such that d n gram 0 m .

In operation DPE can initialize a sketch of the d n gram with a noise constant analogous to the operation described above.

In operation DPE can generate a differentially private sketch of the d n gram as described above in operations above.

In operation term learning server de identifies word and n gram sketch data received from clients . De identification can include removing an internet protocol IP address from the received data removing any metadata that identifies or can be used to identify a particular client with reasonable specificity.

In operation term learning server selects a batch of batch of differentially private words and n grams for a large plurality of clients from the received and de identified client data .

In operation term learning server can generate or retrieve a sketch for each known n gram. A sketch of an n gram can be used as an index to match a received n gram sketch with a known n gram sketch so that the frequency of the n gram at a position can be accumulated. In an embodiment frequently occurring n grams can have a pre generated sketch stored in tuple position database . For example in a first position the n gram th is a commonly occurring n gram as it starts many words. In an embodiment a sketch of each n gram is stored in tuple position database for all n grams e.g. aa ab ac etc.

In operation learn new words job can select all n grams from the received data that are in the first position of the term from which the n gram was extracted e.g. the first position bi gram in the word term is te. 

In operation term learning data can be reset. Term learning data can include a histogram of n gram frequencies per n gram position a histogram of new term frequencies an n gram permutations data structure and other data structures necessary to implement the word learning logic herein.

In operation for each selected n gram sketch for the position a matching sketch is looked up and incremented in a histogram of n grams for the position. The specific operations for updating the histogram of n grams at a position can depend upon whether the client used the local differentially private sketch algorithm A or the Hadamard local differentially private sketch algorithm A. The operations for each are described below.

In the case that the client used the Aalgorithm to generate the selected n gram sketch then in operation the selected sketch data vector v is added to the matching sketch data W as follows 

In the case that the client used the Aalgorithm to generate the selected sketch then in operation the selected sketch data vector v is added to the matching sketch data W as follows 

In operation the frequency histogram of n grams for the position can be ordered by n gram frequency from highest to lowest. A noise floor frequency value can be determined. N grams in the ordered histogram for the position having a frequency below the noise floor can be discarded and excluded from further processing. In an embodiment if there are n samples of n gram data in the histogram then the noise floor 

In operation it can be determined whether there are more positions of clients differentially private words and n grams to process. If so then the method continues at operation . Otherwise the method continues at operation .

In operation learn new terms job can learn new words for the selected class of words using the accumulated differentially private n gram sketches and word sketches. Operation is described in detail below with reference to .

In operation learn new terms job can optionally purge some or all of the received differentially private n gram and word sketch data to help maintain the differential privacy of users of the client devices .

In operation new term learning server can generate an n gram sketch as H PP n gram for each PP and each possible n gram. Any particular generated H PP n gram is the same as if H PP n gram were generated on a client device . Server H PP n gram values can be stored in association with the puzzle piece used to generate H PP n gram so that H PP n gram values can be easily grouped by puzzle piece by new term learning server .

In operation new term learning server can use the histogram of operation of to determine a frequency of received from crowdsourced client data of each H PP n gram at each position in the histogram. New term learning server can group H PP n gram at each position by puzzle piece PP and n gram sketch such that the frequency of a particular n gram sketch having a particular puzzle piece can be determined.

In operation a number of puzzle piece groups of n grams x having a highest frequency at a position can be determined that represents the number of puzzle piece groups of n grams to use at each position for generating candidate words. The value x can depend upon the a maximum number of candidate words that the term learning server is configured to process. For example if a server is configured to process a maximum of ten million words comprising a maximum of 7 bi grams therefore a maximum word length of 14 symbols then the value x can be determined as 

In operation up to x puzzle piece groups of n grams having the highest frequency for the position can be selected for generating candidate words.

In operation a set of ordered combinations of n gram s can be generated from the selected puzzle piece groups of n grams at each position to generate candidate new words. Each of the x n grams having the same puzzle piece selected at the first position can be permuted with each of the x n grams having the same puzzle piece at the second position etc. for all positions that the server is configured to process. The puzzle piece signifies an n gram at a position that belongs with an n gram at another position based on the n grams having been obtained from the same word having the same puzzle piece value.

In operation candidate words having a frequency less than a noise floor can be discarded. In an embodiment the noise floor is calculated similarly to the noise floor for n grams scaled by the maximum number of configured n grams per candidate word maximum.

The search space of candidate words can alternatively or in addition be trimmed by a number of techniques. In an embodiment natural language processing NLP techniques can be applied to trim combinations that are illogical or do not occur in a particular vocabulary. For example an n gram cc would not be followed by any of the following n grams oo ii uu zz etc. Permutations of such n gram sequences can be trimmed from the set of combinations.

In an embodiment an A search can be performed wherein the shortest combinations are traversed first to determine candidate words. NLP can be used to find combinations that are not viable and thus can be trimmed from the set of candidate combinations.

The above methods of trimming the search space of candidates can be used alone or in combination to trim the search space before using the n grams to learn new words.

In operation it can be determined whether the candidate new word is in an existing asset catalog or dictionary of words. Theoretically a newly found candidate word should not be found in an asset catalog or dictionary on new term learning server . Client devices should have the latest asset catalog containing the latest known words and the asset catalog is used by the client device to help eliminate known words from client and server processing. It is possible however that a client may not have upgraded to the latest asset catalog and thus the client may have sent a word that appears new to the client but is known to the server.

If in operation it is determined that the candidate word is in an existing asset catalog or dictionary of words then in an embodiment a frequency of the word can optionally be increased.

If in operation it is determined that the candidate word is a new word then the new word can be added to an updated asset catalog .

In operation it can be determined whether the permutations tree traversal is complete. If not then method continues at operation otherwise method continues at operation .

In operation term learning server can optionally transmit an updated asset catalog to one or more client devices.

In operation a differentially private sketch can be selected for each of n clients represented in the received and de identified data on new term learning server . A bit is generated from the sketch of each client by XORing the 1 bit vector of each row of the sketch for the client.

In operation it can be determined whether there are more client sketches to process. If so then method continues at operation . Otherwise method continues at operation .

In operation a sum of bits is computed using all of the B 1 . . . n computed above for one sketch for each client i of n clients. The sum A is computed as 

In operation a randomization tolerance is computed and it can be determined whether the randomization of clients is within tolerance. In an embodiment the randomization tolerance can be computed as 

If in operation randomization tolerance succeeds then in operation a message can be generated to a user interface of new term learning server indicating that randomization is within tolerance otherwise in operation and message can be generated to the user interface of new term learning server indicating that randomization is not within tolerance indicating that measures need to be taken to further ensure client device differential privacy. Measures could include modifying a randomization algorithm purging more client device data and or purging client device data more frequently.

In Software Stack an exemplary embodiment applications can make calls to Services 1 or 2 using several Service APIs and to Operating System OS using several OS APIs. Services 1 and 2 can make calls to OS using several OS APIs.

Note that the Service 2 has two APIs one of which Service 2 API 1 receives calls from and returns values to Application 1 and the other Service 2 API 2 receives calls from and returns values to Application 2 Service 1 which can be for example a software library makes calls to and receives returned values from OS API 1 and Service 2 which can be for example a software library makes calls to and receives returned values from both as API 1 and OS API 2 Application 2 makes calls to and receives returned values from as API 2.

Computing system includes bus or other communication device to communicate information and processor coupled to bus that may process information.

While computing system is illustrated with a single processor computing system may include multiple processors and or co processors . Computing system further may include random access memory RAM or other dynamic storage device referred to as main memory coupled to bus and may store information and instructions that may be executed by processor s . Main memory may also be used to store temporary variables or other intermediate information during execution of instructions by processor .

Computing system may also include read only memory ROM and or other static storage device coupled to bus that may store static information and instructions for processor s . Data storage device may be coupled to bus to store information and instructions. Data storage device such as flash memory or a magnetic disk or optical disc and corresponding drive may be coupled to computing system .

Computing system may also be coupled via bus to display device such as a cathode ray tube CRT or liquid crystal display LCD to display information to a user. Computing system can also include an alphanumeric input device including alphanumeric and other keys which may be coupled to bus to communicate information and command selections to processor s . Another type of user input device is cursor control such as a touchpad a mouse a trackball or cursor direction keys to communicate direction information and command selections to processor s and to control cursor movement on display . Computing system may also receive user input from a remote device that is communicatively coupled to computing system via one or more network interfaces .

Computing system further may include one or more network interface s to provide access to a network such as a local area network. Network interface s may include for example a wireless network interface having antenna which may represent one or more antenna e . Computing system can include multiple wireless network interfaces such as a combination of WiFi Bluetooth and cellular telephony interfaces. Network interface s may also include for example a wired network interface to communicate with remote devices via network cable which may be for example an Ethernet cable a coaxial cable a fiber optic cable a serial cable or a parallel cable.

In one embodiment network interface s may provide access to a local area network for example by conforming to IEEE 802.11 b and or IEEE 802.11 g standards and or the wireless network interface may provide access to a personal area network for example by conforming to Bluetooth standards. Other wireless network interfaces and or protocols can also be supported. In addition to or instead of communication via wireless LAN standards network interface s may provide wireless communications using for example Time Division Multiple Access TDMA protocols Global System for Mobile Communications GSM protocols Code Division Multiple Access CDMA protocols and or any other type of wireless communications protocol.

In the foregoing specification the invention has been described with reference to specific embodiments thereof. It will however be evident that various modifications and changes can be made thereto without departing from the broader spirit and scope of the invention. The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

