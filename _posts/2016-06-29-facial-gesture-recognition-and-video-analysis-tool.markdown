---

title: Facial gesture recognition and video analysis tool
abstract: Embodiments disclosed herein may be directed to a video communication server. In some embodiments, the video communication server includes: at least one memory including instructions; and at least one processing device configured for executing the instructions, wherein the instructions cause the at least one processing device to perform the operations of: determining a time duration of a video communication connection between a first user of a first user device and a second user of a second user device; analyzing video content transmitted between the first user device and the second user device; determining at least one gesture of at least one of the first user and the second user based on analyzing the video content; and generating a compatibility score of the first user and the second user based at least in part on the determined time duration and the at least one determined gesture.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09531998&OS=09531998&RS=09531998
owner: Krush Technologies, LLC
number: 09531998
owner_city: Dayton
owner_country: US
publication_date: 20160629
---
This application is a continuation in part of U.S. patent application Ser. No. 14 790 913 filed on Jul. 2 2015 and continuation in part of U.S. patent application Ser. No. 14 980 769 filed on Dec. 28 2015 the entire contents of both of which are hereby incorporated by reference in their entirety. This application claims benefit from U.S. Provisional Patent Application No. 62 274 682 filed on Jan. 4 2016 the entire contents of which are hereby incorporated by reference in its entirety.

Embodiments disclosed herein relate to a facial gesture recognition and video analysis tool for real time video communications between devices.

Today social media applications enable users across the world to generate and maintain relationships with others like never before. For example a user who recently moved to a new city may utilize a social media application to meet other users who live nearby in the new city as well as to reconnect with users in another city on the other side of the globe. Different social media applications enable users to communicate with others through a variety of communication channels such as text messaging audio messaging picture sharing and or live video streaming.

However communicating via social media applications has its share of shortcomings which are particularly evident when communication via social media applications is compared to in person communication. For example many social cues regularly identified and received during in person communication such as slight facial movements and or vocal inflections may be imperceivable and or otherwise go undetected over known social media communication channels. So while social media applications indeed provide a variety of channels for users to digitally interact with others across the world their users may still be presented with challenges associated with clarity and or quality of communication. Further systems and techniques as described herein may allow users to communicate more effectively with others by providing certain described contextual clues and feedback.

Briefly aspects of the present invention relate to improved communication clarity quality intelligence and security through the use of video analysis techniques and communications suggestions. In some embodiments a video communication server is provided. The video communication server may include a memory including instructions and a processing device configured to execute the instructions. The instructions may cause the processing device to perform the operations of determining using a communication unit in the processing device a duration of a video communication connection between first and second user devices analyzing using a graphical processing unit GPU in the processing device video content transmitted between the user devices determining using a gesture analysis unit in the processing device gestures of the users based on analyzing the video content and generating using a compatibility unit in the processing device a compatibility score of the first user and the second user based at least in part on the video communication connection duration and a gesture.

In some embodiments the instructions further cause the processing device to perform the operations of determining using a location unit in the processing device a location of a first user device identifying using the location unit a plurality of other user devices determined to be located within a predetermined proximity of the first user device and filtering using a profile management unit in the processing device another user device from the plurality of other user devices based on one or more user preferences of the first user to result in a filtered plurality of other user devices wherein the second user device is included in the filtered plurality of other user devices.

In some embodiments the instructions further cause the processing device to perform the operations of randomly selecting using the profile management unit the second user device from the filtered plurality of other user devices and establishing using the communication unit the video communication connection between the first user device and the second user device.

In some embodiments determining a gesture includes identifying using a facial recognition unit in the processing device a facial feature of the first user in the video content at a first time identifying using the facial recognition unit the facial feature of the first user in the video content at a second time and determining using the facial recognition unit movement of the facial feature from a first location at a first time to a second location at a second time wherein the determined movement of the facial feature includes a gesture.

In some embodiments generating a compatibility score includes assigning using the compatibility unit a numerical value to the determined video communication connection duration and to the gesture weighting using the compatibility unit the numerical value of the determined video communication connection duration and the numerical value of the gesture and processing according to operations included in a computer readable memory in the compatibility unit the numerical value of the determined time duration and the numerical value of the gesture.

In some embodiments analyzing the video content includes determining using the GPU a numerical value of a pixel associated with a facial feature identified in the video content.

In some embodiments generating the compatibility score includes identifying using a vocal recognition unit in the processing device a first vocal pitch of the first user in the video content at a first time identifying using the vocal recognition unit a second vocal pitch of the first user in the video content at a second time and determining using the vocal recognition unit a change of vocal pitch of the first user wherein the change of vocal pitch includes a gesture.

In some embodiments a non transitory computer readable medium including code is provided. The code may when executed by a processing device of a video communication server cause the processing device to perform the operations of determining using a communication unit included in the processing device a duration of a video communication connection between a first user of a first user device and a second user of a second user device analyzing using a graphical processing unit GPU in the processing device video content transmitted between the first user device and the second user device determining using a gesture analysis unit in the processing device a gesture of one of the first user and the second user based on analyzing the video content and generating using a compatibility unit included in the processing device a compatibility score of the first user and the second user based at least in part on the determined video communication connection duration and the gesture.

In some embodiments the non transitory computer readable medium further includes code that when executed by the processing device of the video communication server causes the processing device to perform the operations of determining using a location unit in the processing device a location of a first user device identifying using the location unit a plurality of other user devices determined to be located within a predetermined proximity of the first user device and filtering using a profile management unit in the processing device another user device from the plurality of other user devices based user preferences of the first user to result in a filtered plurality of other user devices wherein the second user device is included in the filtered plurality of other user devices.

In some embodiments the non transitory computer readable medium further includes code that when executed by the processing device of the video communication server causes the processing device to perform the operations of randomly selecting using the profile management unit the second user device from the filtered plurality of other user devices and establishing using the communication unit the video communication connection between the first and second user devices.

In some embodiments the non transitory computer readable medium further includes code that when executed by the processing device of the video communication server causes the processing device to perform the operations of identifying using a facial recognition unit in the processing device a facial feature of the first user in the video content at a first time identifying using the facial recognition unit the facial feature of the first user in the video content at a second time and determining using the facial recognition unit movement of the facial feature from a first location at a first time to a second location at a second time wherein the determined movement of the facial feature includes a gesture.

In some embodiments the non transitory computer readable medium further includes code that when executed by the processing device of the video communication server causes the processing device to perform the operations of identifying using a vocal recognition unit in the processing device a first vocal pitch of the first user in the video content at a first time identifying using the vocal recognition unit a second vocal pitch of the first user in the video content at a second time and determining using the vocal recognition unit a change of vocal pitch of the first user wherein the change of vocal pitch includes a gesture.

In some embodiments the non transitory computer readable medium further includes code that when executed by the processing device of the video communication server causes the processing device to perform the operations of assigning using the compatibility unit a numerical value to the determined video communication connection duration and the gesture weighting using the compatibility unit the numerical value of the determined video communication connection duration and the numerical value of the gesture and processing according to operations included in computer readable memory in the compatibility unit the numerical value of the determined video communication connection duration and the numerical value of the gesture.

In some embodiments the non transitory computer readable medium further includes code that when executed by the processing device of the video communication server causes the processing device to perform the operations of determining using the GPU a numerical value of a pixel associated with a facial feature identified in the video content.

In some embodiments the provided method may include determining using a communication unit in a processing device a time duration of a video communication connection between first and second user devices analyzing using a graphical processing unit GPU in the processing device video content transmitted between the first and second user devices determining using a gesture analysis unit in the processing device a gesture of either or both of first and second users based on analyzing the video content and generating using a compatibility unit in the processing device a compatibility score of the first user and the second user based at least in part on the determined video communication connection duration and the gesture.

In some embodiments the method further includes determining using a location unit in the processing device a location of a first user device identifying using the location unit a plurality of other user devices determined to be located within a predetermined proximity of the first user device and filtering using a profile management unit in the processing device another user device from the plurality of other user devices based on user preferences of the first user to result in a filtered plurality of other user devices wherein the second user device is included in the filtered plurality of other user devices.

In some embodiments the method further includes randomly selecting using the profile management unit the second user device from the filtered plurality of other user devices and establishing using the communication unit the video communication connection between the first and second user devices.

In some embodiments the method further includes identifying using a facial recognition unit in the processing device a facial feature of the first user in the video content at a first time identifying using the facial recognition unit the facial feature of the first user in the video content at a second time and determining using the facial recognition unit movement of the facial feature from a first location at a first time to a second location at a second time wherein the determined movement of the facial feature includes a gesture.

In some embodiments the method further includes identifying using a vocal recognition unit in the processing device a first vocal pitch of the first user in the video content at a first time identifying using the vocal recognition unit a second vocal pitch of the first user in the video content at a second time and determining using the vocal recognition unit a change of vocal pitch of the first user wherein the change of vocal pitch includes a gesture.

In some embodiments the method further includes assigning using the compatibility unit a numerical value to the determined video communication connection duration and to the gesture weighting using the compatibility unit the numerical value of the determined video communication connection duration and the numerical value of the gesture and processing according to an algorithm included in the compatibility unit the numerical value of the determined video communication connection duration and the numerical value of the gesture.

In the various figures the same reference numbers are provided for the same system elements whereas in other instances similar elements shown in different figures may have different reference numbers. The figures and associated description provide a plurality of different embodiments and similar elements among the figures will illustrate to one of ordinary skill in the art the possible functionality and connection of those elements in the multiple and collective embodiments disclosed herein.

Embodiments of the present disclosure may be directed to a system that enables establishment of a video communication connection between two or more user devices. In addition to providing a video communication channel via which the two or more users may communicate the system may further enable real time analysis of video content e.g. the live video feed transmitted between the user devices during the video communication connection. Through analysis of the transmitted video content the system may repeatedly detect facial features of the users to ensure that images and or video feeds of the users faces are appropriately captured and transmitted via the video communication connection. The system may further provide security and blocking of objectionable content such as by ensuring that only a user s facial images are transmitted. Additionally the system may identify various social cues such as facial gestures and or vocal inflections of each user. Upon identification the system may assign a numerical value to each identified social cue. In this manner emotional intelligence associated with social cues readily recognized by people during in person communication that may otherwise have been undetected by users of the video communication connection may be considered by the system when generating a compatibility score of the users and or to otherwise provide social cues to the users.

Referring now to the figures illustrates an exemplary video communication connection for enabling a video communication between a first user and a second user . For example each of the first user and the second user may hold a user device e.g. a first user device and a second user device respectively such as a smartphone or tablet in front of his or her face so that a camera included in each respective user device may capture a live video feed of each user s face e.g. the first user s face and or the second user s face . The first user s face may be presented to the second user on the second user device as well as on the first user device for monitoring purposes. Similarly the second user s face may be presented to the first user on the first user device as well as on the second user device for monitoring purposes. Additionally an inset display may further provide information associated with the first user and the second user e.g. a virtual currency balance a status and or the like in an inset display on the first user device and the second user device respectively.

To ensure that only faces of the users are displayed throughout the entirety of the video communication connection as opposed to inappropriate body parts or other potentially undesirable images a video communication server not pictured in but shown in facilitating the video communication connection may analyze the live video feeds of the users . Additionally and or alternatively each user s respective user device may facilitate the video communication connection and or analyze the live video feeds of the users in accordance with embodiments described herein. Analyzing the live video feeds may enable the video communication server and or the user devices to detect facial features of each user . If the cameras capturing live video feeds of the respective users capture subject matter that is determined by the server to not be a part of the user s face e.g. identifies non facial features or an absence of any facial features in the live video feed then the video communication server and or the user devices may terminate the video communication connection or take another action such as interrupting the live video feeds filtering or obscuring all or part of the video images and or adjusting the focus of the respective cameras for security purposes and or decency considerations.

Continuing with the same example under the assumption that each user allows the camera to capture only her or his face and or the video communication server otherwise provides suitable security measures the video communication server and or the user devices may further analyze the live video feeds of each user s face during the video communication connection to identify social cues such as facial gestures or vocal inflections of each user . Social cues may be identified by the video communication server and or the user devices using a variety of video analysis techniques including comparisons of facial feature locations over time. For example the video communication server and or the user devices may identify social cues of each user based on detected movements of facial features and or changes in vocal pitch or tone identified in the live video feeds.

An exemplary social cue identification may include the video communication server and or the user devices detecting raised eyebrows and a smile of the first user based on an analysis of facial images transmitted during the video communication connection. The video communication server and or the user devices may determine based on a predetermined table and or database of known social cues that these detected social cues e.g. raised eyebrows and smile convey the first user s interest in the second user . Accordingly the video communication server and or the user devices may then assign the detected raised eyebrow gesture and the detected smile gesture to corresponding numerical values. The video communication server and or the user devices may then combine the assigned numerical values with other numerical values associated with other detected social cues of the users as well as numerical values associated with external factors such as a duration of the video communication connection to generate a compatibility score of the two users . The compatibility score may numerically communicate how compatible the two users may be with each other based on social cues detected by the video communication server and or the user devices during the video communication connection.

After the video communication connection is terminated the video communication server and or the user devices may present to each user the generated compatibility score which may be contemplated by the users when determining whether they would like to pursue subsequent communication with each other. In this manner embodiments disclosed herein may be useful in a variety of social media applications including but not limited to video speed dating applications.

In some embodiments the system may include the first user device the second user device and a video communication server . In some embodiments the first user device and or the second user device may include a handheld computing device a smart phone a tablet a laptop computer a desktop computer a personal digital assistant PDA a smart watch a wearable device a biometric device an implanted device a camera a video recorder an audio recorder a touchscreen a computer server or video communications server and or the like. In some embodiments the first user device and or the second user device may each include a plurality of user devices as described herein. In some embodiments the first user device may include various elements of a computing environment as described herein. For example the first user device may include a processing unit a memory unit an input output I O unit and or a communication unit . Each of the processing unit the memory unit the input output I O unit and or the communication unit may include one or more subunits as described herein for performing operations associated with providing relevant contextual features to the first user during a video communication connection.

In some embodiments the second user device may include various elements of a computing environment as described herein. For example the second user device may include a processing unit a memory unit an input output I O unit and or a communication unit . Each of the processing unit the memory unit the input output I O unit and or the communication unit may include one or more subunits as described herein for performing operations associated with providing relevant contextual features to the second user during a video communication connection.

In some embodiments the video communication server may include a computing device such as a mainframe server a content server a communication server a laptop computer a desktop computer a handheld computing device a smart phone a smart watch a wearable device a touch screen a biometric device a video processing device an audio processing device a cloud based computing solution and or service and or the like. In some embodiments the video communication server may include a plurality of video communication servers configured to communicate with one another and or implement load balancing techniques described herein.

In some embodiments the video communication server may include various elements of a computing environment as described herein. For example the video communication server may include a processing unit a memory unit an input output I O unit and or a communication unit . Each of the processing unit the memory unit the input output I O unit and or the communication unit may include one or more subunits and or other computing instances as described herein for performing operations associated with identifying relevant contextual features for presentation to one or more users e.g. the first user and or the second user during a video communication connection.

The first user device the second user device and or the video communication sever may be communicatively coupled to one another by a network as described herein. In some embodiments the network may include a plurality of networks. In some embodiments the network may include any wireless and or wired communications network that facilitates communication between the first user device the second user device and or the video communication server . For example the one or more networks may include an Ethernet network a cellular network a computer network the Internet a wireless fidelity Wi Fi network a light fidelity Li Fi network a Bluetooth network a radio frequency identification RFID network a near field communication NFC network a laser based network and or the like.

The video communication server may include among other elements a processing unit a memory unit an input output I O unit and or a communication unit . As described herein each of the processing unit the memory unit the I O unit and or the communication unit may include and or refer to a plurality of respective units subunits and or elements. Furthermore each of the processing unit the memory unit the I O unit and or the communication unit may be operatively and or otherwise communicatively coupled with each other so as to facilitate the video communication and analysis techniques described herein.

The processing unit may control any of the one or more units as well as any included subunits elements components devices and or functions performed by the units included in the video communication server . The described sub elements of the video communication server may also be included in similar fashion in any of the other units and or devices included in the system of . Additionally any actions described herein as being performed by a processor may be taken by the processing unit alone and or by the processing unit in conjunction with one or more additional processors units subunits elements components devices and or the like. Additionally while only one processing unit may be shown in and or multiple processing units may be present and or otherwise included in the video communication server or elsewhere in the overall system e.g. system of . Thus while instructions may be described as being executed by the processing unit and or various subunits of the processing unit the instructions may be executed simultaneously serially and or otherwise by one or multiple processing units .

In some embodiments the processing unit may be implemented as one or more computer processing unit CPU chips and or graphical processing unit GPU chips and may include a hardware device capable of executing computer instructions. The processing unit may execute instructions codes computer programs and or scripts. The instructions codes computer programs and or scripts may be received from and or stored in the memory unit the I O unit the communication unit subunits and or elements of the aforementioned units other devices and or computing environments and or the like.

In some embodiments the processing unit may include among other elements subunits such as a profile management unit a content management unit a location determination unit a graphical processing unit GPU a facial vocal recognition unit a gesture analysis unit a compatibility unit and or a resource allocation unit . Each of the aforementioned subunits of the processing unit may be communicatively and or otherwise operably coupled with each other.

The profile management unit may facilitate generation modification analysis transmission and or presentation of a user profile associated with a user. For example the profile management unit may prompt a user via a user device to register by inputting authentication credentials personal information e.g. an age a gender and or the like contact information e.g. a phone number a zip code a mailing address an email address a name and or the like and or the like. The profile management unit may also control and or utilize an element of the I O unit to enable a user of the user device to take a picture of herself himself. The profile management unit may receive process analyze organize and or otherwise transform any data received from the user and or another computing element so as to generate a user profile of a user that includes personal information contact information user preferences a photo a video recording an audio recording a textual description a virtual currency balance a history of user activity user preferences settings and or the like.

The content management unit may facilitate generation modification analysis transmission and or presentation of media content. For example the content management unit may control the audio visual environment and or appearance of application data during execution of various processes. Media content for which the content management unit may be responsible may include advertisements images text themes audio files video files documents and or the like. In some embodiments the content management unit may also interface with a third party content server and or memory location.

The location determination unit may facilitate detection generation modification analysis transmission and or presentation of location information. Location information may include global positioning system GPS coordinates an Internet protocol IP address a media access control MAC address geolocation information an address a port number a zip code a server number a proxy name and or number device information e.g. a serial number and or the like. In some embodiments the location determination unit may include various sensors a radar and or other specifically purposed hardware elements for enabling the location determination unit to acquire measure and or otherwise transform location information.

The GPU unit may facilitate generation modification analysis processing transmission and or presentation of visual content e.g. media content described above . In some embodiments the GPU unit may be utilized to render visual content for presentation on a user device analyze a live streaming video feed for metadata associated with a user and or a user device responsible for generating the live video feed and or the like. The GPU unit may also include multiple GPUs and therefore may be configured to perform and or execute multiple processes in parallel.

The facial vocal recognition unit may facilitate recognition analysis and or processing of visual content such as a live video stream of a user s face. For example the facial vocal recognition unit may be utilized for identifying facial features of users and or identifying vocal inflections of users. In some embodiments the facial vocal recognition unit may include GPUs and or other processing elements so as to enable efficient analysis of video content in either series or parallel. The facial vocal recognition unit may utilize a variety of audio visual analysis techniques such as pixel comparison pixel value identification voice recognition audio sampling video sampling image splicing image reconstruction video reconstruction audio reconstruction and or the like to verify an identity of a user to verify and or monitor subject matter of a live video feed and or the like.

The gesture analysis unit may facilitate recognition analysis and or processing of visual content such as a live video stream of a user s face. Similar to the facial vocal recognition unit the gesture analysis unit may be utilized for identifying facial features of users and or identifying vocal inflections of users. Further however the gesture analysis unit may analyze movements and or changes in facial features and or vocal inflection identified by the facial vocal recognition unit to identify social cues of users. As used herein social cues may include facial gestures such as eyebrow movements eyeball movements eyelid movements ear movements nose and or nostril movements lip movements chin movements cheek movements forehead movements tongue movements teeth movements vocal pitch shifting vocal tone shifting changes in word delivery speed keywords word count and or the like.

The compatibility unit may facilitate analysis and or processing of social cues identified by the gesture analysis unit . For example the compatibility unit may quantify identified social cues by assigning a numerical value e.g. an alphanumeric character to each identified social cue. In some embodiments numerical values of identified social cues may be weighted and or assigned a grade e.g. an alphanumeric label such as A B C D F and or the like associated with a perceived value and or quality by the compatibility unit . In addition to assigning numerical values of identified social cues the compatibility unit may quantify and or otherwise utilize other factors associated with the video communication connection such as a time duration of the video communication connection an intensity of an identified social cue and or the like. For example the compatibility unit may assign a larger weight to an identified social cue that occurred during a video communication connection lasting one minute than an identified social cue that occurred during a video communication connection lasting thirty seconds. The compatibility unit may determine appropriate numerical values based on a predetermined table of predefined social cues and or a variety of factors associated with a video communication connection such as time duration a frequency intensity and or duration of an identified social cue and or the like.

The compatibility unit may also facilitate the collection receipt processing analysis and or transformation of user input received from user devices of users participating in a video communication connection e.g. user devices of and or user devices of . For example the compatibility unit may facilitate the prompting of a first participant in a video communication connection to provide feedback of a second participant. This feedback may be received processed weighted and or transformed by the compatibility unit .

The compatibility unit may further utilize the numerical values of identified social cues and or other factors as well as any received feedback e.g. user inputs such as textual and or numerical reviews and or the like to generate a compatibility score associated with the compatibility of the two users between which the video communication is held. In some embodiments the compatibility score may be indicative of a how well the two users may get along in subsequent communications e.g. video communications in person communications and or the like . As such the compatibility unit may facilitate presentation of the compatibility score to each participant of a video communication connection after termination of the video communication connection. In some embodiments the compatibility unit may generate and or otherwise represent a compatibility score in the form of a percentage an alphanumerical grade an icon a sound an image text a color and or the like.

Additionally the compatibility unit may facilitate alone and or in conjunction with the communication unit the profile management unit and or the location determination unit matching of user profiles based on information associated with user profiles of users determined to be located in a predetermined location and or in proximity of a predetermined location a user history of generated compatibility scores associated with a user and or the like. As described herein any unit and or subunit e.g. element of the video communication server and or any other computing environment may be utilized to perform any operation. Particularly the video communication server may not include a generic computing system but instead may include a customized computing system designed to perform the various methods described herein.

The resource allocation unit may facilitate the determination monitoring analysis and or allocation of computing resources throughout the video communication server and or other computing environments. For example the video communication server may facilitate a high volume of e.g. multiple video communication connections between a large number of supported users and or associated user devices. As such computing resources of the video communication server utilized by the processing unit the memory unit the I O unit and or the communication unit and or any subunit of the aforementioned units such as processing power data storage space network bandwidth and or the like may be in high demand at various times during operation. Accordingly the resource allocation unit may be configured to manage the allocation of various computing resources as they are required by particular units and or subunits of the video communication server and or other computing environments. In some embodiments the resource allocation unit may include sensors and or other specially purposed hardware for monitoring performance of each unit and or subunit of the video communication server as well as hardware for responding to the computing resource needs of each unit and or subunit. In some embodiments the resource allocation unit may utilize computing resources of a second computing environment separate and distinct from the video communication server to facilitate a desired operation.

For example the resource allocation unit may determine a number of simultaneous video communication connections and or incoming requests for establishing video communication connections. The resource allocation unit may then determine that the number of simultaneous video communication connections and or incoming requests for establishing video communication connections meets and or exceeds a predetermined threshold value. Based on this determination the resource allocation unit may determine an amount of additional computing resources e.g. processing power storage space of a particular non transitory computer readable memory medium network bandwidth and or the like required by the processing unit the memory unit the I O unit the communication unit and or any subunit of the aforementioned units for enabling safe and efficient operation of the video communication server while supporting the number of simultaneous video communication connections and or incoming requests for establishing video communication connections. The resource allocation unit may then retrieve transmit control allocate and or otherwise distribute determined amount s of computing resources to each element e.g. unit and or subunit of the video communication server and or another computing environment.

In some embodiments factors affecting the allocation of computing resources by the resource allocation unit may include the number of ongoing video communication connections and or other communication channel connections a duration of time during which computing resources are required by one or more elements of the video communication server and or the like. In some embodiments computing resources may be allocated to and or distributed amongst a plurality of second computing environments included in the video communication server based on one or more factors mentioned above. In some embodiments the allocation of computing resources of the resource allocation unit may include the resource allocation unit flipping a switch adjusting processing power adjusting memory size partitioning a memory element transmitting data controlling one or more input and or output devices modifying various communication protocols and or the like. In some embodiments the resource allocation unit may facilitate utilization of parallel processing techniques such as dedicating a plurality of GPUs included in the processing unit for processing a high quality video stream of a video communication connection between multiple units and or subunits of the video communication server and or other computing environments.

In some embodiments the memory unit may be utilized for storing recalling receiving transmitting and or accessing various files and or information during operation of the video communication server . For example the memory unit may be utilized for storing video streams storing recalling and or updating user profile information and or the like. The memory unit may include various types of data storage media such as solid state storage media hard disk storage media and or the like. The memory unit may include dedicated hardware elements such as hard drives and or servers as well as software elements such as cloud based storage drives. For example the memory unit may include various subunits such as an operating system unit an application data unit an application programming interface API unit a profile storage unit a content storage unit a video storage unit a secure enclave and or a cache storage unit .

The memory unit and or any of its subunits described herein may include random access memory RAM read only memory ROM and or various forms of secondary storage. RAM may be used to store volatile data and or to store instructions that may be executed by the processing unit . For example the data stored may be a command a current operating state of the video communication server an intended operating state of the video communication server and or the like. As a further example data stored in the memory unit may include instructions related to various methods and or functionalities described herein. ROM may be a non volatile memory device that may have a smaller memory capacity than the memory capacity of a secondary storage. ROM may be used to store instructions and or data that may be read during execution of computer instructions. In some embodiments access to both RAM and ROM may be faster than access to secondary storage. Secondary storage may be comprised of one or more disk drives and or tape drives and may be used for non volatile storage of data or as an over flow data storage device if RAM is not large enough to hold all working data. Secondary storage may be used to store programs that may be loaded into RAM when such programs are selected for execution. In some embodiments the memory unit may include one or more databases for storing any data described herein. Additionally or alternatively one or more secondary databases located remotely from the video communication server may be utilized and or accessed by the memory unit .

The operating system unit may facilitate deployment storage access execution and or utilization of an operating system utilized by the video communication server and or any other computing environment described herein e.g. a user device such as user devices of and or user devices of . In some embodiments the operating system may include various hardware and or software elements that serve as a structural framework for enabling the processing unit to execute various operations described herein. The operating system unit may further store various pieces of information and or data associated with operation of the operating system and or the video communication server as a whole such as a status of computing resources e.g. processing power memory availability resource utilization and or the like runtime information modules to direct execution of operations described herein user permissions security credentials and or the like.

The application data unit may facilitate deployment storage access execution and or utilization of an application utilized by the video communication server and or any other computing environment described herein e.g. a user device . For example users may be required to download access and or otherwise utilize a software application on a user device such as a smartphone in order for various operations described herein to be performed. As such the application data unit may store any information and or data associated with the application. Information included in the application data unit may enable a user to execute various operations described herein. The application data unit may further store various pieces of information and or data associated with operation of the application and or the video communication server as a whole such as a status of computing resources e.g. processing power memory availability resource utilization and or the like runtime information modules to direct execution of operations described herein user permissions security credentials and or the like.

The API unit may facilitate deployment storage access execution and or utilization of information associated with APIs of the video communication server and or any other computing environment described herein e.g. a user device . For example video communication server may include one or more APIs for enabling various devices applications and or computing environments to communicate with each other and or utilize the same data. Accordingly the API unit may include API databases containing information that may be accessed and or utilized by applications and or operating systems of other devices and or computing environments. In some embodiments each API database may be associated with a customized physical circuit included in the memory unit and or the API unit . Additionally each API database may be public and or private and so authentication credentials may be required to access information in an API database.

The profile storage unit may facilitate deployment storage access and or utilization of information associated with user profiles of users by the video communication server and or any other computing environment described herein e.g. a user device . For example the profile storage unit may store one or more user s contact information authentication credentials user preferences user history of behavior personal information and or metadata. In some embodiments the profile storage unit may communicate with the profile management unit to receive and or transmit information associated with a user s profile.

The content storage unit may facilitate deployment storage access and or utilization of information associated with requested content by the video communication server and or any other computing environment described herein e.g. a user device . For example the content storage unit may store one or more images text videos audio content advertisements and or metadata to be presented to a user during operations described herein. In some embodiments the content storage unit may communicate with the content management unit to receive and or transmit content files.

The video storage unit may facilitate deployment storage access analysis and or utilization of video content by the video communication server and or any other computing environment described herein e.g. a user device . For example the video storage unit may store one or more live video feeds transmitted during a video communication connection. Live video feeds of each user transmitted during a video communication connection may be stored by the video storage unit so that the live video feeds may be analyzed by various components of the video communication server both in real time and at a time after receipt of the live video feeds. In some embodiments the video storage unit may communicate with the GPUs the facial vocal recognition unit the gesture analysis unit and or the compatibility unit to facilitate analysis of any stored video information. In some embodiments video content may include audio images text video feeds and or any other media content.

The secure enclave may facilitate secure storage of data. In some embodiments the secure enclave may include a partitioned portion of storage media included in the memory unit that is protected by various security measures. For example the secure enclave may be hardware secured. In other embodiments the secure enclave may include one or more firewalls encryption mechanisms and or other security based protocols. Authentication credentials of a user may be required prior to providing the user access to data stored within the secure enclave .

The cache storage unit may facilitate short term deployment storage access analysis and or utilization of data. For example the cache storage unit may be utilized for storing numerical values associated with users recognized facial gestures for computing a compatibility score immediately after termination of a video communication connection. In some embodiments the cache storage unit may serve as a short term storage location for data so that the data stored in the cache storage unit may be accessed quickly. In some embodiments the cache storage unit may include RAM and or other storage media types that enable quick recall of stored data. The cache storage unit may included a partitioned portion of storage media included in the memory unit .

The I O unit may include hardware and or software elements for enabling the video communication server to receive transmit and or present information. For example elements of the I O unit may be used to receive user input from a user via a user device present a live video feed to the user via the user device and or the like. In this manner the I O unit may enable the video communication server to interface with a human user. As described herein the I O unit may include subunits such as an I O device an I O calibration unit and or video driver .

The I O device may facilitate the receipt transmission processing presentation display input and or output of information as a result of executed processes described herein. In some embodiments the I O device may include a plurality of I O devices. In some embodiments the I O device may include one or more elements of a user device a computing system a server and or a similar device.

The I O device may include a variety of elements that enable a user to interface with the video communication server . For example the I O device may include a keyboard a touchscreen a button a sensor a biometric scanner a laser a microphone a camera and or another element for receiving and or collecting input from a user. Additionally and or alternatively the I O device may include a display a screen a sensor a vibration mechanism a light emitting diode LED a speaker a radio frequency identification RFID scanner and or another element for presenting and or otherwise outputting data to a user. In some embodiments the I O device may communicate with one or more elements of the processing unit and or the memory unit to execute operations described herein. For example the I O device may include a display which may utilize the GPU to present video content stored in the video storage unit to a user of a user device during a video communication connection.

The I O calibration unit may facilitate the calibration of the I O device . For example the I O calibration unit may detect and or determine one or more settings of the I O device and then adjust and or modify settings so that the I O device may operate more efficiently.

In some embodiments the I O calibration unit may utilize a video driver or multiple video drivers to calibrate the I O device . For example the video driver may be installed on a user device so that the user device may recognize and or integrate with the I O device thereby enabling video content to be displayed received generated and or the like. In some embodiments the I O device may be calibrated by the I O calibration unit by based on information included in the video driver .

The communication unit may facilitate establishment maintenance monitoring and or termination of communications e.g. a video communication connection between the video communication server and other devices such as user devices e.g. user devices of and or user devices of other computing environments third party server systems and or the like. The communication unit may further enable communication between various elements e.g. units and or subunits of the video communication server . In some embodiments the communication unit may include a network protocol unit an API gateway an encryption engine and or a communication device . The communication unit may include hardware and or software elements.

The network protocol unit may facilitate establishment maintenance and or termination of a communication connection between the video communication server and another device e.g. user devices of and or user devices of by way of a network. For example the network protocol unit may detect and or define a communication protocol required by a particular network and or network type. Communication protocols utilized by the network protocol unit may include Wi Fi protocols Li Fi protocols cellular data network protocols Bluetooth protocols WiMAX protocols Ethernet protocols powerline communication PLC protocols and or the like. In some embodiments facilitation of communication between the video communication server and any other device as well as any element internal to the video communication server may include transforming and or translating data from being compatible with a first communication protocol to being compatible with a second communication protocol. In some embodiments the network protocol unit may determine and or monitor an amount of data traffic to consequently determine which particular network protocol is to be used for establishing a video communication connection transmitting data and or performing other operations described herein.

The API gateway may facilitate the enablement of other devices and or computing environments to access the API unit of the memory unit of the video communication server . For example a user device may access the API unit via the API gateway . In some embodiments the API gateway may be required to validate user credentials associated with a user of a user device prior to providing access to the API unit to the user. The API gateway may include instructions for enabling the video communication server to communicate with another device.

The encryption engine may facilitate translation encryption encoding decryption and or decoding of information received transmitted and or stored by the video communication server . Using the encryption engine each transmission of data may be encrypted encoded and or translated for security reasons and any received data may be encrypted encoded and or translated prior to its processing and or storage. In some embodiments the encryption engine may generate an encryption key an encoding key a translation key and or the like which may be transmitted along with any data content.

The communication device may include a variety of hardware and or software specifically purposed to enable communication between the video communication server and another device as well as communication between elements of the video communication server . In some embodiments the communication device may include one or more radio transceivers chips analog front end AFE units antennas processing units memory other logic and or other components to implement communication protocols wired or wireless and related functionality for facilitating communication between the video communication server and any other device. Additionally and or alternatively the communication device may include a modem a modem bank an Ethernet device such as a router or switch a universal serial bus USB interface device a serial interface a token ring device a fiber distributed data interface FDDI device a wireless local area network WLAN device and or device component a radio transceiver device such as code division multiple access CDMA device a global system for mobile communications GSM radio transceiver device a universal mobile telecommunications system UMTS radio transceiver device a long term evolution LTE radio transceiver device a worldwide interoperability for microwave access WiMAX device and or another device used for communication purposes.

With specific reference to the system diagram of the video communication server of an exemplary operation of the video communication server is described. To begin operation of embodiments described herein a user of a user device e.g. user device of may download an application associated with operations described herein to a user device e.g. user device of . For example the user may download the application from an application store or a library of applications that are available for download via an online network. In some embodiments downloading the application may include transmitting application data from the application data unit of the video communication server to the user device e.g. user device of via the communication unit .

Upon download and installation of the application on the user device e.g. user device of the user may select and open the application. The application may then prompt the user via the user device e.g. user device of to register and create a user profile. The user may input through the user s respective device s I O unit authentication credentials such as a username and password an email address contact information personal information e.g. an age a gender and or the like user preferences and or other information as part of the user registration process. This inputted information as well as any other information described herein may be inputted by the user of the user device and or outputted by the video communication server to the user of the user device using the I O device . Once inputted the information may be received by the user device and subsequently transmitted from the user device to the profile management unit of the processing unit and or the profile storage unit of the memory unit which receive s the inputted information via the communication unit .

In some embodiments registration of the user may include transmitting a text message and or another message type requesting the user to confirm registration and or any inputted information to be included in the user profile from the profile management unit to the user device e.g. user device of . The user may confirm registration via the user device e.g. user device of and an acknowledgement may be transmitted from the user device e.g. user device of via the communication unit to the profile management unit of the processing unit which receives the acknowledgement and generates the user profile based on the inputted information.

After registration is complete the user may be prompted by the application e.g. application data stored in the application data unit via the API interface the API gateway and or the communication device to select a gender corresponding to users with which the user desires to be connected via the application. For example if the user is a female and wants to video chat with males then the female may select male as a desired gender. Alternatively the user may not select a gender and therefore the gender of other users with whom the user may share a video communication connection may be random. The selected or unselected gender preference of other users may be received by the I O device associated with an I O unit of a respective user device and subsequently transmitted from the user device to the computing environment for storage in the profile storage unit .

Next the user may utilize an I O device associated with an I O unit of her his user device to capture an picture of her or his face. This picture once generated may be included in the user profile of the user for identification of the user. In some embodiments the user may capture an image of her or his face using a camera on the user device e.g. a smartphone camera . In other embodiments the user may simply select and or upload an existing image file using the user device. The user may further be enabled to modify the image by applying a filter cropping the image changing the color and or size of the image and or the like. Accordingly the user device may receive the image and or image file and transmit the image to the video communication server for processing. Alternatively the image may be processed locally on the user device.

The image may be received and analyzed e.g. processed by the facial vocal recognition unit . In some embodiments the facial vocal recognition unit may utilize the GPU for analysis of the image. The facial vocal recognition unit may process the image of the user s face to identify human facial features. This functionality might be found in one of the processing units of the respective user devices and or in the processing unit of the video communication server . Various techniques may be deployed during processing of the image to identify facial features such as pixel color value comparison. For example the facial vocal recognition unit may identify objects of interest in the image based on a comparison of pixel color values and or locations in the image. Each identified object of interest may be counted and compared to predetermined and or otherwise known facial features included in a database using the facial vocal recognition unit . The facial vocal recognition unit may determine at least a partial match e.g. a partial match that meets and or exceeds a predetermined threshold of confidence between an identified object of interest and a known facial feature to thereby confirm that the object of interest in the image is indeed a facial feature of the user. Based on a number and or a location of identified facial features in the image the facial vocal recognition unit may determine that the image is a picture of the user s face as opposed to other subject matter inappropriate subject matter and or the like . In this manner the facial vocal recognition unit provides a layer of security by ensuring that each image included in a user s profile is a picture of the user s face.

When the facial vocal recognition unit determines that the image is an acceptable picture of the user s face the video communication server may store the image in the profile storage unit so that the image may be included in the user s user profile. Conversely when the facial vocal recognition unit determines that the image is not an acceptable picture of the user s face e.g. the image is determined to not be a picture of the user s face the facial vocal recognition unit may generate a notification to be sent to and or displayed by the user device for presentation to the user that explains that the provided image is unacceptable. The user may then repeat the process of capturing an image of her or his face and or resubmitting an existing image file using the user device. In some embodiments the user may be prohibited by the facial vocal recognition unit of the video communication server and or a video driver of her his respective user device from continuing application use until an image of the user s face is determined by the facial vocal recognition unit to be legitimate. As an additional security measure an additional personal screening may be provided for an acceptable base image. This base image may be specifically compared via computer video processing of live images for closeness.

As stated above the image may be processed by the facial vocal recognition unit on the user device. In other embodiments the image may be transmitted to another device e.g. video communication server a third party server and or the like for processing. In some embodiments any facial features of the user identified by the facial vocal recognition unit may be stored in the profile storage unit for later recall during analysis of video content of the user.

Next the location determination unit may determine the location of the user device of the user and therefore the user using various techniques. For example the location determination under may determine GPS coordinates an IP address a proximity of a predetermined location a nearest zip code and or the like of the user device. Location information of the user s user device may be stored by the video communication server in the profile storage unit so that it may be included in the user s user profile. In some embodiments the location determination unit of the video communication server may perform the location determination steps associated with locating a user device e.g. user device of described herein. Alternatively the location determination unit local to a user device may perform the location determination steps associated with locating a user device e.g. user device of described herein.

Once the image of the user s face is detected and or determined to be sufficient for inclusion in the user s user profile by the facial vocal recognition unit and the location of the user s user device is determined by the location determination unit the user may initiate using the user device e.g. user device of a request to begin a video communication connection between the user device and a second user device of another user. For example in the context of a social media application that enables users to video chat in a speed dating format the user may initiate a request to be connected to another user of the desired gender or an unspecified gender within a predetermined proximity of the determined location of the user s user device e.g. user device of . In some embodiments the request may be initiated by the user using the I O device within the I O unit of the user device . For example the user may perform a gesture recognized by the I O device and or the gesture analysis unit such as holding down one finger on a touchscreen for a predetermined amount of time to initiate the request.

After initiation the request may be transmitted to and or received by the communication unit of the video communication server . The request may include connection information such as wireless band information encryption information wireless channel information communication protocols and or standards and or other information required for establishing a video communication connection between the user device and a second user device.

The communication unit may then utilize one or more units of the processing unit and or the memory unit to determine a device with which the user device may establish a communication connection. For example the communication unit may utilize the profile management unit and or the profile storage unit and or the location determination unit to identify a plurality of second user devices associated with users of the desired gender if specified that are located within a predetermined proximity of the determined location of the user s user device. In some embodiments the location determination unit may first identify the plurality of second user devices. Next the profile management unit may access the profile storage unit to identify which of the second user devices included in the plurality of second user devices identified by the location determination unit are associated with second users of the gender desired by the user. The profile management unit and or the compatibility unit may then filter a second user device from the plurality of second user devices to result in a filtered plurality of second user devices. As such each second user device associated with a second user of a different gender than the gender desired by the user may be filtered e.g. removed from the plurality of second users so that each second user device included in the filtered plurality of second user devices is associated with a second user of the gender desired by the user. In other embodiments gender filtering of second user devices may occur prior to determining locations of second user devices.

The communication unit the profile management unit and or the compatibility unit may select a second user device from the filtered plurality of second user devices. In some embodiments the selected second user device may be randomly selected by the communication unit the profile management unit and or the compatibility unit from the filtered plurality of second user devices. In other embodiments the selected second user device may be selected by the communication unit the profile management unit and or the compatibility unit from the filtered plurality of second user devices based on a variety of factors. For example the communication unit the profile management unit and or the compatibility unit may select the selected second user device based on determining that it is the closest second user device of the filtered plurality of second user devices to the user device of the user. The communication unit the profile management unit and or the compatibility unit may also select the selected second user device based on determining at least a partial match between information included in the user profile associated with the user and information included in the user profile associated with a second user of the selected second user device.

The communication unit may then establish a video communication connection between the user device of the user and the selected second user device. In some embodiments establishing the video communication connection may include receiving and or determining one or more communication protocols e.g. network protocols using the network protocol unit . For example the video communication connection may be established by the communication unit using communication protocols included in the request to establish the video communication connection submitted by the user.

In some embodiments the established video communication connection between the user device of the user and the selected second user device may be configured by the communication unit to last for a predetermined duration. For example according to rules defined by the application and or stored in the application data unit the video communication connection may be established for a duration of one minute after which the video communication connection may be terminated. Limiting the duration of the video communication connection may force communicating users to form an opinion of each other relatively quickly e.g. within the allotted time duration of the video communication .

While the video communication connection is being established e.g. prior to enabling the user and the second user to communicate via a live video feed the content management unit may present each user with content that the two users may discuss during their video communication connection if desired . For example the provided content may serve as an ice breaker for conversation and may include a random fact a joke a quote a news story an image a video clip an audio clip text and or the like. The content may be retrieved from the content storage unit by the content management unit and presented to each user using the I O device included in each of their respective user devices .

Once the video communication connection has been established by the communication unit the user device and or the second user device may enable the user and the second user respectively to stream a live video feed to one another. For example the user may utilize the I O device e.g. a camera and a microphone included in the user device to capture a live video feed of the user s face and voice. Similarly the second user may utilize the I O device e.g. a camera and a microphone included in the second user device to capture a live video feed of the second user s face and voice. In some embodiments the live video feeds and or the live audio feeds captured by the user device may be transmitted from the user device to the second user device for display to the second user and vice versa. In this manner the user and the second user may communicate by viewing and or listening to the live video feeds and or the live audio feeds received from the other user e.g. the second user and or the user respectively using the established video communication connection.

Additionally the live video feeds and or the live audio feeds of the communicating users may be transmitted to and or received by the video communication server for processing. For example the GPU the facial vocal recognition unit the gesture analysis unit and or the compatibility unit may analyze the live video feeds and or the live audio feeds. In some embodiments the GPU the facial vocal recognition unit the gesture analysis unit and or the compatibility unit may analyze the live video feeds and or the live audio feeds to determine whether the live video feeds and or the live audio feeds include appropriate content only e.g. do not include inappropriate content such as inappropriate subject matter profanity and or the like . In some embodiments the facial vocal recognition unit the gesture analysis unit and or the compatibility unit may analyze the live video feeds and or the live audio feeds in real time during the duration of the video communication connection and or after the video communication connection has been terminated.

Similar to the processes outlined above that are associated with confirming the captured image of the user s face indeed includes only the user s face the GPU and or the facial vocal recognition unit may analyze the live video feeds and or the live audio feeds to determine that the live video feeds being transmitted between the users by way of the video communication connection include only each user s face. For example the facial vocal recognition unit may employ various pixel comparison techniques described herein to identify facial features in the live video feeds of each user to determine whether the live video feeds are indeed appropriate. Additionally the facial vocal recognition unit may analyze any captured audio of each user. Analysis of captured audio may include vocal recognition techniques so that the identity of each user may be confirmed. Further the facial vocal recognition unit may analyze captured audio of each user to identify keywords changes in vocal pitch and or vocal tone and or other objects of interest. Identifying objects of interest such as changes in vocal pitch and or vocal tone or keywords in a user s speech may enable the facial vocal recognition unit to determine whether that user is laughing crying yelling screaming using sarcasm and or is otherwise displaying a particular emotion e.g. a positive emotion and or a negative emotion .

If the facial vocal recognition unit determines any content of the live video feeds and or the live audio feeds is inappropriate based on its analysis of the live video feeds and or the live audio feeds e.g. based on determining no facial features are present in the live video feeds and or determining that inappropriate subject matter is present in the live video and or audio feeds then the communication unit may terminate the video communication connection. For example if the facial vocal recognition unit determines that the user s face has left the frame being captured by a video camera on the user device the communication unit may terminate and or otherwise suspend the video communication connection.

Accordingly any objects of interest identified by the facial vocal recognition unit e.g. facial features a vocal identity and or the like may be analyzed by the gesture analysis unit . In some embodiments the gesture analysis unit may compare identified objects of interest over time. For example the gesture analysis unit may determine an amount of movement of one or more facial features based on pixel locations of identified facial features a change in color of one or more facial features a change in vocal inflection vocal pitch vocal phrasing rate of speech delivery and or vocal tone and or the like. The gesture analysis unit may based on the analysis of the live video feeds and or the live audio feeds determine one or more gestures performed by the user and or the second user. For example based on determining that both corners of the user s lips moved upwards in relation to other identified facial features such as the user s chin the gesture analysis unit may determine that the user has smiled. In some embodiments the gesture analysis unit may determine a gesture has been performed by a user based on a combination of factors such as multiple facial feature movements vocal inflections speaking of keywords and or the like. In some embodiments the gesture analysis unit may determine a gesture has been performed based on determining at least a partial match between identified facial feature movements vocal changes and or the like and a predetermined gesture patterns stored in a database e.g. stored in memory unit . In some embodiments a gesture may include a detected movement of one or more facial features a facial expression of an emotion a change in vocal inflection tone and or speech pattern a recitation of one or more keywords phrases and or syllables and or any other audio visual expression associated with an emotion and or a feeling. In some embodiments the gesture analysis unit of the video communication server may perform the video analysis and or gesture identification steps described herein. Alternatively the gesture analysis unit of a user device e.g. user device of may perform the video analysis and or gesture identification steps described herein.

Each identified gesture may next be assigned a numerical value associated with a predetermined emotion by the gesture analysis unit and or the compatibility unit . For example an identified smile gesture may be assigned a positive numerical value whereas an identified frown gesture may be assigned a negative numerical value. Additionally and or alternatively the gesture analysis unit and or the compatibility unit may assign different weights to the numerical values of different identified gestures. For example a numerical value associated with an identified large smile gesture might be weighted by the gesture analysis unit and or the compatibility unit more heavily than a numerical value associated with an identified small smirk gesture.

After expiration of the time duration of the video communication connection the communication unit may terminate the video communication connection. The compatibility unit may determine an amount of time associated with the duration of the video communication connection. In some embodiments the duration of the video communication connection may be predetermined. In other embodiments the duration of the video communication connection may be shorter than a predetermined time duration if the user and or the second user decides to terminate the video communication connection early. The compatibility unit may assign a numerical value to the time duration of the video communication. In this manner the compatibility unit may attempt to reflect an amount of interest between the user and the second user based on how long the video communication connection lasted.

For example a video communication connection lasting for the entire predetermined time duration may indicate interest between the user and the second user or at least may indicate that there was no reduced level of interest . Conversely a video communication connection lasting for a portion of the predetermined time duration may indicate a reduced level of interest between the user and the second user. Accordingly the numerical value assigned by the compatibility unit to the time duration associated with the video communication connection lasting for a portion of the predetermined time duration may be less than the numerical value assigned by the compatibility unit to the time duration associated with the video communication connection lasting for the entire predetermined time duration.

The compatibility unit may combine the numerical value associated with the time duration of the video communication and numerical values associated with gestures identified by the gesture analysis unit to generate a compatibility score. As described above the compatibility score may represent how compatible the user is with the second user based on the analysis of the live video feeds and or the live audio feeds. The compatibility score may be presented to the user and or the second user after termination of the video communication connection to be used by the user and or the second user in determining whether the user and or the second user would like to communicate again with each other. For example a high compatibility score e.g. 98 may suggest that the user and the second user are highly compatible and thus may indicate that the each of user and the second user would like to pursue subsequent communication with each other. Alternatively a low compatibility score e.g. 14 may suggest that the user and the second user are not highly compatible and thus may indicate that the each of user and the second user would not like to pursue subsequent communication with each other.

Next the user and or the second user may be enabled via the I O device to select whether she or he desires to share contact information e.g. information stored in the users profiles with the second user and or the user respectively. If both the user and the second user select to share contact information perhaps based on consideration of a high compatibility score the user and the second user may share contact information with each other and the communication unit may enable the user and the second user to communicate via a variety of communication channels as described herein. Additionally the compatibility unit may increment a digit counter associated with each of the user and the second user. These digit counters may serve as a virtual currency during operation of the application described herein and may be included in each respective user s user profile.

Conversely if one of the users selects not to share contact information perhaps based on consideration of a mediocre compatibility score contact information of each user may not be shared between the user and the second user. Instead the user and or the second user may be enabled by the compatibility unit and or the profile management unit to spend e.g. transfer one or more units of virtual currency in order to reattempt communication with the second user and or the user respectively. Virtual currency spent in this fashion may cause the compatibility unit and or the profile management unit to transfer virtual currency from an account associated with the user to an account associated with the second user or vice versa. For example the digit counter of the user may be decremented a predetermined amount by the profile management unit and or the compatibility unit whereas the digit counter of the second user may be incremented the predetermined amount by the profile management unit and or the compatibility unit . The user and or the second user may accept or reject the reattempt at communication using the I O device . If accepted the communication unit may reestablish the video communication connection for a predetermined amount of time.

In some embodiments the application data stored in the application data unit and or the API unit may enable the application described herein to interface with social media applications. For example a user may be enabled to import from a social media application so that the user may establish video communication connections with existing contacts. The communication unit may further enable the user to communicate in various communication channels such as text messaging video chatting picture sharing audio sharing and or the like.

At various times throughout operation of the application described herein advertisements and or notifications of performed actions may be presented to each of the users by the content management unit . For example if a participating user of a video communication connection ends a video communication connection prematurely e.g. before expiration of the predetermined time duration of the video communication connection then the user may be forced to watch an advertisement video.

In some embodiments the user may be enabled by the communication unit to leave a first video communication connection for a second video communication connection. For example the communication unit may in response to receiving a request to initiate a second video communication connection terminate a first video communication connection with a first second user device and establish a second video communication connection with another second user device.

The profile management unit may enable the user to report any experienced negative behavior of other uses. For example if a live video feed of a second user displays inappropriate subject matter and or a live audio feed of a second user displays profanity the user may provide feedback to the video communication server indicating negative behavior associated with the second user. If any user receives a number of negative reports associated with inappropriate behavior that meets or exceeds a predetermined threshold that user may be banned from and or otherwise limited access to the application for a predetermined period of time by the profile management unit .

In some embodiments the profile management unit may further enable purchase of virtual currency facilitate the transfer of real monetary funds between bank accounts and or the like. Additionally the profile management unit may track behavior of the user and may provide rewards such as virtual currency based on actions performed by the user during operation of the application.

While various implementations in accordance with the disclosed principles have been described above it should be understood that they have been presented by way of example only and are not limiting. Thus the breadth and scope of the implementations should not be limited by any of the above described exemplary implementations but should be defined only in accordance with the claims and their equivalents issuing from this disclosure. Furthermore the above advantages and features are provided in described implementations but shall not limit the application of such issued claims to processes and structures accomplishing any or all of the above advantages.

Various terms used herein have special meanings within the present technical field. Whether a particular term should be construed as such a term of art depends on the context in which that term is used. Connected to in communication with communicably linked to in communicable range of or other similar terms should generally be construed broadly to include situations both where communications and connections are direct between referenced elements or through one or more intermediaries between the referenced elements including through the Internet or some other communicating network. Network system environment and other similar terms generally refer to networked computing systems that embody one or more aspects of the present disclosure. These and other terms are to be construed in light of the context in which they are used in the present disclosure and as those terms would be understood by one of ordinary skill in the art would understand those terms in the disclosed context. The above definitions are not exclusive of other meanings that might be imparted to those terms based on the disclosed context.

Words of comparison measurement and timing such as at the time equivalent during complete and the like should be understood to mean substantially at the time substantially equivalent substantially during substantially complete etc. where substantially means that such comparisons measurements and timings are practicable to accomplish the implicitly or expressly stated desired result.

Additionally the section headings herein are provided for consistency with the suggestions under 37 C.F.R. 1.77 or otherwise to provide organizational cues. These headings shall not limit or characterize the implementations set out in any claims that may issue from this disclosure. Specifically and by way of example although the headings refer to a Technical Field such claims should not be limited by the language chosen under this heading to describe the so called technical field. Further a description of a technology in the Background is not to be construed as an admission that technology is prior art to any implementations in this disclosure. Neither is the Summary to be considered as a characterization of the implementations set forth in issued claims. Furthermore any reference in this disclosure to implementation in the singular should not be used to argue that there is only a single point of novelty in this disclosure. Multiple implementations may be set forth according to the limitations of the multiple claims issuing from this disclosure and such claims accordingly define the implementations and their equivalents that are protected thereby. In all instances the scope of such claims shall be considered on their own merits in light of this disclosure but should not be constrained by the headings herein.

Lastly although similar reference numbers may be used to refer to similar elements for convenience it can be appreciated that each of the various example implementations may be considered distinct variations.

