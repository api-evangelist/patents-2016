---

title: Location-aware virtual service provisioning in a hybrid cloud environment
abstract: A sense of location is provided for distributed virtual switch components into the service provisioning scheme to reduce latency observed in conducting policy evaluations across a network in a hybrid cloud environment. A management application in a first virtual network subscribes to virtual network services provided by a second virtual network. A first message is sent to the second virtual network, the first message comprising information configured to start a virtual switch in the second virtual network that switches network traffic for one or more virtual machines in the second virtual network that are configured to extend services provided by the first virtual network into the second virtual network. A second message is sent to the second virtual network, the second message comprising information configured to start a virtual service node in the second virtual network that provides network traffic services for the one or more virtual machines.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09658876&OS=09658876&RS=09658876
owner: Cisco Technology, Inc.
number: 09658876
owner_city: San Jose
owner_country: US
publication_date: 20160304
---
This application is a continuation of U.S. application Ser. No. 13 438 861 filed Apr. 4 2012 the entirety of which is incorporated herein by reference.

Data centers may host applications and store large amounts of data for an organization or multiple organizations. An enterprise data center or cloud may be privately owned and discretely provide services for a number of customers with each customer using data center resources by way of private networks. In addition these data centers provide server and desktop virtualization that is dramatically changing the enterprise network by creating many virtual networks which connect virtual machines and the physical networks through virtual switches.

When an enterprise data center starts to run out of capacity the enterprise cloud operator may opt to buy more hardware which permanently increases hardware and operational costs. Another solution for increasing capacity is to borrow or lease resources from a public cloud data center thereby only temporarily increasing data center costs during the lease period. When the enterprise data center leases capacity from a public or cloud data center the combination of the enterprise cloud and public cloud is referred to as a hybrid cloud. The hybrid cloud is achieved by way of an overlay network.

Techniques are provided to bring a sense of location i.e. cloud location to distributed virtual switch DVS components for service provisioning and reducing latency observed in conducting policy evaluations across a network e.g. the Internet in a hybrid cloud environment. A management application in a first virtual network subscribes to virtual network services provided by a second virtual network. A first message is sent to the second virtual network the first message comprising information configured to start a virtual switch in the second virtual network to switch network traffic for one or more virtual machines in the second virtual network wherein the one or more virtual machines in the second network are configured to extend services provided by the first virtual network into the second virtual network. A second message is sent to the second virtual network the second message comprising information configured to start a virtual service node in the second virtual network that provides network traffic services for the one or more virtual machines.

Referring first to an example hybrid cloud network or system is shown for a hybrid data center environment. System comprises an enterprise data center and a cloud data center . The data centers and communicate with each other by way of link over a network e.g. the Internet or a virtual private network VPN . The data center employs a switch for hosting hardware and software that form a distributed virtual switch DVS using a component referred to herein as a Virtual Ethernet Module VEM . The switch may comprises a plurality of host devices e.g. Hypervisors and may host a virtual supervisor module VSM . As shown in the switch hosts a cloud manager CM an enterprise virtual service node eVSN an enterprise gateway Ent Gtwy and a plurality of virtual machines that may be configured by way of a port profile .

The cloud data center hosts a cloud gateway and a cloud VEM cVEM that provides switching for a plurality of VMs . Each VM in the cloud data center has a shell component referred to herein as a container or nested VM container that provides a VM interface to the hardware in the cloud data center. The container is indicated by the dashed box surrounding each VM in the cloud data center e.g. as shown at reference numeral . The VM container provides a way for the VM to access cloud data center processing resources while protecting the cloud data center from unauthorized access. In essence the VM shell is responsible for running the enterprise customer s VM as a guest VM e.g. VMs and for providing a network overlay for connecting the guest VM to private networks in the enterprise e.g. enterprise data center via gateways and . Any of the VMs may be started independently or migrated from data center to data center in order to better allocate resources across the hybrid cloud.

To further explain an agreement is set up between the enterprise owner of data center and the service provider for cloud data center e.g. a service level agreement SLA . The service provider for data center may be in the business of leasing excess capacity to any entity that needs processing capacity. The SLA allows the enterprise data center to lease resources through a given service arrangement e.g. pricing resource allocation cloud performance etc.

To extend resources beyond the enterprise data center the cloud manager starts a cloud gateway e.g. cloud gateway using commands authorized by the cloud data center e.g. by way of the SLA. Although not illustrated in the cloud gateway may have a shell component that acts as a processing resource access intermediary. The enterprise gateway the cloud gateway and the cVEM form a base architecture for realizing the techniques described herein and one that is supervised by the CM . This framework is not provided in conventional hybrid cloud environments.

Many traditional enterprise extensions into the cloud data center may use a network overlay technology e.g. OpenVPN to create an overlay network in the cloud data center for connecting cloud resources to the enterprise network. While offering secure transport connections in a cloud environment OpenVPN does not provide a switch infrastructure and thus lacks the ability to switch network traffic locally within the cloud data center extend consistent enterprise network policies into the cloud data center insert network services into the cloud data center e.g. server load balancers firewalls etc. and construct a sophisticated network topology in the cloud data center e.g. systems connected through a router and multiple Virtual Local Area Networks VLANs .

The techniques described herein further introduce several management plane concepts. The first concept is the cloud manager e.g. CM that is a management platform that could be an application or a VM running anywhere in the enterprise. The cloud manager is responsible for providing the hybrid cloud operations management of cloud resources dynamic instantiating of cloud gateways and nested VM container components though the enterprise virtualization platform such as a VM manager e.g. VMWare s vCenter and cloud provider application interfaces APIs e.g. Amazon s Amazon Web Service AWS API. The cloud manager also monitors health of all the components and provides high availability HA for those components. Thus the cloud manager implements hybrid cloud management process logic that encompasses the techniques described herein and is described with specific examples in connection with and and more generally in connection with . The cloud manager may provide a graphical user interface GUI for device and policy management with respect to hybrid cloud components e.g. VMs VSNs and gateways.

The second management concept is the nested VM container within which the guest VM operates guest referring to a guest with respect to the cloud data center. For example in a nested virtualization environment running in the cloud data center the inner most VM i.e. the guest VM is often out of bounds for the operator that provides the actual migration of services e.g. the enterprise operator. As such the out of bound condition makes it difficult for the enterprise operator to monitor the performance of the guest VM. In these cases there exists a need to transparently collect data that provides a picture of the condition inside the VM e.g. processor storage and memory utilization statistics as well as fault detection.

Accordingly a base architecture is created to provide for the automatic scaling and monitoring of components in a hybrid cloud environment. In a virtualized computing environment such as a modern virtualized data center and cloud service provider data center many capacity planning tools and applications are available for a corporate Information Technology IT administrator to accurately allocate network resources on demand i.e. to automatically scale resources to current need. The base architecture described herein allows the IT administrator to automatically perform switching policy management network services and construct sophisticated networks in the cloud data center and within the framework of the base architecture and overlay networks. This technology is scalable both within the cloud data center and to multiple cloud data centers.

The addition of the cloud gateway e.g. cloud gateway and the virtual switching module e.g. cVEM alleviate network latency. The cloud gateway mediates ingress and egress traffic for cVEM while cVEM provides virtual switching at the cloud data center . The cVEM may be based on an extension of DVS technology e.g. based on components used by Cisco s Nexus 1000V technology. Thus the cloud VEM e.g. cVEM may play the role of a virtual line card for a distributed switch e.g. a Nexus 1000V DVS. Multiple instances of cloud gateways and VEMs may be instantiated or started in the cloud data center s . The introduction of cloud gateway and CM into system allows CM to start a service node in cloud data center as shown at reference numeral with dashed lines indicating that VSN has not yet been started. The associated advantages of this arrangement will be described in connection with .

Referring now to an example is shown of a block diagram of the hybrid cloud network from in which location awareness reduces network latency. In this example the cVSN has been fully started. The cVSN may provide the same or other services as eVSN . In this regard cVSN can now provide IVM services for VMs and . This concept is illustrated by traffic being serviced and returned to VM as traffic . The traffic and have a shorter distance to travel when compared to traffic and from thereby reducing network latency. In the case of a firewall VSN for example it may be appreciated that traffic may not be serviced but dropped when that traffic does not meet security policy and the cloud manager or other entity may be notified.

Referring to an example block diagram is shown of relevant portions of the network from in which location awareness is provided using a virtual data center identifier. In this example a second data center is added to the hybrid cloud network that uses a different cloud provider labeled Cloud Provider when viewed in comparison to data center run by Cloud Provider in . Data center has a cloud gateway and a cVEM that provides switching for VMs .

A concept of location awareness is introduced that facilitates processing across the hybrid cloud network . In conventional DVS environments a DVS or VEMs may be distributed across several underlying hardware platforms e.g. Hypervisors in which the DVS operates without knowledge of the hardware. That is the switch just performs its switching functions across the platforms as if it were one switch. However to provide switching and other services in the hybrid cloud environment provisioning of cloud components is facilitated by location awareness.

Each of the VEMs and potentially the associated DVS components e.g. gateways or VMs are associated with an identifier that identifies the location of the VEM instantiation i.e. in which cloud does the VEM physically reside. The techniques provided herein allow providers or users by demand to dynamically instantiate a virtual switch VEM in the cloud data center to connect cloud VMs to the enterprise network over a secure Layer network overlay. As mentioned above it is a challenge to use the same VSN deployed in the enterprise network to protect or service the cloud VMs. Accordingly the cloud manager allows IT administrators to extend enterprise networks to different cloud provider data centers and to connect resources allocated in the clouds to form a flexible and extensible hybrid cloud. In this regard the cloud manager defines these cloud resources allocated in one cloud provider and connected to the hybrid cloud network as a Virtual Data Center VDC .

Each of the VDCs is assigned an identifier ID namely a VDC ID. Within an enterprise cloud the VDC ID is not only used for identifying the resources allocated in a specific cloud service provider but also provides a sense of location for all the cVEM switch modules. In this example VEM is assigned a VCD ID of zero while cVEM and cVEM are assigned VDC IDs of and respectively. When the cloud manager e.g. CM dynamically allocates cVEM modules and creates a network extension each of the cVEM modules allocated within the same cloud data center is assigned with the same VDC ID. For example the VDC ID assignments may be made by applying simple rules such as by default all traditional enterprise VEMs are assigned with a VDC ID of value zero while cVEMs allocated for a specific cloud provider are assigned with a VDC ID other than zero in order to identify cloud resources allocated within a specific provider data center. In the case of a provider that provides data centers in multiple locations e.g. East coast and West coast the VDC ID may be the same for both data centers or different for each data center depending on the hybrid cloud implementation.

At this point it may be helpful to contrast traditional provisioning models to a provisioning model enabled by the techniques described herein. Referring again to the port profile e.g. port profile is described according to prior techniques. The process is as follows VSN service profiles and policies along with VSN IP address are configured at a management platform e.g. a Virtual Network Management Center VNMC that manages individual VMs. The VNMC pushes the configured VSN service profiles and policies to each VSN in this example only VSN . On a VSM of a traditional Nexus 1000V the administrator configures the VSN service profile e.g. VSN Internet Protocol IP address and VNMC IP address in a port profile e.g. port profile . In other words the administrator binds the VSN service profile with port profile and the VSM maps the VSN service profile name to a VSN service profile ID by communicating to the VNMC using an interface e.g. a Representational State Transfer REST application interface API .

Thus when a new VM comes online including a VSN it gets attached to a port profile. In other words the VSM identifies the port profiles bound to the VM s interfaces e.g. virtual network interface card vnic and identifies the corresponding VSN service profile and the VSN associated with those port profiles. Then the VSM updates a virtual service data path VSDP service classification tables within the VEM with a virtual Ethernet port vEth VSN service profile ID and VSN binding. After this part of the provisioning is complete the VSDP tunnels any traffic originating from or destined to the given vEth port to the configured VSN. The VEMs may host the VSDP that provides a dedicated traffic pathway for services provided by VSNs. The VSDPs may be in the form of a service overlay e.g. a layer 2 3 overlay tunnel. The VSDPs also give the VSNs mobility that allows them to migrate from one server to another without routing traffic through an inline service appliance.

As can be seen from Tables 1 and 2 Table 1 relates among other things a VEM vEth port index or ID to a per port policy comprising a VSN service profile ID VN SP ID and a VSN Index that is used as an entry to Table 2. Table 2 further relates among other things the VSN Index to a VSN name and IP address. The VSN IP address is ultimately used to route VM traffic to the appropriate VSN for servicing i.e. the VM s vEth provides the entry to Table 1. For example a VM may have a vEth of 1 which points to a VSN index of 2 which in turn points to a VSN e.g. eVSN . Thus according to traditional bindings a VM in the cloud data center is bound to a VSN in the enterprise data center and would not be able to locate entities e.g. VSNs in the cloud. Tables 1 and 2 may be database tables or other data structures convenient to hold or represent the underlying mappings.

Although not shown in the various figures the VNMC may be maintained as a separate entity specific to enterprise VMs and that operates in cooperation with the cloud manager e.g. CM . Alternatively the VNMC functionality may be incorporated within the cloud manager and together they operate as a single entity. In other words the cloud manager may be configured to manage all binding and database tables or data structures across the entire hybrid cloud network.

As can be seen from Table 3 the VEM assignment provides a location of a VEM in a particular data center. Thus when the cloud manager provides the particular bindings for a VM including a VSN or gateway the cloud manager can provide a location based binding using the appropriate IP address names IDs etc. Further operations associated with Table 3 will be described in connection with

Turning to an example diagram of relevant portions of the network from is shown in which virtual service nodes are deployed with location awareness. As described above provisioning virtual services in the cloud data center reduces the latency in service policy evaluation. Furthermore the cloud manager provides a mechanism to group resources allocated from the same cloud provider to form a VDC as mentioned above. By combining these two approaches the architecture described herein can provide a location aware virtual service provisioning model.

As shown in cVSN from is shown as well as a cVSN that has been instantiated in data center . When a new VSN is installed and provisioned at a specific cloud provider through a VDC management function by CM the CM may bind the VSN with a specific VDC. This binding implies that the resources allocated within the VDC would be provisioned according to the newly installed VSN. As a part of processing the relevant configuration of a given VSN will be distributed to all the cVEMs which belong to the same VDC. Thereafter when the cVEM sees network traffic issued by cloud resources of a given VDC the cVEM can redirect the network traffic to the VSN that was previously provisioned.

Note that Tables 4 and 5 appear almost identical to Tables 1 and 2. However these tables are maintained by a cVEM on the cloud data center and were created via cloud manager operations in the enterprise data center by way of data contained in Table 3. Table 4 relates among other things a VEM vEth port index or ID to a per port policy comprising a VSN service profile ID VN SP ID and a VSN Index that is used as an entry to Table 5. Table 5 further relates among other things the VSN Index to a VSN name and IP address used within a given cloud data center. The VSN IP address is ultimately used to route VM traffic to the appropriate cVSN for servicing i.e. the cloud VM s vEth provides the entry to Table 4. For example a VM may have a vEth of 1 which points to a VSN index of 2 which in turn points to a cloud VSN e.g. cVSN or . Thus a VM in the cloud data center is bound to a VSN in the corresponding cloud data center and therefore receives traffic services from VSNs in the cloud. Tables 4 and 5 may be database tables or other data structures convenient to hold or represent the underlying mappings.

Accordingly with multiple VSNs deployed in the hybrid cloud depicted in the traffic service evaluation duty can be split using the following example rules 1 an eVSN is used for provisioning services for network traffic exchanged among VM resources in the enterprise 2 a first cloud VSN e.g. cVSN is used for provisioning services for network traffic exchanged among VM resources in VDC a second cloud VSN e.g. cVSN is used for provisioning services for network traffic exchanged among VM resources in the VDC and for each of any two given data centers e.g. enterprise and VDC the VSNs deployed in both data centers are used for provisioning services to the inter data center network traffic e.g. between VM and as shown in . In another example services provided by a VSN in one data center may be tagged as such in order to reduce duplicated VSN traffic services e.g. inter data center network traffic may be assigned to a single VSN in the enterprise data center or in the cloud data center.

The example operations of the base architecture presented above are not meant to be limiting but are provided to illustrate the flexibility of the base architecture that traditional architectures e.g. OpenVPN are not able to accommodate. By way of example and although not completely described herein sophisticated network topologies may be constructed by one skilled in hybrid cloud networks using the techniques described herein. Further there are other components in system such as mass storage core and edge switches and in switch e.g. Hypervisors and line cards as one ordinary skill in the art would appreciate but for simplicity those components are omitted in

Referring now to an example of a processing or server device that may host a cloud manager e.g. switch hosting cloud manager is shown. The device comprises a network interface module or unit a processor and a memory . The memory stores instructions for hybrid cloud management process logic . Briefly the hybrid cloud management process logic is configured to cause the processor in the device to dynamically manage hybrid cloud components as described herein.

The network interface device is configured to enable communications over a network e.g. network from and various networks internal to the data centers in the hybrid cloud to among other things manage hybrid cloud components in hybrid cloud network . Processor is coupled to the network interface device and to memory . Processor is for example a microprocessor or microcontroller that is configured to execute program logic instructions i.e. software for carrying out various operations and tasks described herein. For example the processor is configured to execute hybrid cloud management process logic that comprises processor executable software instructions stored in memory in order to manage hybrid cloud components. The functions of processor may be implemented by instructions encoded in one or more tangible computer readable media e.g. embedded logic such as an application specific integrated circuit digital signal processor instructions software that is executed by a processor etc. wherein memory stores data used for the operations described herein and stores software or processor executable instructions that are executed to carry out the operations described herein.

Memory may comprise read only memory ROM random access memory RAM magnetic disk storage media devices optical storage media devices flash memory devices electrical optical or other physical tangible memory storage devices. Thus in general the memory may comprise one or more tangible non transitory computer readable storage media e.g. a memory device encoded with software comprising computer executable instructions and when the software is executed by the processor it is operable or causes the processor to perform the operations described herein in connection with hybrid cloud management process logic .

Referring to flowcharts are now described for depict operations of the process logic for management of enterprise data center components in the hybrid cloud. At a management application in a first virtual network subscribes to virtual network services provided by a second virtual network. At a first message is sent to the second virtual network the first message comprising information configured to start a virtual switch in the second virtual network that switches network traffic for one or more virtual machines in the second virtual network where the one or more virtual machines are configured to extend services provided by the first virtual network into the second virtual network. At a second message is sent to the second virtual network the second message comprising information configured to start a virtual service node in the second virtual network that provides network traffic services for the one or more virtual machines.

At an identifier is assigned to the second virtual network to identify resources in the second virtual network that are associated with the first virtual network where the identifier is configured to indicate a location of the resources as being in the second virtual network. At the identifier is associated with the virtual service node and the virtual switch in order for the virtual switch to direct network traffic to the virtual service node. At the virtual switch routes network traffic associated with the one or more virtual machines to the virtual service node and at the virtual service node provides network traffic services for the associated network traffic.

These techniques further involve defining and storing information representing a plurality of service policies and defining and storing information representing a plurality service profiles comprising one or more identifiers for corresponding service policies for one or more virtual service nodes configured to provide network traffic services. Information may be generated that represents a port profile comprising one or more service profile identifiers and an identifier for the virtual service node thereby assigning one or more service profiles to the port profile. A virtual network port may be assigned to a virtual machine running in the second virtual network and the port profile may be associated with the virtual network port. The virtual switch network routes traffic associated with the virtual machine to the virtual service node based on the virtual service node identifier.

In summary the techniques described create a sense of location i.e. cloud location to DVS components for service provisioning and to reduce latency observed in conducting policy evaluations across a network e.g. the Internet in a hybrid cloud environment.

These techniques offer several advantages over conventional hybrid clouds including 1 provisioning virtual services in the cloud to reduce service policy evaluation latency 2 maintaining compatibility of the service provisioning approach with current DVS architectures as well as current and future DVS features such as service node chaining and clustering and 3 providing for resource management using the locations of cloud resources. The location sense of cloud resources can further be used for provisioning various virtual services such as Virtual Security Gateways VSGs vWAAS and Adaptive Security Appliances ASAs for a specific set of cloud resources.

