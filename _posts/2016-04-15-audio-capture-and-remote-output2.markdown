---

title: Audio capture and remote output
abstract: In a wireless content sharing system, audio may be captured at various levels of a source device, including at an application level. Audio may also be divided into components prior to packetization and transmission, allowing different channels of audio to be sent to different target devices. Audio may be sent with timing information to coordinate playback of content. Audio may be buffered to reduce user noticeable latency.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09569173&OS=09569173&RS=09569173
owner: AMAZON TECHNOLOGIES, INC.
number: 09569173
owner_city: Seattle
owner_country: US
publication_date: 20160415
---
This application is a continuation of and claims the benefit of priority of U.S. Non provisional patent application Ser. No. 14 216 356 filed Mar. 17 2014 and entitled AUDIO CAPTURE AND REMOTE OUTPUT the contents of which is expressly incorporated herein by reference in its entirety.

A wide variety of media devices are available for consumers to use for the consumption of an ever growing selection of content. These media devices may include televisions tablet computers personal computers electronic book readers gaming consoles set top boxes media players in vehicle entertainment systems portable media players smartphones and so forth. The content presented by these media devices may include audio video electronic books games and so forth. The content may be downloaded or streamed from a content provider to the media device.

Certain implementations and embodiments will now be described more fully below with reference to the accompanying figures in which various aspects are shown. However various aspects may be implemented in many different forms and should not be construed as limited to the implementations set forth herein. Like numbers refer to like elements throughout.

Media devices may display audio visual content for display to a user. These media devices may include televisions tablet computers personal computers electronic book readers gaming consoles set top boxes media players in vehicle entertainment systems portable media players tablet computers smartphones and so forth. The content may include audio video electronic books games and so forth. Sometimes a user may wish to take audio visional content that is generated on one device such as a mobile phone or tablet and display that content on another device such as a large screen television providing a display or home audio video receiver AVR providing sound output. Copying the output of the audio of one device to another device may be referred to as audio sharing or mirroring. In audio sharing audio data that is generated at one device called a source device is sent to another device called a target device for playback at the target device. The source device may playback audio at the same time as the target device resulting in simultaneous audio coming from both the audio and the target. Thus traditional audio sharing first involves generating a complete audio output such as an output to be played back at a source device and sending that complete audio output to a target device.

A number of techniques have been developed to share content between devices wirelessly without the use of a cord or other physical connector. Miracast is one protocol that enables content sharing between devices. Bluetooth may also enable content sharing such as audio sharing. For example a Bluetooth enabled speaker may receive audio data over a wireless Bluetooth connection for playback on a remote target speaker possibly along with simultaneous playback from a source device or other remote target speaker. Traditional audio sharing techniques typically focus on true mirroring that is taking the audio output of one device compressing it and sending it another device without regard to application level interactions or splitting the audio signal into discrete components. This focus suffers from a number of drawbacks including a lack of flexibility when it may be desirable to split the audio signal for sending to different devices based on application level processing and or user preferences loss of quality due to compression encoding and latency issues. Latency includes delays such as transmission delays processing delays etc. that may occur between transmission of audio data by a source device and eventual output of audio by the target device.

Offered is an improved audio sharing system and method. Instead of transmitting the processed audio data of a source device to be mimicked on a target device which simply copies the audio data from the source media device and sends it to the target media device for playback the source device may transmit lower level audio data or audio instructions commands to the target device. The audio may be captured as the output of a specific application operating on the source device thus allowing audio captured from different applications of the source device to be sent to different target devices. The audio may also be captured at an even lower level such as at the level of an audio driver just before output or prior to mixing. In this manner different kinds of audio data may be captured by a source device and sent to a target.

The target device also called a remote audio output device may be a device wirelessly connected to the source device that includes audio output components such as one or more speakers. The remote audio output device may include processing components to receive and playback audio data received from a source device such as a mobile phone tablet or other mobile device. Audio data from a source device may be sent to one or more remote audio output devices for coordinated playback.

The audio data may be divided into audio component data segments where individual data segments each correspond to different portions of audio that are to be played together. For example the audio of the source device may be split into channels where an audio channel represents an audio source corresponding to a different direction or frequency of a combined audio system. For example audio may be divided into channels such as a left audio signal and right audio signal for stereo applications into different location based audio channels for example in a 5 1 or 7 1 audio configuration or otherwise divided. The different audio signal components may be sent to and or output by different target devices in different segments called audio component data segments. For example for a 5 1 audio system for a time period of audio to be output an individual audio component data segment may be created for each channel of the audio system. Thus for time period X six audio component data segments may be created the six segments representing the six channels of audio for a 5 1 system for the audio of time period X . Each audio component data segment may be sent to a different remote audio output device such as a remote speaker for playback where the six audio component data segments for time period X are played back at the same time across one or more devices.

In another example the audio component data segments may be grouped when being sent to devices. For example audio component data segments corresponding to the left front right front left rear and right rear channels may be send to a surround sound system remote audio output device while the audio component data segment corresponding to the subwoofer channel may be sent to a different subwoofer remote audio output device. In the above example the audio component data segment corresponding to the center channel may be played back by the mobile device which may be the device closest to the user.

As illustrated above audio data in the individual audio component data segments may be divided by channel but they may be divided in other ways as well. For example high frequency audio data may be included in an audio component data segment intended for a tweeter remote audio output device whereas low frequency audio data may be included in an audio component data segment intended for a woofer remote audio output device. In another example certain audio effects echo special effects etc. may be included in their own audio component data segments for transmission and eventual playback by different remote audio output devices. In certain configurations audio component data segments may include exclusive audio data while in other configurations audio component data may include certain overlapping audio data. Other configurations and arrangements of audio component data segments and target remote audio output devices are possible.

The audio data may also be sent separately from other data such as video data that is to be played back at the same time as the audio data. This allows the audio data to be sent on its own in communications that may be out of band from resource intensive video data. This technique combined with the use of WiFi and other high bandwidth technologies may allow the audio data under certain conditions to be sent without encoding. Thus the present system may offer improved audio quality from transmission schemes such as Bluetooth Miracast etc. that call for compressed audio. The present system also allows for reduced latency by configuring transmission to target media devices based on communication conditions.

Further audio data may also be associated with certain timing information to coordinate playback among media devices to coordinate playback among audio data component segments or with other content such as video. The timing information may include a playback time during which particular segments are to be played back. Such a playback time may include a start time and or end time for a particular audio data component segment. Media devices may also exchange network condition information such as latency information to coordinate playback among media devices of an audio sharing system.

Described below is a system of media devices that may be configured to share audio data using the offered methods.

Each media device may include a communication module. The communication module is configured to discover other media devices and the services they support and provide a framework for establishing and using connections with the other media devices. The connections may be authenticated encrypted and so forth.

The communication module may be configured to operate in conjunction with a content direct sharing module which sends a media stream to a receiving media device. For example the content direct sharing module uses connections maintained by the communication module to send audio and video data from a tablet computer to a television for display and audio playback.

The connection module may be implemented as a software stack executing on the media devices in the system. The connection module on a first media device may differ from the connection module on a second media device. For example the first media device may include a transport module configured to provide secure sockets over Internet Protocol while the second media device may not. The media devices may include the content direct sharing module the device controller module or both.

By providing the communication module the content direct sharing module and the device controller module on media devices the system enhances the user experience. Media devices entering the environment with their associated services may be readily added or removed and content may be easily shared among those media devices.

A user is depicted with several media devices . . . D . While a single user is shown more than one user may be present. The media devices are configured to present store manipulate or otherwise participate in the consumption of content . The media devices may include televisions tablet computers personal computers electronic book readers gaming consoles set top boxes media players in vehicle entertainment systems portable media players smartphones individual audio speakers and so forth.

The media devices may execute one or more services. These services may be configured to interact with the content by receiving and processing the content for presentation generating a stream of content for presentation providing various functionality and so forth. The content may include audio video electronic books games and so forth. The media devices are discussed below in more detail with regard to .

The media devices include a communication module . The communications module is configured to support a framework within which availability of different services on different media devices may be distributed and connections between those media devices may be established. These connections may be used to send receive control or otherwise interact with the content . The communication module is discussed in more detail below with regard to .

These connections maintained by the communication module may use one or more networks. For example the network s illustrated in may include local area networks LANs and wide area networks WANs as illustrated in . The LANs may be supported using an access point topology ad hoc peer to peer topology and so forth. The LANs may be wired wireless or a combination. The LANs may be implemented using Ethernet Wi Fi Bluetooth ZigBee and so forth. Within the system several different LANs may coexist. For example media device and may be connected to one another using Wi Fi while the media device and may be interconnected using Bluetooth. The connections may be between media devices which are on the same or different local area networks .

The LAN s may connect to one or more WANs . The WAN may include one or more public networks such as the Internet private networks cellular data networks or a combination thereof. The WAN may in turn couple to one or more servers . . . S . The servers may exchange information with the one or more media devices . While the servers are depicted as single servers in some implementations the servers or the functions attributed to the servers may be provided by a plurality of devices. For example the server may be implemented as a virtualized server executing across a plurality of physical servers.

In one implementation the server or another device coupled to the WAN may provide a proxy service to transfer information from a media device to another media device using the WAN . These media devices may be on the same or different LANs. In another implementation the media devices on different LANs may establish connections with one another over the WAN without using the proxy service.

The media device may include other modules such as a content direct sharing module . The content direct sharing module provides a media stream from a first media device to a second media device . Certain media devices may be configured differently from other media devices. For example as illustrated here a tablet computer media device may be configured to receive content which may be protected using one or more digital rights management DRM schemes while the television media device may not be configured in this manner. A content direct sharing module executes on both the tablet media device and the television media device . The content direct sharing module of the media device generates a media stream which is sent using the LAN to the media device which presents at least a portion of the media stream . In one aspect the media stream may include coded content on the source media device . In another aspect the media stream may include audio component data to be played back by one or more target media devices.

In some implementations the content direct sharing module which is receiving the media stream may be disallowed from storing the media stream in permanent or semi permanent memory. For example the content direct sharing module may be configured to store no more than 300 frames of media stream data at any given time and may also be configured to display received frames in a streaming manner. The content direct sharing module may also be configured to establish a secured pathway to the display of the media device executing the content direct sharing module to reduce the likelihood of interception of the media stream by other applications or services executing on the media device .

The content direct sharing module may include modules such as a virtual screen module a virtual audio device module or both. The virtual screen module may be configured to acquire graphical command data which is designated for presentation on the display of the media device . The virtual screen module may also be configured to receive graphical command data such as the media stream from another media device and send that graphical command data to a processor of the media device for rendering and display on a display of the media device . This communication may be facilitated by the communication module . The virtual audio device module may be configured to acquire audio data which is designated for presentation on speakers of the media device . The virtual audio device module may be configured to send audio data in the form of audio component data segments as described below. Likewise the virtual audio device module may be configured to receive audio data such as audio component data segments from the media stream and present that audio data on the speakers of the media device .

The content direct sharing module may be configured to send media streams to multiple media devices either as a multicast or as separate streams. For example the media device may provide the media stream comprising audio data to the media devices and for playback using a multicast configuration. In another example the media device may provide a first media stream comprising audio to the media device and a second media stream comprising video and audio to the media device .

The content direct sharing module may be configured to mirror presentation of content or provide different information to different media devices . In one implementation first content may be presented on the media device providing content direct sharing while different second content is sent to another media device . Continuing the example the media device may present a user interface for controlling presentation of the content while a media stream comprising video is sent to the media device for presentation on a display and a media stream comprising audio is sent to the media device an AVR or an individual speaker for presentation by one or more speakers.

The media device may also include a device controller module . The device controller module may be configured to generate media presentation data. In one aspect the media presentation data may include an address and content identifier which when processed by the receiving media device initiates a transfer from a server to the receiving media device over the LAN and or WAN . The address and content identifier may include for example a uniform resource locator URL which directs the target media device to content on the server for retrieval and display playback on the target media device. Content may be shared from the server to a media device through the transmission of graphical commands as described below.

The I O interface s may couple to one or more I O devices . The I O devices may include input devices such as one or more of a camera a microphone a touch sensor a button and so forth. The I O devices may also include output devices such as one or more of a display audio speakers haptic output device and so forth. In some embodiments the I O devices may be physically incorporated with the media device or may be externally placed.

The media device may also include one or more communication interfaces . The communication interfaces are configured to provide communications between the media device and other devices such as other media devices routers access points the servers and so forth. The communication interfaces may include personal area networks wired and wireless local area networks LANs wide area networks WANs and so forth. For example Ethernet Wi Fi Bluetooth ZigBee and so forth.

The media device may also include one or more busses or other internal communications hardware or software that allow for the transfer of data between the various modules and components of the media device . The media device may also include other components such as an audio mixer or other specialized components such as processor s etc. for operating on audio data.

As shown in the media device includes one or more memories . The memory comprises one or more computer readable storage media CRSM . The CRSM may be any one or more of an electronic storage medium a magnetic storage medium an optical storage medium a quantum storage medium a mechanical computer storage medium and so forth. The memory provides storage of computer readable instructions data structures program modules and other data for the operation of the media device .

The memory may include at least one operating system OS module . The OS module is configured to manage hardware resource devices such as the I O interfaces the I O devices the communication interfaces and provide various services to applications or modules executing on the processors . Also stored in the memory may be one or more of the following modules. These modules may be executed as foreground applications background tasks daemons and so forth.

A user interface module is configured to provide a user interface to the user using the I O devices and accept inputs received from the I O devices . The user interface may include one or more visual audible or haptic elements. For example the user interface may be configured to provide a graphic user interface an audible user interface and so forth.

One or more application modules may be stored in the memory . The one or more application modules provide functionality which interacts with the user . For example an application module may be a game which is playable by the user.

One or more service modules may be stored in the memory . The service modules provide one or more services comprising one or more data processing functionalities to other service modules application modules or other modules. The one or more functionalities may be associated with presentation of the content on one of the media devices . For example the service modules may be configured to stream audio or video from a server for presentation transfer and present images transfer files and so forth. Other service modules may provide functionality such authentication to confirm information such as the ownership or affiliation of a particular media device .

As described above the communication module is configured to establish and support communications between the media device other media devices servers and other devices. The communication module may provide an abstraction to allow the application modules service modules and so forth to readily interact with corresponding modules on other media devices . The communication module may access the communication interfaces to exchange information between the devices. The communication module is discussed in more detail below with regard to .

As described above the content direct sharing module provides a media stream from a first media device to a second media device . In one implementation the content direct sharing module may provide for concurrent presentation playback between the first media device and the second or more media devices . In another implementation the content direct sharing module may suppress or discontinue presentation on the first media device while presentation continues on the second or more media devices . For example a media presentation application module on the tablet media device may be receiving a stream of a song. The content direct sharing module may request from the communication module connections to the AVR and solitary speaker which may be proximate to the AVR such as a supplemental speaker for playback of a different channel of audio or may be separate from the AVR such as a speaker in a different room . The communication module may establish these connections and the song may be played back simultaneously on devices and while a user interface allowing for control of the media presentation application module may remain on the tablet media device to facilitate the user s control of the song playback. The audio data comprising the song may be stored and streamed from one of the media devices such as the tablet media device or may be stored at another location such as a server or other location.

A development module may be stored in the memory of the media device . The development module may include various libraries modules functions and so forth such as may be present in a software development kit or other toolset. The development module may implement functions such as default service implementation in which an initial set of basic service housekeeping issues are defined. The development module may also implement a transport manager configured to select and manage particular transport modules for use based on parameters such as access level associated with the service what transport module the service was discovered over and so forth. The transport modules are discussed in more detail below with regard to .

A digital rights management module may provide support for presenting or processing content which is protected using one or more digital rights management schemes. Other modules may also be present. For example a speech recognition module may be present and used to accept spoken input from the user as received from a microphone I O device .

The memory may also include a datastore to store information. The datastore may use a flat file database linked list tree or other data structure to store the information. In some implementations the datastore or a portion of the datastore may be distributed across one or more other devices including servers network attached storage devices and so forth.

The datastore may store content either in its entirety or a portion. One or more route maps may be stored. The route maps provide information about services on other media devices and the routing to access those services.

Service description objects SDO may be stored. The SDO provides information such as service identifiers access information encryption information and so forth associated with a particular service as provided by a service module . The service identifiers may be used to indicate a particular service which is available. The access information may include details on account names passwords supported transports and so forth. The encryption information may include data such as encryption keys protocols and so forth.

Device objects DOs may also be stored in the memory . These may include a service description array indicating available services local to a particular media device universally unique identifier UUID associated with the particular media device friendly name for the particular media device transport information and so forth. Transport modules and the associated information are discussed below with regard to .

The memory may also store one or more graphics libraries . The graphics libraries may include data used by a processor such as a graphics processor to render images for display.

Other data may also be stored. For example the other data may include user preferences configuration files and so forth.

The transport modules are configured to provide functionality at a transport layer and establish and maintain communication channels that transfer bits from one media device to another device. In one implementation the transport modules may operate at layer 4 of the Open Systems Interconnection OSI model. The media device may have multiple transport modules available contemporaneously.

The communication module provides a simplified abstraction to the application modules service modules and other modules. A module requiring communication services may use this simplified abstraction to readily initiate communication without the module knowing the details of the particular transport module and type of connection involved. For example a requesting service module on the media device may initiate a request to communicate with the corresponding service module on the media device . This communication may use one or more of several different transport modules but this complexity may be hidden from the requesting service module and from the receiving service module .

Due to the modular nature of the communication module additional transport modules may be easily added without requiring re engineering of the communication module . For example a transport module supporting an infrared optical transport mechanism may be added without disrupting other existing transport modules or other operational aspects of the communication module .

The transport modules may include a secured Wi Fi Display module and a Wi Fi Display socket . These transport modules may be compliant with the Miracast standard promulgated by the Wi Fi Alliance the Intel Wireless Display WiDi standard developed by Intel Corporation or both. The Wi Fi Display transport module allows for peer to peer exchange of media information. This exchange may be encrypted in the case of the secured transport or unencrypted in the case of the unsecured transport. The transport modules may include transport modules configured for the exchange of graphical data and instructions as described below.

Transport modules which are based on Internet Protocol IP server sockets may be provided such as a secure server socket and an unsecure server socket . These transport modules may support wired or wireless communication.

Transport modules may also support the Bluetooth standard as promulgated by the Bluetooth Special Interest Group. A Bluetooth module which is secured may be provided as well as a Bluetooth module which is unsecured.

Other transport modules may also be provided. For example a transport module may provide transport functionality over a wireless WAN such as LTE 3G 4G and so forth. The transport modules may implement a portion of the standard specification or protocol. For example the transport modules associated with Bluetooth may omit application level functions in the Bluetooth specification such as profiles.

A discovery manager manages the device explorers . The discovery manager provides an interface which abstracts the mechanism provided by the device explorers to search for media devices and discover the services associated with those media devices. The discovery manager provides to other modules the results of the discovery while concealing from other modules consuming these results the complexity of the search and discovery processes which may differ from transport module to transport module .

The device explorers are modules which are configured to gather device object data using one or more of the transport modules . The device explorers may process the device objects to generate one or more route maps . The device explorers may also be configured to respond to the device explorers on other devices to distribute device objects route maps or other information.

The device explorers may operate in active or passive modes. The active mode requires some interaction such as user approval before a service is advertised as being available. The active mode may be time limited such that the associated service is only discoverable for a particular period so long as the user is activating a particular command or button and so forth. For example the service module providing output for the tablet media device may be placed in active mode such that the display and speakers of that media device are only discoverable when the user explicitly makes them so.

In comparison the device explorers may operate in a passive mode. In the passive mode the service modules are available without user interaction. For example the AVR media device and the television media device may be configured to operate in passive mode such that any of the media devices in the system may see the resources they have available to share.

Depicted here are device explorers including for simple service discovery protocol SSDP Wi Fi Display Bluetooth Avahi and so forth. The SSDP allows for advertisement and discovery of services over an IP based network using user datagram protocol UDP packets for transfer using one or more of the transport modules . The Avahi explorer may implement a version of Avahi as developed by Lennart Poettering and others. Avahi provides a zero configuration protocol using least a portion of the multicast domain name service DNS DNS based service discovery DNS SD or both to discover and configure an IP based network without user intervention.

The authentication manager is configured to authenticate the media devices in the system and authorize communications with one or more of those media devices . This authentication may be accomplished within the LAN or may involve external resources such as the servers . In one implementation the authentication may involve parsing a device identifier received from another media device to determine a manufacturer or model number. Previously determined devices may then be allowed to communicate. In another implementation a first media device may interrogate the server to authenticate a second media device . For example the tablet media device may discover the presence of the television media device . Continuing the example the tablet media device may send data about the television media device to the server to confirm that connectivity is permitted. The authentication manager may manage this exchange.

In some implementations the authentication manager or another module may be configured to authenticate the identity of the user . In one implementation access levels to services available on the LAN may be based at least in part on user identity. For example the user who lives in a home environment where the system is implemented may have family access when using the device of another user in that environment.

A security manager is configured to manage use of encryption and other techniques to prevent unauthorized use of the media device . For example the security manager may be configured to require a predetermined encryption for administrative access to the communication module . The security manager may work in conjunction with the authentication manager to manage authentication tokens granted to other media devices . The security manager may permit different access levels. These different access levels permit connectivity and operation with different restrictions.

In one implementation the access levels may include levels such as family friend first party devices and guest. The family level allows connections only from another media device which is registered or otherwise associated with a common account. The friend level allows access to a specifically trusted media device . The first party device level indicates that the media device shares a common manufacturer distributor or other attributes. The guest level is similar to friend level access but has a limited duration in time. For example the media device may be considered a friend device when on the same LAN . Particular service modules may define the access levels they will operate with.

The service router is configured to process incoming connections. The service router may route the connection to the authentication manager for processing. Once authenticated and authorized the service router may direct the traffic to the appropriate service module .

The connection manager manages the active connections in the media device . The user interface module may be configured to present to the user various prompts or information such as whether to permit a particular connection whether to seek out a particular connection and so forth.

When one or more media devices desire to exchange content either as a source device or as a target device they may enter a discover mode where each device makes its presence known to other devices. In this manner a source device may detect a target device and vice versa. A communication connection may then be established between the source device and target device. The communication connection may be established through the exchange of messages including instructions to connect the devices for purposes of exchanging information such as audio data. Audio data may include audio component data segments as described below. Following the establishment of a communication connection the devices may exchange initialization information and beginning an audio sharing session. An audio sharing session is a session during which audio data are sent from the source media device to the target media device.

Devices that wish to connect to each other after device discovery may engage in a handshake and connection setup that may be controlled by various components discussed above with regard to . As part of device discovery or connection setup between two or more devices a device may advertise its capabilities including available services communication protocols and constraints hardware capabilities operating OS and the like. Following detection two or more media devices may connect and form a network for exchanging content and other information. The network may make use of multiple platforms such as WiFi Bluetooth LTE etc. to communicate and is not necessarily limited to a specific platform or even to one platform. The devices may determine among themselves the best platform to use to exchange data using the various components and operations described here.

When a source media device connects to a target media device for purposes of audio sharing an initialization process may be executed by the devices. The initialization process may occur prior to establishing an audio display sharing session where audio data is sent from the source media device to the target media device. During this initialization process various information such as configuration information may be exchanged between the source media device and target media device. Configuration information may include information regarding settings capabilities or other configurations of the respective devices. For example configuration information may include detailed information regarding audio output devices available to each media device such as speaker channel configuration number and placement of speakers whether headphones are being used speaker headphone capabilities model numbers etc. communication configuration data such as available communication platforms and communication conditions like latency between devices latency between a device and audio speaker error rates compression settings etc. timing information such as clock settings timing synchronization information etc. preferred formats for receiving data operating system and other computing capability information etc. Other types of configuration information may also be exchanged.

Such configuration information or other information may continue to be exchanged between media devices as out of band exchanges over a back channel separate from any audio sharing sessions while the source media device and target media device remain capable of communicating with each other. For example a target media device and source media device may regularly exchange information regarding network communication conditions latency etc. Further additional data that may be needed by the target media device to properly playback audio content may also be sent by the source in band during an audio sharing session as needed. Such data may be sent as part of an audio sharing communications during lulls in audio sharing communications or otherwise.

A source media device desires may start an audio sharing session with a target media device by sending an audio sharing session initiation instruction to the target media device. The target media device may acknowledge the instruction and the devices may exchange session information. The session information may include any initialization or configuration information that had not yet already been exchanged as well as information regarding how the source media device and target media device will exchange audio data during the session such as information regarding the source of the audio to be sent such as the app encoding information number of channels associated content such as other video or audio etc. information regarding the target media device capabilities available audio outputs at the target connection specifics error rate throughput channel conditions latency or other information. Once the session has started the source media device sends the processed packetized audio component data segments to the target media device along with associated metadata such as timestamps audio commands etc. The target media device receives the packetized audio data depacketizes it decodes it or performs other operations to make the data operable and plays the audio back on the appropriate speaker at the appropriate time.

A source media device may generate audio for sharing in a number of ways. shows a system for processing audio in a media device. Audio data and audio commands are generated by an application module such as a software application operating on a device. Those commands may include calls to an application programming interface for interfacing between the application module and lower level components such as an audio mixer engine . An application programming interface API is a set of functions or routines executed in software and or hardware to specify how computing components should interact with each other. An API may be in the form of a library that includes specifications for routines data structures object classes variables etc. As used here the API may include an instantiation of the API.

The application may send a call to the API that includes information about what audio should be output for the particular application for example during operation of the particular application . The API may then generate commands for the lower level components and or may generate audio data corresponding to the audio for the application. Audio data from the API may be in a PCM pulse code modulation or non PCM format. The API may generate component data segments for example audio data segments corresponding to different channels of the audio that should be output for the application. Audio data and or commands may be sent through an API to an audio mixer engine which may mix the streams for passing to a kernel level audio driver . The audio driver prepares the audio data on the kernel level for passing to the audio firmware which configure the audio data for playback by the speaker s S . Audio data may be captured by an audio capture module for sending to a target media device at various points in this process.

Audio data from a particular application may be captured as output from the application module or from the API . Audio objects including audio data and commands for execution by lower levels of the device may be captured for processing and sending to one or more target media devices. Capturing audio data from a particular application allows for detailed and customized routing of audio data such as sending audio from one application to one media device and audio from another application to another media device. This differs from traditional audio sharing which typically mirrors the entire audio output of a source device to the target device. To capture audio at the application level and OS or other operational level interface may be configured to identify and capture audio data such as audio objects from the application module or API .

In another aspect audio may be captured after the audio mixer engine or after the audio driver . By capturing audio at the kernel level the capture process need not be dependent on particular OS level components or interfaces. This may allow for a more universally usable capture process rather than one that is configured for a particular OS.

The audio capture module may capture audio data and process the audio data. For example the audio capture module or other module may divide the audio into component data such as data including audio intended for certain speakers of a multi channel audio system or the like. By separating the source audio into audio component data segments in this manner different channels of audio may be sent to different devices. For example audio for an individual channel may be sent directly to a speaker associated with that channel rather than all audio having to travel together to a receiver and then divided into channels and sent to individual speakers by the receiver. Current standards such as Bluetooth or Miracast are designed for sending audio to a single playback device where the audio is sent together rather than being divided into components. The present system may treat each audio channel as a discrete audio source that can be streamed to different target media devices.

As illustrated audio processed by the audio capture module may be sent as output from the application module s API audio mixer engine audio driver or other component. The audio data may be divided into audio component data segments by the audio capture module or may be already divided by the time the data is received by the audio capture module . For example in one aspect the audio signal may already be separated into component streams that may then be captured by the source media device at the appropriate level such as through the API at the driver etc. and then sent to one or more target media devices as audio component data. In another aspect the source media device receives composite audio data that is audio data that is not separated into components such as audio data generated by an application that does not necessarily have the ability to separate audio data into separate components. The source media device may then generate separate component data from the composite audio data. The separation may be based in part on capabilities of the one or more target media devices to which the eventual audio component data segments will be sent.

For example an application may generate audio that includes audio output for different speaker channels but as a composite stream of audio data. The source media device may be connected to a set of target media devices that will output audio in a 5 1 configuration as selected by the user. The source media device may take the composite stream of audio data generated by the application and isolate the different audio for the different speaker channels. If necessary the source media device may also convert the audio channels of the application to operate with the target media devices such as converting speaker audio to 5 1 audio converting 7 1 audio to 5 1 audio or the like. In the example of the target 5 1 configuration the isolated speaker channels may include five directional audio channels center channel front left channel front right channel rear left channel and rear right channel and one non directional channel such as for a subwoofer . The audio for the different channels may then be configured as separate audio component data segments for packetization and transmission to the set of target media devices.

For example an AVR connected to the front three speakers may be sent the audio component data segments for the front three channels a different AVR connected to the rear two speakers may be sent the audio component data segments for the rear two channels and a still different device incorporated into a subwoofer may be sent the audio component data segment for the subwoofer. In still another example if a user wishes to output certain audio component data on the source media device and send other audio component data to target media devices the system may accommodate such a setting. For example a user may desire to output a center channel audio on the source device such as a tablet while playing a movie or video game while outputting the remaining channels of a 5 1 audio system to target media devices connected to various speakers. Using the present system the center channel audio will be output by the source media device whereas the remaining channels will be sent as packetized audio component data for playback on various other speakers of the 5 1 audio system. As described elsewhere the packetized audio component data may include timing information to coordinate audio playback to the user.

Other configurations of creation transmission of audio component are also possible. For example a source media device may connect to multiple different target media devices including on 5 1 audio system one separate subwoofer one 7 1 audio system and one single speaker including a tweeter and woofer. The source media device may create different audio component data streams for each desired audio playback and may then send those streams to the appropriate one or more target media devices. For example in the above illustration the same audio component data stream for subwoofer output may be sent to the 5 1 target audio system the 7 1 target audio system and the target separate subwoofer device. For example as shown in a source media device S may send audio component data across the network to multiple target media devices T . The individual target devices may then process the audio component data for each respective audio output component of the target media devices T thereby sharing the audio of the source media device S among multiple targets. The division of audio from different source media devices and or applications to different target media devices may be configured by a user such as through a user interface on the source device.

Following processing by the audio capture module audio data may be stored in one or more buffers . The buffer may also be located after the content direct sharing module or may be in multiple locations based on the system configuration. The buffer allows for processing and storing of audio slightly ahead of transmission to give the system some flexibility with adjusting for latency and other factors. The buffer may be configured to send certain audio component data at different times even if the different portions of audio component data are associated with a single audio output. This may be done to manage latency when different target media devices experience different communication conditions and different latencies. Buffers may exist on both source and target media devices to buffer audio that is to be transmitted as well as audio that is received.

For example if a source audio device is sending three different streams of audio component data to three different target media devices but the three streams of audio component data are to played back at the same time the source media device may first send the stream of audio component data to the target media device that experiences the largest latency in order to coordinate arrival of the audio component data streams to their respective target devices. Other content besides audio such as video may also be buffered as described. In this manner the system may control the user s perceived latency by managing transmission of different content to reduce latency that is perceptible to the user during content playback. Thus if a particular target media device to which content is being sent experiences a 100 ms delay in receiving and processing content data from the source media device and all other target media devices experience a shorter delay the source media device may delay transmission of content to the other target media devices. Alternatively the source media device may instruct the other target media devices to hold content in their respective buffers before playback to allow the slowest target media device to receive and playback content to avoid user noticeable latency.

Prior to transmission the audio data such as the audio component data may be packetized. The packetization may be performed by the content direct sharing module or by another module. Each packet may include a header with specific information for the particular packet. For example the packet may contain information regarding the packet size source and or contents. The packet header may include timing information such as timestamps from when the audio was captured when the audio was transmitted and or when the audio is scheduled to be played back. To coordinate playback a source media device may synchronize its timing information with the target media device s for example in the initialization process discussed above. Various time management protocols may be used to exchange timing information and commands such as network time protocol NTP precision time protocol PTP or the like.

Audio may be compressed prior to sending such as using a coding scheme such as AAC mp3 or the like or if network conditions allow the audio may be sent uncompressed to allow for greater sound quality. After processing including packetization compression etc. audio data may be sent to the communication interface and then to the network for transmission to the target media device.

Those having ordinary skill in the art will readily recognize that certain steps or operations illustrated in the figures above can be eliminated or taken in an alternate order. Moreover the methods described above may be implemented as one or more software programs for a computer system and are encoded in a computer readable storage medium as instructions executable on one or more processors.

The computer readable storage medium can be any one of an electronic storage medium a magnetic storage medium an optical storage medium a quantum storage medium and so forth. Separate instances of these programs can be executed on or distributed across separate computer systems. Thus although certain steps have been described as being performed by certain devices software programs processes or entities this need not be the case and a variety of alternative implementations will be understood by those having ordinary skill in the art.

Additionally those having ordinary skill in the art readily recognize that the techniques described above can be utilized in a variety of devices environments and situations.

Although the present disclosure is written with respect to specific embodiments and implementations various changes and modifications may be suggested to one skilled in the art and it is intended that the present disclosure encompass such changes and modifications that fall within the scope of the appended claims.

