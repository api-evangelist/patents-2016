---

title: ETL tool interface for remote mainframes
abstract: Embodiments of the present invention disclose a method for remote job submission. A computer receives a first job of a job stream. If the first job accesses a mainframe operating system, then the computer retrieves at least a return code threshold for the first job from a data store. If an option to build job control language is selected for the first job, then the computer generates job control language for the first job. The computer submits the first job to a job reader on the mainframe operating system using a file transfer protocol. The computer parses a retrieved output file to determine a return code for the first job.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09613114&OS=09613114&RS=09613114
owner: International Business Machines Corporation
number: 09613114
owner_city: Armonk
owner_country: US
publication_date: 20160414
---
The present invention relates generally to the field of data processing and more particularly to a mainframe interface for an extract transform and load ETL process.

ETL extract transform and load systems facilitate extracting data from various sources transforming the extracted data to fit operational requirements and loading the transformed data into a data repository such as a database at a target location. In many cases the extracted and accumulated data is in a different format than what is needed in the target data repository. The process of acquiring this data and converting the data into useful compatible and accurate data is referred to as an ETL process as in extract transform and load.

In an ETL process the extract phase acquires data from the source system s . Data extraction can be as simple as copying a flat file from a database or as sophisticated as setting up interdependencies with remote systems which supervise the transportation of source data to the target system. The extracted source data is often temporarily stored as one or more relational database tables. The transform phase in the ETL process is typically made up of several stages and includes parsing data converting data formats and merging extracted source data to create data in a format suitable for the data repository or target database s . The load phase of the ETL process includes depositing the transformed data into the new data store e.g. the data repository Warehouse mart etc. . The target database may be located on the same local computer as the data source on a separate computer from the data source or on a remote system such as a mainframe computer.

Mainframe computers process large amounts of data such as census information industry and consumer statistics and financial transactions. Current mainframe computers are defined by the redundancy of their internal design extensive throughput capabilities and backward compatibility with older software. Mainframe computers utilize proprietary operating systems for running applications such as data processing. The operating system of a mainframe computer may include an interface for file transfer protocol FTP functions. FTP is a part of a standard transmission control protocol TCP used to transfer data sets and files between a client host computer and a remote host server computer running an FTP server application over a network. FTP users may authenticate with a username and password or connect anonymously depending on the mainframe server configuration.

Embodiments of the present invention disclose a method for remote job submission. Responsive to determining that a first job of an extract transform load ETL job stream accesses a mainframe operating system a computer retrieves at least a return code threshold for the first job from a data store. The data store includes parameters for remote job submission including one or more of a target computer operating system type a host Internet protocol IP address or domain name system DNS server name a userid and password for the mainframe operating system a userid and password for an FTP server an output class for job results an output wait time the return code threshold a job file location and a job file name. Responsive to determining that an option to build job control language is selected for the first job the computer generates job control language for the first job utilizing parameters stored in the data store including one or more of an output class for job results an output wait time the return code threshold a job file location and a job file name. Responsive to determining that the option to build job control language is not selected for the first job the computer retrieves job control language for the first job from a library in the mainframe operating system wherein the library comprises job control language for a plurality of jobs including the first job. The computer submits the first job to a job reader on the mainframe operating system using a file transfer protocol. The computer parses a retrieved output file of job results to determine a return code for the first job. Responsive to parsing a retrieved output file of job results the computer determines a return code for the first job based at least in part on the parsed retrieved output file of job results. The computer compares the return code for the first job to the return code threshold for the first job. The computer determines if the job stream is continuing based at least in part on the comparison and if not the computer transmits an error message and aborts the job stream. The computer receives the first job including a selection of a job type. Responsive to determining that the job type of the first job is an ETL job type the computer receives a selection of at least one data source and one or more data transformation rules. The computer receives a selection of at least one data target. Responsive to determining that the mainframe operating system is selected for the at least one data source or the at least one data target or both the computer receives one or more job parameters comprising one or both of the return code threshold for the first job and an option to build job control language for the first job. The computer stores the one or more job parameters for the first job in the data store. The computer inserts the first job into the job stream. The computer receives at least one of the one or more job parameters further comprising the option to build job control language for the first job.

Mainframe computers utilize proprietary operating systems which do not easily interface with data processing applications running on the operating systems of other server computers. Mainframe operating systems may use scripting languages such as a job control language JCL to describe a job stream as a series of jobs performed by the computer in a particular order. Each job may comprise one or more data processing steps or tasks for execution in a distributed data environment that are saved in a job file. The series of commands in a job file may specify the input data sets to be accessed the output data set to be created or updated the resources to be allocated for the job and the programs to be run using these input and output data sets. A job file may be started or triggered directly by an administrator or may be scheduled. Mainframe operating systems may schedule a job file through a job control subsystem that includes components to receive jobs schedule jobs for processing and control any associated output processing. Mainframe computers may retrieve or receive job files via file transfer protocol FTP functions within the mainframe operating system.

Data warehouse applications use an extract transform and load ETL tool to extract data from a source database on a server computer transform the extracted data for insertion into a target database and then subsequently load the transformed data into a remote database such as on a mainframe computer via a network. An embodiment in accordance with the present invention recognizes that ETL tools in data warehouse applications do not interface efficiently with the proprietary operating systems of mainframe computers due to differences in technology. In accordance with the present disclosure embodiments provide for a data warehouse application comprising an ETL tool with a programmed interface for remote job submission to a mainframe computer. The programmed interface provides capabilities including but not limited to building a job file based on stored rules submitting the job file to a job reader on a mainframe computer via FTP monitoring the job for completion retrieving and parsing the output file of job results and based on the job completion status determining if a job stream continues to the next job.

An embodiment in accordance with the present invention recognizes that automation of the job building and remote job submission process will free up time for ETL programmers and database administrators and that scheduling database utilities based on the interim job results within a job stream will increase efficiencies associated with valuable computing resources.

Embodiments may apply to all database types including but not limited to relational hierarchical network and object oriented databases. Specific details disclosed herein are not to be interpreted as limiting but merely as a representative basis for teaching one skilled in the art to variously employ the methods and structures of the present disclosure.

The present invention will now be described in detail with reference to the Figures. is a functional block diagram illustrating a distributed data processing environment generally designated in accordance with an embodiment of the present invention. Distributed data processing environment includes server computers and mainframe computer and client computer interconnected over network . Distributed data processing environment may include additional server computers client computers or other devices not shown.

Network can be for example a local area network LAN a wide area network WAN such as the Internet or a combination of the two and can include wired wireless fiber optic or any other connection known in the art. In general network can be any combination of connections and protocols that may support communications between server computers and mainframe computer and client computer in accordance with an embodiment of the present invention.

Server computers and can each respectively be a server computer an application server a laptop computer a tablet computer a netbook computer a personal computer PC a desktop computer a personal digital assistant PDA a smart phone or any programmable electronic device capable of communicating with mainframe computer client computer and each other via network . In certain embodiments server computers and can each respectively represent a computer system utilizing clustered computers and components that act as a single pool of seamless resources when accessed through network as is common in data centers and with cloud computing applications. Server computers and may each be a node in a distributed database management environment. In general server computers and can each respectively be representative of any computing device or a combination of devices with respective access to data warehouse application ETL tool job rule store and data source and sever computer is capable of executing data warehouse application and ETL tool . Server computers and may each include internal and external hardware components as depicted and described in further detail with respect to .

Server computer includes an instance of data warehouse application . In the depicted environment data warehouse application is a customizable ETL application to extract data from data source transform the extracted data to meet requirements of data target and load the transformed data into data target . Data warehouse application may perform other tasks such as create and publish a report from the updated database after the initial ETL task is finished. Data warehouse application includes a job stream. A job stream is a sequence of operational steps or tasks such as performing an ETL task and then running a report. A developer using an integrated development environment IDE which facilities programming the logic of data processing tasks builds data warehouse application using application development program on client computer . In other embodiments data warehouse application and data source may be on one computer or more than one computer and each item itself may be split into a plurality of parts or modules and spread across more than one computer. An example of a job stream within data warehouse application is described further in .

Server computer includes an instance of ETL tool . ETL tool may include middleware that allows a developer to specify the requirements for performing ETL extract transform and load tasks between customized data related applications. ETL tool provides an application programming interface API that enable custom applications to connect to databases and issue commands for manipulating databases saving a developer from having to write complex ETL code. In an embodiment ETL tool provides an interface which enables data warehouse application to create a job stream in the job control language associated with mainframe OS such that the job stream is executable on mainframe computer . ETL tool waits for the output of the job stream retrieves the output file parses out the return code and compares the return code to a threshold value to determine the next processing step. ETL tool may be fully integrated with partially integrated with or be completely separate from data warehouse application . ETL tool is described further in .

Server computer includes an instance of job rule store . Job rule store is a data store within ETL tool providing storage for parameters used in configuring the interface between data warehouse application on server computer and mainframe OS on mainframe computer . In one embodiment job rule store comprises a list of parameters for remote job submission including one or more of a target computer operating system type a host internet protocol IP address or domain name system DNS server name related to mainframe computer a userid and password for mainframe computer a userid and password for the FTP server an output class for job results an output wait time a return code threshold a job file location and a job file name. In another embodiment job rule store additionally comprises parameters related to database access of data target such as a userid a password field names table names a database location and an operating system for the computer on which the database resides. In some embodiments job rule store organizes parameters by job file name for each job of a job stream. In other embodiments job rule store organizes parameters by operating system type. The parameters enable remote job submission by server computer to mainframe computer via FTP over network . Job rule store may be fully integrated with partially integrated with or be completely separate from ETL tool .

Server computer includes an instance of data source . Data source may include one or more of the following a relational database flat files comma separated text a non relational database hierarchical databases or other data structures such as Virtual Storage Access Method VSAM and Indexed Sequential Access Method ISAM . In one embodiment data warehouse application may collect data from various sources not all shown such as data source on server computer each with differing formats of data organization and which are transformed into a single format appropriate for validation processing and loading into data target . In another embodiment data warehouse application may collect data from a database table on mainframe computer and then load the transformed data into data source on server computer . One skilled in the art will recognize that there may be many other types of data sources available for use by ETL tools.

Mainframe computer is typically a mainframe computer but may also be a personal computer a laptop computer a workstation computer or any programmable electronic device capable of operating with a mainframe operating system such as mainframe OS or a mainframe operating system emulator. Mainframe computer may act as a server computer or an application server and is capable of communicating with server computers and and client computer via network . In certain embodiments mainframe computer can represent a computer system utilizing clustered computers and components that act as a single pool of seamless resources when accessed through network as is common in data centers and with cloud computing applications. Mainframe computer may be a node in a distributed database management environment. In general mainframe computer can be representative of any computing device or a combination of devices with access to mainframe OS job scheduler job reader library data target and output and is capable of executing mainframe OS job scheduler and job reader . Mainframe computer may include internal and external hardware components as depicted and described in further detail with respect to .

Mainframe computer includes an instance of a mainframe operating system or mainframe OS . In accordance with an embodiment of the present invention mainframe OS supports remote job triggering via FTP. One skilled in the art will recognize that there may be other communication protocols used to submit and trigger jobs remotely other than FTP. The illustrative embodiments of the Figures employ FTP for remote job triggering but are not intended to be limiting of the invention. In an alternate embodiment the mainframe operating system may be an emulator program running on a non mainframe computer not shown .

Mainframe computer includes an instance of each of job scheduler and job reader within mainframe OS . Job scheduler and job reader are each components of a batch processing subsystem or spooler of mainframe OS which is responsible for receiving jobs into the operating system scheduling the jobs for processing and controlling the job output processing. Job reader is a component that receives a job submitted from an outside application or other source via FTP and submits the received job to job scheduler for execution. Job scheduler schedules the job for processing by placing the job file into an input queue. Job scheduler manages the priority of each job in the input queue the resources for the job and the associated input data and output results for each job. Both job reader and job scheduler may respectively be fully integrated with partially integrated with or be completely separate from mainframe OS .

Mainframe computer includes an instance of library within mainframe OS . Library stores customized program code for use by mainframe OS . Code may be stored as a text file or other forms of a flat file. Library may contain procedures or a list of pre written JCL steps which may be inserted into a job as requested. Library may contain whole jobs pre written in JCL for executing routine tasks such as monthly reports which may be inserted into a job as requested. In an embodiment the job stream of data warehouse application may request a stored job to be run which is enabled by ETL tool retrieving the stored job from library and submitting the stored job to job reader via FTP. Job reader then submits the stored job to job scheduler . Library may be fully integrated with partially integrated with or be completely separate from mainframe OS .

Mainframe computer includes an instance of output within mainframe OS . Output may be an output queue or hold queue comprising a collection of output files for each job run on mainframe computer . After a job executes mainframe OS logs any resulting output in a file with a name related to the job file name and places the output file in output . The output file contains a return code indicating the status of the job completion such as clean warning or abnormal ending abend . ETL tool waits for the output retrieves the output file parses out the return code and compares the return code to a threshold value to determine the next processing step. Output may be fully integrated with partially integrated with or be completely separate from mainframe OS .

Mainframe computer includes an instance of data target . In the illustrative embodiment of data target is a relational database with tables used as a data warehouse. In an embodiment data warehouse application on server computer loads the transformed data extracted from data source of server computer into data target on mainframe computer via network utilizing ETL tool . In an alternate embodiment data warehouse application may extract data from data target for loading onto a database on server computer .

In various embodiments client computer can be a laptop computer a tablet computer an application server a netbook computer a personal computer PC a desktop computer a personal digital assistant PDA a smartphone or any programmable electronic device capable of communicating with server computers and and mainframe computer via network . In general client computer can be representative of any computing device or a combination of devices with access to application development program and is capable of executing application development program . Client computer may include internal and external hardware components as depicted and described in further detail with respect to .

Client computer includes an instance of application development program which may execute locally on the respective client computer and has the capability to create or update data warehouse application on server computer via network . Application development program integrates data across multiple systems using a high performance parallel framework and supports extended metadata management and enterprise connectivity. Application development program supports integration of data at rest or in motion on both distributed and mainframe platforms.

Application development program may be a suite of applications including but not limited to business intelligence tools database management tools metadata management and retrieval tools reporting tools and analysis tools used by business professionals for data mining online analytical processing and market research. In some embodiments application development program may be an associated client application created by the vendor or developer of ETL tool for use in a server client environment. Application development program may use a graphical notation to construct data integration solutions with individual icons for data source data target and the query that relates them. In the depicted environment application development program uses a user interface such as UI to receive user input and to output responses to a user. In the depicted environment application development program is an application allowing authorized users such as database developers and architects to create custom ETL applications such as data warehouse application using ETL tool for data integration against a central repository of data on a server such as data target on mainframe computer . Application development program is described further in .

In other embodiments data warehouse application application development program ETL tool and data source may be on one computer.

Client computer includes an instance of a user interface UI within application development program which may utilize a web page application a command line processor or any other graphical user interface GUI . UI includes components used to receive input from a user and transmit the input to application development program residing on the respective client computer. In an embodiment UI uses a combination of technologies and devices such as device drivers to provide a platform to enable users of client computer to interact with application development program . In the exemplary embodiment UI receives input such as dragging and dropping data icons onto a workspace using a physical input device such as a keyboard or mouse via a device driver that corresponds to the physical input device.

In the illustrative embodiment application development program residing on client computer allows a developer to create or customize data warehouse application on server computer via network . Application development program allows the developer to configure data warehouse application with a job stream for ETL processing. In accordance with various embodiments of the present invention a job stream is a sequence of processing tasks or jobs written in a job control language JCL or other batch job scripting language which may be proprietary to a specific operating system such as mainframe OS . Each job consists of a statement defining the executable program or code and a list of resources such as data files and devices for use. The job stream is stored as data warehouse application on server computer . Independent of the operating system the job stream may include information regarding data source transformation queries or commands and data target used for each ETL task within the job stream. Application development program requests from the developer the database location information and validation credentials for both data source and data target to be stored in data warehouse application as needed for running the tasks of the job stream. When defining data source and data target the developer selects the operating system type for each. The selection of operating system allows ETL tool to determine the method for submitting each job in the job stream to the target computer such as mainframe computer . Along with jobs for ETL steps in the job stream application development program allows the developer to insert one or more stored jobs from library on mainframe computer into the job stream for pre defined tasks such as starting a database utility or requesting a report incorporating the recently loaded data within data target . In one embodiment the developer builds an ETL job stream for doing a bulk database load. In other embodiments the developer builds a job stream that does not perform ETL tasks or a bulk database load and only runs one or more stored jobs such as a report. In another embodiment the developer builds a job stream with any combination of job types.

In the illustrative embodiment ETL tool on server computer includes job rule store which enables remote job submission on mainframe computer . Job rule store comprises a list of parameters for remote job submission including one or more of a target computer operating system type a host IP address or DNS server name related to mainframe computer a userid and password for mainframe computer a userid and password for the FTP server an output class for job results an output wait time a return code threshold a job file location and a job file name. In one embodiment job rule store organizes parameters by job file name for each job of a job stream. In another embodiment job rule store organizes parameters by operating system type. Application development program enables the developer to configure parameters for each job each operating system type or each target database and store the configured parameters in job rule store on server computer when customizing data warehouse application . In an embodiment job rule store additionally comprises database metadata for data target . One skilled in the art will recognize that there may be other ways to organize parameters in job rule store .

In the illustrative embodiment upon execution of data warehouse application on server computer if data target is on a mainframe computer such as mainframe computer then ETL tool provides an interface for mainframe OS which enables the submission of each job in the job stream of data warehouse application . ETL tool determines if the job already exists pre written in the JCL and stored in either library on mainframe computer or in ETL tool on server computer . Responsive to determining that the job already exists pre written in the JCL ETL tool issues an FTP get command to retrieve the job file from the respective location. Responsive to determining that the job does not exist pre written in the JCL ETL tool builds the job file dynamically in JCL utilizing parameters stored in job rule store . ETL tool submits the job file to job reader on mainframe computer via FTP. Job reader submits the job file to job scheduler which triggers the job to start. Mainframe computer executes the job within mainframe OS .

In the illustrative embodiment ETL tool monitors each job of the job stream for completion. ETL tool retrieves the wait time and a return code threshold for a job or an operating system type from job rule store . For example a job return code may be a two digit code such as 00 04 08 etc. where a return code of 00 means the job completed without any errors and a return code of 08 means the job failed before completion. After waiting the wait time associated with the current job ETL tool retrieves the job output file from the job log or hold queue of output on mainframe computer via network . ETL tool parses the retrieved job output file to determine the return code associated with the completion status of the job. ETL tool determines based at least in part on a comparison of the return code to the retrieved return code threshold for a job whether the job stream continues to the next job or task of the job stream or aborts execution of the job stream.

In one embodiment ETL tool interprets the return code threshold as a maximum. If the return code from the job output is below the return code threshold then ETL tool continues to the next job in the job stream. If the return code from the job output is equal to or above the return code threshold for the job then ETL tool aborts execution of the job stream. An error message regarding the reason for aborting the job stream including the job file name and the job return code may be sent to the database administrator or be included in an error log.

In an alternate embodiment ETL tool interprets the return code threshold as a minimum. If the return code from the job output is above the return code threshold then ETL tool continues to the next job in the job stream. If the return code from the job output is equal to or below the return code threshold for the job then ETL tool aborts execution of the job stream. An error message regarding the reason for aborting the job stream including the job file name and the job return code may be sent to the database administrator or be included in an error log. One skilled in the art will recognize that ETL tool may compare the return code threshold to the return code from the job output using variations of the above determinations.

Application development program receives a selection of job type step . Application development program provides a user interface UI which allows a user such as a database developer or architect to select a job type of a job to be added to the job stream of data warehouse application . Application development program may request the user to select a specific job type or to select a category of jobs such as ETL jobs and non ETL jobs.

Application development program determines if an ETL job is selected decision block . If application development program determines that an ETL job is not selected no branch decision block then application development program receives a selection of data target step . If application development program determines that an ETL job is selected yes branch decision block then application development program receives a selection of data source step . When defining ETL jobs data source and the transformation rules are defined in the subsequent steps. When defining non ETL jobs of a job stream such as a report or utility data source and ETL transformation rules may not be required and therefore steps and may be skipped.

Application development program receives a selection of data source step . Application development program provides a user interface UI which allows a user such as a database developer or architect to define data source . As noted in data source may be one or more databases or flat files on one or more computers. For example application development program allows the user to define the criteria for extracting data from data source including but not limited to defining source tables and filter criteria SQL commands how to parse the data and verification of initial structure. Application development program receives the database location information and validation credentials for data source to be stored in data warehouse application as needed for running the tasks of the job stream.

Application development program receives transformation rules step . Application development program allows the user to define one or more transformation rules such as queries or SQL commands to transform the extracted data. Application development program allows the user to define the criteria for transforming the extracted data including but not limited to parsing the data cleaning the data applying a series of rules or functions to the extracted data checking data integrity and creating aggregates or disaggregates of the extracted data.

Application development program receives a selection of data target step . Application development program allows the user to define data target . For example application development program allows the user to define the criteria of an ETL job for loading data into data target including but not limited to staging data before loading defining target source tables and selection criteria defining criteria for audit tables and defining overwrite update criteria. If application development program arrived at step directly from decision block then application development program enables the user to define a non ETL job. When defining non ETL jobs for a job stream such as a report or a utility application development program defines data target as one or more databases utilized in the report or utility. Application development program receives the database location information and validation credentials for data target to be stored in data warehouse application as needed for running the tasks of the job stream. Application development program requests and receives a selection for the operating system of data target . In one embodiment application development program may divide the operating system selections between mainframe operating systems such as mainframe OS and other operating systems. Application development program may request the user to select the specific operating system or a generic operating system type.

Application development program determines if mainframe OS is selected decision block . If application development program determines that mainframe OS is not selected no branch decision block then application development program inserts job into job stream step .

If application development program determines that mainframe OS is selected yes branch decision block then application development program receives job parameters step . When the user selects mainframe OS application development program may offer dynamic selections to the user through a graphical user interface such as UI allowing the user to specify the job parameters in various ways. In one embodiment the selections may be displayed graphically using checkboxes or a pull down menu within a tab or box for job stream criteria. The received job parameters enables remote job submission on mainframe computer by ETL tool . Job rule store comprises a list of parameters for remote job submission including one or more of a target computer operating system type a host IP address or DNS server name related to mainframe computer a userid and password for mainframe computer a userid and password for the FTP server an output class for job results an output wait time a return code threshold a job file location and a job file name. In the illustrative embodiment of job rule store organizes parameters by job for each job of a job stream. In other embodiments job rule store organizes parameters by operating system type. In various embodiments job rule store additionally comprises parameters related to database metadata for data target . During development of data warehouse application using application development program an option to build the JCL for each job may be selected by the developer and stored in job rule store within ETL tool or within the code of data warehouse application .

Application development program stores parameters into job rule store step . In the illustrative embodiment of application development program enables the developer to configure parameters for each job and store the configured parameters from step in job rule store in ETL tool on server computer when customizing data warehouse application .

Application development program inserts job into job stream step . Application development program inserts the ETL task defined by steps and or the non ETL task defined in step to the job stream of data warehouse application . For example a non ETL task includes a utility or report available from stored jobs residing in library on mainframe computer .

Application development program determines if job stream is complete decision block . If application development program determines that the job stream is complete yes branch decision block then application development program ends. If application development program determines that the job stream is not complete no branch decision block then application development program receives a selection of job type step . In one case if the user is not finished then the steps listed above may be repeated as needed to create a job stream of two or more jobs for data warehouse application . An example of a multiple step job stream is detailed in . After all jobs of the job stream are entered application development program stores the finished application on server computer . For example application development program saves data warehouse application on server computer via network .

Data warehouse application transmits credentials for validation step . In an embodiment data warehouse application sends the application credentials at the start of the job stream to the database management system DBMS of data target to validate that the userid has the authority to retrieve data from data source and to load data on data target . Responsive to a determination that the application credentials have authority data warehouse application loads the transformed data into data target . If the userid does not have the proper authority the ETL job aborts. In an alternate embodiment this validation may be done prior to each load step of one or more ETL jobs within a job stream. ETL tool may be an integrated part of data warehouse application and provides the database connections and ability to issue commands to perform the three ETL jobs and the report job.

Data warehouse application performs job to extract transform and load data from table A to table B step . Table A is a table or flat file within data source and table B is a table within data target . The details of the ETL task were configured by the user using application development program as shown in . During development of data warehouse application using application development program selections were made indicating that data source is on a non mainframe operating system and data target is on a mainframe operating system.

ETL tool retrieves the wait time and return code threshold for job from job rule store . After waiting the wait time associated with job ETL tool retrieves the job output file from the job log of output on mainframe computer via network . ETL tool parses the retrieved job output file to determine the return code associated with the completion status of the job. ETL tool determines based at least in part on the return code and the retrieved return code threshold whether the job stream continues to the next job. In the illustrative embodiment of if the return code is equal to or below the return code threshold then ETL tool triggers the next job in the job stream. If the return code from the job output is higher than the return code threshold for the job then ETL tool determines to abort execution of the job stream. An error message regarding the reason for aborting the job stream including the job file name and the job return code may be sent to the database administrator or be included in an error log.

Data warehouse application performs job to extract transform and load data from table B to table C step . Table B and table C are tables within data target . The details of the ETL task were configured by the user using application development program as shown in . In one embodiment during development of data warehouse application using application development program a selection was made indicating that data target is on a mainframe operating system. In one embodiment ETL tool may build the JCL code for job dynamically during execution of data warehouse application . In an alternate embodiment ETL tool may retrieve previously written and stored JCL code for job from library on mainframe computer . In both embodiments ETL tool submits the job via FTP to job reader on mainframe computer .

ETL tool retrieves the wait time and return code threshold for job from job rule store . After waiting the wait time associated with job ETL tool retrieves the job output file from the job log of output parses the retrieved job output file to determine the return code and determines whether the job stream continues to the next job as detailed above.

Data warehouse application performs job to extract transform and load data from table D to table E step . Table D is a table within data target residing on mainframe computer and table E is a table within data source residing on server computer . In the illustrated example data is extracted from table D on mainframe computer transformed and then loaded onto table E on server computer . This is the reverse of job where data flows from server computer to mainframe computer . During development of data warehouse application using application development program selections were made indicating that data source is on a non mainframe operating system and data target is on a mainframe operating system. While data is to be loaded onto a non mainframe operating system data warehouse application still needs integration by ETL tool to extract the data from a database on a mainframe operating system.

ETL tool retrieves the wait time and return code threshold for job from job rule store . After waiting the wait time associated with job ETL tool retrieves the job output file from the job log parses the retrieved job output file to determine the return code and determines whether the job stream continues to the next job as detailed above.

Data warehouse application performs job to run report F step . In the illustrative embodiment job may be a stored job from library on mainframe computer . In this example job may access data target only and data warehouse application requires that ETL tool enable submitting job remotely to mainframe computer running mainframe OS . An FTP get command copies a file from a remote machine such as mainframe computer to a local machine such as server computer . An FTP put command copies a file from a local machine such as server computer to a remote machine such as mainframe computer . In one embodiment ETL tool may use an FTP get command to copy the job file from library on mainframe computer to server computer and then use an FTP put command to copy the file from server computer to job reader on mainframe computer . In another embodiment ETL tool may use FTP to transfer the job file from library directly to job reader . Job reader submits the job file to job scheduler which triggers the job to start. In yet another embodiment ETL tool may use FTP to transfer the job file directly to job scheduler bypassing job reader depending on the capability of the operating system. Data warehouse application may retrieve and format data into a specialized report e.g. report F based on the updated tables in data target .

ETL tool retrieves the wait time and return code threshold for job from job rule store . After waiting the wait time associated with job ETL tool retrieves the job output file from the job log of output parses the retrieved job output file to determine the return code and determines whether the job stream continues on as detailed above.

Data warehouse application performs job to extract transform and load data from table F to table G step . Table F and table G are tables within data source . The details of the ETL task were configured by the user using application development program as shown in . During development of data warehouse application using application development program a selection was made indicating that data source is on a non mainframe operating system. The inclusion of a non mainframe operating system job creates a mixed job stream. Embodiments provide an ETL tool capable of processing a mixed job stream.

ETL tool processes job using methods known in the art for non mainframe operating systems. ETL tool receives a job return code from the database management system of data source and determines whether the job stream continues to the next job in the job stream. At this point all jobs of the illustrated job stream have completed and processing ends.

ETL tool receives a first job in the job stream of data warehouse application step . Data warehouse application executes on server computer which is a non mainframe operating system. As an integrated component of data warehouse application ETL tool receives a first job in the job stream. In an embodiment prior to processing the first job the credentials of the application userid are submitted to and validated by the database management systems of both data source and data target to have authority for database reading and writing. If the userids do not have the authority for database reading and writing then data warehouse application aborts. In some embodiments this validation is done at each data loading step of an ETL task rather than at the start of a job stream.

ETL tool determines if a job accesses a mainframe operating system decision block . The ETL code attached to data warehouse application includes the information which can be used to determine if the job accesses a mainframe operating system for at least one data source or data target. During development of data warehouse application using application development program selections for each data source and data target may have taken the form of checkboxes or highlights in drop down menus. In one embodiment application development program may have divided the operating system selections between categories for mainframe operating systems and non mainframe operating systems. In another embodiment application development program may have requested the user to select the specific operating system. During runtime these selections have been translated into code within data warehouse application . From the ETL code ETL tool determines which selections were made during development. The code may only contain the selected option with the appropriate criteria to perform the job.

If ETL tool determines that a job does not access a mainframe operating system no branch decision block then ETL tool processes the job normally step using methods known in the art without having to use FTP or JCL code. After the job completes ETL tool determines if the job return code is below the job threshold decision block as detailed below.

If ETL tool determines that a job accesses a mainframe operating system yes branch decision block then ETL tool retrieves criteria for the job from job rule store step . After determining the mainframe operating system option is selected for at least one of data source or data target the purpose of the remaining flowchart is for ETL tool to enable formatting the job for remote submission to a mainframe operating system during the current application. ETL tool retrieves criteria for the current job from job rule store such as the target computer operating system type a host IP address or DNS server name related to the mainframe computer a userid and password for the mainframe computer a userid and password for the FTP server an output class for job results an output wait time a return code threshold a job file location and a job file name.

ETL tool determines if the option to build JCL is selected for the current job decision block . Every job of the job stream of data warehouse application which accesses a mainframe operating system is written in a batch processing script or job control language JCL readable by the mainframe operating system such as mainframe OS . During development of data warehouse application using application development program a selection to build the JCL was made by the developer. The ETL code attached to data warehouse application includes the information which can be used to determine if the option to build the JCL was selected. Some jobs are pre written in JCL code and stored in library on the mainframe computer and do not need to be dynamically written in JCL by ETL tool . In that case the option to build JCL would not be selected. In another example the pre written code may be stored on server computer within ETL tool .

If ETL tool determines that the option to build JCL is not selected for the job no branch decision block then ETL tool pulls or retrieves JCL code for the job from library step . In the case where the option to build JCL is not selected ETL tool retrieves previously written and stored JCL code. ETL tool uses criteria such as a userid and password for the FTP server a job file location and a job file name previously retrieved from job rule store in step to retrieve a stored job or file containing JCL code from a location such as library on mainframe computer . ETL tool authenticates with the FTP server on mainframe computer and then ETL tool issues an FTP get command to retrieve the job file from the specified location i.e. library .

If ETL tool determines that the option to build JCL is selected for the job yes branch decision block then ETL tool generates JCL code for the job step . In one embodiment ETL tool builds the job file dynamically in JCL code or some other batch processing script utilizing parameters stored in job rule store .

In an alternate embodiment application development program may generate the JCL code for the job when data warehouse application is initially developed and the JCL code may be saved as a stored job on either mainframe computer in library within ETL tool on server computer or some other location in communication with network . In that case steps and would be unnecessary as all JCL code would already exist and step would be performed every time.

ETL tool submits the job to job reader via FTP step . At this point the job file may have been modified to include JCL code. ETL tool issues an FTP put command to send the job file to job reader . Subsequently job reader submits the job file to job scheduler which triggers the job to start.

ETL tool waits the job wait time step . In one embodiment ETL tool uses criteria such as the wait time for a job or an operating system type previously retrieved from job rule store in step to determine how long to wait for the job to complete execution. In other embodiments ETL tool may receive a message from the system indicating when the job is completed. One skilled in the art will recognize that there may be other ways to determine when a job is completed.

ETL tool retrieves the job output from output step . ETL tool uses criteria such as an output class for job results previously retrieved from job rule store in step to locate the type and location of output results for the current job. After waiting the wait time associated with the current job in step ETL tool retrieves the job output file from the job log such as from a hold queue of output on mainframe computer via network . In one embodiment ETL tool issues an FTP get command to retrieve the job output file. One skilled in the art will recognize that there may be other ways to retrieve the job output file or results.

ETL tool parses the job output to determine the job return code step . ETL tool uses criteria such as the return code threshold for a job or an operating system type previously retrieved from job rule store in step to determine the completion status of a job. ETL tool parses the retrieved job output file into components to determine the return code associated with the completion status of the job.

ETL tool determines if the job return code is below the job return code threshold decision block . ETL tool determines based at least in part on the return code and the retrieved return code threshold whether the job stream continues to the next job or task. If the return code is less than the return code threshold then ETL tool triggers the next job in the job stream. In an example a return code may be a two digit code such as 00 04 08 etc. In our example a return code of 00 means the job completed without any errors. A return code of 04 means the job completed with a warning. A return code of 08 means the job failed before completion or had an abnormal ending abend . If the return code threshold for the current job is 07 and the return code from the parsed output file is 04 then ETL tool continues to the next job. In other embodiments the threshold value may be a minimum instead of a maximum depending on the return code definitions for the operating system.

If ETL tool determines that the job return code is not below the job return code threshold value no branch decision block then ETL tool aborts the job stream step . By comparing the job return code to the job threshold value ETL tool determines if the job stream continues or aborts. If the return code from the job output is greater than or equal to the job threshold value then ETL tool determines to abort execution of the job stream. An error message regarding the reason for aborting the job stream including the job file name and the job return code may be sent to the database administrator or be included in an error log. A determination at this point is helpful when the next job in the job stream is dependent on the results of the previous job.

If ETL tool determines that the job return code is below the job return code threshold value yes branch decision block then ETL tool continues to the next job in the job stream of data warehouse application step and no further processing is required by ETL tool for the current job in the job stream.

Server computers and mainframe computer and client computer each include respective communications fabric which provides communications between computer processor s memory persistent storage communications unit and input output I O interface s . Communications fabric can be implemented with any architecture designed for passing data and or control information between processors such as microprocessors communications and network processors etc. system memory peripheral devices and any other hardware components within a system. For example communications fabric can be implemented with one or more buses.

Memory and persistent storage are computer readable storage media. In this embodiment memory includes random access memory RAM and cache memory . In general memory can include any suitable volatile or non volatile computer readable storage media.

Data warehouse application ETL tool data source data target mainframe OS job scheduler job reader library and application development program are stored in respective persistent storage for execution and or access by one or more of the further respective computer processors via one or more memories of memory . In this embodiment persistent storage includes a magnetic hard disk drive. Alternatively or in addition to a magnetic hard disk drive persistent storage can include a solid state hard drive a semiconductor storage device read only memory ROM erasable programmable read only memory EPROM flash memory or any other computer readable storage media that is capable of storing program instructions or digital information.

The media used by persistent storage may also be removable. For example a removable hard drive may be used for persistent storage . Other examples include optical and magnetic disks thumb drives and smart cards that are inserted into a drive for transfer onto another computer readable storage medium that is also part of persistent storage .

Communications unit in these examples provides for communications with other data processing systems or devices including resources of server computers and mainframe computer and client computer . In these examples communications unit includes one or more network interface cards. Communications unit may provide communications through the use of either or both physical and wireless communications links. Data warehouse application ETL tool data source data target mainframe OS job scheduler job reader library and application development program may be downloaded to respective persistent storage through communications unit .

I O interface s allows for input and output of data with other devices that may be connected to server computers and mainframe computer and client computer . For example I O interface may provide a connection to external device s such as a keyboard a keypad a touch screen and or some other suitable input device. External device s can also include portable computer readable storage media such as for example thumb drives portable optical or magnetic disks and memory cards. Software and data used to practice embodiments of the present invention e.g. data warehouse application ETL tool data source data target mainframe OS job scheduler job reader library and application development program can be stored on such portable computer readable storage media and can be loaded onto respective persistent storage via I O interface s . I O interface s also connect to a display .

The present invention may be a system a method and or a computer program product. The computer program product may include a computer readable storage medium or media having computer readable program instructions thereon for causing a processor to carry out aspects of the present invention.

The computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device. The computer readable storage medium may be for example but is not limited to an electronic storage device a magnetic storage device an optical storage device an electromagnetic storage device a semiconductor storage device or any suitable combination of the foregoing. A non exhaustive list of more specific examples of the computer readable storage medium includes the following a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory a static random access memory SRAM a portable compact disc read only memory CD ROM a digital versatile disk DVD a memory stick a floppy disk a mechanically encoded device such as punch cards or raised structures in a groove having instructions recorded thereon and any suitable combination of the foregoing. A computer readable storage medium as used herein is not to be construed as being transitory signals per se such as radio waves or other freely propagating electromagnetic waves electromagnetic waves propagating through a waveguide or other transmission media e.g. light pulses passing through a fiber optic cable or electrical signals transmitted through a wire.

Computer readable program instructions described herein can be downloaded to respective computing processing devices from a computer readable storage medium or to an external computer or external storage device via a network for example the Internet a local area network a wide area network and or a wireless network. The network may comprise copper transmission cables optical transmission fibers wireless transmission routers firewalls switches gateway computers and or edge servers. A network adapter card or network interface in each computing processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium within the respective computing processing device.

Computer readable program instructions for carrying out operations of the present invention may be assembler instructions instruction set architecture ISA instructions machine instructions machine dependent instructions microcode firmware instructions state setting data or either source code or object code written in any combination of one or more programming languages including an object oriented programming language such as Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The computer readable program instructions may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider . In some embodiments electronic circuitry including for example programmable logic circuitry field programmable gate arrays FPGA or programmable logic arrays PLA may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to personalize the electronic circuitry in order to perform aspects of the present invention.

Aspects of the present invention are described herein with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer readable program instructions.

These computer readable program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks. These computer readable program instructions may also be stored in a computer readable storage medium that can direct a computer a programmable data processing apparatus and or other devices to function in a particular manner such that the computer readable storage medium having instructions stored therein comprises an article of manufacture including instructions which implement aspects of the function act specified in the flowchart and or block diagram block or blocks.

The computer readable program instructions may also be loaded onto a computer other programmable data processing apparatus or other device to cause a series of operational steps to be performed on the computer other programmable apparatus or other device to produce a computer implemented process such that the instructions which execute on the computer other programmable apparatus or other device implement the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of instructions which comprises one or more executable instructions for implementing the specified logical function s . In some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.

The descriptions of the various embodiments of the present invention have been presented for purposes of illustration but are not intended to be exhaustive or limited to the embodiments disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the invention. The terminology used herein was chosen to best explain the principles of the embodiment the practical application or technical improvement over technologies found in the marketplace or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.

The programs described herein are identified based upon the application for which they are implemented in a specific embodiment of the invention. However it should be appreciated that any particular program nomenclature herein is used merely for convenience and thus the invention should not be limited to use solely in any specific application identified and or implied by such nomenclature.

It is to be noted that the term s Smalltalk and the like may be subject to trademark rights in various jurisdictions throughout the world and are used here only in reference to the products or services properly denominated by the marks to the extent that such trademark rights may exist.

