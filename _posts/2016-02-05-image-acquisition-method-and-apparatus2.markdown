---

title: Image acquisition method and apparatus
abstract: A method and an apparatus for acquiring an image of a subject are provided. The method for acquiring the image of the subject includes acquiring a first preliminary image and a second preliminary image of the subject through an image sensor operatively coupled to an electronic device, determining a candidate emission time relating to an acquisition of an output image of the subject, based on a difference between state information of at least part of the first preliminary image and state information of at least part of the second preliminary image, comparing the candidate emission time with a time corresponding to a synchronization period where a plurality of lines of the image sensor simultaneously acquires the output image, and acquiring the output image of the subject based on the comparison.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09635279&OS=09635279&RS=09635279
owner: Samsung Electronics Co., Ltd.
number: 09635279
owner_city: Suwon-si
owner_country: KR
publication_date: 20160205
---
This application is a continuation application of prior application Ser. No. 14 501 637 filed on Sep. 30 2014 which has issued as U.S. Pat. No. 9 258 489 on Feb. 9 2016 and claimed the benefit under 35 U.S.C. 119 a of a Korean patent application filed on Sep. 30 2013 in the Korean Intellectual Property Office and assigned Serial number 10 2013 0116306 the entire disclosure of which is hereby incorporated by reference.

The present disclosure relates to an electronic device. More particularly the present disclosure relates to a method and an apparatus for image acquisition.

A camera is an optical device for capturing still or moving images of a subject and widely applied to art industrial and academic fields. In recent various mobile devices e.g. mobile phone laptop or wearable electronic device have a camera function based on technological advance and thus general users can easily utilize the camera. The camera can include an image sensor for sensing an image and a flash for emitting light. The flash can include for example a light emitting diode LED flash and a xenon flash. The camera can adjust brightness of the image of the subject by controlling an intensity of the flash or an exposure time of the image sensor.

A camera e.g. a camera including the LED flash may apply the uniform exposure time of the image sensor and the uniform emission time of the flash to capture the subject. For example the camera controls the flash to discharge the flash throughout the exposure time of the image sensor. Such a camera control method controls the image sensor and the flash emission time without considering a distance between the main subject and the camera and the exposure difference of the light e.g. the light produced from the flash according to a distance between the background and the camera. As a result either the main subject or the background cannot obtain an adequate brightness.

For example a main subject e.g. a person is close to the camera and other subject e.g. the background is far away from the camera. In this case the distance difference of the main subject e.g. the person and the other subject e.g. the background can change the brightness of the corresponding image area e.g. a main subject area or other subject area according to the flash emission. For example the main subject which is close to the camera can receive more light from the flash. Hence the image area corresponding to the main subject is brighter than the user s intended brightness and the image of the main subject can be too much bright.

By contrast the other subject which is away from the camera can receive little light from the flash. Accordingly the image area corresponding to the other subject can be too dark to identify the other subject.

The above information is presented as background information only to assist with an understanding of the present disclosure. No determination has been made and no assertion is made as to whether any of the above might be applicable as prior art with regard to the present disclosure.

Aspects of the present disclosure are to address at least the above mentioned problems and or disadvantages and to provide at least the advantages described below. Accordingly an aspect of the present disclosure is to provide image acquisition method and apparatus for obtaining an adequate brightness in the image areas corresponding to the main subject and the other subject by dynamically determining the flash emission time and the exposure time of the image sensor based on the exposure difference of the light source e.g. the flash light .

In accordance with an aspect of the present disclosure a method of an electronic device for acquiring an image of a subject is provided. The method includes acquiring a first preliminary image and a second preliminary image of the subject through an image sensor operatively coupled to the electronic device determining a candidate emission time relating to an acquisition of an output image of the subject based on a difference between state information of at least part of the first preliminary image and state information of at least part of the second preliminary image comparing the candidate emission time with a time corresponding to a synchronization period where a plurality of lines of the image sensor simultaneously acquires the output image and acquiring the output image of the subject based on the comparison wherein the acquiring of the output image further includes when the candidate emission time is smaller than or equal to the synchronization period controlling a light emitting module operatively coupled to the electronic device to produce light during the candidate emission time in the synchronization period.

In accordance with another aspect of the present disclosure an electronic device for acquiring an image of a subject is provided. The electronic device includes a light emitting module configured to emit light an image sensor configured to acquire a first preliminary image and a second preliminary image of a subject a calculation module configured to determine a difference between state information of at least part of the first preliminary image and state information of at least part of the second preliminary image and a determination module configured to determine a candidate emission time relating to an acquisition of an output image of the subject based on the calculated difference wherein the determination module is further configured to compare the candidate emission time with a time corresponding to a synchronization period where a plurality of lines of the image sensor simultaneously acquires the output image and when the candidate emission time is smaller than or equal to the synchronization period to acquire the output image by controlling the light emitting module to produce light during the candidate emission time in the synchronization period.

In accordance with an aspect of the present disclosure a non transitory computer readable recording medium having a computer program thereon is provided wherein the computer program causes a computer to execute a method. The method includes acquiring a first preliminary image and a second preliminary image of the subject through an image sensor operatively coupled to an electronic device determining a candidate emission time relating to an acquisition of an output image of the subject based on a difference between state information of at least part of the first preliminary image and state information of at least part of the second preliminary image comparing the candidate emission time with a time corresponding to a synchronization period where a plurality of lines of the image sensor simultaneously acquires the output image and acquiring the output image of the subject based on the comparison wherein the acquiring of the output image further includes when the candidate emission time is smaller than or equal to the synchronization period controlling a light emitting module operatively coupled to the electronic device to produce light during the candidate emission time in the synchronization period.

Other aspects advantages and salient features of the disclosure will become apparent to those skilled in the art from the following detailed description which taken in conjunction with the annexed drawings discloses various embodiments of the present disclosure.

Throughout the drawings like reference numerals will be understood to refer to like parts components and structures.

The following description with reference to the accompanying drawings is provided to assist in a comprehensive understanding of various embodiments of the present disclosure as defined by the claims and their equivalents. It includes various specific details to assist in that understanding but these are to be regarded as merely exemplary. Accordingly those of ordinary skill in the art will recognize that various changes and modifications of the various embodiments described herein can be made without departing from the scope and spirit of the present disclosure. In addition descriptions of well known functions and constructions may be omitted for clarity and conciseness.

The terms and words used in the following description and claims are not limited to the bibliographical meanings but are merely used by the inventor to enable a clear and consistent understanding of the present disclosure. Accordingly it should be apparent to those skilled in the art that the following description of various embodiments of the present disclosure is provided for illustration purpose only and not for the purpose of limiting the present disclosure as defined by the appended claims and their equivalents.

It is to be understood that the singular forms a an and the include plural referents unless the context clearly dictates otherwise. Thus for example reference to a component surface includes reference to one or more of such surfaces.

By the term substantially it is meant that the recited characteristic parameter or value need not be achieved exactly but that deviations or variations including for example tolerances measurement error measurement accuracy limitations and other factors known to those of skill in the art may occur in amounts that do not preclude the effect the characteristic was intended to provide.

An electronic device according to various embodiments of the present disclosure can be a device including a camera or a camera function. For example the electronic device can include a smartphone a tablet Personal Computer PC a mobile phone a video phone an e book reader a desktop PC a laptop PC a netbook computer a Personal Digital Assistant PDA a Portable Multimedia Player PMP an MP3 player a mobile medical appliance and a wearable device e.g. at least one of a head mounted device HMD such as electronic glasses an electronic textiles an electronic bracelet an electronic necklace an electronic accessory and a smart watch .

The electronic device can be a smart home appliance having the camera function. The smart home appliance can include for example at least one of a television a Digital Video Disk DVD player an audio system a refrigerator an air conditioner a vacuum cleaner an oven a microwave oven a washing machine an air purifier a set top box a TV box e.g. Samsung HomeSync AppleTV or Google TV game consoles an electronic dictionary a digital key a camcorder and a digital frame.

The electronic device can include at least one of various medical appliances e.g. Magnetic Resonance Angiography MRA Magnetic Resonance Imaging MRI Computed Tomography CT X ray ultrasonicator a navigation device a Global Positioning System GPS receiver an Event Data Recorder EDR a Flight Data Recorder FDR an in vehicle infotainment device marine electronic equipment e.g. marine navigation device and gyro compass avionics a home or industrial robot and a security device with the camera function.

The electronic device can include at least one of furniture or part of building structure having the camera function an electronic board an electronic signature receiving device a projector and various gauges e.g. gauges for water electricity or radio wave . The electronic device can be one or a combination of those various devices. Those skilled in the art shall understand that the electronic device of the present disclosure is not limited those devices. Now an electronic device and a method for acquiring e.g. capturing an image are explained by referring to the attached drawings.

Referring to a camera module is illustrated where the camera module can include a lens an image sensor a camera module and a light emitting module . The lens can be an optical component for receiving an optimal image of a subject. For example the lens can include at least one of a zoom lens a focus lens and an apochromatic lens. The zoom lens can adjust the size the focus lens can adjust a point of the subject and the apochromatic lens can distort the image of the subject. Each lens can include one or more lenses.

The image sensor can convert an incident optimal image from the lens to an electric signal and acquire e.g. capture the image e.g. a digital image of the subject. The image sensor can acquire an image of different properties according to a mode of the camera module . For example in a flash mode the image sensor can acquire preliminary images of different brightness under different light emission e.g. light intensity of the light emitting module . For example the image sensor can acquire a first preliminary image of a first brightness in non flash mode e.g. no flash of the light intensity 0 of the light emitting module and acquire a second preliminary image of a second brightness of the light intensity greater than 0 e.g. pre flash of the light emitting module .

The preliminary image can be temporarily acquired before the output image acquisition so as to acquire the image hereafter referred to as an output image finally output to the user when the user wants the flash mode. The flash mode can emit the light emitting module with the light intensity set by a user through a menu of the camera module or automatically light the light emitting module according to an external luminance.

The image sensor can provide the acquired image information e.g. the captured image data to the control module . The image sensor can sense e.g. capture the image based on exposure time information received from the control module . In the flash mode the image sensor can receive its exposure time information determined based on first preliminary image information and second preliminary image information from the control module and sense the output image based on the exposure time information e.g. during the determined exposure time . For example the image sensor can employ a Complementary Metal Oxide Semiconductor CMOS sensor a Charged Coupled Device CCD image sensor and a Foveon image sensor. For example the image sensor can be driven as at least one of a rolling shutter and a global shutter.

The control module can control at least one of the modules e.g. the lens the image sensor and the light emitting module of the camera module to capture the image of the subject. The control module can include a calculation module and a determination module . The calculation module can determine one or more brightness information of the image information based on the image information e.g. the first preliminary image or the second preliminary image of the given subject which is provided from the image sensor .

For example each image the first preliminary image or the second preliminary image can be divided into a plurality of image subareas corresponding to a plurality of pixel groups of the image sensor respectively. The pixel groups can include at least one of pixels of the image sensor . In this case the calculation module can determine the brightness information of the image subareas. The calculation module can determine the image brightness information in all or in average by weighting one or more brightness information of the image subareas of the image.

The calculation module can determine a difference between one or more brightness information of the image subareas corresponding to one image e.g. the first preliminary image and one or more brightness information of the image subareas corresponding to the other image e.g. the second preliminary image . For example the calculation module can calculate at least one of the brightness differences of the corresponding image subareas e.g. the same pixel group of the first preliminary image and the second preliminary image.

The calculation module may calculate the brightness information of the image subareas based on distance information between the subject and the lens. For example the calculation module can calculate the brightness information difference of the image subareas of the same or similar distance information between a light source e.g. the flash and the subject in the first preliminary image and the second preliminary image. For example the calculation module can calculate the brightness difference between the image subarea corresponding to the distance information from 1 m to 2 m between the subject and the light source in the first preliminary image and the image subarea corresponding to the distance information from 1 m to 2 m between the subject and the light source in the second preliminary image.

To acquire e.g. capture the image e.g. the output image of the subject the calculation module can determine the exposure time of the image sensor taken to acquire the image e.g. the first preliminary image or the second preliminary image . For example when the image sensor acquires the first preliminary image with a two second exposure the calculation module can determine the exposure time of the first preliminary image as two seconds. The calculation module can determine not only the exposure time of the image sensor for the image acquisition but also a gain of the image sensor . The gain of the image sensor can be a ratio e.g. photoconversion ratio of the optical signal received from the lens to the electric signal. The gain can be used to determine the exposure of the image sensor together with the exposure time of the image sensor . For example the exposure of the image sensor can combine the exposure time and the gain of the image sensor according to a preset algorithm.

The calculation module can calculate at least one of the brightness information e.g. the total or average brightness of the image of the given image e.g. the first preliminary image or the second preliminary image of the subject the brightness information corresponding to the image subareas respectively of the image and the brightness difference of the corresponding image subareas e.g. the same pixel group of the two corresponding images e.g. the first preliminary image and the second preliminary image and provides at least one of them to the determination module . A method of the control module e.g. the calculation module for determining various information relating to the brightness of the image shall be explained by referring to .

The determination module can determine the exposure time of the image sensor to acquire the output image based on the brightness difference e.g. the whole or average brightness of the first preliminary image and the second preliminary image of the first preliminary image and the second preliminary image. The determination module can provide the exposure time information to the image sensor so as to control the image sensor to sense e.g. capture the data of the output image during the exposure time. For example the determination module can generate an image control signal based on the exposure time information. The determination module can send the image control signal including the exposure time information to the image sensor to control the image sensor to sense the output image of the subject during the exposure time.

The determination module can determine the emission mode e.g. an emission time or the emission intensity of the light emitting module required to acquire the image e.g. the output image based on the information provided from the calculation module . The determination module can determine the emission time hereafter referred to as a candidate emission time of the light emitting module estimated for the output image acquisition of the subject based on the brightness difference of at least one e.g. the image subarea of the first preliminary image and the image subarea of the second preliminary image of the same pixel group of the pixel groups of the image sensor of the image subareas of the first preliminary image and the second preliminary image of the subject.

The determination module can determine an emission reference time based on the exposure time of the image sensor determined for the output image acquisition of the subject and a driving signal e.g. a vertical synchronization signal Vsync of one frame for controlling the image sensor . The emission reference time can be used to determine whether the candidate emission time can be the actual emission time hereafter referred to as a target emission time of the light emitting module for the output image acquisition. The emission reference time shall be explained by referring to .

When the candidate emission time satisfies the emission reference time the determination module can control the light emitting module to produce the light during the candidate emission time for the output image acquisition. For example when the candidate emission time is smaller than or equal to the emission reference time the determination module can determine the candidate emission time as the actual emission time for example as the target emission time of the light emitting module for the output image acquisition.

For example when the candidate emission time is greater than the emission reference time the determination module can determine the target emission time based on the exposure time of the image sensor determined for the output image acquisition. For example when the candidate emission time is greater than the emission reference time the determination module can determine the target emission time for the output image acquisition by adding the exposure time and an image readout time of the image sensor .

To determine the target emission time for the output image acquisition the determination module can compare the exposure time for the output image acquisition with a preset referee time hereafter referred to as an exposure reference time . For example the exposure reference time can be used to determine whether the exposure time can be used for the target emission time. For example the determination module can determine the target emission time by comparing the exposure time and the exposure reference time.

For example when the exposure time is smaller than or equal to the exposure reference time the determination module can determine the target emission time for the output image acquisition by adding the exposure time and the image readout time of the image sensor . By contrast when the exposure time is greater than the exposure reference time the determination module can determine the target emission time by comparing the candidate emission time and the emission reference time as stated above. To determine the target emission time the comparison of the exposure time and the exposure reference time can be omitted according to characteristics or design of the electronic device. The exposure reference time shall be explained by referring to .

The determination module can generate a flash control signal based on the target emission time determined based on at least one of the candidate emission time and the exposure time. The determination module can control the light emitting module to produce the light during the target emission time for the output image acquisition by sending the flash control signal to the light emitting module .

The light emitting module can control the emission time of an artificial lighting e.g. the flash required to acquire the output image based on the flash control signal received from the determination module . The light emitting module can include a flash control module and a flash . The flash control module can control at least one of the light intensity e.g. the emission time and an on off timing of the flash based on the received flash control signal. For example the flash control module can control the emission e.g. the emission time of the flash by controlling voltage or current flowing through the flash supplied to the flash based on the flash control signal. The flash produces the light under the control of the flash control module . For example the flash can include at least one of an LED flash and a xenon flash.

Now a method for determining the brightness information relating to the image information through the camera module e.g. the calculation module of is explained by referring to .

Referring to a conceptual diagram of an image sensor e.g. the image sensor of is illustrated where the image sensor can include a plurality of subareas SAs e.g. a plurality of pixel groups including a matrix with first through N th columns through and first through M th rows through . The each SA can include at least part of pixels not shown of the image sensor .

Image information e.g. the first preliminary image or the second preliminary image obtained from the image sensor can be divided into a plurality of image subareas ISAs corresponding to the SAs. For example the ISA of the first row and the first column of the ISAs can correspond to the SA of the first row and the first column of the image sensor . In this case the ISA of the image information can include for example image data of the subject obtained from the SA of the image sensor .

Each ISA can correspond to for example an automatic exposure window. The automatic exposure window can be a subblock divided to automatically determine the exposure e.g. the exposure determined based on the gain and the exposure time of the image sensor of the camera module of based on the brightness e.g. luminance of the subject. Each ISA of the image information can contain proper brightness information based on the brightness of the area corresponding to the subject. The proper brightness information of the ISAs can be determined using for example automatic exposure window information or an algorithm of a designer.

The camera module e.g. the calculation module of can determine for example an image histogram the brightest part of the image the darkest part of the image and the image brightness e.g. the whole or average image brightness based on the brightness information of the ISAs of the image information of the subject. To determine the image brightness information the camera module e.g. the determination module of can use for example the brightness information of the ISAs of the image information and image metering. For example the determination module can determine the image brightness information by applying a different weight to the brightness information of the ISA according to the image metering.

The image metering can include center weighted metering average metering spot metering and evaluative metering according to the weight applied to the ISAs. The center weighted metering applies the highest weight to the central part of the image the average metering applies the same weight to a plurality of groups the spot metering applies the highest weight to the group selected by the user and the evaluative metering applies the high weight to the group determined based on the image analysis.

Referring to a conceptual diagram is illustrated where the conceptual diagram can include the first preliminary image which can be divided into a plurality of first ISAs. The second preliminary image can be divided into a plurality of second ISAs. The ISAs and the ISAs each can contain their own brightness value according to the brightness of the area corresponding to the subject.

The camera module e.g. the calculation module of can determine the brightness difference e.g. luminance difference Y of the area corresponding to the image brightness information by comparing the brightness between at least part e.g. at least one ISA of the first preliminary image and at least part e.g. at least one ISA of the second preliminary image . For example the calculation module can determine the brightness difference Y between the first ISA of the first preliminary image and the second ISA of the second preliminary image corresponding to the same SA in the image sensor e.g. the image sensor of . The calculation module can determine the brightness difference of a first ISA and a second ISA as the brightness difference of a corresponding area of the image brightness information .

The calculation module can determine the brightness difference between the first ISA of the first preliminary image and the second ISA of the second preliminary image corresponding to the same area of the image sensor. The calculation module can determine the brightness difference between the first ISA of the first preliminary image and the second ISA of the second preliminary image corresponding to different areas of the image sensor. For example the calculation module can determine the brightness difference between at least one ISA and the ISA e.g. the ISA corresponding to the area adjoining the ISA next to the ISA. For example the calculation module can determine the brightness difference between the first ISA of the first preliminary image and at least one of second ISAs and of the second preliminary image . For example the calculation module can set the determined brightness difference to the brightness difference Y of the area of the image brightness information corresponding to the first ISA . For example the camera module can give priority to the brightness difference Y in a descending order and determine the candidate emission time using the brightness difference Y corresponding to the designated priority e.g. the priority corresponding to the designated range .

For example to determine the candidate emission time of the light emitting module e.g. the light emitting module of for the output image acquisition the camera module e.g. the determination module of can use the greatest one of the brightness differences of the ISA and the ISA of the first preliminary image and the second preliminary image . For example when the brightness difference of the first ISA of the first preliminary image and the second ISA of the second preliminary image is the greatest value the determination module can use the brightness difference Y of the area corresponding to the ISAs and of the image brightness information .

To determine at least one of the candidate emission time and the exposure time for the output image acquisition the determination module can use at least one of the brightness of the first preliminary image e.g. the whole or average brightness of the first preliminary image the brightness of the second preliminary image the intensity information of the light emitting module the light emitting module of corresponding to the first preliminary image and the second preliminary image and the preset intensity information or the preset image brightness information of the light emitting module for the output image acquisition e.g. the image brightness set by the user or automatically for the output image acquisition which is given by Equation 1. Flash  Target  Flash  Flash  Flash  Flash   Flash Exp.Factors  Flash Exp.Factors Equation 1 

Flash AE Target denotes the image brightness set for acquiring the output image for example the target output image brightness information. N Flash Y denotes the brightness of the first preliminary image . P Flash  Y denotes the brightness difference of a particular area of the first preliminary image and the second preliminary image . M Flash L denotes the intensity of the flash e.g. the flash of set for the output image acquisition.

P Flash L denotes the intensity of the flash used to acquire the second preliminary image . N Flash Exp.Factors denotes the exposure e.g. the combined value of the exposure time and the gain of the image sensor to acquire the first preliminary image . M Flash Exp.Factors denotes the candidate emission time or the exposure of the image sensor for the output image acquisition. For example Flash AE Target and P Flash L can be specified using a program. N Flash Y N Flash Exp.Factors and P Flash  Y can be calculated by the calculation module as stated earlier. M Flash L can be fixed to a specific value.

To determine the candidate emission time for the output image acquisition P Flash  Y can use the greatest one e.g. the brightness difference corresponding to the area of the image brightness information of the brightness differences of the ISAs of the first preliminary image and the second preliminary image . To determine the exposure time of the image sensor for the output image acquisition P Flash  Y can use the brightness difference of the first preliminary image and the second preliminary image e.g. the average brightness difference of the first preliminary image and the second preliminary image . To determine the exposure time of the image sensor the gain of the image sensor can be set to a specific value.

To determine the candidate emission time the greatest one of the brightness differences Y of the ISAs of the first preliminary image and the second preliminary image is used so that the light emitting module can illuminate the brightest area of the subject with the adequate brightness e.g. the unsaturated light with the flash by emitting the light based on the brightness area of the subject. To determine the exposure time of the image sensor for the output image acquisition the brightness difference of the first preliminary image and the second preliminary image is used so that a particular area e.g. the dark area of the output image can attain the adequate brightness by exposing the image sensor based on the brightness of the whole image.

Referring to operation timings are illustrated where a first waveform relates to a driving signal e.g. a vertical synchronization signal Vsync of an image sensor . A second waveform magnifies a portion corresponding to a first dotted line and a second dotted line of the first waveform . The image sensor e.g. the image sensor of can include a plurality of lines e.g. a plurality of horizontal lines Lthrough L. The lines Lthrough Leach can include a plurality of pixels not shown . The lines Lthrough Lof the image sensor can sequentially acquire e.g. capture the image information e.g. the first preliminary image the second preliminary image or the output image based on the driving signal e.g. the vertical synchronization signal Vsync of the image sensor .

For example the lines Lthrough Lof the image sensor can be exposed during an exposure time t to acquire the output image information. The pixels of the image sensor can be exposed in sequence. A time gap corresponding to a line readout time can take place between an exposure of a first pixel e.g. a first pixel of the first line L of a current line and an exposure of a first pixel e.g. a first pixel of a second line L of a next line. The line readout time can store for example the image information e.g. the output image information corresponding to the lines of the subject acquired by the lines Lthrough L. The line readout time can be variously set according to a designer or characteristics of the electronic device.

A time t can be an exposure reference time. The exposure reference time t can be used to determine whether the exposure time t determined for the output image acquisition can be used as an emission time of the light emitting module e.g. the light emitting module of for the output image acquisition. The exposure reference time t can be for example an image readout time. This is because a period for acquiring the output image in the lines Lthrough Lat the same time hereafter referred to as a synchronization period is not sufficient when the exposure time t of the image sensor is smaller than or equal to the image readout time. In this case the emission time for the output image acquisition can be a sum of a whole exposure time t and the image readout time. When the exposure time t is greater than the image readout time the emission time for the output image acquisition can be determined based on the candidate emission time as mentioned above.

The exposure reference time t can be 1 Frame Per Second FPS  max. The FPS can indicate the number of frames per second in the image sensor . The image sensor can include the frames in various numbers per second in the electronic device according to the design of the electronic device. For example the image sensor can include the frames between 15 frames and 60 frames per second. In this case FPS max can be set to a specific number of frames e.g. 15 frames according to the user s setting or the environment. The exposure reference time t can be designed variously according to the designer or the characteristics of the electronic device.

A time t for the synchronization period can range from a start when N th line Lbeing the last line of the image sensor acquires the image information e.g. the output image to the end when the first line Lacquires the image information e.g. the output image . According to the design of the electronic device the synchronization period can lie between an end of the current frame and a start of the next frame. The time t for the synchronization period can have a preset error e.g. the line readout time from the time of the frame according to the design.

The synchronization period can be determined using at least one of a Start of Frame SOF and an End of Frame EOF of the vertical synchronization signal Vsync. For example the synchronization period can start after an image readout time t from the exposure time t of the image sensor . The image readout time t is a fixed value according to a pixel clock and image frame register setting of the image sensor and accordingly the synchronization period can be determined using the SOF the EOF or a timer. The synchronization period can vary based on the image readout time the line readout time or other factors e.g. the characteristics of the electronic device .

The time t for the synchronization period can be the emission reference time for the output image acquisition. To acquire the output image of the subject when the candidate emission time is smaller than or equal to the time t for the synchronization period the control module e.g. the control module of of the electronic device can control the light emitting module e.g. the light emitting module of to produce the light during the candidate emission time in the synchronization period . As all the pixels of the image sensor are exposed in the synchronization period every pixel can receive the light e.g. the same intensity of the flash.

An electronic device for acquiring an image of a subject includes a light emitting module for emitting light an image sensor for acquiring a first preliminary image and a second preliminary image of the subject a calculation module for determining a difference between state information of at least part of the first preliminary image and state information of at least part of the second preliminary image and a determination module for determining a candidate emission time relating to output image acquisition of the subject based on the difference. The determination module compares the candidate emission time with a time corresponding to a synchronization period where a plurality of lines of the image sensor simultaneously acquires the output image and when the candidate emission time is smaller than or equal to the synchronization period acquires the output image by controlling the light emitting module to produce light during the candidate emission time in the synchronization period.

The image sensor acquires the first preliminary image without the emission of the light emitting module and acquires the second preliminary image with a preset intensity which is greater than non emission of the light emitting module.

The calculation module uses brightness information as the state information of the first preliminary image and the second preliminary image.

The calculation module determines brightness information of the first preliminary image based on state information of at least part of the first preliminary image determines brightness information of the second preliminary image based on state information of at least part of the second preliminary image and determines a brightness difference of the first preliminary image and the second preliminary image based on the brightness information of the first preliminary image and the brightness information of the second preliminary image.

The calculation module determines brightness information of at least one of first Image Sub Areas ISAs of the first preliminary image determines brightness information of at least one of second ISAs of the second preliminary image and determines at least one brightness difference of the first ISAs and the second ISAs.

The determination module determines the candidate emission time using a maximum brightness difference of the at least one brightness difference.

The determination module determines an exposure time of the image sensor to acquire the output image based on the brightness difference of the first preliminary image and the second preliminary image.

When the candidate emission time is greater than the synchronization period the determination module controls the light emitting module to produce the light based on a sum of the exposure time and the output image readout time of the lines.

The electronic device e.g. the camera module acquires the first preliminary image and the second preliminary image determines whether a mode for acquiring the output image is a flash mode for lighting the light emitting module and when the mode is the flash mode acquires the first preliminary image and the second preliminary image.

The electronic device acquires the first preliminary image using the light emitting module of a first light intensity and acquires the second preliminary image using the light emitting module of a second light intensity which is different from the first light intensity.

To determine the candidate emission time the electronic device uses brightness information as state information of the first preliminary image and the second preliminary image.

To determine the candidate emission time the electronic device determines brightness information of the first preliminary image based on state information of at least part of the first preliminary image determines brightness information of the second preliminary image based on state information of at least part of the second preliminary image and determines a brightness difference of the first preliminary image and the second preliminary image based on the brightness information of the first preliminary image and the brightness information of the second preliminary image.

To determine the candidate emission time the electronic device determines brightness information of at least one of first ISAs of the first preliminary image determines brightness information of at least one of second ISAs of the second preliminary image determines at least one brightness difference of the first ISAs and the second ISAs and determines the candidate emission time using the brightness difference corresponding to a preset priority of the at least one brightness difference.

To determine the candidate emission time the electronic device determines the candidate emission time based on at least one of the brightness of the first preliminary image and the second preliminary image light intensity information corresponding to the first preliminary image and the second preliminary image preset light intensity information for acquiring the output image and preset image brightness information for acquiring the output image.

To determine the candidate emission time the electronic device determines an exposure time of the image sensor for the output image acquisition based on the brightness difference of the first preliminary image and the second preliminary image.

To acquire the output image the electronic device compares the exposure time with a preset reference time relating to the emission time for the output image acquisition and when the exposure time is smaller than or equal to the reference time controls the light emitting module to produce the light based on a sum of the exposure time and a third image readout time of the lines.

To acquire the output image when the candidate emission time is greater than the synchronization period the electronic device controls the light emitting module to produce the light based on a sum of the exposure time and the output image readout time of the lines.

The lines includes first through N th N is a natural number greater than 1 lines and the electronic device uses a period from a start of the output image information acquisition of the N th line to an end of the output image information acquisition of the first line as the synchronization period.

A computer readable recording medium records program operations including acquiring a first preliminary image and a second preliminary image of a subject through an image sensor operatively coupled to an electronic device determining a candidate emission time relating to output image acquisition of the subject based on a difference between state information of at least part of the first preliminary image and state information of at least part of the second preliminary image comparing the candidate emission time with a time corresponding to a synchronization period where a plurality of lines of the image sensor simultaneously acquires the output image and acquiring the output image of the subject based on the comparison. The acquiring of the output image includes when the candidate emission time is smaller than or equal to the synchronization period controlling a light emitting module operatively coupled to the electronic device to produce light during the candidate emission time in the synchronization period.

Referring to a flowchart is illustrated where an electronic device e.g. the determination module of can determine whether a mode for output image acquisition is a flash mode. When determining the flash mode the electronic device e.g. the image sensor of can acquire the first preliminary image and the second preliminary image of the subject in operation . In the non flash mode the electronic device can acquire the output image of the subject without acquiring the first preliminary image or the second preliminary image.

In operation the electronic device e.g. the determination module of can determine the candidate emission time to acquire the output image of the subject based on the difference between state information e.g. the brightness information of at least part of the first preliminary image of the first preliminary image and state information e.g. the brightness information of at least part of the second preliminary image of the second preliminary image.

In operation the electronic device e.g. the determination module of can compare the candidate emission time and the synchronization period. When the candidate emission time is smaller than or equal to the synchronization period the electronic device can control the light emitting module e.g. the light emitting module of to produce the light during the candidate emission time in the synchronization period to acquire the output image of the subject in operation . When the candidate emission time is greater than the synchronization period time the electronic device can determine the emission time required to acquire the output image of the subject based on the exposure time of the image sensor in operation .

Referring to a same emission time of the light emitting module and a same exposure time of the image sensor are applied to image information and based on a particular area. Image information is captured according to an embodiment of the present disclosure. The image information is acquired based on the exposure time and the emission time determined based on the bright area e.g. the face of the main subject of the subject. When the output image is acquired with the exposure time and the emission time determined based on the bright area e.g. the face of the main subject of the subject a particular area e.g. the face of the person is too white and the face is blown out in the image information .

The image information is acquired with the exposure time and the emission time determined based on the dark area e.g. the background subject of the subject. When the output image is acquired with the exposure time and the emission time determined based on the dark area e.g. the road of the other subject of the subject the image information represents the other area e.g. the road than the main subject e.g. the person area too dark to identify subjects. When the flash light is not uniform and the same emission time and exposure time area applied the exposure of the flash light onto the whole image is not adequate.

In the image information captured with the exposure time and the emission time dynamically determined based on the state information e.g. the brightness information of the SA of the main subject the person area receives the adequate brightness to easily identify the person. Also the background area also receives the adequate brightness to identify the specific shape of the road. As such the image of subject is captured with the adequate brightness and thus the enhanced final image can be acquired.

A method for acquiring an image of a subject includes acquiring a first preliminary image and a second preliminary image of the subject through an image sensor operatively coupled to an electronic device determining a candidate emission time relating to output image acquisition of the subject based on a difference between state information of at least part of the first preliminary image and state information of at least part of the second preliminary image comparing the candidate emission time with a time corresponding to a synchronization period where a plurality of lines of the image sensor simultaneously acquires the output image and acquiring the output image of the subject based on the comparison. The acquiring of the output image includes when the candidate emission time is smaller than or equal to the synchronization period controlling a light emitting module operatively coupled to the electronic device to produce light during the candidate emission time in the synchronization period.

The acquiring of the first preliminary image and the second preliminary image includes determining whether a mode for acquiring the output image is a flash mode for lighting the light emitting module and when the mode is the flash mode acquiring the first preliminary image and the second preliminary image.

The acquiring of the first preliminary image and the second preliminary image includes acquiring the first preliminary image using the light emitting module of a first light intensity and acquiring the second preliminary image using the light emitting module of a second light intensity which is different from the first light intensity.

The determining of the candidate emission time includes using brightness information as state information of the first preliminary image and the second preliminary image.

The determining of the candidate emission time includes determining brightness information of the first preliminary image based on state information of at least part of the first preliminary image determining brightness information of the second preliminary image based on state information of at least part of the second preliminary image and determining a brightness difference of the first preliminary image and the second preliminary image based on the brightness information of the first preliminary image and the brightness information of the second preliminary image.

The determining of the candidate emission time includes determining brightness information of at least one of first ISAs of the first preliminary image determining brightness information of at least one of second ISAs of the second preliminary image determining at least one brightness difference of the first ISAs and the second ISAs and determining the candidate emission time using the brightness difference corresponding to a preset priority of the at least one brightness difference.

The determining of the candidate emission time includes determining the candidate emission time based on at least one of the brightness of the first preliminary image and the second preliminary image light intensity information corresponding to the first preliminary image and the second preliminary image preset light intensity information for acquiring the output image and preset image brightness information for acquiring the output image.

The determining of the candidate emission time includes determining an exposure time of the image sensor for the output image acquisition based on the brightness difference of the first preliminary image and the second preliminary image.

The acquiring of the output image includes comparing the exposure time with a preset reference time relating to the emission time for the output image acquisition and when the exposure time is smaller than or equal to the reference time controlling the light emitting module to produce the light based on a sum of the exposure time and a third image readout time of the lines.

The acquiring of the output image includes when the candidate emission time is greater than the synchronization period controlling the light emitting module to produce the light based on a sum of the exposure time and the output image readout time of the lines.

The lines comprises first through N th N is a natural number greater than 1 lines and the acquiring of the output image includes using a period from a start of the output image information acquisition of the N th line to an end of the output image information acquisition of the first line as the synchronization period.

The method includes acquiring the first preliminary image without the emission of the light emitting module and acquiring the second preliminary image with a preset intensity which is greater than non emission of the light emitting module.

The method includes using brightness information as the state information of the first preliminary image and the second preliminary image.

The method includes determining brightness information of the first preliminary image based on state information of at least part of the first preliminary image determining brightness information of the second preliminary image based on state information of at least part of the second preliminary image and determining a brightness difference of the first preliminary image and the second preliminary image based on the brightness information of the first preliminary image and the brightness information of the second preliminary image.

The method includes determining brightness information of at least one of first ISAs of the first preliminary image determining brightness information of at least one of second ISAs of the second preliminary image and determining at least one brightness difference of the first ISAs and the second ISAs.

The method includes determining the candidate emission time using a maximum brightness difference of the at least one brightness difference.

The method includes determining an exposure time of the image sensor to acquire the output image based on the brightness difference of the first preliminary image and the second preliminary image.

The method includes when the candidate emission time is greater than the synchronization period controlling the light emitting module to produce the light based on a sum of the exposure time and the output image readout time of the lines.

Referring to an electronic device is illustrated in which the electronic device can include a bus a processor a memory an input output interface a display and a communication interface .

The bus can be a circuit for interlinking the above stated components and transferring communication e.g. control messages between the above stated components.

The processor can receive an instruction from the other components e.g. the memory the input output interface the display and the communication interface via the bus interpret the received instruction and perform an operation or a data processing according to the interpreted instruction.

The memory can store the instruction or the data received from or generated by the processor or the other components e.g. the user input module the display and the communication interface . For example the memory can include programming modules of for example a kernel a middleware an Application Programming Interface API and an application . The programming modules can be implemented using software firmware and hardware or a combination of at least two of them.

The kernel can control or manage system resources e.g. the bus the processor and the memory used to execute the operation or the function of the other programming modules for example the middleware the API or the application . Also the kernel can provide an interface allowing the middleware the API or the application to access and to control or manage the individual component of the electronic device .

The middleware can relay data between the API or the application and the kernel . In relation to task requests received from the application the middleware can for example control the task request e.g. scheduling or load balancing by giving priority of the system resource e.g. the bus the processor or the memory of the electronic device to at least one of the applications .

The API which is an interface for the application to control the function provided from the kernel or the middleware can include at least one interface or function e.g. instruction for for example file control window control image processing or text control.

The input output interface can forward the instruction or the data input from the user to the processor or the memory for example via the bus . Also the input output interface can output audio information received from the memory or the communication interface for example via the bus .

The communication interface can connect the communication between one or more other electronic devices and the electronic device . The communication interface can support a short range communication protocol e.g. Wireless Fidelity Wifi Wifi direct WiGig Bluetooth BT Bluetooth Low Energy BLE Zigbee UWB Near Field Communication NFC RFID audio sync Electric Field Communication EFC Human Body Communication HBC or VLC or a network communication e.g. Internet Local Area Network LAN Wire Area Network WAN telecommunication network cellular network satellite network or Plain Old Telephone Service POTS to communicate to an electronic device and a server . The electronic devices and can be the same as or different from the electronic device in type.

Referring to an electronic device is illustrated where the electronic device can include one or more processors a Subscriber Identity Module SIM card a memory a communication module a sensor module a user input device a display an interface an audio codec a camera module a power management module a battery an indicator and a motor .

The processor can include one or more Application Processors APs or one or more Communication Processors CPs . The processor can be the processor of . While the AP and the CP are included in the processor in the AP and the CP can be included to different IC packages. For example the AP and the CP can be included in a single IC package.

The AP can control a plurality of hardware or software components connected to the AP by driving an operating system or an application program and carry out various data processing and operations including multimedia data. The AP can be implemented using for example a System on Chip SoC . The processor can further include a Graphic Processing Unit GPU not shown .

The CP manages data links and converts the communication protocol in the communication between the electronic device e.g. the electronic device including the electronic device and the other electronic devices connected over the network. The CP can be implemented using for example the SoC. The CP can perform at least part of a multimedia control function. The CP can identify and authenticate the electronic device using a subscriber identification module e.g. the SIM card in the communication network. The CP can provide the user with services such as voice call video call text message and packet data.

The CP can control data transmission and reception of the communication module . While the components of the CP the power management module and the memory are depicted separately from the AP in the AP can include at least part e.g. the CP of the above stated components.

The AP or the CP can load and process the instruction or the data received from its connected non volatile memory or at least one of the other components in a volatile memory. Also the AP or the CP can store data received from or generated by at least one of the other components in the non volatile memory.

The SIM card can be a card including the subscriber identity module and be inserted to a slot formed at a specific location of the electronic device. The SIM card can include unique identification information e.g. Integrated Circuit Card Identifier ICCID or subscriber information e.g. International Mobile Subscriber Identity IMSI .

The memory can include an internal memory or an external memory . The memory can be for example the memory of . The internal memory can include at least one of for example volatile memory e.g. Dynamic RAM DRAM Static RAM SRAM Synchronous Dynamic RAM SDRAM or non volatile memory e.g. One Time Programmable ROM OTPROM Programmable ROM PROM Erasable and Programmable ROM EPROM Electrically Erasable and Programmable ROM EEPROM mask ROM flash ROM NAND flash memory NOR flash memory . The internal memory may employ a Solid State Drive SSD . The external memory can further include a flash drive for example a Compact Flash CF a Secure Digital SD a Micro Secure Digital SD a Mini SD an extreme digital xD or a memory stick.

The communication module can include a wireless communication module and a Radio Frequency RF module . The communication module can be for example the communication interface of . The wireless communication module can include for example a Wifi a BT a GPS and an NFC . For example the wireless communication module can provide a wireless communication function using a radio frequency. Additionally or substantially the wireless communication module can include a network interface e.g. LAN card or a modem for connecting the hardware to the network e.g. Internet LAN WAN telecommunication network cellular network satellite network or POTS .

The RF module can control the data transmission and reception including the transmission and reception of the RF signal or the paged electric signal. For example the RF module can includes a transceiver a Pulse Amplitude Modulation PAM a frequency filter or a Low Noise Amplifier LNA which are not shown. The RF module can further include a component e.g. a conductor or a conducting wire for sending and receiving electromagnetic waves in free space in the wireless communication.

The sensor module can include at least one of a gesture sensor A a gyro sensor B an atmospheric pressure sensor C a magnetic sensor D an acceleration sensor E a grip sensor F a proximity sensor G a Red Green Blue RGB sensor H a biometric sensor I a temperature humidity sensor J a light sensor K and an UltraViolet UV sensor M. The sensor module can measure a physical quantity or detect the operation status of the electronic device and convert the measured or detected information to an electric signal. Additionally or substantially the sensor module can include an E noise sensor an electromyography EMG sensor an electroencephalogram EEG sensor an electrocardiogram ECG sensor or a finger print sensor. The sensor module can further include a control circuit for controlling its one or more sensors.

The user input device can include a touch panel a digital pen sensor a key and an ultrasonic input device . For example the user input device can be the user input output interface of . The touch panel can recognize the touch input using at least one of capacitive resistive infrared and Surface Acoustic Wave SAW techniques. The touch panel may further include a controller not shown . The capacitive touch panel can recognize not only the direct touch but also the proximity. The touch panel may further include a tactile layer. In this case the touch panel can provide a tactile response to the user.

The digital pen sensor can be implemented using the same or similar method as or to the user s touch input or using a separate recognition sheet. The key can include a keypad or a touch key. The ultrasonic input device which obtains data by detecting microwave through a microphone e.g. a microphone in the electronic device allows radio frequency identification through the pen which generates an ultrasonic signal. The electronic device may receive the user input from the external device e.g. network computer or server connected using the communication module .

The display can include a panel or a hologram . For example the display can be the display of . The panel can employ a Liquid Crystal Display LCD or an Active Matrix Organic Light Emitting Diode AMOLED . The panel can be implemented flexibly transparently or wearably. The panel may be constructed as the single module with the touch panel . The hologram can present a three dimensional image in the air using interference of light. The display can further include a control circuit for controlling the panel and the hologram .

The interface can include a High Definition Multimedia Interface HDMI a Universal Serial Bus USB a projector and a D sub . Additionally or substantially the interface can further include a SD MMC not shown or Infrared Data Association IrDA not shown .

The audio codec can convert the voice to an electric signal and vice versa. For example the audio codec can convert voice information which is input or output through a speaker a receiver an earphone or the microphone .

The camera module can capture a still picture and a moving picture. For example the camera module can include one or more image sensors e.g. front lens or rear lens an Image Signal Processor ISP or a flash LED.

The power management module can manage power of the hardware . For example the power management module can include a Power Management IC PMIC a charging IC or a battery gauge.

For example the PMIC can be mounted in an IC or a SoC semiconductor. The charging type of the power management module can be divided to a wired type and a wireless type. The charging IC can charge the battery and prevent overvoltage or overcurrent from flowing from a charger. The charging IC can include a charging IC for at least one of the wired charging type or the wireless charging type. For example the wireless charging type includes magnetic resonance magnetic induction and microwave and can further include an additional circuit for example coil loop resonance circuit rectifier circuit for the wireless charging.

The battery gauge can measure the remaining capacity of the battery and the voltage the current or the temperature of the charging. The battery can supply the power by generating the electricity. For example the battery can be a rechargeable battery.

The indicator can display a specific status e.g. booting state message state or charging state of the electronic device or part e.g. AP of the electronic device . The motor can convert the electric signal to a mechanic vibration. An MCU can control the sensor module

In addition the electronic device can further include a processor e.g. GPU for supporting mobile TV. For example the processor for supporting the mobile TV can process media data in conformity with Digital Multimedia Broadcasting DMB Digital Video Broadcasting DVB or media flow standard. The names of the hardware components of the present disclosure can differ according to the type of the electronic device. The hardware of the present disclosure can include at least one of the components omit some components or further include other components. Some of the hardware components can be united to the single entity to carry out the same functions of the corresponding components.

The term module used in various embodiments of the present disclosure can indicate for example a unit including a combination of one or more of hardware software or firmware. The module can be interchangeably used with the term for example a unit logic a logical block a component or a circuit. The module can be a minimum unit or part of the components integrally formed. The module may be a minimum unit or part for one or more functions. The module can be implemented mechanically or electronically. For example the module according to various embodiments of the present disclosure can include at least one of an Application Specific Integrated Circuit ASIC chip Field Programmable Gate Arrays FPGAs or a programmable logic device for performing operations which are well known or to be invented.

The module or the programming module according to various embodiments of the present disclosure can include at least one of the aforementioned components omit some components or further include other components. The operations fulfilled by the modules the programming modules or other components according to various embodiments of the present disclosure can be carried out in sequence in parallel repeatedly or heuristically. Also some operations can be executed in a different order or omitted or other operations can be added.

Various embodiments can be realized as program instructions executable by various computer means e.g. the processor and recorded in a non transitory computer readable recording medium. The computer readable recording medium can include a computer program a program instruction a data file and a data structure alone or in combination. The program instruction recorded in the recording medium can be specially designed for the present disclosure or well known to those skilled in computer software.

The computer readable recording medium can include magnetic media such as hard disk floppy disk and magnetic tape optical media such as Compact Disc Read Only Memory CD ROM and Digital Versatile Disc DVD magneto optical media such as floptical disk and hardware devices specifically configured to store and execute the program instruction e.g. the programming module such as Read Only Memory ROM Random Access Memory RAM and flash memory. Also the program instruction can include not only a machine code made by a complier but also a high level language code executable by a computer using an interpreter. The above stated hardware device can serve as one or more software modules for fulfilling the operations of various embodiments of the present disclosure and vice versa.

As set forth above the method and the apparatus for acquiring the image determines the emission time and the exposure time of the image sensor by considering the exposure difference of the flash light and thus acquire the image with the adequate brightness on the main subject e.g. the focused person or object and the other subject e.g. the background excluding the main subject . Also the method and the apparatus for acquiring the image can acquire the image with the adequate brightness using the algorithm without having to use a separate device such as Xenon flash for producing the strong light up to the other subject. Thus the manufacturing cost of the camera module for generating the enhanced image captured can be reduced.

While the present disclosure has been shown and described with reference to various embodiments thereof it will be understood by those skilled in the art that various changes in form and details may be made therein without departing from the spirit and scope of the present disclosure as defined by the appended claims and their equivalents.

