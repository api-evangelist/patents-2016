---

title: Gesture-based signature authentication
abstract: Embodiments of the invention are generally directed to systems, methods, devices, and machine-readable mediums for implementing gesture-based signature authentication. In one embodiment, a method may involve recording a first gesture-based signature and storing the recorded first gesture-based signature. Then the method compares the first gesture-based signature with a second gesture-based signature. Then the method verifies the first gesture-based signature as authentic when the first gesture-based signature is substantially similar to the second gesture-based signature.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09560044&OS=09560044&RS=09560044
owner: Intel Corporation
number: 09560044
owner_city: Santa Clara
owner_country: US
publication_date: 20160219
---
This application is a continuation of U.S. Ser. No. 12 655 380 filed Dec. 30 2009 the content of which is hereby incorporated by reference.

Embodiments of the invention generally relate to the field of integrated circuits and more particularly to systems methods devices and machine readable mediums for gesture based signature authentication.

There are a number of software applications that require authentication. For example many e commerce home banking and network access applications need authentication to provide the user a level of security. In most cases the need for authentication is addressed by requiring the user to enter a text based password or passphrase. Text based passwords and especially passphrases are more difficult to input when using a small mobile devices. The use of passwords and passphrases are restricted to the availability of suitable keyboards. Additionally text based passwords and passphrases can be easily compromised when a malicious user determines the correct password or passphrase.

Embodiments are generally directed to systems methods and apparatuses for implementing gesture based signature authentication.

In many embodiments a process to use a combination of gestures including glyphs entered in a touch screen which may include single touch or multi touch capable touch screens sounds captured by a microphone and movements registered by motion sensors may be used in place of a standard text based password for use with a mobile computing device. The term gesture will be applied to any user entered combination of glyphs movements and sounds that the user enters into the mobile computing device through input devices. A gesture based signature can be verified as performed by the authentic user i.e. authenticated through a series of calculations. Once the gesture based signature has been authenticated the gesture based signature can be substituted for a correct text based password that is then input into a password field to gain access to a software application or website. Logic to perform gesture identification comparison and verification processes may be present within the mobile computing device. This process does not require significant changes to application or website infrastructure.

Each of the samples involves a user holding the mobile computing device A and making a series of movements in three dimensional space. In order for these movements to be recognized mobile device A needs an integrated motion sensor device e.g. an accelerometer .

A coordinate space reference at the top of the page illustrates the positive X Y and Z directions in three dimensional space. Based on that reference we now turn to gesture sample signature A which shows the mobile device A first moving in the positive Z direction then the negative Z direction then a clockwise circle and finally the negative X direction. This description is rudimentary for ease of explanation. In a real example a user s hand is generally not going to only travel back and forth along an axis in three dimensional space.

Rather in a true example of motion capture in three dimensional space a buffer will be created to store X Y Z coordinate triplets in 3D space. The coordinate triplets will be stored at the end of a time interval since the previous coordinate triplet was acquired. For example mobile device A may store a coordinate triplet of the current location of the mobile device A in 3D space every 0.001 seconds. This would create a histogram in 3D space of the location of the mobile device at a 0.001 second granularity. In other embodiments the interval granularity may be shorter or longer.

In many embodiments a user presses a button on the mobile device to begin capture of the signature. Once the button is pressed the 3D coordinates at the current location of the device may be zeroed out as a relative reference point. Then the coordinate capture begins upon pressing the button and the coordinate triplets are continuously stored until a button is pressed again by the user to indicate that the gesture based signature is complete.

Gesture sample signature B utilizes mobile device B which includes a touch screen display. The touch screen display may be utilized to capture a glyph. In some embodiments a user may use their hand as the input instrument on the touch screen. In other embodiments the user may use a pen or other pointing device as the input instrument on the touch screen. In different embodiments the glyph may be any combination of movements captured by the touch screen. The combination of movements may resemble a collection of letters or symbols. Although any combination of movements is acceptable so even seemingly random movements that do not resemble letters or symbols may be captured as the glyph such as a handwritten signature.

Glyph capture may resemble the 3D space motion capture where a buffer may be created that stores X Y coordinate doubles. These X Y coordinate doubles may then be saved into the buffer once every time interval which creates a time based memory of how the glyph was created on the touch screen.

Furthermore the mobile devices each include a microphone e.g. the audio receiver in a cell phone . A word or phrase may be spoken into the microphone and saved as an audio frequency pattern over time in a buffer in the mobile device.

Returning to gesture sample signature B the user may enter a glyph on the touch screen and then speak a word e.g. football into the microphone on the mobile device as a combination of a glyph and audio gesture based signature. Gesture sample signature C illustrates a gesture based signature utilizing all three types of input methods. For example the user may enter a glyph on the touch screen then speak a phrase into the microphone on the mobile device e.g. Umbrella and then move the mobile device in 3D space.

In many embodiments two or more types of gestures may be simultaneously entered as a more advanced requirement for the gesture based signature. For example in gesture sample signature C the user might first enter the glyph but then speak the phrase and move the device in 3D space simultaneously. In many embodiments a user may press a start gesture capture sequence button on the mobile device indicating the start of the sequence. At the start of the gesture capture sequence the glyph capture buffer audio capture buffer and 3D movement buffer are each initialized. Then the three buffers are utilized simultaneously to capture all three types of gestures i.e. glyph voice and 3D movement throughout the entire length of the gesture capture sequence. The gesture capture sequence ends as soon as an end capture sequence button is pressed on the mobile device.

In many embodiments memory includes each of a glyph capture buffer an audio capture buffer and 3D movement buffer . These buffers are initialized at the start of a gesture capture sequence. In many embodiments these buffers line up by acquisition times as shown by the time column to the left of the buffers. For example if Time represents the start of a gesture capture period and there are n capture intervals then Time n intervals is the end of the gesture capture period. Each time interval has a saved amount of glyph data X Y coordinates audio data instantaneous frequency map of the audible spectrum as captured by the microphone and 3D location data X Y Z coordinates in the respective buffers.

Once the capture period has completed the buffers may be saved to a gesture based signature file and stored in a storage location. In many embodiments the storage location of the gesture based signature file may be secured through the use of hardware or software based security measures e.g. signed public and private security keys hash algorithms hardware measurement techniques etc. . In other embodiments storage location may be a remote server using a secure channel for connected comparison and use of the signature.

In order to harden the password several variables are taken into account including the timing and the way in which a glyph is drawn on the screen the time and speed at which a phrase is spoken in relation to the drawing of the glyph the frequency of the user voice etc. By taking all these points of data into account even if the spoken phrase and the handwritten signature are compromised it remains difficult to forge the gesture based signature. Using a basic example of utilizing time as a factor in the comparison of two gesture based signatures a relative temporal i.e. time element may be introduced for the entire capture period length. In other words the length of time it takes to fully record two separate attempts at the same gesture based signature may need to be within a predetermined maximum discrepancy of time when comparing the two signatures. So if a first signature very nearly duplicates the coordinates of a second signature but the first signature takes twice as long to complete this may cause comparison logic to result with a no match. 

There are two general phases associated with gesture based signature authentication. The first phase is the registration phase which deals with generating a new gesture and safely storing it into the mobile device. The new gesture may require a training period where the user becomes familiar with the gesture and can substantially repeat the gesture combination desired as the password. Once the user has become confident that he or she can successfully repeatedly enter the full gesture without a substantial chance of having gesture comparison logic reject the gesture due to discrepancies the gesture signature file may then be stored for future use.

In many embodiments gesture identification and comparison logic within the mobile device will have the user enter the gesture based signature several times and average out the coordinate audio and time data stored in the buffers during each capture period. Additionally the variability of the user s ability to recreate the gesture based signature may cause a maximum discrepancy threshold to increase or decrease. The maximum discrepancy threshold may be a discrepancy per time interval between the averaged coordinate and audio data and the most recently captured coordinate and audio data. For example if the observed glyph coordinate data between several capture period training attempts varies widely the gesture comparison and verification logic may allow a greater variability in the X Y glyph data when determining the authenticity of the signature most recently recorded and a stored version of the signature.

Glyph and 3D movement gestures are represented by a finite list of one or more for multi touch devices coordinates and their corresponding acquisition times. This makes a handwritten glyph based and or 3D movement based signature harder to forge since time based coordinate information is stored which reveals the way the signature is drawn on the touch screen or in the air as well as the speed at which each stroke is usually performed.

In many embodiments the gesture based signature file is stored as a list of tuples of the form input device input value acquisition time for example touch screen 8 33 0 .

Each registered gesture based signature may be associated with a given application or website. Therefore additional information is requested from the user including the site application username and text based password if the user already possesses such password. If the user does not already possess such a password then the text based password can be automatically generated in this phase. This text based password information is stored in a safe storage location.

The process is performed by processing logic which may comprise hardware e.g. circuitry software e.g. an operating system or application firmware e.g. microcode or any combination of two or more of the listed types of processing logic.

The process begins with a user starting the signature registration processing logic to register a gesture based signature processing block . Next a user enters a gesture based signature into the processing logic processing block . In many embodiments block is performed several times until the entry has been sufficiently learned by the processing logic including the variability levels of each type of gesture the user makes for the signature being registered.

Processing logic then determines if a username exists for user at the application or website that the user wants to implement a gesture based signature for processing block . If the username exists then processing logic associates the gesture based signature to the website application the username and the password. The ASCII based i.e. text based password will correspond to the gesture based signature. For example if a user wants to log in to a website that requires a username and password processing logic first associates a valid text based username and password for the user to gain access to the website. Once the valid text based username and password have been discovered processing logic may associate this information with a particular gesture based signature file. Processing logic then stores the gesture based signature in a secure storage location processing block .

Returning to block if the username does not exist for the application or website then processing logic generates an ASCII based password from the signature processing block and then associates the gesture based signature to the website application and username processing block . Finally processing logic then stores the gesture based signature in a secure storage location processing block .

The authentication phase deals with the moment when the signature is being compared with the registered one for authentication purposes. Specifically the process to authenticate a user proceeds as follows. An application or website requires the user to enter his her username and password. The application website developer uses a provided API application programming interface that will launch a graphical interface asking the user to enter a gesture based signature.

The user then enters a gesture based signature. The gesture based signature entered by the user is then compared to the registered signature for that site application. Since no two signatures from the same user are likely to be identical algorithms that take into account variability as mentioned above may be used to compare the registered gesture based signature with the newly entered gesture based signature. Signatures that are compared would be required to be substantially similar in regard to time coordinates and voice frequencies. Just how similar would be signature specific considering the variability per signature may differ depending on how well a user can repeat the signature during initial training capture periods. In some embodiments a process described as Dynamic Type Warping may be utilized. Dynamic Type Warping performs point to point correspondence for data at each acquisition time. A smart selection of acquisition points may then be compared.

In some embodiments the gesture based signature comparison processing logic may be offloaded to a backend server coupled to a network that the mobile computing device is also coupled to. In many embodiments that utilize a backend server for comparison of the two signatures the registered signature may be stored at the backend server.

Once the newly entered gesture based signature is matched to a registered signature the associated text based password is returned to the external application website which then permits the user to log in.

The process is performed by processing logic which may comprise hardware e.g. circuitry software e.g. an operating system or application firmware e.g. microcode or any combination of two or more of the listed types of processing logic.

The process begins by processing logic in the application or web browser calling gesture based signature comparison logic through the provided API processing block . Then the user enters the gesture based signature processing block . Processing logic then compares the gesture based signature that has been newly entered by the user with an existing registered signature in storage processing block .

Processing logic then determines if the signatures match processing block . If the signatures do not match then the signature entry has failed and the process returns to block to re enter the gesture based signature. Otherwise if the signatures do result in a match then processing logic returns the stored ASCII based password to the application browser for use processing block and the process is finished.

Computer system is shown. The computer system in generally comprises a system on a chip SoC layout. The SoC layout may be utilized in any type of computer system but is useful for small form factor mobile computing devices such as cellular phones smart phones and personal digital assistants PDAs .

The computer system includes a central processing unit CPU . In a SoC layout it is common to have a single CPU though in other embodiments that are not shown one or more additional CPUs are also located in computer system .

CPU may be Intel Corporation CPU or a CPU of another brand. CPU includes one or more cores. In the embodiment shown CPU includes Core A Core B Core C and Core D . Only one core is needed for operation of the computer system but additional cores can distribute workloads and potentially increase overall system performance. In many embodiments each core such as core A includes internal functional blocks such as one or more execution units retirement units a set of general purpose and specific registers etc. If the cores shown in are multi threaded or hyper threaded then each hardware thread may be considered as a core as well.

CPU may also include one or more caches such as last level cache LLC . In many embodiments that are not shown additional caches other than cache are implemented where multiple levels of cache exist between the execution units in each core and memory. In different embodiments cache may be apportioned in different ways. Cache may be one of many different sizes in different embodiments. For example cache may be an 8 megabyte MB cache a 16 MB cache etc. Additionally in different embodiments the cache may be a direct mapped cache a fully associative cache a multi way set associative cache or a cache with another type of mapping. The cache may include one large portion shared among all cores or may be divided into several separately functional slices e.g. one slice for each core . Each cache may also include one portion shared among all cores and several other portions that are separate functional slices per core.

In many embodiments CPU includes a system memory controller to provide an interface to communicate with system memory . System memory may comprise dynamic random access memory DRAM such as a type of double data rate DDR DRAM non volatile memory such as flash memory phase change memory PCM or another type of memory technology. System memory may be a general purpose memory to store data and instructions to be operated upon by CPU . Additionally there may be other potential devices within computer system that have the capability to read and write to the system memories such as a direct memory access DMA capable I O input output device. The link i.e. bus interconnect etc. that couples CPU with system memory may include one or more optical metal or other wires i.e. lines that are capable of transporting data address control and clock information.

CPU also may include an integrated graphics subsystem that is capable of computing pixel vertex and geometry data to be displayed on display device . CPU additionally may include a communication subsystem that provides an I O interface to communicate with external devices. The communication subsystem may include both wired and wireless interfaces. The wired interface may be an Ethernet compatible interface in some embodiments. The wireless interface through one or more antenna components for transmitting and receiving may be compatible for wireless communications through several protocols. For example the communication subsystem wireless interface may communicate through an IEEE 802.11 based protocol a Bluetooth protocol a cellular protocol a WiMAX protocol and or one or more other wireless protocols.

CPU also includes a storage controller to provide an interface to a mass storage device . Mass storage device may be a hard disk drive a solid state drive or another form of mass storage. Additionally CPU also is capable of communicating to I O devices such as I O device and I O device through I O adapters and respectively. The I O adapters each may allow the CPU to communicate with one or more I O devices through a certain protocol. For example one I O adapter may be a Universal Serial Bus USB adapter to allow for plug in communication through USB ports between the CPU and other external USB interfaces.

An input interface allows the computer system to be coupled to input devices such as a touchscreen or microphone . Additionally a motion sensor unit is located on the system which tracks the movement of computer system in 3 dimensional space.

In many other embodiments that are not shown the computing system may be implemented in a different way such as in a standard CPU chipset configuration instead of as a SoC design.

In many embodiments gesture based signature identification comparison and verification logic may be present in any one of the following locations. When at least a portion of the logic is implemented in software the logic may be present in system memory logic mass storage logic cache logic or potentially in any core not shown . When at least a portion of the logic is implemented in hardware the logic may be present in the general circuitry uncore of the CPU outside of the cores logic .

Elements of embodiments of the present invention may also be provided as a machine readable medium for storing the machine executable instructions. The machine readable medium may include but is not limited to flash memory optical disks compact disks read only memory CD ROM digital versatile video disks DVD ROM random access memory RAM erasable programmable read only memory EPROM electrically erasable programmable read only memory EEPROM magnetic or optical cards propagation media or other type of machine readable media suitable for storing electronic instructions. For example embodiments of the invention may be downloaded as a computer program which may be transferred from a remote computer e.g. a server to a requesting computer e.g. a client by way of data signals embodied in a carrier wave or other propagation medium via a communication link e.g. a modem or network connection .

In the description above certain terminology is used to describe embodiments of the invention. For example the term logic is representative of hardware firmware software or any combination thereof to perform one or more functions. For instance examples of hardware include but are not limited to an integrated circuit a finite state machine or even combinatorial logic. The integrated circuit may take the form of a processor such as a microprocessor an application specific integrated circuit a digital signal processor a micro controller or the like.

It should be appreciated that reference throughout this specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Therefore it is emphasized and should be appreciated that two or more references to an embodiment or one embodiment or an alternative embodiment in various portions of this specification are not necessarily all referring to the same embodiment. Furthermore the particular features structures or characteristics may be combined as suitable in one or more embodiments of the invention.

Similarly it should be appreciated that in the foregoing description of embodiments of the invention various features are sometimes grouped together in a single embodiment figure or description thereof for the purpose of streamlining the disclosure aiding in the understanding of one or more of the various inventive aspects. This method of disclosure however is not to be interpreted as reflecting an intention that the claimed subject matter requires more features than are expressly recited in each claim. Rather as the following claims reflect inventive aspects lie in less than all features of a single foregoing disclosed embodiment. Thus the claims following the detailed description are hereby expressly incorporated into this detailed description.

