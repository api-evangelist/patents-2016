---

title: Wet ink texture engine for reduced lag digital inking
abstract: A wet ink texture engine and associated method. The wet ink texture engine may run in the context of any application on any device, service, or general endpoint capable of receiving ink input. For example, the wet ink texture engine may be used in the context of a note application that receives input in the form of writing or drawing. The wet ink texture engine reduces, minimizes, or eliminates lag between receiving the input and displaying the input to improve inking experience for the user.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09454254&OS=09454254&RS=09454254
owner: Microsoft Technology Licensing, LLC
number: 09454254
owner_city: Redmond
owner_country: US
publication_date: 20160504
---
This application is a continuation application of U.S. patent application Ser. No. 14 065 139 now U.S. Pat. No. 9 360 956 entitled WET INK TEXTURE ENGINE FOR REDUCED LAG DIGITAL INKING filed on Oct. 28 2013 the entire disclosure of which is hereby incorporated herein by reference.

Computers tablets smart phones and other computing devices adopting natural user interfaces NUIs allowing users to input information as handwriting or drawings by writing directly on the screen or a digitizer are increasingly common. The process of receiving and rendering written or drawn information from a stylus is referred to as inking. The stylus may be a digital pen mouse finger or other suitable device that can be used to write or draw on the screen or digitizer. During inking each move sequence of the stylus is recorded as a stroke storing the coordinates of and properties associated with the input. For example a stroke may include the movements from the time when the pen tip is moved closed enough to be detected by the digitizer the mouse button is depressed or the finger touches the screen until the time that pin tip is moved away from the digitizer and no longer detectable the mouse button is released or the finger is no longer touching the screen. One or more strokes make up the ink i.e. digital ink used with applications running on the computing device.

On screen the ink may appear as natural looking handwriting or hand drawn pictures. In the case of handwriting the ink may be converted to standard text through handwriting recognition. The converted text may be associated with the corresponding natural looking handwriting as an alternate data format useful when working with e.g. searching inked information or may replace the natural looking handwriting on screen and in the application e.g. creating a typed document .

At times the ink drawn on the screen severely lags behind the stylus. This lag is a result of the application attempting to do three actions simultaneously process the ink input render the ink to the screen and save the ink to the application canvas i.e. what the application displays to the user . Attempting to accomplish all of these tasks simultaneously slows each of them down because the user interface pipeline backs up quickly.

Lag is especially problematic for single threaded applications but remains a concern even for multi threaded applications. In a multi threaded application lag may be addressed by creating additional threads and handling each action in a separate thread however this solution is not available for single threaded applications and may not be viable or suitable for all multi threaded applications.

When saving ink to the application canvas lag may occur as a result of hardware timing constraints. For example updates to the application canvas may be tied to the screen refresh frequency while input devices such as the stylus operate at the system bus speed. In a typical example screens are refreshed on a 60 Hz cycle while the system bus operates at 133 Hz. Limited to one update of the application canvas per screen refresh i.e. frame the stylus generates ink more than twice as fast as it can be displayed by the application. As the user continues to write or draw the ink lags further and further behind the stylus and is displayed to the user in choppy bursts rather than smoothly appearing with the movements of the stylus.

Different combinations of hardware and software have been found to produce significant lag where the ink does not appear for six or seven frames which translates to the ink trailing the stylus by one to two inches. At a minimum lag detracts from the pen and paper experience that inking is designed to provide. More than just being noticeable lag creates efficiency and usability problems when the user has to stop and wait for the ink to catch up with the stylus so the user can see or make changes to what has been written or drawn. It is with respect to these and other considerations that the present invention has been made. Although relatively specific problems have been discussed it should be understood that the embodiments disclosed herein should not be limited to solving the specific problems identified in the background.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description section. This summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

Embodiments described in the present disclosure provide for a wet ink texture engine that may run in the context of any application on any device service or general endpoint capable of receiving ink input. Ink input begins when the user starts writing or drawing with ink. Original ink rendering happens continuously and frequently while the user is actively producing ink strokes. Original ink is viewable but has not yet been transferred to the application for which the ink input is intended. The process of rendering of the original ink is referred to as wet inking. Wet inking reduces user perceptible lag between the time when the user moves the stylus and the time ink appears on the screen. Ink input stops when there is break in the active production of ink strokes. When this happens original ink strokes are passed to an ink analysis component to produce final ink. The process of replacing of original ink with final ink is referred to as dry inking.

During wet inking the original ink is cached in the wet ink texture. The wet ink texture is composed of wet ink and semi dry ink. The application canvas stores the virtual texture holding the ink captured by and available in to and from the application i.e. dry ink . Wet ink is stored in the input layer and the semi dry ink is stored in the transfer layer. Each layer is a virtual frame buffer used to hold the original ink at different stages in the wet inking process. The original ink input is rendered in the input layer. The image stored in the input layer is an unprocessed representation of the most recent ink data received including partial strokes. Frequently presenting the input layer for display minimizes user perceptible lag between the time when the user moves the stylus and the time ink appears on the screen.

After being rendered wet ink is moved to the transfer layer. The transfer layer serves as an intermediate frame buffer for wet ink that is ready is to be committed to or consumed by the application i.e. semi dry ink . The transfer involves removing at least some of the rendered wet ink from the input layer and re rendering it in the transfer layer as semi dry ink. The image stored in the transfer layer is an unprocessed representation of wet ink that has been rendered and is ready to be moved i.e. committed to the application canvas.

During dry inking at least a portion of the ink in the wet ink texture is moved to the virtual texture of the application canvas. When the application is ready to accept any available semi dry ink the application requests the contents of the transfer layer. The semi dry ink is re rendered in the virtual texture of the application canvas and the transfer layer is cleared. The flow continues until all ink is transferred from the wet ink texture to the virtual texture.

In various embodiments the wet ink texture engine provides at least one dedicated worker thread to receive and render ink input. Regardless of number these worker threads are independent from the user interface UI thread that becomes sluggish as activity increases. Ink input happens on a dedicated ink input thread and is marshaled to a dedicated ink render thread. Rendering of the raw i.e. wet ink in the input layer happens on the ink render thread without any further processing of the wet ink at this time. Receiving input and rendering wet ink occurs with high priority. Once rendered the wet ink is presented to the system compositor and displayed to the user at the next screen update. In other words the wet ink appears on screen with minimal user perceivable lag between the time that the input is received and the time that it is displayed.

Transfer of the rendered wet strokes to the transfer layer happens on the ink render thread. The transfer may occur at lower priority than receiving input and rendering wet ink to allow the wet ink to be displayed as rapidly as possible. Following a transfer the wet ink and the semi dry ink are presented to the system compositor at the same or substantially the same time and displayed to the user at the next screen update. Transferring the semi dry ink to the application as dry ink involves locking the transfer layer re rendering the semi dry ink on the application canvas and clearing the transfer layer. Once the transfer layer is locked the semi dry ink is marshaled to the application thread which renders it on the application canvas as dry ink. After the dry ink has been rendered the transfer layer is cleared and unlocked by the ink render thread.

Various embodiments of a wet ink texture engine are described herein and illustrated in the accompanying figures. The wet ink texture engine may run in the context of any application on any device service or general endpoint capable of receiving ink input. For example the wet ink texture engine may be used in the context of a note application that receives input in the form of writing or drawing. The wet ink texture engine reduces minimizes or eliminates lag between receiving the input and displaying the input to improve inking experience for the user.

Ink input stops when there is break in the active production of ink strokes. Examples of events signifying the end of ink input include but are not limited to a digital pen moving out of range of the digitizer releasing the mouse button ceasing finger contact with the touch screen and deactivating the ink input mode. When this happens original ink strokes are passed to an ink analysis component to produce final ink. The process of replacing of original ink with final ink is referred to as dry inking. At a minimum the ink analysis component commits the ink to application however the ink analysis component may perform additional optional processing of the ink. Dry inking triggers re rendering of original ink because dry inking involves deleting original ink strokes when rendered as final ink.

The wet ink and the semi dry ink are stored in separate layers. Wet ink is stored in the input i.e. wet ink layer and the semi dry ink is stored in the transfer i.e. semi dry ink layer . Each layer is a virtual frame buffer used to hold the original ink at different stages in the wet inking process. The layers and the application canvas may be implemented as objects e.g. bitmaps rasterized images or swap chains accessible through an application programming interface API handling tasks related to displaying graphics e.g. DirectX controls e.g. swap chain layers in a visual presentation markup language such as the Extensible Application Markup Language XAML or managed rendering surfaces using a visual presentation markup language to manage the interactions between the graphics display API and the image source. In various embodiments the application canvas is a managed rendering surface such as a Virtual Surface Image Source VSIS or a Surface Image Source SIS and the input layer and transfer i.e. semi dry ink layers are swap chain layers.

The original ink input is rendered in the input i.e. wet ink layer. The image stored in the input layer is an unprocessed i.e. raw representation of the most recent ink data received including partial strokes. Frequently presenting the input layer for display minimizes user perceptible lag between the time when the user moves the stylus and the time ink appears on the screen.

After being rendered wet ink is moved to the transfer i.e. semi dry ink layer. The transfer layer serves as an intermediate frame buffer for wet ink that is ready is to be committed or consumed to the application i.e. semi dry ink . The transfer involves removing at least some of the rendered wet ink from the input layer and re rendering it in the transfer layer as semi dry ink. The image stored in the transfer layer is an unprocessed representation of wet ink that has been rendered and is ready to be moved i.e. committed to the application canvas.

During dry inking at least a portion of the wet ink is moved to the virtual texture of the application canvas. When the application is ready to accept any available semi dry ink the application requests the contents of the transfer layer. The semi dry ink is re rendered in the virtual texture of the application canvas and the transfer layer is cleared. The flow continues until all ink is transferred from the wet ink texture to the virtual texture.

The input device is a coordinate based input device. In various embodiments of the input device a stylus is used for inking i.e. writing or drawing on a surface. In some embodiments the stylus is an active component e.g. a digital pen or mouse that produces a coordinate based input as it moves. An active stylus may be used with a passive surface e.g. a piece of paper mouse pad or desktop . In other embodiments the surface is the active component e.g. a digitizer or touch screen that produces a coordinate based input based on the position and movement of the user s finger a digital pen or other stylus either active or passive . In some embodiments the input device is an electronic sensor that produces a coordinate based input based on movement of a user s body e.g. a finger hand or arm or other object relative to a screen image displayed or projected on a large surface e.g. a wall table or digital whiteboard . In various embodiments the electronic sensor operates based on infrared ultrasonic thermal laser or other vision or sonic based sensing technology suitable for tracking an object. One example of a suitable electronic sensor is a Microsoft Kinect sensor. It should be appreciated that the input device may also be used for inputs other than inking.

The output device is a visual display device for presenting information including the application user interface and ink to the user. Examples of suitable output devices include but are not limited to display screens monitors projectors and digital white boards. As previously mentioned the layers and the application canvas are combined to produce the final image displayable on the output device . For example the wet ink texture engine may present each of the layers to a system compositor running on the computing device while the application may present the application canvas to the system compositor . The system compositor receives image sources from the applications running on the computing devices and composes the final image that is displayed on the screen.

The wet ink texture engine operates in conjunction with an application capable of receiving ink through the coordinate based input device. For example the wet ink texture engine may operate in conjunction with an application e.g. a note application drawing application or an operating system running on the computing device. In various embodiments the wet ink texture engine is an integrated component of the application. In other embodiments the wet ink texture engine and the application are separate but interactive components. For example the wet ink texture engine may be a service add in interface applet or other software component callable by or otherwise working with the application to process ink inputs.

Ink input happens on a dedicated ink input thread and is marshaled to a dedicated ink render thread . Rendering of the raw i.e. wet ink in the input layer happens on the ink render thread without any further processing of the wet ink at this time. Receiving input and rendering wet ink occurs with high priority. Once rendered the wet ink is presented to the system compositor and displayed to the user at the next screen update. In other words the wet ink appears on screen with minimal user perceivable lag between the time that the input is received and the time that it is displayed.

Transfer of the rendered wet strokes to the transfer layer happens on the ink render thread . The transfer may occur at lower priority than receiving input and rendering wet ink to allow the wet ink to be displayed as rapidly as possible. In some embodiments the semi dry ink conversion occurs substantially contemporaneously with rendering the wet ink. In other embodiments the semi dry ink conversion occurs at a break in ink input. In such cases the transfer layer will only contain complete strokes which may be useful to facilitate optional processing when the semi dry ink strokes are committed to the application.

Following a transfer the wet ink and the semi dry ink are presented to the system compositor at the same or substantially the same time and displayed to the user at the next screen update. Waiting to present the input layer with the transfer layer once the semi dry ink has been rendered instead of presenting the input layer immediately after the wet ink has been removed works to maintain the visual fidelity of the ink display. For example synchronizing the presentation of the input and transfer layers minimizes user perceived flicker that might result from the displaying the input and transfer layers after the wet ink has been removed and before it has been re rendered as semi dry ink.

Transferring the semi dry ink to the application as dry i.e. committed ink involves locking the transfer layer re rendering the semi dry ink on the application canvas and clearing the transfer layer . Once the transfer layer is locked the semi dry ink is marshaled to the application on the application thread which renders it on the application canvas as dry ink. In various embodiments the application thread is the UI thread. In other embodiments the application thread is a dedicated worker thread for rendering ink to the application canvas . After the dry ink has been rendered the transfer layer is cleared and unlocked by the ink render thread . In various embodiments the application thread sends a request for the ink render thread to delete the contents of the transfer layer after rendering the dry ink.

As discussed above the application may periodically poll the wet ink texture engine to determine if semi dry ink is available. In some embodiments the wet ink texture engine may provide notification to the application at a break in ink input and or at the end semi dry ink conversion. Committing semi dry ink to the application may occur at lower priority than receiving and rendering wet ink and or converting wet ink to semi dry ink. In some embodiments committing semi dry ink may only occur when sufficient resources are available to minimize the likelihood of causing user perceptible ink lag. For example committing semi dry ink may only occur when processor utilization is below a threshold level.

In various embodiments the application thread performs optional processing before or after rendering the dry ink. In some embodiments the semi dry ink strokes are smoothed before being rendered to the application canvas. In some embodiments the semi dry ink strokes are subjected to character recognition processing to identify ink corresponding to writing. The results of character recognition may be used to enhance the appearance of handwritten text e.g. to improve legibility or aesthetic quality or to create an object containing standard characters e.g. ASCII Unicode or other computer readable text corresponding to the handwritten text to facilitate use e.g. indexing or full text searching of the information represented by the ink by the application or other software accessing the application data. Such additional processing is generally but not necessarily provided separately and independently from the wet ink texture engine.

Semi dry ink rendered in the transfer layer is available to be committed to the application canvas in the semi dry ink commit operation . In various embodiments the semi dry ink commit operation begins with a semi dry ink availability operation that confirms the availability of semi dry ink in response a request from the application thread. If semi dry ink is available the transfer layer lock operation locks the transfer layer . Locking the transfer layer prevents freshly rendered wet ink from being converted to semi dry ink. While the transfer layer is locked wet ink continues to accumulate in the input layer and be displayed to the user. Once the transfer layer is locked the dry ink render operation re renders the semi dry ink in the transfer layer on the application canvas. Once the dry ink has been rendered the transfer layer clear operation deletes the semi dry ink in the transfer layer . After the transfer layer is cleared the transfer layer unlock operation unlocks the transfer layer .

Locking the transfer layer keeps the semi dry ink committed to the application separate from wet ink received during the commit operation. By locking the transfer layer only the semi dry ink that is actually committed to the application is cleared. Without the lock wet ink converted to semi dry ink after the application thread collects the available semi dry ink and before the transfer layer would be cleared and lost.

The subject matter of this application may be practiced in a variety of embodiments as systems devices and other articles of manufacture or as methods. Embodiments may be implemented as hardware software computer readable media or a combination thereof. The embodiments and functionalities described herein may operate via a multitude of computing systems including without limitation desktop computer systems wired and wireless computing systems mobile computing systems e.g. mobile telephones netbooks tablet or slate type computers notebook computers and laptop computers hand held devices multiprocessor systems microprocessor based or programmable consumer electronics minicomputers and mainframe computers. respectively show ink being entered without user perceptible lag in an application utilizing one embodiment of the wet ink texture engine using a finger with a touch screen based computing device and using a digital pen with a computing device having a digitizer.

User interfaces and information of various types may be displayed via on board computing device displays or via remote display units associated with one or more computing devices. For example user interfaces and information of various types may be displayed and interacted with on a wall surface onto which user interfaces and information of various types are projected. Interaction with the multitude of computing systems with which embodiments of the invention may be practiced include keystroke entry touch screen entry voice or other audio entry gesture entry where an associated computing device is equipped with detection e.g. camera functionality for capturing and interpreting user gestures for controlling the functionality of the computing device and the like.

As stated above a number of program modules and data files may be stored in the system memory . While executing on the processing unit the software applications may perform processes including but not limited to one or more of the stages of the wet inking method . Other program modules that may be used in accordance with embodiments of the present invention may include electronic mail and contacts applications word processing applications spreadsheet applications database applications slide presentation applications drawing or computer aided application programs etc.

Furthermore embodiments of the invention may be practiced in an electrical circuit comprising discrete electronic elements packaged or integrated electronic chips containing logic gates a circuit utilizing a microprocessor or on a single chip containing electronic elements or microprocessors. For example embodiments of the invention may be practiced via a system on a chip SOC where each or many of the illustrated components may be integrated onto a single integrated circuit. Such an SOC device may include one or more processing units graphics units communications units system virtualization units and various application functionality all of which are integrated or burned onto the chip substrate as a single integrated circuit. When operating via an SOC the functionality described herein with respect to the software applications may be operated via application specific logic integrated with other components of the computing device on the single integrated circuit chip . Embodiments of the invention may also be practiced using other technologies capable of performing logical operations such as for example AND OR and NOT including but not limited to mechanical optical fluidic and quantum technologies. In addition embodiments of the invention may be practiced within a general purpose computer or in any other circuits or systems.

The computing device may also have one or more input device s such as a keyboard a mouse a pen a sound input device a touch input device etc. The output device s such as a display speakers a printer etc. may also be included. The aforementioned devices are examples and others may be used. The computing device may include one or more communication connections allowing communications with other computing devices . Examples of suitable communication connections include but are not limited to RF transmitter receiver and or transceiver circuitry universal serial bus USB parallel and or serial ports.

The term computer readable media as used herein may include computer storage media. Computer storage media may include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures or program modules. The system memory the removable storage device and the non removable storage device are all examples of computer storage media i.e. memory storage. Computer storage media may include random access memory RAM read only memory ROM electrically erasable read only memory EEPROM flash memory or other memory technology compact disc read only memory CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other article of manufacture which can be used to store information and which can be accessed by the computing device . Any such computer storage media may be part of the computing device .

One or more application programs may be loaded into the memory and run on or in association with the operating system . Examples of the application programs include phone dialer programs e mail programs personal information management PIM programs word processing programs spreadsheet programs Internet browser programs messaging programs and so forth. The system also includes a non volatile storage area within the memory . The non volatile storage area may be used to store persistent information that should not be lost if the system is powered down. The application programs may use and store information in the non volatile storage area such as e mail or other messages used by an e mail application and the like. A synchronization application not shown also resides on the system and is programmed to interact with a corresponding synchronization application resident on a host computer to keep the information stored in the non volatile storage area synchronized with corresponding information stored at the host computer. As should be appreciated other applications may be loaded into the memory and run on the mobile computing device including software applications described herein.

The system has a power supply which may be implemented as one or more batteries. The power supply might further include an external power source such as an AC adapter or a powered docking cradle that supplements or recharges the batteries.

The system may also include a radio that performs the function of transmitting and receiving radio frequency communications. The radio facilitates wireless connectivity between the system and the outside world via a communications carrier or service provider. Transmissions to and from the radio are conducted under control of the operating system . In other words communications received by the radio may be disseminated to the application programs via the operating system and vice versa.

The visual indicator may be used to provide visual notifications and or an audio interface may be used for producing audible notifications via the audio transducer . In the illustrated embodiment the visual indicator is a light emitting diode LED and the audio transducer is a speaker. These devices may be directly coupled to the power supply so that when activated they remain on for a duration dictated by the notification mechanism even though the processor and other components might shut down for conserving battery power. The LED may be programmed to remain on indefinitely until the user takes action to indicate the powered on status of the device. The audio interface is used to provide audible signals to and receive audible signals from the user. For example in addition to being coupled to the audio transducer the audio interface may also be coupled to a microphone to receive audible input such as to facilitate a telephone conversation. In accordance with embodiments of the present invention the microphone may also serve as an audio sensor to facilitate control of notifications as will be described below. The system may further include a video interface that enables an operation of an on board camera to record still images video stream and the like.

A mobile computing device implementing the system may have additional features or functionality. For example the mobile computing device may also include additional data storage devices removable and or non removable such as magnetic disks optical disks or tape. Such additional storage is illustrated by the non volatile storage area .

Data information generated or captured by the mobile computing device and stored via the system may be stored locally on the mobile computing device as described above or the data may be stored on any number of storage media that may be accessed by the device via the radio or via a wired connection between the mobile computing device and a separate computing device associated with the mobile computing device for example a server computer in a distributed computing network such as the Internet. As should be appreciated such data information may be accessed via the mobile computing device via the radio or via a distributed computing network. Similarly such data information may be readily transferred between computing devices for storage and use according to well known data information transfer and storage means including electronic mail and collaborative data information sharing systems.

The description and illustration of one or more embodiments provided in this application are intended to provide a complete thorough and complete disclosure the full scope of the subject matter to those skilled in the art and not intended to limit or restrict the scope of the invention as claimed in any way. The embodiments examples and details provided in this application are considered sufficient to convey possession and enable those skilled in the art to practice the best mode of claimed invention. Descriptions of structures resources operations and acts considered well known to those skilled in the art may be brief or omitted to avoid obscuring lesser known or unique aspects of the subject matter of this application. The claimed invention should not be construed as being limited to any embodiment example or detail provided in this application unless expressly stated herein. Regardless of whether shown or described collectively or separately the various features both structural and methodological are intended to be selectively included or omitted to produce an embodiment with a particular set of features. Further any or all of the functions and acts shown or described may be performed in any order or concurrently. Having been provided with the description and illustration of the present application one skilled in the art may envision variations modifications and alternate embodiments falling within the spirit of the broader aspects of the general inventive concept embodied in this application that do not depart from the broader scope of the claimed invention.

