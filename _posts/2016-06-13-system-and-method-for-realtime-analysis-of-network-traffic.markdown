---

title: System and method for real-time analysis of network traffic
abstract: A system for monitoring live-data flow through a network includes a processor implementing a first processing node including an ingestor virtual machine (ingestor VM) for monitoring a mirrored live-data flow of the live-data flow passing through a selected point within the network in a non-intrusive manner that does not affect the live-data flow of at least one live data flow passing through the selected point. The ingestor VM further decodes each packet within the mirrored data flow according to each protocol associated with a packet and manages processes occurring within and between the first processing node and a second processing node. A time dependent buffer virtual machine (TDB VM) allocates a time dependent buffer (TDB) within the memory for executing the processes performed within and between the first processing node and a second processing node, and releasing the allocated TDB after completion of the processes. A governor virtual machine (governor VM) allocates memory resources within the memory between the first processing node and the second processing node for the processes performed within and between the first processing node and a second processing node. A grid virtual machine (grid VM) controls communications within and between the first processing nodes and between the first processing node and the second processing node.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09529621&OS=09529621&RS=09529621
owner: Network Kinetix, LLC
number: 09529621
owner_city: Austin
owner_country: US
publication_date: 20160613
---
This application is a continuation of U.S. patent application Ser. No. 14 962 660 filed on Dec. 8 2015 entitled SYSTEM AND METHOD FOR REAL TIME ANALYSIS OF NETWORK TRAFFIC now U.S. Pat. No. 9 369 366 issued on Jun. 14 2016 which is a continuation of U.S. patent application Ser. No. 14 596 781 filed on Jan. 14 2015 entitled SYSTEM AND METHOD FOR REAL TIME ANALYSIS OF NETWORK TRAFFIC now U.S. Pat. No. 9 210 061 issued Dec. 8 2015 which is a continuation of U.S. application Ser. No. 14 485 172 filed on Sep. 12 2014 entitled SYSTEM AND METHOD FOR REAL TIME ANALYSIS OF NETWORK TRAFFIC now U.S. Pat. No. 8 966 074 issued on Feb. 24 2015 which claims benefit of U.S. Provisional Application No. 61 877 810 filed Sep. 13 2013 entitled REAL TIME ANALYSIS OF NETWORK TRAFFIC. U.S. patent application Ser. Nos. 14 596 781 14 485 172 and 61 877 810 are incorporated by reference herein in their entirety.

The invention relates to voice and data networks and more particularly to the real time analysis of a live data stream resulting in a situational deduction simultaneous to the live data transmission over the voice and data networks and as a result providing an opportunity to make effective an alert or action that now affects a set of probable outcomes before that data in transmission exits the network or becomes at rest as a stored event log record or application record of what has already happened as the only outcome.

The proliferation of internet and mobile connected devices the Internet of Everything has increased data traffic volume transmission speeds and usage on communications networks. The ubiquity of device types and connections cellular wireless multi SIM machine to machine and the expansion of usage types voice high definition video music data have also made it more complex to monitor and secure these networks and to conduct analysis on the traffic and content.

To accomplish this the traffic must be instrumented what data is moving across the network analyzed what is the content of the traffic and understood what are the implications of this so a relevant decision can be made or action taken within the available window of opportunity. This is especially so in the case of time critical revenue customer operational or security impacting events. Examples of such events include fraud occurring on mobile carrier networks cellular zones dropping calls above an acceptable threshold malfunctioning mobile applications or malicious content or agents compromising a network.

This network data is captured by a variety of network probes sitting inline intrusively inside the network. Network events must first complete example after a voice call is completed and goes through call teardown before they are translated into offline database records example Call Detail Records Event Detail Records . These records are extracted at regular time intervals and provided to applications in offline enterprise data centers for post event processing and analysis.

These systems can suffer from latency delays of up to 15 minutes for event data to be extracted and delivered to databases. In many cases multiple terabytes of data are written into databases posing Big Data analytical challenges when time critical results are needed. The inline hardware represents significant capital expenditures. These types of systems also provide a limited ability to respond flexibly to live conditions as the application layer is not integrated contextually within the data collection layer. Database records are not generated for some network events that may provide indications of fraud or other critical issues that must be detected.

A use case is mobile carrier fraud detection that utilizes call detail records that have been delivered to a data warehouse after the relevant network traffic or calls have been completed. Detection of fraud in this case occurs after the actual fraudulent event has occurred and in many cases the carrier has already incurred a financial loss. Any actions taken to remediate example block the caller can only be applied to the next time a relevant event appears in the network.

The present invention as disclosed and described herein in one aspect thereof comprises a system for monitoring live data flow through a network includes a server communicating with the network and a memory associated with the server. A processor within the server the processor implements a first processing node and a second processing node. The first processing node including an ingestor virtual machine ingestor VM that configures the processor to monitor a mirrored live data flow of at least one live data flow passing through a selected point within the network in a non intrusive manner that does not affect the live data flow passing through the selected point. The live data flow comprises data that is in active transmission between endpoints in the network and prior to storage of the data in a database. The ingestor VM further decoding each packet within the mirrored data flow according to each protocol associated with a packet. The packets have a plurality of protocols associated therewith and are decoded in parallel with each other. The ingestor VM manages processes occurring within and between the first processing node and the second processing node and controls the operation of the network. A time dependent buffer virtual machine TDB VM configures the processor to allocate a time dependent buffer TDB within the memory for executing the processes occurring within and between the first processing node and the second processing node and release the allocated TDB after completion of the processes. A governor virtual machine governor VM configures the processor to allocate memory resources within the memory between the first processing node and the second processing node for the processes occurring within and between the first processing node and the second processing node. A grid virtual machine grid VM configures the processor to control communications within the first processing node and between the first processing node and the second processing node.

Referring now to the drawings wherein like reference numbers are used herein to designate like elements throughout the various views and embodiments of a system and method for real time live data analysis of network traffic are illustrated and described and other possible embodiments are described. The figures are not necessarily drawn to scale and in some instances the drawings have been exaggerated and or simplified in places for illustrative purposes only. One of ordinary skill in the art will appreciate the many possible applications and variations based on the following examples of possible embodiments.

Referring now to the drawings and more particularly to there is illustrated the operational environment of the network live data real time analysis system the System according to the present disclosure. ARCHITECTURE A system and methodology results in the ability to integrate an application and its relational language processing example SQL in parallel and in real time operational unity with network signaling packet or data content network traffic as it is in transmission live data and to make situational deductions and to take action on that live data as it is being transmitted between points within a network. The usefulness here is the ability to take meaningful derived or deduced action on the information in transmission or to use such information in relationship to other situations to predictively inform of alert on alter or prepare for or shape or execute a desired outcome in advance of the live data exiting the network and becoming a data center log record or database application event under its normal course of business operations.

The System uses relational processing languages and techniques to enable detection of a situation in real time and in parallel to its occurrence within a network and not at a later point in time after the data has left the network for analysis based upon post event data processing which does not allow an opportunity to affect a change in outcome on that present event. The network traffic is comprised of continuous transmissions of signaling and related data content live data as can be found within voice communications or data networks such as those provided by mobile broadband or data communications network service providers. The System provides any network provider wireless carrier fixed wire line carrier cable operator etc. an opportunity to detect and identify target events or patterns of data flow or relationships Events occurring within its network traffic as they occur and to automatically deduce and take predictively relevant actions or control responsive to the detection in a concurrent manner to those transmissions. The network live data real time analysis and deduction system provides the automated action in any number of fashions including but not limited to providing information to a dashboard web based or mobile device display that responds to a detected Event in parallel to the Event occurring and remaining open within the network traffic or the generation of automated alerts that may then be responded to manually or by the network.

Live data is data that is in transmission between endpoints not at rest within a database. Live data is transient data in that it exists only for that period of time it is in transmission. The term real time typically refers to the immediacy of a process or response to a query being made available in time for its usefulness. The term real time has nothing to do with the age or relevancy of the data but instead has everything to do with the timeliness of response relevant to a time period. The term real time is therefore an omni available description that introduces a time period and that needs to be qualified as real time to what Data that is time critical relates to the period of urgency or usefulness applied to it. Real time live data analysis is the time critical processing of network traffic in parallel with its transmission and before such network traffic completes its transmission and exits the network to become an already happened data event at rest.

The System provides a non intrusive process that enables data center logic to operate concurrently with the transmission before the transmission terminates and exits the network to become a data center application event and additionally provides the ability for the data warehouse system to interact in a time critical manner with the same network traffic to provide contextualization of conditions based on trends or other data. The System enables concurrent analysis and deduction of relationships and probabilities as Events occur and are transmitted as network traffic thus allowing deductive parallel operations with the concurrently occurring network traffic and its operations. The System does not reside within a data center that operates on a sequence of post event analytical functions rather it is architected as a larger network topology operating non intrusively and in parallel to the network traffic .

Within a network topology the system is able to use one or more virtual machines as data collection devices ingestor node s connected non intrusively to network elements that provide a port mirror to non intrusively ingest network traffic live data source to dynamically and continuously decode signaling packet or data content network traffic and action such identifiable selected network traffic to trap and generate immediate alerts and additionally pass through all or such selected subject matter for further processing simultaneously with and live to the network traffic event remaining open or in transit or before the transmission exits the network and becomes a data center log record or application event. The system is in two parts consisting of one or more ingestor nodes and one or more semantic nodes . The ingestor node enables a non intrusive direct mirroring of network traffic and its content and provides protocol decoding data extraction and prescribed Event alert capabilities. The ingestor node also feeds an assigned semantic node with such prescribed traffic as required. The ingestor node non intrusively undertakes its analysis and alerts while a particular Event is occurring or in transmission.

The various rules in control that dynamically instruct ingestor nodes as to what particular protocol and information is being sought to be alerted by the System are provided by the semantic node . The semantic node provides one or more virtual machines for the purpose of collecting all or selective network traffic from the ingestor node s and enabling access to relational language processing in combination with their application use cases and variable windows of time to provide analysis and reasoned deduction of outcomes of time critical live data situations for the generation of further alerts intercept and interdiction actions semantic node s being able to affect a more desirable or predictable outcome of the network traffic before the transmission exits the network and becomes a data center log record or application event. The primary functions of the semantic node are to attach to the ingestor node for the receipt of all ingestor node packets . Functions include to receive selected ingestor node packets the preparation and management of time critical processes required by use case applications to process the described use cases to provide fast in memory storage for statistical models required by a use case application to provide application visualization and system administration visualization through the visualization VM and to provide integrity check of packets mirrored to packets that exit the network.

The System has the ability to process data from the network traffic at gigabit speeds. The ingestor node filters decodes undertakes prescribed alerts and feeds selective or all network traffic into the semantic node . The semantic node undertakes application specific use case tasks including situational analysis contextual reasoning and deductive processing according to rules statistical models and if any subject matter databases attached to the semantic node .

Referring now to a more detailed illustration of the functioning of the system is provided. The System may include multiple ingestor nodes that are each capable of providing a number of functionalities by way of accessing the mirrored data flow provided by a targeted live data source. Multiple ingestor nodes are able to form a non intrusive analytical grid with regard to the desired traffic flow to be analyzed. The ingestor node is able to ingest and process mirrored network traffic at network speeds. Each of the ingestor nodes and semantic nodes use in memory database architectures C programming language and commodity servers and operating systems.

The semantic node provides rules engine functionalities visualization functionality and command and control framework to provide for an application use case execution. The rules engine visualization and command and control provide a manner for analyzing the received data according to a particular use case. Specific use cases are provided within this framework using an open application programming interface API application blade architecture that enables a user to develop and add multiple application use cases to the System . The semantic node can be expanded to incorporate SSD and hard drive databases provided they are able to perform at the time critical speeds of the live data processing. In direct relation to an embedded use case the semantic node has the ability for internal contextual evolution of the application specific statistical models by way of contextual table update and dynamically allocated stored procedures. This provides a certain amount of internally biased situational learning based on the correctness of the recommended decisions and execution of each application use case. Multiple applications can coexist and be implemented within the same semantic node and processed from the same live data input.

Referring now to there is a flow chart illustrating the operation of the system . The data flow is mirrored at step . Next at step the ingestor node ingests a mirrored copy of the network traffic provided by the live data source. Using mobile network traffic as an example the ingest VM writes the network traffic into an allocated time dependent buffer TDB at step . The protocol decoder commences decoding at step the contents of the TDB to find the protocol required. In the case of SS7 network traffic there are many protocols. The decoder checks for these protocols such as ISUP or TCAP MAP protocols. If found the decoder continues to decode and retrieves any required information that may be present such as a phone number. The process is granular in that it decodes small portions of the TDB rapidly to identify specific requirements before proceeding to decode the next set of requirements or the entire contents of the TDB. The decoded contents are passed to packet sniper for analysis in accord with a set of criteria for action at step .

If no prescribed conditions are detected control passes back to step and the process repeats. Once a particular prescribed condition is detected the ingestor node sends an alert to the semantic node or undertakes a preset action at step . This action could be to send a prescribed alert to network elements to truncate or trap and redirect that particular network traffic to other systems including the semantic node for processing. Such processing may include change of content copy of content or to create interdiction schemes for further network traffic of a like nature. All decoded network traffic is sent at step to the semantic node wherein such particular use case rules associated with any detected conditions is applied to the data.

Referring now to there are illustrated block diagrams for implementation of the system with a network packet data configuration and a FTP file based data configuration . The System causes application driven relational language processing situational analysis deduction and resulting actions to be not limited to events that have happened but to bring such situational analysis deduction and resulting actions into operational real time unity at the time of and concurrent with their live transmission. The System therefore enables understanding and calculation of relevant actions to be taken to better affect a desired outcome before closure of that opportunity by the network traffic exiting the network to become a post event log record or stored data center application event.

Referring now to there is illustrated a system block architecture for the System configured to monitor network traffic transmissions. The network traffic passes through some type of switch live data source or other network element that provides a port to mirror the data for ingestion. Within the ingestor node a pipeline packet reader ingests the mirrored network traffic passing through the switch live data source or other network element and reads all of the data passing therethrough. A packet handler within the ingestor node processes all of the packets and decodes the associated protocols of the packet using protocol decoders . A packet sniper within the ingestor node monitors for the occurrence of particular conditions or packet combinations as defined by the semantic node use cases. The information monitored for by the packet sniper is controlled by a semantic node and in memory database which provides application specific parameters traps and alerts that are to be monitored for and provided by the semantic node .

This information may be monitored for using particular statistical models implemented within the semantic node and in memory database and may additionally use additional contextual data from outside databases . The information within the semantic node and in memory database controls the operation of a rules engine that generates the appropriate responses to information detected by the packet sniper and generates various responses thereto such as email alerts visualization outputs configuration parameters and framework queries . Information within the semantic node and in memory database may also be updated through a machine learning feedback loop .

Referring now to there is illustrated the architecture for the system whereby a file server acts as a live data source port mirror and transmits FTP files to the ingestor node for processing using a parallel file reader . The System provides a file handler that processes the monitored files via a file decoder . The packet sniper within the ingestor node monitors for specific information and sends the file information to the semantic node as per the System requirements.

In a method similar to that of the live data network traffic ingest the file based information is also ingested monitored and analyzed using particular statistical models implemented within the semantic node and in memory database and may additionally use contextual data from outside databases . The information within the semantic node and in memory database controls the operation of a rules engine that generates the appropriate responses to information detected by the packet sniper and generates various responses thereto such as email alerts visualization outputs configuration parameters and framework queries . Information within the semantic node and in memory database may also be updated through a machine learning feedback loop .

The systems of provide the ability to bring application driven relational language processing situational analysis deductions and resulting actions into operational real time unity with network traffic while it is being transmitted within its associated network. Actions may then be taken on the Event to shape truncate alert or redirect before it exits the network and becomes a post Event fixed log record or data center application event.

Referring now to there is illustrated the configuration of the System within a function specific topology layered architecture. The first layer comprises the ingestor node . Each of the ingestor nodes are connected to a live data source through an associated port mirror or network interface controller port mirror that provides the ingestor nodes access to mirrored network traffic. Each of the ingestor nodes connects to a second layer which provides the semantic node . The semantic node interconnects with the ingestor node via an Ethernet or Infiniband connection .

The semantic node in layer contains the application decision matrices self learning cognitive decision support and action logic to enable execution of the desired use case outcome. Each semantic node contains the use case or pattern recognition logic to identify with instances and situations that are of interest in accordance with their use case. The semantic node provides a contextual learning loop through an independent process connecting to legacy storage and providing updates to the semantic node in parallel to the system .

Referring now to there is illustrated a functional block diagram of the methodology used for nonintrusive live data ingest at the ingestor node to the application specific situational analysis performed at the semantic node . The process provides a relational processing language driven analysis for the stated applications to occur while the Event is still open by way of its transmission within the network and thus provides the ability for real time dynamic relational processing language driven intercept adjustment of content prevention of action or interdiction to occur before the data exits the network and becomes a data center application event. This provides the opportunity to stop shape alter copy redirect or release the network activity while it is still in transit. The result is that the method allows for high data rate high volume signaling data to be analyzed in real time while it is still within the network so that certain enterprise policies controls predictive probability alerts or other actions can be applied in real time to the monitored data flow.

The live data source provides network traffic structured or unstructured to the ingestor node for decoding and identification. Upon ingestion by the ingestor node the network traffic is sent to the protocol decoder that decodes and identifies each wanted protocol packet and discretizes such wanted decoded network traffic as packets into a time dependent buffer TDB as allocated by the time dependent buffer VM TDB VM . The TDB VM is a semaphore based internal memory allocation manager for the ingestor node that assists in the integrity of memory allocation and release to ensure that both locked and lockless operations can occur in parallel in real time as needed and without clash. This memory is allocated and distributed at arbitrary lengths based on need via a variable length bitmap . The address of each newly loaded TDB is passed to a process whereby prescribed or deduced events are looked for in packet sniper .

The packet sniper compares the decoded data to certain conditions of interest as indicated by the prescribed rules provided by the semantic node or by deduced conditions determined by the contextual data and feedback loop learning loop undertaken by the semantic node . The packet sniper provides positive indications upon detection of these conditions. On completion of its search each packet sniper releases its previously allocated TDB to the ingestor node memory manager for use by other parallel current tasks or future operations that could be requested or introduced to the ingestor node . The TDB allows a no lock variable time latency multiprocessing of each packet by the ingestor node and the capability for locked operation in the eventuality of write functions being required to change the contents of packets. The packet sniper further counts the number of packets that are received from the decoder and provides this as a packet count indication . The packet count is used to verify live event network traffic flow with post event network traffic records providing a network transmission integrity check for network operations. The packets of interest detected by the packet sniper are referenced against an action table by the ingestor node and such prescribed action is executed. Network traffic of interest is flagged and sent to the semantic node for application based processing. Selected or all network traffic flows to the application relevancy filter within the semantic node these are provided for longer term storage or transferred to legacy data or discard . Relevant network traffic is passed to the application rules engine for further analysis to determine the actions required based upon the detected data.

The application rules engine initiates particular actions and interventions in accord with each application use case deduction and initiates the desired analytic outcome s . The application rules engine may also provide information to enable contextual updates with live data events and actions at in addition to the ability to enable manual input output as part of the learning loop at step . The determined actions and interventions at drive contextual updates with live data events and actions that occur at . The actions and interventions are used to execute particular actions at or to provide information to the grid manager within the ingestor node . The contextual update with live data events and actions at enable the creation of visualization and notifications of live data alerts and other metrics to provide necessary notifications at step . The contextual update with live data events and actions also provides information for storage and application specific static and dynamic statistical model and provides information to the activity and packet count journal . They also enable adjustment to the conditions rules and actions which are passed back to ingestor node and packet sniper to provide dynamic and deducted additions to those prescribed by the use case. The visualization and notification of live data alerts and other metrics execute an action at or alternatively or additionally enact live output to dashboards or data integration with other systems such as email SMS etc. at . After the executed actions at are caused to occur unwanted packets are discarded at . Information generated responsive to the activities are stored within the packet count journal .

Each use case provides the control information that controls the operation of its respective processes within the semantic node and ingestor node . Each blade may be associated with a particular use case such that a particular condition or operation may be monitored and detected by the ingestor node and semantic node . Multiple blades may be utilized such that different use cases may be implemented by the system on the same network traffic in parallel in a multithreaded fashion.

Referring now to there is illustrated the topical data flow through the ingestor and semantic nodes. A packet source is associated with a particular network traffic and may be read by a live data source reader within the ingestor node . Additionally various files may be read by a live data source reader configured for reading files. Reading data from and can be enacted simultaneously. The data read by the data source readers and are processed by data handlers which utilize a number of data decoders in order to decode data from the various data readers and .

The data handler generates various sources of semantic data . This data is provided to a semantic data writer so that it may be written to a semantic data application program interface . The API provides the data to the semantic node and in memory database that contains application specific parameters traps and alerts that are generated responsive to various statistical models relating to received Events within the semantic node . Various alerts and reports are generated responsive to the semantic node and in memory database operations.

Referring now to there is more particularly illustrated a block diagram of the various virtual machine functions that make up the ingestor node . The primary functions of the ingestor node are to attach the System to a live data source for the purpose of receiving mirrored data from that source then decoding and preprocessing before forwarding to the semantic node . The ingestor node attaches to the live data source through a live data source port mirror or other non intrusive method that enables access to data as a parallel observe and duplicate process and not by being a network element step of pass through stop copy forward . Each ingestor node is able to directly communicate with its peer nodes in a grid and with an assigned semantic node . The ingestor node feeds information to its assigned semantic node for use case application analysis and deduction. The ingestor node provides peer to peer communications.

The ingestor node consists of four agents able to operate independently and in parallel 1 the ingest VM 2 the governor VM 3 the time dependent buffer TDB VM and 4 the grid VM . The ingest VM ingests the mirrored network traffic undertakes protocol decoding acquires a TDB and discretizes and writes the required packetized data to the assigned TDB. The protocol decoder process within the ingest VM uses an informational map that the ingestor node uses for the dynamic allocation of threads and cores to decode one or potentially more protocol packets in parallel.

A network packet may contain multiple protocols. For example an internet protocol IP packet may include web traffic HTTP mail SMTP internet phone VOIP file transfer FTP and network monitor SNMP amongst others. When the protocol decoder tells the ingestor node to decode HTTPs SMTP FTP protocols the protocol decoder collects information on both the sender and the target servers. The ingestor node allocates three threads each operating on its assigned protocol and all three threads run in parallel to more readily operate on the packet. The design of the protocol decoder is lockless and a read only operation. As an example a decoded packet within a TDB VM could be analyzed by three or more protocol decoders independently in parallel and with no fixed ordering. Thus the HTTP decoder would perform a bit comparison to determine if there were an HTTP page request within the packet retrieve the target server name and place the information within the semantic data queue. The SMTP decoder would perform a bit comparison to determine if there were an SMTP send mail within a packet retrieve the mail server name and sender and place the information within the semantic data queue. The FTP decoder would perform a bit comparison to determine if there were an SMTP PASV within the packet retrieve the mail server name and place the information within the semantic data queue. Each protocol decoder would independently release its use of its allocated TDB VM .

The ingest VM also includes one or more packet sniper process es for providing multi threaded parallel comparisons for prescribed or deduced conditions. The packet sniper process also includes the information that the ingestor node uses for allocation of threads and or cores to analyze per data type along with where and or how to generate alerts to the semantic node . Similar to the protocol decoders multiple packet sniper processes can be enacted on any assigned TDB each process releasing its interest in the TDB when finished. The conditions being sought by packet sniper processes are set up by the semantic node or may optionally be established by direct input to the ingest VM . The ingest VM is also able to simultaneously transmit selected or all data to the semantic node .

In one example a decoded SS7 packet contains the phone number of a caller and the phone number of a call recipient. To address the requirement of alerting when caller 1234567890 makes calls to any number and to alert when called number 1900PREMIUM receives calls from any number the packet sniper configuration tells the ingestor node of these two separate operations with respect to an outgoing sniper and an incoming sniper. The ingestor node allocates two packet snipers each operating on its assigned task and within its own in memory database or assigned TDB VM . Each thread runs in parallel and independently with no fixed ordering and will operate on a decoded packet. When the outgoing sniper matches the caller number to a caller blacklist in its in memory database an alert will be generated. Similarly if the incoming sniper matches a called number to a called blacklist within its memory database the packet sniper generates an alert. Packet sniper will independently release use of its TDB VM .

The governor VM acts as a performance watchdog with the ability to organize core and or memory availability of the ingest VM responsive to its detected conditions. The dynamic allocation and release of multiple TDB VM allows multiple functions of disparate timing to be scheduled by the ingest VM so that optimum memory availability is provided to those functions. The TDB VM provides the ingestor node with the ability to use memory efficiently in concert with the speed of ingest and any disparate ingestor node processing. The TDB VM uses a combination of semaphores and arbitrary memory mapping dynamically responding to allocation of memory requests. The TDB VM allows for the efficient use and tuning of memory based upon time required and size needed. Multiple ingestor node tasks and VMs are able to request workspace of varying need and time. TDB VM flags the required memory blocks. These can be flagged as a lock or no lock status. The flagged memory can then be used in parallel by multiple tasks in read only mode and dynamically locked if in write mode. Each task releases its need for the memory block on completion of its task. The final release will release that memory block back to the TDB VM for further use. TDB VM is able to allocate as a single block of memory non contiguous blocks grouped as a virtual contiguous allocations of memory.

This memory management is illustrated for three simultaneously operating processes in . illustrates four separate tasks that are occurring in parallel within the same TDB as allocated by the TDB VM . The processes search for the next available data packet at step for decoding. Step checks if all packets have been received and if not control passes back to step to get the next packet for decoding. As packets are decoded and identified they are placed into requested TDBs. Control passes to step and the addresses of buffered packets are passed to the packet sniper or other ingest VM tasks. Packet sniper analyzes the buffered data comparing it for triggers of interest to its sniper list at step to determine if any relevant conditions are detected. If a trigger is detected an alert is executed at step and in parallel any recorded action beyond a trigger is also executed. If no trigger is detected at inquiry step or following an alert or action executed at step the contents of the data packets are forwarded on to the semantic node at step and that interest in that TDB memory is released by packet sniper back to TDB VM at step . An action at step could be to change the contents of that packet content or to alert a network operations center to truncate the transmission of that Event or to trigger other events that may or may not activate intercept or interdiction processes. As can be seen the same data packets can be monitored in three separate use cases that are each monitoring for different types of information in the same manner. Governor VM monitors the timeliness of disparate use cases as to their use of the same memory buffer for different purposes in relationship to the overall memory available for allocation by the TDB VM .

Referring now to there is illustrated the process flow of an ingestor node with respect to each of the virtual machines described herein above. The ingest VM uses a packet capture agent at to allocate available cores and request allocation of TDB from the TDB VM . If a TDB is not available the threshold alarm is generated at step . If a TDB is available the mirror of the network traffic is copied and processed at . Protocol decoders at ingest the mirrored packets to determine if the packets are wanted. Unwanted packets are discarded at step .

Thus from the port mirror the network traffic can be copied in parallel to its transmission into one or more of the allocated TDBs and made available to one or more of assigned scheduled cores of the ingest VM and by using variable bitmap searching the required protocols are decoded and recognized or the required patterns are recognized at step . The address of TDBs containing wanted protocols packets patterns are passed to packet sniper and other such tasks for further processing or inspection. The TDB VM process monitors the availability of memory blocks and presents the available status to the ingest VM . The ingest VM schedules the sending of the ingested data to the semantic node in parallel scheduling routines through the packet sniper that compares data for preselected alerts or actions at inquiry step . Once a TDB is fully released and its contents transmitted at step to the semantic node the now available TDB addresses are returned at step to the TDB VM memory map as being available. Control will then pass back to step .

If the packet sniper does not detect a comparison match at inquiry step control passes to step to determine if different content exists. If so additional comparisons are performed at step . If no further comparison data is available control passes to steps and wherein the packet sniper journal is updated at step and the memory associated with the compared data is released and the TDB VM memory map updated at step . The TDB VM does not clear buffers for use until every task has issued a clear status on that TDB .

Packet sniper is engaged when each ingest VM has completed its loading of live data from the allocating core. The packet sniper is responsive to dynamic or deduced updates received from the semantic node at . This update information enables the packet sniper to target particular content and or situations. This information is stored within a target content and or situation file that controls the operation of the packet sniper . Packet sniper analyses the contents of the TDB for content or conditions that have already been determined as being of interest at inquiry step as well as updated deduced conditions from step . If found packet sniper performs predetermined action triggers at that can either execute within the ingestor node or defer to the semantic node . If inquiry step determines that a match does exist the action associated with the match is executed at step and an alert is generated to the semantic node at step . Packet sniper will then continue its searches at step .

The role of the governor VM is to monitor and maintain the preset performance levels of core usage and memory space available to all virtual machines and tasks within their host ingestor node . Assigned cores that operate at a higher percent busy value or excessive memory usage cause an alarm to be sent to the semantic node for diagnostic records and alerts.

The governor VM measures the time periods of the ingestor node . This comprises measuring the time taken for the TDB VM the packet sniper s and other tasks to complete their operations and additionally ensuring that memory usage is not growing beyond a certain threshold. The governor VM operates in parallel to all of the other virtual machines in the ingestor node and engages dynamic performance balancing of available cores and memory should processes start to encroach on preset or dynamically set hurdles. The performance gathering data of the governor VM is logged and sent at regular intervals to the semantic node for journal entry at . The governor VM also acts as the entry point for executing messaging from the grid VM and command and control functions from the assigned semantic node . The governor VM determines at inquiry steps whether there has been a grid VM condition set or an internal performance breach. When a grid VM condition or performance breach is detected the governor VM undertakes reallocation of priorities and resources as provided by the resident operating system and utilities at step and at step . Governor VM undertakes similar actions when receiving command control update or diagnostic instructions by the assigned semantic node .

As a result of a threshold alarm the governor VM commences working with the operating system and TDB VM to reassign other cores and memory of a lower priority and to allocate the newly available resources to assist in reducing the workload of other cores. Thus in a situation where cores running ingest or decode or packet sniper tasks approached a set threshold level of for example 70 and or the amount of available memory for allocation to those tasks in the TDB also reached a threshold level of for example not less than 20 the governor VM would a attempt to reassign or cease lower priority work b attempt to increase available memory in the TDB and c inform the assigned semantic node of the condition.

The role of the grid VM is to manage for its host ingestor node the intercommunications between peer ingestor nodes and thereby the intercommunications between multiple semantic nodes . Based on use case performance requirements it is possible to configure any number of ingestor nodes and semantic nodes into an analytical grid architecture. Thus the grid VM receives inter ingestor node notification at and makes notes of these indications at . The grid VM is also able to send notifications to other ingestor nodes at . The data within the grid VM is referred to as map of operations and contains a role both within the grid and within the node. The grid VM enables notification of dynamic conditions and required action among various ingestor nodes within a set of Systems .

Referring now to there is more particularly illustrated the semantic node . The semantic node provides a use case application environment for time critical situational analysis contextual deduction decision support and follow up action as dictated by the use case applications defined within that semantic node working within a required window of time set by the application in regard to any desired result remaining relevant to its opportunity to effect change or alert. The semantic node is able to inform other network elements or outside data processing environments of conditions within the System and additionally request or send determined intercept or interdiction commands that are in accord with the application.

The semantic node provides a framework for time critical situational analysis decision support deduction and action processing of multiple use applications with regard to the live data packets sent by the ingestor node . In some cases this may require the use case application to access various other data such as legacy data center records or to send alerts or to seek action that may require the servicing of the use case application s needs to include non live data access to data storage outside the System .

The decision accuracy and situational relevancy of semantic node is continually updated through the recording of actions and alerts within the action and alerts database . The actions and alerts are deemed to be correct non correct through programmatic access to data center records and the subsequent reformulation of statistical subject matter used in decision support situational analysis. The semantic node consists of three processes that operate dynamically and independently to form the rules engine . These include the application blade manager visualization VM and self learning loop . A semantic node further includes two virtual machines agents including a grid VM and governor VM . The grid VM and governor VM operate in the same fashion discussed herein above with respect to the ingestor node and provide the same functionalities. Queries to the semantic node can be dynamically and programmatically executed responsive to use case application control or may also be learned through matrices input and defined or external machine big data input including statistical models and pattern recognition.

The visualization VM provides the framework to drive dashboards visual analysis tool or data presentation media reporting in real time to the activities being undertaken or their results and provides an operational command and control entry point to the System .

Referring now to there is illustrated a manner of operation of an application blade manager . The application blade manager is responsible for managing and providing control based upon the various use case applications defined in use case application blades within the semantic node . The application blade manager runs at an individual application blade associated with a use case application to execute the customer use case algorithm. Input to the modular application blade is received from the process at step from data provided from the ingestor node for a specific window from user supplied run parameters and from related historical and static data . Each of these is received as input to the modular application blade at step . Next at step the use case algorithm is executed as a series of dependent ordered steps using the provided data. The algorithm concludes at step rendering a set of outcomes. These outcomes may be used to provide GUI reports alerts and use case related displays on a dashboard as indicated at . Additionally the outcomes may be used to provide processing metrics at run time at . Finally the outcomes may provide at known unlabeled data from the user algorithm.

This known unlabeled data may be used to determine the statistical accuracy of customer algorithm results at step or provide customer analyst label outcomes at step . The customer analyst label outcomes may provide known data with labeled responses at step which may be used to derive an action list for the ingestor node at step . Inquiry step determines if there is a learned classification algorithm based upon the labeled responses. If not the machine learning algorithm builds a classification model using the labeled responses as a training data set at step . If so the machine learned algorithm is run against data for validation to calculate the statistical accuracy at step . At step a comparison of the accuracy and speed of the machine learned algorithm against the statistical accuracy of the customer algorithm may be based upon the result from step and the statistical accuracy of customer algorithm results at step . All this information is used to generate a report outcome to the graphical user interface as a customer inquiry at step . Additionally this outcome is used to calculate the deduced conditions which are provided back to the ingestor node and packet sniper .

Referring now to there is provided an illustration of the operation of a semantic node user application blade. A particular application blade is selected at step and the associated information related to the blade is read. Next at inquiry step the applications assigned to the use case application are determined. The assigned application information is forwarded to the resource manager to assign the core memory requirements necessary for executing the application. The application assignments are based upon load parameters that are provided to the application assignment process and selected from the number of available applications that may be utilized. Each application has various operational tasks associated therewith. The resource manager will start the selected applications at . The started applications may comprise any number of applications and execution of the applications will generate a decision to either flush or save data that is being analyzed by the use case application at . These decisions to flush or save data are provided to action profiles that identify particular actions to be taken depending upon the decisions made by the applications . Additionally the decisions may be provided to a graphical user interface for display of information in the form of alerts or other dashboard activities or the information may be stored within a journal for later or further analysis. The action profile information may be forwarded to the load parameters block for further action or stored within a learning database . The various applications that are implemented may utilize information from existing databases such as metadata applications statistical model or the learning database .

The system described herein above with respect to may be implemented in a number of manners in order to provide real time monitoring of live data flowing through such associated live data sources and other network elements. Various applications in which the methodology may be utilized include business assurance applications customer experience applications network operations applications and network security applications. Various business assurance applications include ways for monitoring and confirming that a business model implemented by a system is operating in a known and desired manner. These applications include international roaming fraud Wangiri inbound calls text messages SMS international revenue share country or number callout fraud SMS fraud SMS spam whitelisting SLA service level agreement verification shared services fraud management monitoring shared services fraud threat aggregation and alerting M2M mobile to mobile usage fraud monitoring SIM subscriber identification module cloning interconnect bypass SIM box usage fraud phishing farming stolen device IMEI international mobile equipment identity hotlist femto cell fraud detection subscriber fraud detection mobile payment system monitoring content distribution SLA monitoring network event verification for revenue assurance real time margin calculations for subscriber profitability interconnect charges verification PBX corporate account hacking mobile banking 2 Factor authentication fraud detection mobile churn protection head off.

This methodology may also be utilized in a number of applications for controlling and managing customer experience. These include things such as bill shock management social network analysis for churn avoidance identification of non optimal network conditions and immediately notifying or offloading subscribers for amelioration high value subscribers and the provision of granularized service to them for things such as dropped calls wireless offloading for congestion dynamic notifications for network outages All You Can App customized tariff plans based on personalized application usage and social network analysis for individualized experiences.

With respect to network operations applications the system methodology can provide an intelligent network planning to prioritize plan optimize investments ahead of a demand curve provide subscriber centric wireless offload based on contextual intelligence provide congestion control at the granular level provide core instrumentation and alerting provide traffic management provide instrumentation for circuit measurements detect silent dropped calls calculate answer ratios real time control and alerts and to provide for data session quality of service monitoring and control. In one example the System receives outage plans for cell towers and commences monitoring in conjunction with a live data source the presence movement and activities of such mobile devices or devices within that nominated cell tower transmission area. A file is built in real time to that monitoring and a usage map is dynamically built. The map is used to selectively alert through SMS email or other such contact methods such dynamic situations or planned outages creating a just in time dynamic alert system based in real time to the live data deductions.

Finally with respect to network security applications the system methodology enables analysis of live data network traffic for the purpose of identifying malicious content or agents as they enter the network at any determined location or between two or more points in applications packets on devices or network elements. This identification and detection in concert with the packet sniper capabilities of automated alert and prescribed or dynamic deduced actions can isolate trap or reject the passage of such threats from further movement through or into the network or out of the network into further onwards data centers or enterprise systems . While each of these various applications of the described methodology are only examples thereof it would be appreciated by one skilled in the art that various other implementations of the methodology in accordance with the general process described herein may also be implemented.

Referring now to there are more particularly described implementations of various applications utilizing the methodology described herein with respect to . is a flow diagram relating to a use of the system for detection of international roaming fraud. Perpetrators of international roaming fraud make international calls on stolen or purchased SIM cards with no intention of paying the roaming charges. Perpetrators steal SIM cards and make international calls or calls to premium numbers leaving a large unpaid bill. In other occurrences perpetrators purchase large blocks of SIM cards from the carrier country roam out of country and use the cards to call their own premium numbers profiting off the calls and leaving the roaming charges to be absorbed by the carrier. The present methodology would make use of the roaming data files provided by the roaming data file syndicator. This data may be used to detect patterns indicative of roaming fraud.

The System can detect the number of outgoing calls from a single roaming subscriber to one or more international numbers at step . Next a determination is made at inquiry step as to whether the number of outgoing calls from a single roaming subscriber to one or more international numbers has exceeded a user configurable threshold and if so whether this has occurred within a user configurable period of time at inquiry step . If the number of outgoing calls has exceeded the threshold within the configured time period alarms with associated reports may be generated at step . The alarm may be used to indicate to the network provider that an outgoing call threshold from the specified roaming subscriber number has been exceeded and further scrutiny is necessary. A drill down report generated along with the alarm is made available for the network provider that will list the international numbers that are being called. If inquiry steps and determine that the configurable call numbers or time periods have not been exceeded control passes back to step to continue monitoring the roaming data at step . Outcomes from are integrated with external contextual data at and this information is utilized by the semantic node to calculate dynamic changes to any parameters relevant to the use case.

Referring now to there is illustrated a manner in which the methodology may be used for detecting Wangiri fraud. Owners of premium numbers may drive traffic to their numbers by calling unsuspecting subscribers or sending them SMS messages to lure or trick them into calling the premium number. This is referred to as Wangiri fraud and frequently occurs over the weekend between Friday evening and Monday morning or during holidays when there are fewer people staffing the carrier network and thus making it less likely they will notice traffic spikes indicating possible fraud. Subscribers will receive inbound calls from what may at first glance appear to be a local number. In some cases the calls are brief and the recipient hears a baby crying or a woman screaming. After the call is disconnected the subscriber will call back out of concern. In other cases recipients may have missed the call during the night and will return it in the morning under the presumption that the call must have been important. In another variant subscribers will receive an SMS message informing them that they have won a prize or have a gift to be delivered and they must call a number to arrange delivery. The customer calls the number which is again an international premium number.

The methodology uses data sources consulted by the semantic node that include known revenue share fraud databases or threat lists that have been built based on past calling behavior carrier fraud and threat databases. In using the methodology of to detect Wangiri fraud the system detects multiple calls SMS messages from a single number or range or an excessive number of calls SMS messages at step . The allowable number of SMS messages or calls is a user configurable number. It is determined at inquiry step whether the configured number of call or SMS message number has been exceeded and whether this exceeded number has occurred within the user configured time period at inquiry step . If so alarms with associated reports may be generated at step . Otherwise the system continues monitoring at step until a problem condition is detected. Any outcome from is integrated with external contextual data at and this information is utilized by the semantic node to calculate dynamic changes to any parameters relevant to the use case. This includes packet sniper conditions for alert or action statistical or risk scoring models and or additional information that can be provided back to the network carrier to enhance the alert or report contents at . Examples include customer billing records to determine how the subscriber s current balance may affect their perceived risk in real time social analysis of calling maps to determine circles of subscribers involved with suspicious network activity or contrasting the live network activity with the subscriber s normal behavioral patterns to determine if an outlier or anomaly has been detected.

The reports generated in response to detection of this condition would include updates of all current fraud events updated with all victims who have received SMS or phone calls. The reports would show common numbers any victims are calling back in order to identify the callback numbers of the SMS attacks. The reports would further provide real time calculations of KPIs and savings in the dashboard to show cost call of each return call so analysts can track savings from the time the callback number is barred to customers. This will calculate how much it would have cost the customer had the Wangiri fraud not been identified and stopped. Thus a particular savings benefit can be numerically defined for customers and the network provider.

Another type of fraud which may be detected by the system is International Revenue Share fraud. This type of fraud involves perpetrators making calls to international premium numbers on stolen or purchased SIM cards from within the carrier network. This type of fraud has two subtypes. Within the number callout scenario subscribers call international premium numbers as evidenced by a sudden high number of outbound calls to a small range of destinations. This could indicate the usage of stolen SIMs or SIMs purchased with no intention to pay the full contract bill. In this case there is no correlated inbound trigger of calls from an international number as in Wangiri Fraud and the calls are placed from within the carrier network unlike the international roaming fraud. In the country callout scenario a high number of calls are suddenly placed to a specific country. These calls exceed the normal baseline call rates and the calls are placed from within the carrier network. External data sources may be consulted by the semantic node in order to access known revenue sharing databases threat lists that have been built on past calling behavior carrier fraud and threat databases.

The calling patterns are detected in the manner illustrated in . With respect to the number callout scenario the cumulative minutes from a single A number to any B number in any country is first detected at step . Inquiry step determines if the cumulative minutes exceed a user defined threshold level and if so inquiry step determines whether the cumulative minutes exceed a call count from a single A number to any B number in any of the countries within a configurable time period. If so an alert and associated report may be generated at step . If the cumulative minutes have not been exceeded within a configured time period or the call count has not been exceeded within a configured time period the cumulative minutes are further monitored at step to continue monitoring for possible issues. Any outcome from is integrated with external contextual data at and this information is utilized by the semantic node to calculate dynamic changes to any parameters relevant to the use case.

Referring now to in the country callout configuration at step the cumulative minutes from a carrier network to a specific country are first detected and inquiry step determines whether these cumulative minutes exceed a predetermined threshold within a defined time limit. If so a further determination is made at step whether the cumulative minutes involve an excessive call count threshold within a defined time period. If so this causes the generation of alerts and reports at step . If the threshold call limit or call count are not exceeded at step and respectively control passes back to step to continue monitoring for issues. Any outcome from is integrated with external contextual data at and this information is utilized by the semantic node to calculate dynamic changes to any parameters relevant to the use case. Both the semantic node and the data in enable adjustments to the input parameters to adjust for the live data conditions of the network. In the case of country specific thresholds this dynamic input enables variations to account for regular network baselines which days of the week are highest lowest traffic to and from each country for example as well as unexpected or uncontrollable factors such as world events natural disasters terror attacks religious holidays that prompt an unusual surge of traffic to or from specific locations.

The drilldown reports provided at and respectively can provide updates on the configurable time period of each fraud event. Reports may also provide a summary of each fraud alert for immediate scanning by an analyst enabling them to determine how many A numbers B numbers cumulative duration etc. The reports may also provide risk scoring of each alert based upon a configurable set of questions e.g. are 90 of calls being answered are majority of calls 2 minutes plus . The report may also provide risk scoring of each alert based upon an external big data contextualization do any A numbers in this alert have a current balance owing greater than X . The alert generation may comprise the provision of an application program interface to customer billing and customer profile information as at and . Finally calling maps may be generated to show the relationship between anyone involved in the fraud event showing all activity for the past 48 hours. These external data sources can be linked to semantic node for ongoing automatic adjustment or feedback to the use case rules and can inform packet sniper in ingestor node to be aware of specific subscribers phone numbers relationships patterns thresholds or other factors that when encountered in the network traffic will be automatically alerted on or actions instructions sent to other systems. Examples include communications to network operations to terminate a call bar a specific subscriber prevent outbound calls to a specific phone number all of these are actions to alter the specific activity as it is detected. This enables the carrier to prevent the losses from being incurred by intercepting the fraudulent activity before or while it happens.

Referring now to there is illustrated the manner in which the system may detect inbound SMS fraud. Within the SMS fraud situation subscribers receive SMS messages designed to trick them into either calling international premium numbers or clicking on links designed to phish for usernames and passwords to give access to private information. The system may detect inbound SMS messages at step that come from a particular international number or range of numbers. The determination is made at inquiry step whether the number of SMS messages exceeds a configurable limit established by the system. If so an alert and associated report may be generated at step . If a selected number of SMS messages has not been exceeded control passes to inquiry step which determines if an allowable number of responding subscribers who have received the SMS message have dialed a same international number greater than a configurable threshold number of times within a configurable time period. If so a report and alert are generated at step . If not control passes to step and SMS messages will continue to be monitored. To enhance this ongoing monitoring external contextual data is integrated at and this information is utilized by the semantic node to calculate dynamic changes to any parameters relevant to the use case. In this case the contextual data enables for example correlation to identify common numbers being dialed even if those numbers did not originate the inbound spam so that action can be taken to bar monitor or otherwise take action on parties involved in a fraud event as it is happening.

Referring now to there is illustrated the manner in which the system may be used to ensure service level agreement compliance. Various service level agreement SLA parameters are monitored in real time at step and a determination is made whether all parameters are met. When inquiry step determines that certain parameters are not met an alert flag is generated at step . If the parameters are met control returns to step to continue monitoring the parameters. An example of this would be if international roaming files must be generated and submitted to a syndicate service within 4 hours of a call closure. The system automatically checks for SLA compliance and flags any roaming file that is not compliant so that it can be diverted to billing systems department so that it is not paid back to the roaming carrier.

Referring now to there is illustrated the manner in which the system may be used to provide real time live data usage verification and notification in order to prevent bill shock for subscribers. Carriers must provide subscribers with up to date data usage information so that subscribers do not inadvertently burst through their upper data limits and incur a large overcharge on their monthly bills. This requires the ability to define thresholds of data usage for alerts based upon live customer activity. Responsive to these thresholds notification triggers are provided to carrier messaging systems enabling further action by the subscribers to interact with the carrier to respond to their respective data usage position. Thus subscriber data usage is monitored at step and when various notification levels are reached as determined at inquiry step a notification is provided to the carrier messaging system at step . The carrier generates messages to the customer at step enabling a customer response at step . Customer responses may range from upgrading their plan blocking further data usage shifting remaining data to shared devices or instantly adding data amounts to their device etc. If no notification is needed at step the system continues monitoring data usage at step . This is particularly important so that carriers remain in compliance with regulatory mandates on overage charges for customer satisfaction and to maintain brand reputation.

Referring now to the system is also useful in providing services to various high value subscribers. In order to bridge the current chasm between OSS and BSS toolsets carriers can identify high value subscribers HVS in real time and set policies and rules for a variety of conditions and actions. These policies can be adjusted in real time based upon the HVS score and controlled by customer care network operations marketing promotions etc. Examples of granularity include the ability to set automatic actions for subscribers with certain HVS levels and manual actions via dashboard for subscribers with other HVS scores. Thus the system would monitor data usage at step and determine the high value subscribers at in real time. Policies are established for the high value subscribers at step and the data associated with the subscriber monitored at step responses based upon the HVS status are generated at step . Examples of particular types of services which could be provided to HVS users include HVS users that are determined to be victims of fraud or phishing can receive an SMS message if they are identified as a victim of an inbound fraud or phishing attempt. With respect to network quality of service the HVS will be flagged if they have x number of dropped or silent or incomplete calls which are detected by the System as they occur and are mapped against each HVS. The HVS can automatically receive an SMS with an apology and an offer of credit toward next month s bill. Based upon network voice and data usage patterns of the HVS the carrier can choose to offer completely customized tariff plans. All You Can App offers include the option of paying per month for unlimited access to certain frequently used applications with the data usage not counted against the data limits of the subscriber s base plan. This sort of offer must be calculated and maintained in real time with live network traffic as the billing system and the customer s real time usage must be kept in sync.

Referring now to there is illustrated the manner in which the real time data monitoring system may be used to provide network outage notifications. As carriers upgrade network infrastructure to 4G LTE cell towers and sites must periodically be brought down for planned maintenance. Additionally unplanned outages occur with regularity. Carriers must be able to notify subscribers of these outages. The system can utilize contextual big data to model the cell site s subscribers spend the majority of their time in and automatically push SMS message notifications when there is a planned outage. In the case of an unplanned outage or an outage that will affect subscribers that are not usually in that cell site but are headed toward it the system can identify which subscribers will soon be approaching a degraded service area and send an SMS message to anyone who is signed up for just in time notifications.

Simultaneously the planned cell tower outage schedules act as event triggers and manual updates and changes to these schedules are ingested by the ingest VM . These are integrated at and sent onwards to the network topology bitmap . The network topology bitmap represents a live data mirror of device locations the cell tower locations or planned or dynamically required outages for service improvements of those towers as well as accessing a historical record of the presence of the device locations within the targeted cell tower locations. This historical record allows for a deductive process to occur as to the multiple locations over a period of time with regard to both individual devices as well as multiple cell towers. In this fashion outage notifications can be based on both real time immediately occurring or historically based device presence in each cell tower location.

The role of the semantic node is shown in . The semantic node deductive processes and access the network topology bitmap and compare cell tower outage trigger dates with regard to the need for an action. Should action be required process deduces the current and historic presence relationship of mobile devices to the triggered cell tower address and accesses prescribed notification content data . Step builds the required notification and embeds any prescribed or dynamically available additional information based on customer status carrier events or sentiment analysis feedback. Step sends the completed message to the carrier notification gateway for transmission to the selected mobile device s or other communication endpoints and additionally sends notification metrics for live data display . Step sends a copy of the notification output to a journal for later analysis.

The ability for the system to provide real time sentiment analysis to the carrier is illustrated in . Step retrieves sent notification information and compares with feedback messages from carrier message hub. Step compares sentiment feedback with regard to keywords timeliness of response to outage notification redemption of included coupons use of curse words and other embedded criteria used to measure subscriber sentiment. Such information is compiled into a live data report at and additionally readied for transmission at to display as live data sentiment analysis with regard to the impact of the outage. Such live data sentiment analysis provides time and opportunity for the carrier to respond in kind to the sentiment reporting.

A further example of the use of the real time data monitoring system is with respect to network core instrumentation and alerting. Examples of this include the ability to monitor measure and alert on any network operation or function with the option to set configurable parameters for threshold limits alarms and performance optimums. In all cases visualizations and queries can be drilled down to show innumerable combinations of data e.g. calls by time country circuit partner device etc. and time periods real time immediate performance and drill down to show how immediate conditions compare against any desired time period of minutes hours days weeks months etc. . In all cases thresholds or performance norms can be set or changed in real time by the customer and any deviation or desired alerting alarming can be sent to a variety of destinations including dashboards email mobile devices or other applications solutions or systems.

The system can measure the performance of network circuits CICs in real time and provide visualization of all monitored CICs over a selectable time period to show trends and performance norms. When any single CIC or group of fellow CICs fall below the threshold which are configurable and changeable in real time from the dashboard alerts can be sent to the dashboard and or to email SMS or other connected systems.

Measurements of total network traffic can be as granular as the customer desires. Measurements can include total calls in out total SMS in out and any combination of drill down on these analyses including querying the data by circuit by cell tower by interconnected partner by inbound or outbound traffic by destination or origin country by device type by conversation length etc. Anything that can be measured can be queried and displayed on the dashboard.

The system may be used to measure the ratio of answered to unanswered calls against a customer configured threshold. Real time data can be drilled down by any of the categories mentioned in the previous use case and thresholds can be changed in real time. Alerts can be sent to a dashboard email SMS or other system. This system may also detect average conversation times and interconnect traffic data and provide alerts reports etc. based upon this information. Thus using the above described system and method real time data flow within a network via a connection to a particular network element switch etc. may be achieved in order to analyze the real time data flow in order to generate analysis and reports of the data while the data is actively being generated before it exits the network for onward storage. This enables network providers to provide much more up to date and real time responses to the analyzed data and achieve improvements to system performance and issues as these events are occurring rather than at a later date based upon post data analysis.

It will be appreciated by those skilled in the art having the benefit of this disclosure that this system and method for real time live data analysis of network traffic provides a manner for monitoring and analyzing network content as the data is moving through the network and provides an ability to affect the outcome that ordinarily in the absence of such a system and method would be not affected in relationship to its normal course of business.

It should be understood that the drawings and detailed description herein are to be regarded in an illustrative rather than a restrictive manner and are not intended to be limiting to the particular forms and examples disclosed. On the contrary included are any further modifications changes rearrangements substitutions alternatives design choices and embodiments apparent to those of ordinary skill in the art without departing from the spirit and scope hereof as defined by the following claims. Thus it is intended that the following claims be interpreted to embrace all such further modifications changes rearrangements substitutions alternatives design choices and embodiments.

