---

title: Loose term-centric representation for term classification in aspect-based sentiment analysis
abstract: A method for aspect categorization includes receiving an input text sequence and identifying aspect terms and sentiment phrases in the input text sequence, where present. For an identified aspect term, identifying sentiment dependencies in which the aspect term is in a syntactic dependency with one of the identified sentiment phrases, and identifying pseudo-dependencies from a dependency graph of the input text sequence. The dependency graph includes a sequence of nodes. In a pseudo-dependency, a node representing the aspect term precedes or follows a node representing a semantic anchor in the dependency graph without an intervening other aspect term. Features for the aspect term are extracted from at least one of identified sentiment dependencies and identified pseudo-dependencies. With a classifier trained to output at least one of category labels and polarity labels for aspect terms, classifying the identified aspect term based on the extracted features.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09633007&OS=09633007&RS=09633007
owner: XEROX CORPORATION
number: 09633007
owner_city: Norwalk
owner_country: US
publication_date: 20160324
---
The exemplary embodiment relates to sentiment analysis and finds particular application in connection with aspect based sentiment analysis.

Sentiment analysis or opinion mining analyzes people s opinions sentiments evaluations attitudes and emotions from written text using natural language processing. It finds uses in a variety of applications such as in analysis of data from blogs social media websites and product review websites enabling detection of customer opinions about the products and or services of a business or other organization and may be used for making business decisions or for making recommendations to product reviewers.

The majority of current sentiment analysis approaches attempt to detect the overall polarity of a sentence paragraph or text span irrespective of the entities mentioned e.g. laptops battery screen and their attributes e.g. price design quality . When a text is classified at a document level or a sentence level the resulting classification may not provide meaningful data concerning what the opinion holder likes or dislikes about aspects of an item. If a document is positive concerning an item for example this clearly does not mean that the opinion holder holds positive opinions about all the aspects or features of the item. Similarly if a document is negative it does not mean that the opinion holder dislikes everything about the item described.

Aspect based sentiment analysis however aims to detect fine grained opinions expressed about different aspects of a given entity. See for example M. Hu et al. Mining and summarizing customer reviews. ACM SIGKDD Int l Conf. on Knowledge Discovery Data Mining KDD pp. 168 167 2004. Aspect based sentiment analysis systems generally receive textual input e.g. product reviews or messages from social media discussing a particular item e.g. a restaurant a movie or a new model of a mobile phone . Such a system attempts to detect the main aspects features of the item and to estimate the polarity expressed about these aspects usually positive negative and neutral . The detection of aspects entails detecting the aspect terms common to the particular domain and then associating them with semantic categories or topics . For example value and cost may be associated with the general semantic category price while waiter staff and chef may be associated to the semantic category service. 

For example given a restaurant review The pizza was delicious but service was slow the aim would be to identify the different aspect terms that relate to the restaurant domain pizza and service about which an opinion is expressed positive and negative respectively assign these terms to semantic categories e.g. food and service and associate them with a measure of polarity.

However training a system for such a fine grained task is difficult particularly when the number of aspect categories is high. As a result high accuracy may not always be achieved.

The following references the disclosures of which are incorporated herein by reference in their entireties are mentioned 

U.S. application Ser. No. 14 569 899 filed Dec. 15 2014 entitled CATEGORY AND TERM POLARITY MUTUAL ANNOTATION FOR ASPECT BASED SENTIMENT ANALYSIS by Caroline Brun et al.

U.S. Pub. No. 20150120788 published Apr. 30 2015 entitled CLASSIFICATION OF HASHTAGS IN MICRO BLOGS by Caroline Brun et al.

U.S. Pub. No. 20140067370 published Mar. 6 2014 entitled LEARNING OPINION RELATED PATTERNS FOR CONTEXTUAL AND DOMAIN DEPENDENT OPINION DETECTION by Caroline Brun.

U.S. Pub. No. 20130218914 published Aug. 22 2013 entitled SYSTEM AND METHOD FOR PROVIDING RECOMMENDATIONS BASED ON INFORMATION EXTRACTED FROM REVIEWERS COMMENTS by Anna Stavrianou et al.

U.S. Pub. No. 20130097174 published Apr. 18 2013 entitled CALCULATING VALENCE OF EXPRESSIONS WITHIN DOCUMENTS FOR SEARCHING A DOCUMENT INDEX by Livia Polanyi et al.

U.S. Pub. No. 20130096909 published Apr. 18 2013 entitled SYSTEM AND METHOD FOR SUGGESTION MINING by Caroline Brun et al.

U.S. Pub. No. 20120245924 published Sep. 27 2012 entitled CUSTOMER REVIEW AUTHORING ASSISTANT by Caroline Brun.

U.S. Pub. No. 20120245923 published Sep. 27 2012 entitled CORPUS BASED SYSTEM AND METHOD FOR ACQUIRING POLAR ADJECTIVES by Caroline Brun.

U.S. Pub. No. 20110099052 published Apr. 28 2011 entitled AUTOMATIC CHECKING OF EXPECTATION FULFILLMENT SCHEMES by Caroline Brun et al.

U.S. Pat. No. 7 058 567 issued Jun. 6 2006 entitled NATURAL LANGUAGE PARSER by Salah A t Mokhtar et al.

In accordance with one aspect of the exemplary embodiment a method for aspect categorization includes receiving an input text sequence. Provision is made for identifying aspect terms in the input text sequence and for identifying sentiment phrases in the input text sequence. For an identified aspect term provision is made for identifying sentiment dependencies in which the aspect term is in a syntactic dependency with one of the identified sentiment phrases. Provision is made for identifying pseudo dependencies from a dependency graph of the input text sequence the dependency graph including a sequence of nodes each of the pseudo dependencies being between a node representing the aspect term and a node representing a semantic anchor which precedes or follows the aspect term node in the dependency graph without an intervening other aspect term. Features are extracted for the aspect term from at least one of identified sentiment dependencies and identified pseudo dependencies. With a classifier trained to output at least one of category labels and polarity labels for aspect terms the identified aspect term is classified based on the extracted features. Information based on the classification is output.

In accordance with another aspect of the exemplary embodiment a system for aspect categorization includes an aspect term detection component which detects aspect terms providing for identifying aspect terms in an input text sequence. A sentiment phrase detection component detects sentiment phrases in the input text sequence. A sentiment dependency extraction component identifies sentiment dependencies in which an identified aspect term is in a syntactic dependency with an identified sentiment phrase. A pseudo dependency extraction component identifies pseudo dependencies from a dependency graph of the input text sequence. The pseudo dependencies including an aspect term and a semantic anchor that precedes or follows the aspect term in the dependency graph without an intervening other aspect term. A feature extraction component extracts features from at least one of the identified sentiment dependencies and identified pseudo dependencies. A classifier classifies an identified aspect term based on the extracted features according to at least one of categories and polarity. A processor implements the components.

In accordance with another aspect of the exemplary embodiment a method for training classifiers for aspect categorization includes receiving a set of training samples in which aspect terms are labeled with a category selected from a plurality of predefined categories and with a polarity selected from a plurality of polarities. The method includes extracting sentiment dependencies and pseudo dependencies from the training samples. Each sentiment dependency includes an aspect term in a syntactic dependency with a sentiment phrase. Each pseudo dependency includes an aspect term and a semantic anchor which precedes or follows the aspect term in a dependency graph of the input text sequence without any intervening aspect terms. Features are extracted for each of a plurality of the aspect terms based on any sentiment dependencies and pseudo dependencies in which the aspect term participates. At least one classifier model is learned for predicting category labels and polarity labels for an input text sequence based on the extracted features.

At least one of the extraction of sentiment dependencies and pseudo dependencies and the extraction of features is performed with a processor.

A system and method for aspect based sentiment analysis include for a given input text string such as a sentence identifying aspect terms in the text string for a selected domain of interest classifying each aspect term into one of a set of predefined aspect categories and classifying the aspect term based on the polarity of sentiment opinion related term s which are in a dependency relationship with the aspect term. The dependencies are selected from sentiment dependencies and pseudo dependencies. Sentiment dependencies are a class of semantic dependencies. Pseudo dependencies are dependencies that lack a formal syntactic or semantic dependency relationship based on the applied grammar rules but instead are defined by proximity of the aspect term and an anchor term which may bear polarity and aspect category lexical information such as sentiment phrases in the text string.

The loose dependencies created between the aspect term and the sentiment phrase of a sematic category polarity term in the pseudo dependencies may be limited by specifying a number of linguistic and ordering constraints that restrict the dependencies generation thus reducing potential noise. This allows capture of relatively long range dependencies that are often difficult to capture with traditional approaches.

An aspect term as used herein is a word or sequence of words which names a particular aspect of a target entity in the domain of interest. A sentiment phrase is a phrase that is identified as expressing a sentiment and includes one or more words.

With reference to a computer implemented system for aspect based sentiment analysis is shown. The illustrated system includes memory which stores software instructions for performing the method illustrated in and a processor in communication with the memory for executing the instructions. The system also includes one or more input output I O devices such as a network interface and a user input output interface . The I O interface may communicate with one or more of a display device for displaying information to users speakers and a user input device such as a keyboard or touch or writable screen and or a cursor control device such as mouse trackball or the like for inputting text and for communicating user input information and command selections to the processor device . Alternatively the system may be linked to a web server which includes a portal for receiving user comments about items in a particular domain e.g. laptops cell phones books movies restaurants or the like. The various hardware components of the system may all be communicatively connected by a data control bus .

The computer system may include one or more computing devices such as a PC such as a desktop a laptop palmtop computer portable digital assistant PDA server computer cellular telephone tablet computer pager combination thereof or other computing device capable of executing instructions for performing the exemplary method.

The memory may represent any type of non transitory computer readable medium such as random access memory RAM read only memory ROM magnetic disk or tape optical disk flash memory or holographic memory. In one embodiment the memory comprises a combination of random access memory and read only memory. In some embodiments the processor and memory may be combined in a single chip. Memory stores processed data and instructions for running the computer as well as the instructions for performing the exemplary method.

The network interface allows the computer to communicate with other devices via a computer network such as a local area network LAN or wide area network WAN or the internet and may comprise a modulator demodulator MODEM a router a cable and or Ethernet port.

The digital processor device can be variously embodied such as by a single core processor a dual core processor or more generally by a multiple core processor a digital processor and cooperating math coprocessor a digital controller or the like. The digital processor in addition to executing instructions may also control the operation of the computer .

The term software as used herein is intended to encompass any collection or set of instructions executable by a computer or other digital system so as to configure the computer or other digital system to perform the task that is the intent of the software. The term software as used herein is intended to encompass such instructions stored in storage medium such as RAM a hard disk optical disk or so forth and is also intended to encompass so called firmware that is software stored on a ROM or so forth. Such software may be organized in various ways and may include software components organized as libraries Internet based programs stored on a remote server or so forth source code interpretive code object code directly executable code and so forth. It is contemplated that the software may invoke system level code or calls to other software residing on a server or other location to perform certain functions.

The illustrated instructions include a set of components e.g. software including a classifier training component a syntactic parser a term detection component a sentiment phrase detection component a sentiment dependency extraction component a pseudo dependency extraction component a feature extraction component an aspect term classification component a polarity classification component and an output component .

Briefly the classifier training component trains classifier models denoted Mand M which are used by the respective classifier components . For training the classifier models a collection of labeled sample sentences may be provided in a natural language such as English or French. The classifiers are trained on features extracted from the training sentences as described in greater detail below.

The aspect term detection component detects aspect terms in input text and may utilize a lexicon of aspect terms for this purpose. The aim of aspect term extraction is to identify each of the aspect terms present in the sentence and label them. An aspect term names a particular aspect of a target entity. For example in I liked the service and the staff but not the food the aspect terms may be identified as service staff and food. Similarly in The food was nothing much but I loved the staff the aspect terms are food and staff. Multi word aspect terms e.g. hard disk are treated as single terms e.g. in The hard disk is very noisy the aspect term is hard disk .

The sentiment phrase detection component detects sentiment phrases in the sentence e.g. by accessing polar vocabulary in which sentiment phrases are each associated with a respective measure of polarity.

The sentiment dependency extraction component extracts sentiment dependencies where present between aspect terms and sentiment phrases in a sentence e.g. using a set of parser rules. For example the rules include rules for detecting when a sentiment phrase is in an adjectival relationship with an aspect term i.e. the aspect term is the subject or object of an adjective that is a sentiment phrase.

The pseudo dependency extraction component extracts pseudo dependencies between aspect terms and sentiment phrases in a sentence e.g. based on proximity of an aspect term and a sentiment phrase in a sentence. In the exemplary embodiment if a semantic relationship is found by the semantic dependency extraction component no pseudo dependency between the two terms will be extracted by the pseudo dependency extraction component.

The feature extraction component uses the information extracted by the sentiment dependency extraction component and pseudo dependency extraction component to generate features for input to the classifiers . The features may be input to the classifiers in the form of a respective features based representation such as a vector.

The aspect term classification component classifies aspect terms based on the extracted aspect term related features using the trained model .

The polarity classification component assigns a polarity to the aspect term based on the polarity related features using the trained model .

The output component outputs information such as the predicted category of each aspect term in the sentence and its associated polarity or information based thereon.

At S classifier models are learned by the classifier training component using the labeled training samples .

At S input text to be processed is received which may include one or more sentences. The text may be stored in system memory during processing.

At S the text is split into sentences and each sentence is parsed by the syntactic parser to identify syntactic dependencies.

At S sentiment phrases are identified in the input sentence by the sentiment phrase detection component .

At S sentiment dependencies are extracted from the input sentence by the sentiment dependency extraction component each sentiment dependency including one of the identified aspect terms which is in a syntactic dependency with one of the sentiment phrases.

At S pseudo dependencies are extracted from the input sentence by the pseudo dependency extraction component each pseudo dependency including one of the identified aspect terms and one of the sentiment phrases.

At S features are extracted for the input sentence based on the extracted sentiment dependencies and pseudo dependencies by the feature extraction component .

At S the features are used to classify each aspect term and its polarity using the classification components and models .

The method illustrated in may be implemented in a computer program product that may be executed on a computer. The computer program product may comprise a non transitory computer readable recording medium on which a control program is recorded stored such as a disk hard drive or the like. Common forms of non transitory computer readable media include for example floppy disks flexible disks hard disks magnetic tape or any other magnetic storage medium CD ROM DVD or any other optical medium a RAM a PROM an EPROM a FLASH EPROM or other memory chip or cartridge or any other non transitory medium from which a computer can read and use. The computer program product may be integral with the computer for example an internal hard drive of RAM or may be separate for example an external hard drive operatively connected with the computer or may be separate and accessed via a digital data network such as a local area network LAN or the Internet for example as a redundant array of inexpensive of independent disks RAID or other network server storage that is indirectly accessed by the computer via a digital network .

Alternatively the method may be implemented in transitory media such as a transmittable carrier wave in which the control program is embodied as a data signal using transmission media such as acoustic or light waves such as those generated during radio wave and infrared data communications and the like.

The exemplary method may be implemented on one or more general purpose computers special purpose computer s a programmed microprocessor or microcontroller and peripheral integrated circuit elements an ASIC or other integrated circuit a digital signal processor a hardwired electronic or logic circuit such as a discrete element circuit a programmable logic device such as a PLD PLA FPGA Graphical card CPU GPU or PAL or the like. In general any device capable of implementing a finite state machine that is in turn capable of implementing the flowchart shown in can be used to implement the method. As will be appreciated while the steps of the method may all be computer implemented in some embodiments one or more of the steps may be at least partially performed manually. As will also be appreciated the steps of the method need not all proceed in the order illustrated and fewer more or different steps may be performed.

The labels for the training samples may include aspect term labels. For example each word in the sentence is labeled as either part of an aspect term or null indicating that the word is not part of an aspect term for the particular domain of interest restaurants in the illustrative examples used herein . Each aspect term is also labeled with a respective aspect category label corresponding to one of a predefined set of at least two aspect categories. As one example there may be at least four or at least six or at least ten pre defined aspect categories related to the domain of interest and in some embodiments up to 50 or up to 20 pre defined aspect categories. Aspect categories may be hierarchical such that one or more aspect categories topics has at least one or at least two sub categories sub topics . In the examples below twelve pre defined aspect categories are used which combine topics and sub topics. Words in the sentence are also labeled with sentiment phrase labels according to whether they are part of a sentiment phrase or not. The identified sentiment phrases are also labeled with a polarity measure for example selected from among three polarity labels positive negative and neutral or with values on a numerical scale ranging from highly positive to highly negative. The aspect and term labels may be in the form of XML tags or the like.

As an example there may be twelve categories provided in the context of the SEMEVAL 2016 Challenge which are a combination of topic and sub topic as follows 

When used as a training sample this sentence may be annotated in XML format with aspect terms referred to in this example as opinion targets and polarity as follows where the aspect terms are shown in bold italic the categories in bold upper case and the polarity in bold lower case for ease of illustration 

The categories food drinks and restaurant can be associated with three different subcategories. As can be seen from this example a single aspect term may be associated with more than one semantic category such as FOOD STYLE OPTIONS FOOD PRICES etc. and a respective polarity which may be derived from the sentiment phrase which is in a syntactic dependency with the aspect term such as huge best or price. 

In the exemplary method instead of performing term detection in parallel with sentence classification in terms of topics and polarity term detection and classification are performed for both topics and polarity.

The classification components are trained with the labeled training samples in particular with features based representations extracted from the training samples and aspect category and aspect polarity labels obtained from the labels of the training samples. The annotation of explicit aspect terms may thus be treated as a classification task for both the semantic category of the aspect term and the polarity of the aspect term.

S may include parsing the training text samples with the syntactic parser to extract syntactic dependencies S identifying aspect terms S and sentiment phrases S with components and extracting sentiment dependencies between aspect terms and sentiment phrases with component S extracting pseudo dependencies between aspect terms and sentiment phrases with component S and extracting aspect category and aspect polarity features from the labeled training samples with the feature extractor S based on the extracted dependencies. Steps S S may be performed as for steps S S which are described in further detail below.

At S the classifier model is trained with the aspect category features extracted at S and the aspect category labels provided with the training samples and the classifier model is trained with the aspect polarity features extracted at S and the aspect polarity labels provided with the training samples. Two different classifier models useful as models are suggested by way of example and are used in the Examples described below 

Model 1 Logistic regression. A tool for performing this is available from the Liblinear classification library. See R. E. Fan et al. LIBLINEAR A Library for Large Linear Classification J. Machine Learning Research 9 pp. 1871 1874 2008 . The appendices of this paper give the implementation details of the LIBLINEAR classifier.

Model 2 This uses an interactive method which is able to cope with the high degree of sparsity of the data. provides an example of such a model. First the set of features associated with the considered aspect term is defined S . Then in order to cope with sparsity truncated singular value decomposition can be performed on the original set of features S . See e.g. P. C. Hansen The Truncated SVD as a Method for Regularization BIT Numerical Mathematics 27 4 534 553 1987. At S a one versus all Elastic Net regression model is then used to infer the target concept in the present case category and polarity. See Hui Zou at al. Regularization and variable selection via the Elastic Net J. R. Statist. Soc. Series B. 67 2 301 320 2005 for a discussion of elastic nets. An advantage of the Elastic Net is that it explicitly defines a trade off between L1 norm and L2 norm type of regularization. A model is output at S. Cross validation scores may also be computed S in order to allow for improvement of the feature set used as decision support method returns to S . The decision on which features to select or to weight more heavily in the model may be performed manually and or automatically in order to reduce classification errors .

The training set can be relatively small for example a set of about 2000 sentences is sufficient for training the classifier models as described in the examples below.

A robust syntactic parser may be used to parse the training samples and input text sentences . An exemplary parser provides a full processing chain including tokenization morpho syntactic analysis POS tagging Named Entity Detection chunking and extraction of syntactic dependency relations such as subject object and modifiers between lexical nodes of a chunk tree.

Tokenization involves splitting the text into tokens generally words often by looking for white spaces between characters. Morpho syntactic analysis entails identifying candidate parts of speech POS for each word such as noun verb adjective adverb which may be refined to a single part of speech per word as ambiguities are resolved and the most likely POS tags are assigned. This may be performed via a combination of hand written rules and hidden Markov Modeling HMM . Proper nouns and Named Entities are identified and may tagged as nouns. See for example U.S. Pat. Nos. 6 263 335 6 311 152 6 975 766 and 7 171 350 and U.S. Pub. Nos. 20080319978 20090204596 20100082331 and 20140163951 the disclosures of which are incorporated herein by reference. Chunking allows words to be grouped around a head to form noun phrases adjectival phrases and the like. Extraction of dependency relations or simply dependencies may involve extracting SUBJ relations between a noun or more generally a noun phrase and a verb in which the noun phrase serves as a subject of the verb OBJ relations between a noun phrase that serves as an object of a verb NOUN ATTRIBUTE and NOUN PREDICATE dependencies and the like.

The parser may provide this functionality by applying a set of rules called a grammar dedicated to a particular natural language such as French English or Japanese. The grammar is written in a formal rule language and describes the word or phrase configurations that the parser tries to recognize. The basic rule set used to parse basic documents in French English or Japanese is called the core grammar. Through use of a graphical user interface a grammarian can create new rules to add to such a core grammar. In some embodiments the syntactic parser employs a variety of parsing techniques known as robust parsing as disclosed for example in Salah A t Mokhtar et al. Robustness beyond shallowness incremental dependency parsing in special issue of the NLE Journal 2002 U.S. Pat. No. 7 058 567 and Caroline Brun et al. Normalization and paraphrasing using symbolic methods ACL 2nd Int l Workshop on Paraphrasing Paraphrase Acquisition and Applications 2003. In one embodiment the syntactic parser may be based on the Xerox Incremental Parser XIP which may have been enriched with additional processing rules to facilitate the extraction of aspect terms and sentiment phrases associated with them. Other natural language processing or parsing algorithms can alternatively be used. The parser can be adapted for performing other steps of the method such as S and S through additional rules.

Aspect terms can be nouns or noun phrases. Aspect term detection can be performed in various ways. As examples one or more of the following two methods for aspect term spotting in the sentences can be used 

In this embodiment a set of local grammar rules e.g. based on regular expressions over syntactic categories are provided and may be implemented by the parser . These rules take into account lexical semantic information collected for the domain e.g. collected semi automatically. These grammar rules may detect multi words terms as well as single word terms e.g. pastrami sandwiches group them under the appropriate syntactic category such as noun verb adjective or other part of speech and associate with them corresponding lexical semantic feature s . Such a method is described in Brun C. et al. XRCE Hybrid Classification for Aspect based Sentiment Analysis Proc. 8th Int l Workshop on Semantic Evaluation SemEval 2014 pp 838 842 August 2014 and in above mentioned U.S. application Ser. No. 14 569 899.

In this method a lexicon adapted to the task and to the domain e.g. restaurant reviews may be employed. For example words from the training corpus are first extracted and their words encoded in the lexicon optionally assigning to them semantic categories such as in the restaurant review example food service ambiance and price. The list can then be extended with for example synonyms obtained for example from a resource such as Wordnet. To improve coverage one or more of the lists e.g. the food term list can be extracted and filtered from for example Wikipedia pages Wikipedia Food Portal and then encoded.

With the generated lexicon given a new sentence single and multi word terms identified by the parser are checked against the lexicon and if present can be labeled as an aspect term and may be associated with their list of semantic categories.

Conditional Random Fields CRF have been used for sequential data labeling see e.g. John Lafferty et al. Conditional Random Fields Probabilistic Models for Segmenting and Labeling Sequence Data Proc. 18th Int l Conf. on Machine Learning pp. 282 289 2001 . Such methods can be applied to term detection. CRF is a class of statistical modeling applied in pattern recognition and machine learning. The specificity of a CRF model compared to a more traditional classifier is that it can take as input the combination of different samples together to make its prediction. For example in the case of a text sequence it can consider each word from the text as a sample that associates diverse linguistic data for that word e.g. part of speech lemma number etc. which the CRF model then combines with the previous or the next samples i.e. the linguistic information for the previous or the next words from the text. The words of a sentence are thus considered as a sequence with predictions for one word impacting the predictions for surrounding words. This helps with the identification of multi word terms.

The CRF model takes as input the features extracted by the parser for each word such as POS tags lemma form surface form syntactic dependencies in which the word occurs semantic features such as food drink service and other linguistic features . These features together with those of the next and preceding words are used to predict the most probable label for the word. The label for each word may be a binary label belongs to aspect term or not . For the aspect terms the label may be a more informative label for such as a category of aspect term e.g. food drink or service.

The information generated by the term detection component can be added to the rest of the information generated by the parser for use in the extraction of sentiment dependencies and pseudo dependencies.

The aspect terms extracted at this stage may be regarded as candidate aspect terms since they are only retained if a dependency with a respective sentiment phrase is identified at S or S for the training samples or at S or S for the input text .

While rule based systems have been shown to perform well for this task aspect term detection is often context dependent since aspect terms are annotated only when an explicit opinion is expressed about them. Thus the CRF method may be more useful in some cases.

In some embodiments some or all of the aspect terms in the training samples are identified from their labels rather than as described above.

Once the aspect terms in the input text have been detected they are classified into aspect categories topics as described in the following steps. As one example there may be at least six or at least 10 pre defined topics and in some embodiments up to 50 or up to 20 pre defined topics. In the examples below 12 pre defined topics are used.

Sentiment phrases such as opinion related predicates and adjectives may be identified using the polar vocabulary . The parser may include a normalization component that matches words such as verbs to their lemmatized root form which in the case of verbs may be the infinitive form and in the case of nicknames the stored name of the person. For example the parser compares the words and phrases in the input sentence that have been tagged with the part of speech ADJ adjective or VERB with the terms in the polar vocabulary and any terms that are found in the polar vocabulary are tagged as sentiment phrases and may be assigned a polarity based on the assigned polarity of the respective term in the polar vocabulary such as positive negative or neutral. Methods for generating a polar vocabulary which may be used herein. are described in above mentioned U.S. Pub. No. 20120245923 published Sep. 27 2012 entitled CORPUS BASED SYSTEM AND METHOD FOR ACQUIRING POLAR ADJECTIVES by Caroline Brun the disclosure of which is incorporated herein by reference.

Some words and phrases however may be considered as polar only in certain contexts which may be identified using specific opinion detection patterns. See for example U.S. Pub. No. 20140067370 published Mar. 6 2014 entitled LEARNING OPINION RELATED PATTERNS FOR CONTEXTUAL AND DOMAIN DEPENDENT OPINION DETECTION by Caroline Brun the disclosure of which is incorporated herein by reference for a discussion of the generation of such patterns. For example the word vote may be treated as positive in polarity if it is in a syntactic dependency with a named entity of the type Person or Organization otherwise it has no polarity.

In the parsing stage dependencies of a set of predetermined type s may be extracted such as NOUN ATTRIBUTE and NOUN PREDICATE dependencies and normalized to form patterns. In particular syntactic analysis by the parser extracts syntactic relationships dependencies between POS labeled terms words and or phrases . Syntactic relations are thus found between terms which need not be consecutive and which can be spaced by one or more intervening words within the same phrase or sentence. Coreference resolution anaphoric and or cataphoric can be used to associate pronouns such as he she it and they with a respective noun based on analysis of surrounding text which need not necessarily be in the same sentence. Words of negation which are in a syntactic relation with the adjective in the expression may also be considered and used to modify e.g. reverse the polarity of a sentiment phrase identified from the polar vocabulary .

In some embodiments some or all of the sentiment phrases in the training samples are identified from their labels rather than as described above.

The exemplary sentiment dependency extraction component extracts semantic information about the aspect terms and their polarities. The dependency parser augmented with a specific semantic component thus plays the role of a feature generator for the automatic classifiers .

The semantic extraction component may be in the form of rules in the same grammar formalism as the parser rules and may operate top of the other parser rules. For this task syntactic dependencies lexical information about word polarities and semantic classes and sub categorization information may all be combined e.g. within the parser to extract semantic relations associated to aspect terms.

A suitable component that extracts semantic dependencies which express a sentiment taking into account contexts and scope of the opinion related predicates is described for example in Brun C. Detecting Opinions Using Deep Syntactic Analysis Proc. Recent Advances in Natural Language Processing RANLP Hissar Bulgaria Sep. 12 14 2011 and Caroline Brun Learning Opinionated Patterns Detection for Contextual Opinion Proc. COLING 2012 Posters pp. 165 174 2012 and U.S. Pub. No. 20140067370 published Mar. 6 2014 entitled LEARNING OPINION RELATED PATTERNS FOR CONTEXTUAL AND DOMAIN DEPENDENT OPINION DETECTION by Caroline Brun.

Each semantic dependency includes an aspect term as identified at S which is in a syntactic dependency with a sentiment phrase in the sentence as identified at S. In the syntactic dependency the aspect term is either the subject or object of the sentiment phrase attribute or predicate . Lexical semantic information related to the domain of interest e.g. restaurant is also used to associate semantic classes to domain words and to the aspect term transmitted by the detection component .

For example if Service and people have been detected as aspect terms at S the sentiment dependency extraction component may extract the following dependencies on the following example sentence 

The sentiment dependency extraction component thus adds semantic information to a syntactic dependency between the identified aspect term and a sentiment phrase.

The term centric feature representation provided by the sentiment dependency extraction component is extended with high recall but low precision loose dependencies that aim to capture 1 long distance dependencies 2 cataphoric relations and 3 multiple semantic categories and opinions associated to ambiguous terms. The aim is to link aspect terms with semantic and polarity anchor nodes in a dependency graph under a certain number of linguistic constraints in order to generate potential decision features to help to classify the aspect terms. Like the sentiment dependencies these include a head an aspect term and one or more arguments but in this case the arguments are semantic anchor terms and are not required to be in a syntactic dependency with the head.

As illustrated in a dependency graph is generated for an input sentence . A dependency graph is a flattened representation of the sentence as a sequence of nodes. The nodes need not be in exactly the same order as the corresponding words appear in the sentence but follow the same general pattern. The dependency graph includes aspect term nodes and semantic anchor nodes . The aspect term nodes represent aspect terms exclusively single word nouns or multi word nouns . The semantic anchor nodes are non aspect term nodes which include one or more of 

Aspect term nodes may each be linked to one or more of the semantic anchor nodes and vice versa by links shown as arcs . The links can be forward links in which case the aspect term node precedes the semantic anchor node or backward links in which case the semantic anchor node precedes the aspect term node in the dependency graph. The forward and backward links take into account the order of the words in the chunking tree created from the input sentence and linguistic constraints on the dependency graph in order to link domain terms. Linguistic constraints take into account syntactic information such as negation on an anchor node and or the fact that the aspect term is already in semantic relation with a sentiment phrase these are sentiment dependencies identified in S .

The links generate pseudo dependencies that capture semantic and polarity information. The links encode linguistic patterns as follows 

Forward links these encode relations between a domain aspect term and all following semantic anchor nodes as long as there is no aspect term node in between and if and only if the anchor node is not in a semantic relation with another sentiment phrase as determined previously by the sentiment dependency extraction component . Syntactic negation is taken into account by inverting the polarity.

Backward links these encode relations between the last previous semantic anchor node and a domain aspect term if and only if the anchor node is not in a semantic relation with another aspect term and the domain aspect term is not in a semantic relation with another anchor node as determined by the sentiment dependency extraction component . Syntactic negation is taken into account to invert polarity. In some embodiments backward links are not created for an aspect term node when the semantic anchor node to which they would be linked is already linked to another term node e.g. by a forward link.

These patterns which are applied by the illustrated pseudo dependency extraction component may in practice be integrated into the rules of the parser together with the rules implemented by the sentiment dependency extraction component . All semantic features related to category and polarity attached to the different nodes can be migrated to on the output pseudo dependency.

Some of the dependencies extracted are thus neither syntactic dependencies nor semantic dependencies syntactic dependencies with added constraints but they encode potential interesting semantic information describing the terms in the sentences. The following examples where domain terms are in bold and the anchor node underlined.

In a the output link captures a very long distance dependency overcoming the problem of coreference linking. In b the output links capture the semantic ambiguity expressed on the domain term it is a case of multiple annotation. In c the second relation links the term and its attribute regardless of the interpolated clause in between and the third relation capture the inversion of the modifier and the term.

Semantic anchor nodes carry one or more of these features. Aspect terms node TERM are characterized by the semantic feature term and anchor node ANCHOR with the feature anchor .

Negation on a feature or a constraint is denoted with denotes any node in the chunk tree is the Kleene star denotes the feature percolation from a node to a node or to a dependency.

As will be appreciated these patterns tend to overgenerate links and also not be linguistically sound. However since the information generated is used in combination with the information provided by the parser as input to the machine learning classification models these classification models can be relied on to select the appropriate decision features and overcome problems related to the high recall low precision characteristic of these patterns.

For aspect term classification it is advantageous to have a fairly precise extraction of features that are relevant for a given aspect term in a given sentence knowing that several aspect terms can be present in the same sentence. A term centric feature extraction method may be used. For example for a given aspect term the features extracted for aspect category classification may include some or all 

In the exemplary embodiment an aspect term serving as a node in the dependency graph is represented by the information captured by the arcs connecting this specific node to other nodes of the graph i.e. incorporating information from both sentiment dependencies and pseudo dependencies .

For polarity classification of aspect terms the features can be those used for category classification but may be generalized by delexicalizing the term by replacing it with its semantic category e.g. staff is replaced with term service and bigram containing it great staff is replaced by great term service .

The aspect terms are classified in terms of category for example among twelve categories by using the trained classifier model to predict category labels using the extracted aspect category features .

The aspect terms are then classified based on the polarity features by the trained classifier model in terms of polarity for example among three polarity labels positive negative or neutral although different numbers of labels are contemplated.

The system and method may find application in various contexts such as social media analytics projects in particular in the context of customer care for sentiment analytics including aspect based emotion detection.

The exemplary method addresses explicit aspect terms i.e. terms which are explicitly mentioned in the sentence. The case of implicit terms can be covered by classification at sentence level.

Without intending to limit the scope of the exemplary embodiment the following examples illustrate the application of the method.

A prior method for term correction is described in above mentioned U.S. application Ser. No. 14 569 899 which was designed in the context of the SemEval2014 challenge Maria Pontiki et al. Semeval 2014 Task 4 Aspect based sentiment analysis Proc. 8th Int l Workshop on Semantic Evaluation SemEval 2014 pp. 27 35 2014.

The present method focuses on adaptations made for term classification in the case of explicit terms. A term centric representation is used taking into account information extracted from sentiment dependencies as well as long distance information in the sentence. This approach appears to be quite effective for the task of aspect categories and polarity classification as shown in the following Examples.

Training examples were taken from the Semeval 2016 dataset. In this dataset only terms about which an opinion is expressed are annotated. When an aspect category is expressed implicitly without the explicit presence of an aspect term the annotation target is NULL . For example in the sentence 

the aspect term Purple Haze is an explicit term and is labeled. The expression made for us upon request is associated with an implicit aspect term and receives category SERVICE GENERAL . The resulting training sample may thus be labeled as follows using bold and italic for emphasis 

In the case of the English training dataset Table 2 shows that it contains 2000 sentences 2506 annotated targets among which 627 are Null annotations topic without an explicit term . The 1879 annotations of explicit terms correspond to 1616 terms with a single annotation 118 terms with a double annotation and 9 terms with a triple annotation. This means that 7.9 of the terms have more than one annotation and that 14 of the explicit annotations come from an ambiguous term.

The classifier models described above Model 1 Logistic regression and Model 2 an interactive ensemble method pipeline were evaluated.

Feature extraction for the aspect terms was performed as described above using a Lexical semantic features associated to the term by the parser b Bigrams and trigrams involving the term and c All syntactic dependencies involving the term.

For polarity classification features are generalized by replacing the term by its semantic category e.g. staff is replaced with term service .

For example for the sentence Patroon features a nice cigar bar and has great staff. the system extracts the following features 

For example for the sentence Patroon features a nice cigar bar and has great staff. the system may extract the features shown in Table 3 

Features such as those in Table 1 are first used to train the two different classifiers but without using features obtained from pseudo dependencies. Performances on term classification are evaluated on the English training set with 10 fold cross validation as shown in Table 4. In this experiment the term detection step was skipped as the gold standard terms are known from the training set. The classification system was applied on these known terms in order to have a precise idea of the performances. In practice the CRF method may be used as the first step of the processing chain.

As will be appreciated these measures do not allow direct comparison between the two models but is useful in comparing the model improvements in Table 5 below. Looking at the results and in particular the cross validation errors there are some detectable weaknesses in the term representation used to train the classifiers. For example ambiguous terms which have several annotations have exactly the same feature representation for all their annotations intrinsically because they have the same lexical semantic information and belong to the same n grams and dependencies. Long distance and inverted dependencies are not captured well by the parser. As will be appreciated in traditional robust parsing grammars are generally designed to have high precision in dependency extraction leaving complex phenomena such as long distance dependencies or subject object inversion unsolved rather than providing a large set of low precision dependencies. These problems restrict the ability of the system to capture decision features for the classification models.

In this evaluation the representation for the aspect terms is also based on pseudo dependency based features.

The same processing chain described above was used but now including the new term representation on the English training data. The same 10 fold cross validation settings are used to evaluate the performances of the classification system on aspect categories and polarities. Table 5 shows the results obtained.

These results show significant improvement of the performances over the results in Table 4 as shown by the improvement gain in the performance measures and seems to be particularly significant for term aspect category classification.

The exemplary system and method which provide a combination of machine learning classification techniques with a component outputting loose semantic relations is particularly useful for addressing the problem of aspect category and aspect polarity classification. The loose semantic relations pseudo dependencies have the advantage of being able to link an aspect term with semantic information that goes beyond syntactic dependencies in particular they can capture long distance dependencies in an approximate way . The gain in performance demonstrates that this representation improves the classifier decisions even if the symbolic patterns are over generating low precision high recall .

It will be appreciated that variants of the above disclosed and other features and functions or alternatives thereof may be combined into many other different systems or applications. Various presently unforeseen or unanticipated alternatives modifications variations or improvements therein may be subsequently made by those skilled in the art which are also intended to be encompassed by the following claims.

