---

title: Transmitters for optical narrowcasting
abstract: Systems and methods for optical narrowcasting are provided for transmitting various types of content. Optical narrowcasting content indicative of the presence of additional information along with identifying information may be transmitted. The additional information (which may include meaningful amounts of advertising information, media, or any other content) may also be transmitted as optical narrowcasting content. Elements of an optical narrowcasting system may include optical transmitters and optical receivers which can be configured to be operative at distances ranging from, e.g., 400 meters to 1200 meters. Moreover, the elements can be implemented on a miniaturized scale in conjunction with small, user devices such as smartphones, thereby also realizing optical ad-hoc networking, as well as interoperability with other types of data networks. Optically narrowcast content can be used to augment a real-world experience, enhance and/or spawn new forms of social-media and media content.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09654222&OS=09654222&RS=09654222
owner: SureFire LLC
number: 09654222
owner_city: Fountain Valley
owner_country: US
publication_date: 20161230
---
This application claims the benefit of U.S. Provisional Patent Application No. 62 273 276 filed on Dec. 30 2015 which is incorporated herein by reference in its entirety.

The present disclosure relates generally to wireless optical communications. Some embodiments relate to systems and methods for optical narrowcasting.

Generally mobile communications systems both long and short range are based on the transmission and or receipt of radio waves e.g. cellular networks WiFi networks Bluetooth communications Near Field Communications NFC etc. . Services such as location based services may oftentimes also rely on radio wave based communications e.g. Global Positioning System GPS positioning WiFi triangulation etc. .

In various embodiments a first transmitter comprises a first light source and a first collimator. The first collimator may include a first portion and a second portion each of which being rotationally symmetric about an optical axis substantially centered on a light emitting element of the first light source. The first portion of the first collimator may have a broad middle body between a narrow circular first entrance pupil and a narrow circular first exit pupil. The broad middle body may have a first diameter greater than a second diameter of the narrow circular first entrance pupil and greater than a third diameter of the narrow circular first exit pupil. The second portion of the first collimator may have a flared body between a narrow circular second entrance pupil and a broad circular second exit pupil the narrow second entrance pupil being coupled to and having the same diameter as the narrow circular first exit pupil. A fourth diameter of the broad second exit pupil may be greater than the first diameter of the broad middle body of the first portion. The narrow first entrance pupil may be positioned near the light source to receive light from the first light source. The light may be emitted from the broad second exit pupil.

In some embodiments the first transmitter may further comprise a data format converter configured to convert data to an optical format for optical transmission and a light source driver configured to receive data from the data format converter and control the first light source to transmit the converted data. The data format converter may be configured to convert data to a return to zero on off keying RZ OOK format or a non return to zero on off keying NRZ OOK format. In some embodiments the data format converter is configured to incorporate transmit and receive first in first outs FIFOs to prevent overflow errors.

The first transmitter may further comprise a first pair of lenslet arrays positioned in front of the broad second exit pupil of the first collimator. The first pair of lenslet arrays may be identical K hler homogenizers to improve uniformity of light output from the broad second exit pupil of the first collimator. The first pair of lenslet arrays may be positioned parallel to each other in front of the broad second exit pupil of the first collimator. Each of the first pair of lenslet arrays may be separated from each other by a distance equal to a focal length of each of the lenslets of the first pair of lenslet arrays.

The first portion of the first collimator may have a length from the narrow circular first entrance pupil to the narrow first exit pupil that is 10 mm or less. The second portion of the first collimator may have a length from the narrow second entrance pupil to the broad second exit pupil of the first collimator that is 12 mm or less. The first and second portions of first collimator may each include an inner surface and an outer surface the inner surfaces being reflective. The first light source may output optical radiation with a spectrum having a centroid wavelength of 850 nm. In some embodiments the first light source includes an incoherent light emitter or a coherent light emitter.

In various embodiments the first transmitter may further comprise a digital device that is coupled to the data format converter the digital device being configured to provide data to be transmitted as a modulated optical beam by the first transmitter.

The first transmitter may comprise a tilt actuator configured to control a pointing direction of the first transmitter. The first transmitter may further comprise a heat sink configured to dissipate heat from the first light source.

In various embodiments there may be one or more additional transmitters each being identical to each other and identical to the first transmitter each optical axis of each collimator of each of the one or more additional transmitters and the first transmitter may be parallel to each other. A digital device may be simultaneously coupled to each of the one or more additional transmitters and the first transmitter. The digital device may be configured to provide data to be transmitted as a modulated optical beam by each of the one or more additional transmitters and the first transmitter. In some embodiments the optical intensity output produced at any given time by each of the one or more transmitters and the first transmitter as a function of a horizontal and a vertical angular coordinate has a root mean square RMS non uniformity of 5 or less within a polygonal angular region wherein sizes and shapes of each of the polygonal angular regions are identical and wherein a mean optical intensity produced at a given time by each of the one or more transmitters and the first transmitter within the respective polygonal angular region is approximately equal to a mean optical intensity produced at a same time by each of the one or more transmitters and the first transmitter within each of their respective polygonal angular regions. The angular orientation of each of the one or more transmitters and the first transmitter may be relative to each other such that corresponding individual polygonal angular regions of 5 or lower RMS non uniformity associated with each of the one or more transmitters and the first transmitter are arranged in a non overlapping configuration without gaps between any adjacent polygonal regions such that the RMS non uniformity of the optical intensity within a single larger combined polygonal angular region constructed from each of the individual polygonal angular regions is 5 or lower.

An example method may comprise receiving light from a first light source of a first transmitter and aligning the light received from the first light source with a first collimator of the first transmitter. The first collimator may include a first portion and a second portion each of which being rotationally symmetric about an optical axis substantially centered on a light emitting element of the first light source. The light may be received by a narrow circular first entrance pupil of a first portion of the first collimator. The first portion of the first collimator may have a broad middle body between the narrow circular first entrance pupil and a narrow circular first exit pupil. The broad middle body may have a first diameter greater than a second diameter of the narrow circular first entrance pupil and greater than a third diameter of the narrow circular first exit pupil. The narrow circular first exit pupil may provide light from the broad middle body to the a narrow circular second entrance pupil of the second portion of the first collimator. The second portion of the first collimator may have a flared body between the narrow circular second entrance pupil and a broad second exit pupil the narrow circular second entrance pupil being coupled to the narrow circular first exit pupil of the first portion of the first collimator to receive the light from the first portion of the first collimator. A fourth diameter of the broad second exit pupil may be greater than the first diameter of the broad middle body of the first portion of the first collimator. The broad second exit pupil may emit the light to transmit aligned optical energy.

The method may further comprise converting received data to an optical format for optical transmission to create optically formatted data and driving the first light source to emit the optically formatted data as optical beams at least a portion of the optical beams being received by the first collimator. The optically formatted data may be converted using a return to zero on off keying RZ OOK format or a non return to zero on off keying NRZ OOK format. The method may further comprise incorporating transmit and receive first in first outs FIFOs within the optically formatted data to prevent overflow errors.

The method may further comprise increasing uniformity of the aligned optical energy with a first pair of lenslet arrays positioned in front of the broad second exit pupil of the second portion of the first collimator. The first pair of lenslet arrays may be identical K hler homogenizers. The first pair of lenslet arrays may be positioned parallel to each other in front of the broad second exit pupil of the second portion of the first collimator each of the first pair of lenslet arrays may be separated from each other by a distance equal to a focal length of each of the lenslets of the first pair of lenslet arrays.

In some embodiments the first portion of the first collimator has a length from the narrow circular first entrance pupil to the narrow circular first exit pupil that is 10 mm or less. The second portion of the first collimator may have a length from the narrow circular second entrance pupil to the broad second exit pupil of the first collimator that is 12 mm or less. The first and second portions of the first collimator may each include an inner surface and an outer surface the inner surfaces being reflective.

The method may further comprise controlling a pointing direction of the first transmitter using a tilt actuator. In some embodiments the method may further comprise receiving device data from a digital device by the data format converter to create received data the device data including at least one file to be transmitted as a modulated optical beam by the first transmitter.

The first light source may output optical radiation with a spectrum having a centroid wavelength of 850 nm. The first light source may be an incoherent or coherent light emitter. The method may further comprise dissipating heat from the first light source with a heat sink.

In various embodiments the method further comprises emitting optical beams by one or more additional transmitters each being identical to each other and identical to the first transmitter each optical axis of each collimator of each of the one or more additional transmitters and the first transmitter being parallel to each other. The method may comprise providing by a digital device data to be transmitted as a modulated optical beam by each of the one or more additional transmitters and the first transmitter. The digital device may be simultaneously coupled to each of the one or more additional transmitters and the first transmitter. The optical intensity output produced at any given time by each of the one or more transmitters and the first transmitter may be a function of a horizontal and a vertical angular coordinate which has a root mean square RMS non uniformity of 5 or less within a polygonal angular region. Sizes and shapes of each of the polygonal angular regions may be identical. A mean optical intensity produced at a given time by each of the one or more transmitters and the first transmitter within the respective polygonal angular region may be approximately equal to a mean optical intensity produced at a same time by each of the one or more transmitters and the first transmitter within each of their respective polygonal angular regions. The angular orientation of each of the one or more transmitters and the first transmitter relative to each other may be such that corresponding individual polygonal angular regions of 5 or lower RMS non uniformity associated with each of the one or more transmitters and the first transmitter are arranged in a non overlapping configuration without gaps between any adjacent polygonal regions such that the RMS non uniformity of the optical intensity within a single larger combined polygonal angular region constructed from each of the individual polygonal angular regions is 5 or lower.

Another example transmitter may include a light source and a wineglass collimator. The wineglass collimator may include a first portion and a second portion each of which being rotationally symmetric about an optical axis substantially centered on a light emitting element of the light source. The first portion may be approximately ellipsoidal in shape with a broad middle body between a narrow entrance pupil and a narrow circular exit. The broad middle body may have a first diameter greater than a second diameter of the narrow entrance pupil and greater than a third diameter of the narrow circular exit. The second portion may be approximately paraboloidal in shape with a flared body between a narrow circular entrance and a broad exit pupil. The narrow circular entrance may be coupled to the narrow circular exit of the first portion. A fourth diameter of the broad exit pupil may be greater than the first diameter of the broad middle body of the first portion. The narrow entrance pupil positioned near the light source to receive light from the light source. The broad exit pupil may emit the light.

In various embodiments a receiver comprises a lenslet array an optical detector array a signal amplifier and filter a format converter and a port. The lenslet array may include a plurality of lenslets each of the plurality of lenslets including a first side and a second side the first side being convex and the second side being planar. The optical detector array may include a plurality of optical detectors each optical detector of the plurality of optical detectors positioned in the focal plane of the plurality of lenslets. Each of the lenslets may be positioned to concentrate flux collected over the convex side received from a field of view FOV onto at least one optical detector of the plurality of optical detectors. The signal amplifier and filter may be coupled to the optical detector array and configured to amplify and filter signals received from the optical detector array to create an amplified signal. The format converter may be configured to convert an optical format of the amplified signal to a digital signal. The port may be configured to output the digital signal to a digital device.

In some embodiments a digital device case is capable of coupling with a digital device the digital device case may include the lenslet array the optical detector array the signal amplifier and filter the format converter and the port. Alternately a digital device may include the lenslet array the optical detector array the signal amplifier and filter the format converter and the port.

The width from one of the optical detectors of the plurality of optical detectors to an apex of the closest lenslet of the plurality of lenslets is 4 mm or smaller.

In various embodiments the receiver may further comprise an imaging lens at least one beacon detector and a data processor. The at least one beacon detector may be in the focal plane of the imaging lens. The imaging lens and the at least one beacon detector may be capable of receiving at least one optical beacon from at least one transmitter. The data processor may be configured to generate a notification when the optical beacon is detected to indicate that additional information may be detectable by at least one optical detector of the plurality of optical detectors.

Each optical detector in some embodiments can detect an optical signal in the 10 nm to 106 nm spectrum. The optical detector array may include for example a 6 6 array of optical detectors and the lenslet array includes a 6 6 array of lenslets. The lenslet array may be for example a 2.75 mm or less square.

The receiver may be a multi channel receiver and each optical detector of the plurality of optical detectors may be dedicated to receive flux within an optical waveband of a channel. The receiver may further comprise a spectral filter configured to reduce levels of out of band flux incident on at least one side of the at least one optical detector of the plurality of optical detectors. In some embodiments a spectral filter may be configured to reduce levels of out of band flux incident on the at least one beacon detector.

In various embodiments a tilt actuator may be configured to control tilt orientation of the receiver. The receiver may further comprise a processor configured to control the tilt actuator based on transmitter position information calculated by the processor using a position of the beacon received at one location on the at least one beacon detector. Each lenslet of the plurality of lenslets may be approximately a 2.75 mm square with a lens thickness at the center of approximately 1.85 mm.

An example method may comprise collecting an optical signal from an optical transmitter by a lenslet array including a plurality of lenslets each of the plurality of lenslets including a first side and a second side the first side being convex and the second side being planar concentrating by the lenslet array the optical signal to an optical detector array including a plurality of optical detectors each optical detector of the plurality of optical detectors positioned in the focal plane of the plurality of lenslets each of the lenslets concentrating flux collected over the convex side received from a field of view FOV onto at least one optical detector of the plurality of optical detectors generating a detector signal by the plurality of optical detectors in response to the concentration of the optical signal amplifying and filtering the detector signal by a signal amplifier and filter coupled to the optical detector array to create an amplified signal converting the amplified signal from an optical format to a digital signal and providing the digital signal to a digital device.

In some embodiments the method may further comprise coupling a digital device case with the digital device the digital device case including the lenslet array the optical detector array the signal amplifier and filter the format converter and the port. Alternately the digital device may comprises the lenslet array the optical detector array the signal amplifier and filter the format converter and the port.

In some embodiments the width from one of the optical detectors of the plurality of optical detectors to an apex of the closest lenslet of the plurality of lenslets is 4 mm or smaller.

The method may further comprise collecting an optical beacon from the optical transmitter by an imaging lens concentrating by the imaging lens the optical beacon to an beacon detector in the focal plane of the imaging lens the imaging lens generating a beacon detector signal by the beacon detector in response to the concentration of the beacon signal and generating by a data processor a notification based on the beacon detector signal to indicate that additional information may be detectable from the optical transmitter through the lenslet array and by at least one optical detector of the plurality of optical detectors.

In some embodiments each optical detector can detect the optical signal in the 10 nm to 106 nm spectrum. The optical detector array may include a 6 6 array of optical detectors and the lenslet array may include a 6 6 array of lenslets. The lenslet array may be a 2.75 mm or less square. In various embodiments the receiver is a multi channel receiver and each optical detector of the plurality of optical detectors is dedicated to receive flux within an optical waveband of a channel.

The method may further comprise reducing by a spectral filter levels of out of band flux incident on at least one side of the at least one optical detector of the plurality of optical detectors. In some embodiments the method may further comprise reducing by a spectral filter levels of out of band flux incident on the at least one beacon detector.

In some embodiments the method may further comprise controlling direction of the lenslet array and the optical detector array with a tilt actuator. The method may further comprise controlling by a processor the tilt actuator based on transmitter position information calculated by the processor using a position of the beacon received at one location on the at least one beacon detector. Each lenslet of the plurality of lenslets may be approximately a 2.75 mm square with a lens thickness at the center of approximately 1.85 mm.

In accordance with one embodiment a system comprises a plurality of light sources. The system further comprises a light source driver element adapted to receive data to be optically transmitted and to output modulated electrical signals representative of the received data identical and synchronized copies of the output modulated electrical signals driving each of the plurality of light sources. Further still the system comprises a plurality of beamforming optics one of each of the plurality of beamforming optics having an optical axis substantially centered on a light emitting element of one of each of the plurality of light sources such that the plurality of beamforming optics transmit a combination of optical beams the combination of optical beams comprising an optical beam output from each of the plurality of beamforming optics the combination of optical beams having an optical intensity distributed over a two dimensional angular output region.

In accordance with some aspects the light source driver element may comprise a single light source driver or a plurality of mutually synchronized light source drivers. One or more of the plurality of beamforming optics and one or more light sources of the plurality of light sources corresponding to the one or more of the plurality of beamforming optics are positioned with an angular offset. The optical intensity distribution may be a function of a horizontal angular coordinate and a vertical angular coordinate within the two dimensional angular output region. The angular offset comprises at least one of a horizontal angular offset or a vertical angular offset relative to the two dimensional angular output region. Each optical beam transmitted by each of the plurality of beamforming optics has a uniform optical intensity distribution that is a function of a horizontal angular coordinate and a vertical angular coordinate within the two dimensional angular output region specified for each of the plurality of beamforming optics.

In some embodiments a first subset of the plurality of beamforming optics collects light from a first corresponding subset of light sources and outputs the collected light as a modulated optical beam comprising an optical beacon including beacon information indicative of a presence or availability of additional or other information associated with the system and representative of at least a portion of the received data. A second subset of the plurality of beamforming optics collects light from a second corresponding subset of light sources and outputs the collected light as a modulated optical beam comprising an optical signal including the additional or other information associated with the system and representative of at least another portion of the received data.

In some embodiments the combination of optical beams comprises the optical signals temporally interleaved with the optical beacons. In some embodiments the combination of optical beams comprises a combination of the optical signals and the optical beacons each of the optical signals including a first identifier and each of the optical beacons including a second identifier. In some embodiments the combination of optical beams comprises a combination of optical signals transmitted in a first optical wavelength band and optical beacons transmitted in a second optical wavelength band the first optical wavelength band being a different non overlapping optical wavelength band than that of the second optical wavelength band.

In some embodiments each of the plurality of beamforming optics collects light from a corresponding light source and outputs the collected light as a modulated optical beam. The modulated optical beam comprises at least one of an optical beacon including beacon information indicative of a presence or availability of additional or other information associated with the system and representative of at least a portion of the received data or an optical signal including the additional or other information associated with the system and representative of at least another portion of the received data.

In some embodiments the combination of optical beams comprises the optical signals temporally interleaved with the optical beacons.

In some embodiments the combination of optical beams comprises a combination of the optical signals and the optical beacons each of the optical signals including a first identifier and each of the optical beacons including a second identifier.

In some embodiments the combination of optical beams comprises a combination of the optical signals modulated by the optical beacons. In some embodiments a first data rate used to transmit the optical beacons is lower than a second data rate used to transmit the optical signals. In some embodiments a modulation representative of the optical signals is modulated by a modulation representative of the optical beacons wherein the received data comprises beacon information indicative of a presence or availability of additional or other information associated with the system and signal information comprising the additional or other information associated with the system.

In accordance with some embodiments each of the plurality of beamforming optics comprises a wineglass collimator including a first portion and a second portion each of which being rotationally symmetric about the optical axis substantially centered on the light emitting element of a corresponding light source the first portion of the wineglass collimator having a broad middle body between a narrow circular first entrance pupil and a narrow circular first exit pupil the broad middle body having a first diameter greater than a second diameter of the narrow circular first entrance pupil and greater than a third diameter of the narrow circular first exit pupil the second portion of the wineglass collimator having a flared body between a narrow circular second entrance pupil and a broad circular second exit pupil the narrow second entrance pupil being coupled to and having the same diameter as the narrow circular first exit pupil a fourth diameter of the broad second exit pupil being greater than the first diameter of the broad middle body of the first portion the narrow first entrance pupil positioned near the corresponding light source to receive light from the corresponding light source and emit the light from the broad second exit pupil.

In accordance with one embodiment an optical receiver assembly comprises an optical beacon receiver configured to detect and receive an optical beacon from an optical transmitter assembly and extract identification information from the received optical beacon wherein the extracted identification information identifies a source of the optical transmitter assembly. The optical receiver assembly further comprises an optical signal receiver configured to detect and receive an optical signal from the optical transmitter assembly and extract information from the received optical signal.

In some aspects the optical beacon receiver comprises a plurality of optical detectors. Each of the plurality of optical detectors may comprise an optical detector array.

In some aspects the optical beacon receiver comprises a plurality of receiver optics each one of the plurality of receiver optics being optically aligned with a corresponding one of the plurality of optical detectors. The plurality of receiver optics may be positioned such that each of their respective optical axes are parallel to each other.

In some aspects the optical signal receiver comprises a plurality of optical detectors. Each of the plurality of optical detectors may comprise an optical detector array.

In some aspects the optical signal receiver comprises a plurality of receiver optics each one of the plurality of receiver optics being optically aligned with a corresponding one of the plurality of optical detectors. Each of the plurality of receiver optics may be positioned such that each of their respective optical axes are parallel to each other.

In some embodiments the optical receiver assembly further comprises a non transitory computer readable medium having instructions stored thereon that when executed by a processor causes the system to display on a graphical user interface based on the identification information extracted from the received optical beacon a visual representation of the source overlaid over a live display of a field of view of a video camera receive data at the graphical user interface corresponding to user input selecting the visual representation of the source and in response to receiving the data display on the graphical user interface a visual representation of the information extracted from the received optical signal.

In accordance with one embodiment a method for presenting an augmented reality experience utilizing optically narrowcast information comprises capturing a live scene detecting the presence of a beacon determining an angular position of the beacon extracting identification data from the beacon indicative of a source of the beacon augmenting the live scene with an augmented reality representation of the beacon s angular positioning and identification data receiving a selection regarding the augmented reality representation extracting descriptive data from an optical signal transmitted by the source of the beacon or an optical signal source associated with the source of the beacon and presenting the extracted descriptive data.

In accordance with one aspect the presenting of the extracted descriptive data comprises augmenting the live scene with an augmented reality representation of the extracted descriptive data in conjunction with or as a replacement for the augmented reality representation of the beacon s angular positioning and identification data. The presenting of the extracted description data may occur on a user device with which the live scene is captured.

The method may further comprise pointing one or more optical receivers in a direction of the source of the beacon based on the angular position of the beacon. Moreover the method may comprise forwarding the extracted descriptive data to one or more applications that when executed cause one or more processors to display the extracted description data.

The one or more processors may comprise an additional user device other than a user device with which the live scene is captured. The method may further comprise forwarding the extracted descriptive data to one or more applications that when executed cause one or more processors to display a website associated with the source of the beacon. The extracted descriptive data may comprise a universal resource locator directing the one or more applications to the website wherein the one or more applications comprise a web browser. The extracted descriptive data may comprise advertising information associated with one or more objects of interest within a field of view of the captured live scene. The extracted descriptive data may comprise advertising information regarding an entity associated with at least one of the source of the beacon or the optical signal source.

In accordance with one embodiment a system comprises a camera adapted to capture a live scene and an optical beacon receiver adapted to detect the presence of a beacon determine an angular position of the beacon and extract identification data from the beacon indicative of a source of the beacon. The system further comprises one or more processors operatively connected to a non transitory computer readable medium having computer executable program code embodied thereon the computer executable program code when executed cause the one or more processors to augment the live scene with an augmented reality representation of the beacon s angular positioning and identification data. The system further comprises an optical signal receiver adapted to extract descriptive data from an optical signal transmitted by the source of the beacon or an optical signal source associated with the source of the beacon upon receiving a selection regarding the augmented reality representation. Additionally the computer executable program code when executed further causes the one or more processors to present the extracted descriptive data.

In presenting the extracted descriptive data the one or more processors may augment the live scene with an augmented reality representation of the extracted descriptive data in conjunction with or as a replacement for the augmented reality representation of the beacon s angular positioning and identification data. The presentation of the extracted description data can occur on a display operatively connected to the camera with which the live scene is captured.

Moreover the computer executable program code when executed further causes the one or more processors to forward the extracted descriptive data to one or more applications that when executed cause one or more processors to display the extracted description data. The one or more applications are executed on the system or a user device remotely located from the system.

The computer executable program code when executed further causes the one or more processors to forward the extracted descriptive data to one or more applications that when executed cause one or more processors to display a website associated with the source of the beacon. In accordance with some aspects the extracted descriptive data comprises a universal resource locator directing the one or more applications to the website the one or more applications comprising a web browser. In accordance with other aspects the descriptive data comprises advertising information associated with one or more objects of interest within a field of view of the captured live scene. In accordance with still other aspects the extracted descriptive data comprises advertising information regarding an entity associated with at least one of the source of the beacon or the optical signal source.

The optical beacon receiver and the optical signal receiver are implemented within a single optical receiver assembly.

In accordance with one embodiment a method comprises initializing on a device an application for displaying information extracted from a modulated optical beam by an optical receiver communicatively coupled to the device and displaying on a graphical user interface of the application a visual representation of the optical receiver s field of view FOV overlaid over a live display of a FOV of a video camera of the device wherein the displayed visual representation of the optical receiver s FOV is sized relative to the displayed FOV of the video camera. In implementations the device is a mobile device such as a smartphone or a head mounted display.

In one implementation of this method the optical receiver is an optical signal receiver. In this implementation the method further includes zooming the camera e.g. digitally or optically and in response to zooming the camera resizing the visual representation of the optical signal receiver s field of view. In further implementations the visual representation of the optical signal receiver s field of view is not resized when the camera is panned tilted or rolled.

In various implementations of this method the visual representation of the optical receiver s field of view comprises a geometric shape having boundaries. For example the geometric shape may be a polygon e.g. a rectangle or square or an ellipse e.g. a circle . In particular implementations the boundaries of the geometric shape are based on an area of an optical signal receiver s FOV that receives optical signals at a threshold signal to noise ratio SNR or a threshold bit rate.

In one implementation of this method the optical signal receiver is a component of an optical receiver assembly comprising the optical signal receiver and an optical beacon receiver. In such an implementation the FOV of the optical signal receiver may be less than a FOV of the optical beacon receiver.

In one implementation of this method the method further includes the step of activating the optical receiver and the camera in response to initializing the application for displaying information extracted from the modulated optical beam.

In one implementation of this method the method includes the additional steps of detecting an optical beacon within a field of view of an optical beacon receiver communicatively coupled to the mobile device extracting identification information from the received beacon and based on the extracted identification information rendering on the graphical user interface a visual representation of the beacon s source overlaid over the live display of the FOV of the camera. In yet further implementations the method may include the steps of estimating an angular position of the received beacon relative to the optical beacon receiver s field of view. In such implementations the visual representation of the beacon s source may be rendered based on the estimated angular position and the visual representation of the beacon s source visually may represent a location of the source relative to the live display of the FOV of the camera.

In one implementation of this method the method includes the additional steps of receiving data corresponding to user input selecting the visual representation of the beacon s source and in response to receiving the data determining if an optical signal transmitted by the beacon s source is within the optical signal receiver s FOV. If it is determined that the optical signal transmitted by the beacon s source is not within the optical signal receiver s FOV the method may include the additional step of displaying on the GUI a prompt to position the mobile device such that the visual representation of the optical signal receiver s FOV surrounds the visual representation of the beacon s source. Additionally if it is determined that the optical signal transmitted by the beacon s source is not within the optical signal receiver s FOV the method may include the additional step of using a tilt actuator to tilt the optical signal receiver in a direction such that the optical signal transmitted by the beacon s source falls within the optical signal receiver s FOV.

In one implementation of this method the method includes the additional steps of receiving at the optical signal receiver an optical signal transmitted by the beacon s source extracting information from the received optical signal and displaying the extracted information on the graphical user interface. The information extracted from the received optical signal may include at least one of video data audio data or textual data.

In one embodiment a non transitory computer readable medium may have instructions stored thereon that when executed by a processor causes a system to initialize an application for displaying information extracted from a modulated optical beam by an optical receiver communicatively coupled to a mobile device and display on a graphical user interface of the application a visual representation of the optical receiver s field of view FOV overlaid over a live display of a FOV of a video camera of the mobile device wherein the displayed visual representation of the optical receiver s FOV is sized relative to the displayed FOV of the video camera. In implementations of this embodiment the non transitory computer readable medium may be a component of a mobile device communicatively coupled to the optical receiver.

In one embodiment a system includes an optical receiver assembly and a mobile device communicatively coupled to the optical receiver assembly where the mobile device comprises a camera and the non transitory computer readable medium described in the previous paragraph. The optical receiver assembly may include an optical signal receiver configured to detect and receive an optical signal from an optical transmitter assembly and extract information from the received optical signal. The optical receiver assembly may be physically integrated into the mobile device or a case attached to the mobile device e.g. a smartphone case .

In one embodiment a method may be implemented for bidirectional communication in an optical narrowcasting system. In this embodiment the method includes receiving at an optical receiver assembly communicatively coupled to a mobile device a first modulated optical beam transmitted by an optical transmitter assembly of a source extracting information from the modulated optical beam displaying the extracted information on a graphical user interface of an application presented on the mobile device receiving data corresponding to user input at the graphical user interface selecting the displayed information in response to receiving the data corresponding to user input at the graphical user interface selecting the extracted descriptive data generating digital data to be transmitted by an optical transmitter assembly communicatively coupled to the mobile device to an optical receiver assembly of the source transferring the digital data to the optical transmitter assembly communicatively coupled to the mobile device and transmitting an optical beam modulated with the digital data from the optical transmitter assembly communicatively coupled to the mobile device.

In one implementation of this embodiment the method further includes the step of determining prior to transmitting the second modulated optical beam if the source s optical receiver assembly is within a signal path of an optical transmitter of the optical transmitter assembly communicatively coupled to the mobile device. In this implementation the method may further include displaying on the graphical user interface an augmented reality object corresponding to a transmitting emitting region covered by the optical transmitter displaying on the graphical user interface a visual representation of the source and displaying a prompt to position the mobile device such that the visual representation of the source is within the augmented reality object corresponding to the transmitting emitting region covered by the optical transmitter. In such an implementation the method may additionally include the step of tilting the optical transmitter assembly communicatively coupled to the mobile device such that the source s optical receiver assembly is within a signal path of the optical transmitter.

In one implementation of this embodiment the modulated optical beam is an optical beacon the information extracted from the modulated optical beam indicates that the source is an optical narrowcasting hotspot and the generated digital data is a request to access the hotspot. In another implementation of this embodiment the modulated optical beam is an optical signal. In this implementation the information extracted from the modulated optical beam may include information associated with a product offered for sale by the source and the generated digital data may be a request to conduct a transaction to purchase the product.

In one embodiment a system comprises an optical receiver assembly communicatively coupled to a mobile device the optical receiver assembly adapted to receive a first modulated optical beam transmitted by an optical transmitter assembly of a source and extract information from the modulated optical beam and a non transitory computer readable medium having instructions stored thereon that when executed by a processor causes the mobile device to display the extracted information on a graphical user interface receive data corresponding to user input at the graphical user interface selecting the displayed information in response to receiving the data corresponding to user input at the graphical user interface selecting the extracted descriptive data generating digital data to be transmitted by an optical transmitter assembly communicatively coupled to the mobile device to an optical receiver assembly of the source and transfer the digital data to an optical transmitter assembly communicatively coupled to the mobile device. The system may additionally include the optical transmitter assembly where the optical transmitter assembly is adapted to transmit an optical beam modulated with the digital data to an optical receiver assembly of the source. In one implementation of this system the optical receiver assembly and or the optical transmitter assembly is are integrated into a case attached to the mobile device.

In one implementation of this system the modulated optical beam is an optical beacon the information extracted from the optical beam indicates that the source is an optical narrowcasting hotspot and wherein the generated digital data is a request to access the hotspot.

In one embodiment a method implemented in an optical narrowcasting ad hoc network system comprises transmitting an optical beacon from a beacon transmitter of a first device where the optical beacon is modulated with information identifying the device as an optical narrowcasting hotspot receiving at an optical signal receiver of the first device an optical signal from a second device where the optical signal is modulated with information to be transmitted over a radio frequency network extracting the information from the received optical signal and transmitting the information over a radio frequency network using a radio frequency connection interface of the first device. In particular implementations of this embodiment the first device is an internet gateway and the second device is a mobile device.

In one implementation of this embodiment the method further comprises in response to transmitting the information over the radio frequency network receiving a response signal over the radio frequency network modulated with information modulating the information from the response signal onto an on optical signal and transmitting the optical signal to an optical signal receiver of the second device.

In one implementation of this embodiment the method further comprises receiving at an optical beacon receiver of the first device an optical beacon from the second device requesting access to the optical narrowcasting hotspot and permitting the second device to access the optical narrowcasting hotspot. The optical beacon may include a unique optical narrowcasting identification associated with the second device and the step of permitting the second device to access the optical narrowcasting hotspot may include a determination that the device is trusted based on the unique optical narrowcasting identification.

In accordance with one embodiment a signal enhanced media system configured to enhance captured media with optically narrowcast content may comprise an optical receiver assembly adapted to receive the optically narrowcast content extracted from one or more optical beams transmitted by one or more optical transmitter assemblies. The system may further comprise an enhanced media component. The enhanced media component may be adapted to receive at least one media representation of a real world scene and embed the optically narrowcast content within or as part of the at least one media representation to generate an enhanced media dataset.

The one or more optical beams may comprise an optical beacon including beacon information indicative of a presence or availability of additional or other information associated with a source of the optical beacon. The beacon information may further comprise information identifying the source of the optical beacon. In accordance with another aspect the beacon information may further comprise information regarding the source of the optical beacon. The one or more optical beams may comprise an optical signal including signal information comprising the additional or other information associated with the source of the optical beacon.

The enhanced media component may be adapted to embed two or more portions of the optically narrowcast content into two or more respective media representations. At least one media representation may comprise at least one of a photographic video or audio representation of the real world scene.

According to one aspect the enhanced media dataset may comprise the at least one of the photographic video or audio representations of the real world scene in combination with information regarding a horizontal and vertical position of each of the one or more optical transmitter assemblies. Each of the one or more optical transmitter assemblies may be detected in a field of view of the optical receiver assembly. In accordance with another aspect the enhanced media dataset may comprise the at least one of the photographic video or audio representations of the real world scene in combination with at least one of a timestamp or a geographical position of the optical receiver assembly associated at a time during which the optical receiver assembly received the optically narrowcast content.

The system may further comprise a communications interface adapted to at least one of store or transmit the enhanced media dataset to one or more user devices adapted to consume the enhanced media dataset in real time or non real time.

In accordance with another embodiment a media presentation system may comprise one or more physical processors and a memory having computer code being executed to cause the one or more physical processors to receive an enhanced media dataset detect existence of optically narrowcast content embedded within or as part of the enhanced media dataset extract some or all of the embedded optically narrowcast content from the enhanced media dataset and present some or all of the embedded optically narrowcast content with a presentation of some or all of a media representation portion of the enhanced media dataset.

The media representation portion of the enhanced media dataset may comprise at least one of a photographic video or audio representation of a real world scene captured in conjunction with at least one of beacon information or signal information comprising the embedded optically narrowcast content. According to one aspect the beacon information comprises information identifying a source entity from which the optically narrowcast content is transmitted. According to another aspect the signal information comprises information other than the identifying information that is associated with the source entity.

The embedded optically narrowcast content may be represented as one or more interactive graphical elements overlaid on the media representation portion of the enhanced media dataset. The presentation of some or all of the media representation portion of the enhanced media dataset is navigable to bring the one or more interactive graphical elements representing the embedded optically narrowcast content into view commensurate with a location of one or more optical transmitter assemblies from which the optically narrowcast content is transmitted. The presentation of some or all of the embedded optically narrowcast content with the presentation of some or all of the media representation portion of the enhanced media dataset may include a graphical user interface through which one or more options for filtering the embedded optically narrowcast content are presented.

In accordance with another embodiment a signal enhanced media system may comprise an optical receiver adapted to receive optically narrowcast content extracted from one or more optical beams transmitted by an optical transmitter. The system may further comprise a first user device operatively connected to the optical receiver. The first user device may be adapted to capture at least one media representation of a real world scene in which the one or more optical beams are detected and embed the optically narrowcast content within the at least one media representation. The system may comprise a second user device adapted to receive an enhanced media dataset comprising some or all of the embedded optically narrowcast content and some or all of the at least one media representation extract some or all of the embedded optically narrowcast content from the enhanced media dataset and present some or all of the embedded optically narrowcast content in conjunction with some or all of the at least one media representation. The second user device may be further adapted to at least one of download store or transmit some or all of the embedded optically narrowcast content to a third user device.

Other features and aspects of the disclosed method will become apparent from the following detailed description taken in conjunction with the accompanying drawings which illustrate by way of example the features in accordance with embodiments of the disclosure. The summary is not intended to limit the scope of the claimed disclosure which is defined solely by the claims attached hereto.

As used herein an optical narrowcasting system or ONS is a system that can transmit information from one or more locations to one or more other locations using one or more digitally modulated optical beams transmitted through one or more propagation media. Contemplated propagation media may include but are not limited to air water glass windows and the vacuum of space. An ONS may include one or more optical transmitter assemblies OTAs to transmit optical beams to one or more optical receiver assemblies ORAs .

As used herein an optical beam is a directed beam of electromagnetic radiation having wavelengths in a spectral region ranging from approximately 10 nm e.g. extreme ultraviolet UV radiation to approximately 10nm e.g. far infrared IR radiation . As used herein to refer to an optical beam the term directed beam can refer to energy e.g. light energy sent in a specific range of propagation directions but not in other directions. For example a laser may emit a narrow directed beam of light whereas the sun may be understood to emit undirected light that propagates outward in all possible directions.

As used herein an optical transmitter assembly or OTA is a device including electronics software and or firmware and one or more optical transmitters OTs . An OTA may be an element of an ONS. The OT s within an OTA can provide the functionality of at least one optical beacon transmitter OBT and or at least one optical signal transmitter OST . In some implementations a single OT may function as both an OBT and an OST. In other implementations the OBT s and OST s of an OTA can be separate devices. An OTA may also contain one or more tilt actuators allowing it to control the pointing direction s of the optical beam s output by its OT s . An OTA s electronics and associated software and or firmware may perform various useful functions such as providing an interface between the OTA and its user s or its users devices supplying timing pulses and electrical power to its OT s controlling the operation of the OT s e.g. turning them on and off setting their data transmission rate etc. transferring digital data to the OT s for them to output as one or more digitally modulated optical beams and controlling one or more tilt actuators to alter the pointing direction s of the output optical beam s .

As used herein an optical transmitter or OT is a device including one or more optical sources one or more beam forming optics and electronics with associated software and or firmware adapted to transmit optical beams. One or more OTs may form at least part of an OTA. The optical sources may be coherent e.g. lasers or incoherent e.g. light emitting diodes LEDs . The optical output of each optical source may be electronically modulated at a desired bit rate or at one of a user selectable range of bit rates to transmit digital data in the form of a series of one bits and zero bits. The optical source s produce optical radiation in a desired optical waveband. Each beam forming optic may collect flux emitted by one or more optical source s and utilize refraction reflection and or diffraction to concentrate it into a transmitted beam having a desired angular intensity distribution. In some cases the beam forming optic may also include one or more spectral filters to minimize the amount of flux transmitted outside of the desired waveband. Multiple OTs could in some implementations be used in a single OTA to increase the solid angle of the output beam and or to increase the output intensity in certain solid angular regions. The electronics and associated software and or firmware of an OT may perform the following functions receive and if necessary modify timing pulses and electrical power sent to it by the OTA of which it is a component receive and properly interpret various control signals sent to it from the OTA and receive from the OTA data in digital electronic form that it will then output in digital optical form.

As used herein an optical beacon transmitter or OBT is a type of OT that produces a beacon associated with an OTA. An optical beacon or beacon is a modulated optical beam containing information that allows an ORA to detect the presence of an OTA. An optical beacon makes a user or entity receiving optically transmitted information aware of the presence or availability of information transmitted by the OTA associated with the beacon. In addition to detecting the presence of the OTA a beacon produced by an OBT may also contain information allowing an optical receiver assembly ORA to identify the entity e.g. business organization private individual product landmark etc. and type i.e. category of entity e.g. restaurant department store movie theater etc. with which the OTA is associated. A beacon may also be used by an OBR to determine the angular position of the OTA. In some embodiments the angular position e.g. horizontal and or vertical angular position of the OTA can be determined based on information optically transmitted within or as part of the optical beacon. For example latitudinal longitudinal and latitudinal information indicative of the location of an OTA may be transmitted in a beacon. In some embodiments one or more measurements made by an OBR of the propagation direction of an optical beacon can be used by the OBR to derive calculate or otherwise determine an angular position of the OTA within the FOV of the OBR. As mentioned previously a single OT within an OTA may function as both an OBT and an OST or the OBT s and OST s within an OTA may be separate devices.

As used herein an optical signal transmitter or OST is a type of OT that produces an optical signal associated with an OTA. An optical signal is a modulated optical beam containing information other than information contained in an optical beacon which the operators of an OTA desire to transmit to optical receiver assemblies ORAs . The purpose of an OST is to transmit information to ORAs that have already detected the OTA of which the OST is a component. In some instances the ORAs may have also identified and determined the angular location of the OTA prior to receiving optical signals transmitted by the OTA. A single OT within an OTA may function as both an OBT and an OST or the OBT s and OST s within an OTA may be separate devices.

A modulated optical beam produced by an OTA may contain both optical beacons and optical signals. Alternatively a modulated optical beam may contain only one or more optical beacons and no optical signals or it may contain only one or more optical signals and no optical beacons. For example an OTA may simultaneously output two separate optical beams one being an optical beacon and another being an optical signal where the optical beacon has a different wavelength spectrum than the optical signal.

As used herein the term optical information generally refers to information extracted from a modulated optical beam or used to modulate an optical beam. Optical information may include identification data extracted from or contained in an optical beacon e.g. identifying a particular OTA and or source of the OTA and descriptive data extracted from or contained in an optical signal e.g. an advertisement or other message . This data may comprise machine readable and or human readable data such as text video audio metadata or other types of information.

As used herein an optical receiver assembly or ORA is a device including electronics software and or firmware and one or more optical receivers OR . The OR s within an ORA can provide the functionality of at least one optical beacon receiver OBR and or at least one optical signal receiver OSR . An ORA may be an element of an ONS. In some cases an ORA may also contain one or more tilt actuators allowing it to control the directions from which its OBR s and OSR s can receive modulated optical beams. An ORA can perform one or more of the following functions. It may detect the presence of beacons transmitted by OTAs. It may extract information from beacons such as the identities of the entities e.g. businesses organizations private individuals products landmarks etc. with which OTAs are associated. It may determine the angular positions of OTAs by sensing the direction of incidence of beacons or extracting positioning information therefrom. It may receive and or extract data from optical signals transmitted by OTAs. An ORA s electronics and associated software and or firmware perform various useful functions such as providing an interface between the ORA and its user s or its users devices supplying timing pulses and electrical power to its OBR s and OSR s controlling the operation of its OBR s and OSR s e.g. turning them on and off setting their data reception rate etc. receiving and transferring to users or to users devices information such as identifying information and angular position obtained by its OBR s regarding OTAs that have been detected receiving and transferring to users or to users devices data received from OTAs by its OSR s and controlling one or more tilt actuators to alter the pointing direction s of one or more OBRs and one or more OSRs.

As used herein an optical beacon receiver or OBR is a device adapted to receive an optical beacon that may make up at least part of an ORA. An OBR may detect the presence of one or more OTAs. An OBR may also identify the entities e.g. businesses organizations or private individuals with which OTAs are associated through e.g. information contained within an optical beacon as well as determine the angular positions of OTAs. As noted previously the angular positions of OTAs may be derived from measurement s of the propagation direction of a beacon and or determined from information contained within the beacon. An OBR may include for example one or more optical detectors or detector arrays one or more collection optics each including one or more optical components e.g. lenses reflectors and or diffractive optical elements and control electronics with associated software and or firmware . A spectral filter may be included in each collection optic to reduce to low levels the out of band flux incident on the detector s . The optical detectors are capable of detecting optical flux in the waveband and at the bit rates of beacons which the OBR is designed to receive. In some cases an OBR could share some or all of its detectors collection optics electronic hardware and software firmware with one or more OSRs within the ORA of which it is a part. The electronics and associated software and or firmware of an OBR perform at least the following functions providing the means to receive and if necessary modify timing pulses and electrical power sent to it by the ORA of which it is a part receiving and properly interpreting various control signals sent to it by the ORA and transferring to the ORA information e.g. identifying information and angular position it has obtained regarding beacons it has detected and from which it has received information.

As used herein an optical signal receiver or OSR is a device adapted to receive optical signals and to convert the data they contain into digital or electronic form. An OSR may include one or more optical detectors or detector arrays one or more collection optics and control electronics with associated software and or firmware . The optical detectors are capable of detecting optical flux in the waveband and at the bit rates of optical signals the OSR is designed to receive. Each collection optic can collect incident in band flux over its entrance pupil and within its specified field of view FOV and utilizes refraction reflection and or diffraction to concentrate it onto one or more of the optical detectors. A spectral filter may also be included in the optical train to reduce to low levels the out of band flux incident on the detectors. In some cases an OSR may share some or all of its detectors collection optics electronic hardware and software firmware with one or more OBRs within the ORA of which it is a part. The electronics and associated software and or firmware of an OSR can perform one or more of the following functions receive and if necessary modify timing pulses and electrical power sent to it by the ORA of which it is a part receive and properly interpret various control signals sent to it by the ORA and transfer to the ORA digital data extracted from optical signals it has received.

Disclosed herein are systems and methods of communication that utilize non radio wave based communications channels. That is communications may be achieved through the transmission and or receipt of information in the form of modulated optical beams. In this way a user or entity such as a business wishing to transmit information e.g. advertising information may do so by utilizing an OTA that can convert a digital representation of the information into one or more modulated optical beams for transmission. It should be noted that the information transmitted may include information disseminated by businesses and other organizations including government agencies for example and by individuals. Personal content such as messages photos and videos shared by individuals within a social media context are other examples of information that may be transmitted.

A characteristic of the optical communications methods and systems disclosed herein is that a user of an ORA designed to receive information sent by one or more OTAs may not know ahead of time what specific optical transmitters will be sending information of interest to him her or where they will be located. For this reason one aspect of various embodiments is that an ORA may be equipped with one or more components adapted to detect the presence of optically transmitted information prior to receiving that information.

A user wishing to receive the information transmitted in the form of one or more modulated optical beams may utilize an ORA implemented within or in conjunction with a user device such as a smartphone to scan for and detect the presence of available optical beacons extract the identifying information contained in the beacons and display the identifying information through e.g. an augmented reality AR interface. Upon selecting a specific OTA using information extracted from its associated beacon and displayed on the AR interface the user if he she so desires may further obtain some or all of the information contained within or represented by the optical signal associated with said OTA through the AR interface or other information presentation mechanism such as a media player e.g. advertising information in the form of digital video .

Advantages can be realized by using such an optical communications system referred to herein as an optical narrowcasting system. For example optical narrowcasting systems such as those disclosed herein may have long range high bandwidth capabilities avoid regulatory limitations optical transmissions are thus far unregulated by the Federal Communications Commission FCC or any other regulatory body . For example optical narrowcasting systems can provide users with the ability to utilize existing hardware and or software technologies that are enhanced by extremely compact non imaging optical components that have low power needs and are energy efficient. For example the operable range of an optical narrowcasting system can be approximately 400 m e.g. during the day to approximately 1200 m e.g. during nighttime compared to that of WiFi that is effective within approximately 50 m. Moreover optical narrowcasting systems are able to direct information in one or more desired directions using e.g. beamforming. This can be accomplished through the use of the aforementioned non imaging optics whereas directionality using WiFi is not practical given the need of WiFi routers to use expensive and bulky directional antennas. Regarding efficiency optical narrowcasting networks can be up to 300 times more energy efficient than WiFi networks. Further still the security that can be achieved in an optical narrowcasting network is much higher than that possible in a WiFi network due to the directionality of the transmitted optical beams.

Optical transmitter assembly may receive modulate convert and or otherwise process digital information into an optical format for transmission as an optical beam to be received by optical receiver assembly . The digital information may be received by optical transmitter assembly from one or more sources e.g. source device . Source device may be a computer tablet smartphone data server or other information source.

Optical transmitter assembly may be installed on various fixed structures such as buildings billboards road signs and the like. It may also be installed on vehicles such as automobiles and buses. It should be understood that these installations are merely examples and not limiting in any way. Optical transmitter assembly may also be incorporated into portable and or handheld devices such as smartphones tablet computers and head mounted displays or it may be incorporated into devices intended to be attached to or kept in close proximity to portable and or handheld devices such as smartphone cases and cases for tablet computers. It should be understood that the devices mentioned here are merely examples and not limiting in any way. Moreover although optical transmitter assembly is illustrated as being associated with a single source device optical transmitter assembly in some embodiments may be associated with and or receive digital information from additional source devices.

Optical receiver assembly may be installed on various fixed structures such as buildings billboards road signs and the like. It may also be installed on vehicles such as automobiles and buses. It should be understood that these installations are merely examples and not limiting in any way. Optical receiver assembly may also be incorporated into portable and or handheld devices such as smartphones tablet computers and head mounted displays or it may be incorporated into devices intended to be attached to or kept in close proximity to portable and or handheld devices such as smartphone cases and cases for tablet computers. It should be understood that the devices mentioned here are merely examples and not limiting in any way. Moreover although optical receiver assembly is illustrated as being associated with a single user device optical receiver assembly in some embodiments may be associated with controlled by and or share digital information with additional user devices.

Optical receiver assembly may be an optical narrowcasting element adapted to receive one or more optical beams and can include certain electronics and or circuitry software and or firmware and one or more optical receivers which will be described in detail below with reference to . Optical receiver assembly may receive an optical beam and demodulate convert and or otherwise process the optical beam back into digital information. Optical receiver assembly may transmit or forward the digital information to a receiving device such as user device . User device may be a computer tablet smartphone network server or other device capable of receiving and or utilizing the digital information or data. Optical receiver assembly may be integrated with user device or optical receiver assembly may be operatively attached to user device . It should be noted that optical receiver assembly need not be associated with only a single user device. In some embodiments optical receiver assembly may transmit or forward received digital information to more than one user device e.g. via broadcasting multicasting etc.

It should be noted that although depicts one way communications between optical transmitter assembly and optical receiver assembly an optical narrowcasting system may also involve two way communications. For example source device and user device may each have respective optical transmitter and optical receiver assemblies integrated therein or operatively attached thereto. Optical beams may in some cases be in the visible or near IR bands. Optical beams may be produced using either incoherent sources e.g. light emitting diodes LEDs lasers or other appropriate light sources. Depending on the application different angular beam widths can be used. Optical beams may either propagate from an optical transmitter assembly directly to an optical receiver assembly along an unobstructed line of sight LOS or optical beams may propagate along an indirect non LOS path utilizing diffuse reflections from ceilings walls or other structures for example or from suspensions of small particles e.g. airborne dust or liquid droplets e.g. clouds or fog . As illustrated in two or more identical modular transmitter optics units may be used to produce combined beams having increased horizontal and or vertical angular beam widths and or increased intensity within certain solid angular regions.

An ad hoc network e.g. a communications network established directly between two or more computers or other devices need not rely on a base station or other centralized access point. Such communications networks are generally established on a temporary basis between a small number of participants in close physical proximity for a specific common purpose such as sharing a set of documents being written by the participants or playing multi player computer games. In some embodiments two or more user devices one embodiment of which can be user device may each comprise optical transmitter assemblies and optical receiver assemblies embodiments of which can be optical transmitter assembly and optical receiver assembly of . The two or more user devices may be used to transmit and receive data via optical beams thereby creating an ad hoc optical narrowcasting network.

Optical transmitter assembly may include control electronics . Control electronics may receive the above noted values that have been input by the user and utilized to control operation of optical transmitter assembly . For example control electronics may supply timing pulses and electrical power to the optical transmitters control the operation of one or more optical transmitters e.g. optical beacon transmitter and optical signal transmitter for example by turning them on and off setting their data transmission rate etc. . Control electronics may effectuate the transfer of digital data to one or more of the optical transmitters to be output as one or more digitally modulated optical beams.

In some embodiments optical transmitter assembly may also comprise one or more tilt actuators such as microelectromechanical systems MEMS actuators that allow optical transmitter assembly to control direction s in which one or more optical beams may be pointed upon being output. For example optical beacon transmitter optical signal transmitter and or combined optical transmitter may be mounted or otherwise incorporated into optical transmitter assembly via a connection that allows for the one or more tilt actuators to move the transmitters. Control electronics may control operation of the one or more tilt actuators.

Optical transmitter assembly may include one or more optical transmitters adapted to process digital information received from e.g. source device for transmission as an optical beam. As illustrated in some embodiments may have an optical beacon transmitter and an optical signal transmitter . Optical beacon transmitter may be adapted to transmit optical beacons that are specifically intended to be received by optical beacon receivers. Optical beacons allow the presence of optical transmitter assembly to be detected. Optical beacons may allow the source e.g. user or entity associated with source device source device and or optical transmitter assembly to be identified. Optical beacons may also allow the horizontal and or vertical angular position of the optical transmitter assembly within the FOV of an OBR at a different location to be determined. This can be accomplished for example by an OBR utilizing a lens such as an imaging lens to concentrate i.e. focus optical beacons incident on the lens from different directions onto correspondingly different locations on a detector array located in the focal plane of the lens. The location in the detector array at which an optical beacon is currently focused can be a measure of the current angular position relative to the OBR s FOV of the OTA from which the optical beacon is transmitted. That is optical power in the form of an optical beacon may be currently primarily or entirely concentrated by the OBR s lens onto a detector located at a particular row and column of the detector array used in the OBR. The OBR may be a camera that is sensitive to the waveband of the optical beacon. The row and column of the detector array at which the optical beacon is concentrated can be a current estimated location within the FOV of the OBR of the OTA that sent the beacon. OTA locations in this form can be mapped to analogous locations within the FOV of an associated visible light camera such as the forward looking camera of a smartphone. This allows the locations of OTAs to be represented on a user s real time video display e.g. that of the smartphone . An icon representing the OTA can then for example be overlaid at this location in the real time video display. It should be noted that the horizontal and vertical angular location of an OTA can in general be a function of time. For example if an OTA moves due to it being mounted on a vehicle that moves its location within the FOV of an OBR may change. Similarly if the ORA moves to a new location and or is tilted the OTA location within the FOV of the OBR may also change even though the OTA has stayed in the same physical location. 

Optical signal transmitter may be adapted to transmit optical signals specifically intended to be received by optical signal receivers. Optical signals transmit information from optical transmitter assembly to optical receiver assembly where optical transmitter assembly and or an entity associated with it may have already been detected identified and whose horizontal and or vertical angular position relative to the FOV of an OBR has already been determined. Moreover two or more optical transmitters may be implemented in optical transmitter assembly to increase the solid angle of an output optical beam and or to increase output intensity in certain solid angular regions.

As also illustrated in an alternative may be to utilize a combined optical transmitter that realizes the functionality of both optical beacon transmitter and optical signal transmitter . For example combined optical transmitter may comprise a single optical transmitter adapted to transmit both optical beacons and optical signals. That is combined optical transmitter may be designed to transmit an optical beam intended to be received both by optical beacon receivers and by optical signal receivers.

An optical transmitter e.g. optical beacon transmitter optical signal transmitter and or combined optical transmitter may include one or more optical sources one or more beam forming optics as well as electronics with associated software and or firmware see . The optical sources may be coherent e.g. lasers or incoherent e.g. LEDs . The optical output of each optical source may be electronically modulated at a desired bit rate or at one of a user selectable range of bit rates to transmit digital information in the form of a series of one bits and zero bits. The optical source s may produce optical radiation in a desired optical waveband. Each beam forming optic can collect flux emitted by the one or more optical sources and utilizes refraction reflection and or diffraction to concentrate it into a transmitted beam having a desired angular intensity distribution. In some cases a beam forming optic may include one or more spectral filters to minimize the amount of flux transmitted outside of a desired waveband.

The electronics and associated software and or firmware of an optical transmitter e.g. optical beacon transmitter optical signal transmitter and or combined optical transmitter may perform one or more of the following functions receiving and if necessary modifying timing pulses and or electrical power received from optical transmitter assembly receiving and properly interpreting various control signals sent to it from optical transmitter assembly and receiving from e.g. data interface by way of control electronics information or data in digital form that it will then output in digital optical form vis vis an optical beam. It should be noted that in some embodiments digital information or data may be received directly from data interface A.

In some embodiments similar to optical transmitter assembly optical receiver assembly may include one or more tilt actuators allowing optical receiver assembly to control the direction s from which its optical beacon receiver s and or optical signal receiver s may receive optical beams transmitted by one or more optical transmitter assemblies e.g. optical transmitter assembly .

The purpose of optical receiver assembly as alluded to previously may be to detect the presence of and or receive data in the form of optical beacons and or optical signals transmitted by optical transmitter assembly . For example optical receiver assembly may detect the presence of optical transmitter assemblies by detecting optical beacons sent by them extract identifying information from optical beacons regarding e.g. entities associated with the optical transmitters that sent the optical beacons determining horizontal and or vertical angular positions of optical transmitter assemblies by sensing the direction of incidence of the optical beacons and receiving information or data in the form of optical signals.

Optical receiver assembly may comprise a data interface that provides an interface between the optical receiver assembly and one or more users and or user devices e.g. user device . Data interface may be responsible for receiving and transferring to users or to users devices e.g. user device information such as identifying information and horizontal and or vertical angular positions obtained by optical beacon receiver regarding detected optical beacons. Data interface may be responsible for receiving and transferring to users or to users devices e.g. user device data received via an optical signal by optical signal receiver for example. Optical receiver assembly may be interfaced with user device by way of a wired or wireless connection via data interface . Software resident on user device may be utilized by a user to operate optical receiver assembly . Additionally the user may be able to specify the range of bit rates for signals to be received error correction methods to be used and or various other receiver operating parameters using user device where the operating parameters may be transmitted to optical receiver assembly via data interface

Optical receiver assembly may comprise control electronics . Control electronics may supply timing pulses and electrical power to optical beacon receiver optical signal receiver or alternatively to combined optical receiver . Control electronics may control the operation of optical beacon receiver optical signal receiver or alternatively combined optical receiver e.g. turning them on and off setting the data output format etc. . Data interface may control the one or more tilt actuators that can be used to alter the direction s in which of one or more optical beacon receivers and or one or more optical signal receivers may be pointed.

Optical beacon receiver and or combined optical receiver may be adapted to detect the presence of one or more transmitted optical beams distinguishing them from incident in band radiation produced by radiation sources other than optical transmitters of an optical narrowcasting system e.g. natural and artificial illumination sources . Optical beacon receiver and or combined optical receiver may be configured to determine a horizontal and vertical angular position of one or more transmitted optical beams within its field of view FOV . Optical beacon receiver and or combined optical receiver may receive identifying information from one or more optical transmitter assemblies e.g. optical transmitter assembly whose optical beacons it has detected and received. For example an optical transmitter assembly operated by a restaurant may transmit an optical beacon containing the digitally encoded name of the restaurant and or type of restaurant in a format intended to be received by optical beacon receiver and or combined optical receiver

Optical beacon receiver and or combined optical receiver may include one or more optical detectors or detector arrays one or more collection optics each including one or more optical components e.g. lenses reflectors and or diffractive optical elements as well as its own control electronics with associated software and or firmware . A spectral filter may be included in each collection optic to increase communication range by reducing to low levels the out of band flux incident on the detector s . Optical beacon receiver and or combined optical receiver may be capable of detecting optical flux in the waveband and at the bit rates used by optical transmitters to transmit optical beacons it is designed to detect. The component parts of optical beacon receiver and or combined optical receiver are described in greater detail with respect to .

In some cases an optical beacon receiver may share some or all of its detectors collection optics electronic hardware and software firmware with one or more optical signal receivers an embodiment of which may be combined optical receiver . The electronics and associated software and or firmware of optical beacon receiver and or combined optical receiver can perform at least one or more of the following functions receive and if necessary modify timing pulses and electrical power sent to it by optical receiver assembly receive and properly interpret various control signals sent to it by optical receiver assembly and transfer to optical receiver assembly information e.g. identifying information and angular position it has obtained regarding optical beacons it has detected.

Optical signal receiver and or combined optical receiver may receive optical signals from one or more optical transmitter assemblies e.g. optical transmitter assembly . Optical signal receiver and or combined optical receiver may convert the optically formatted digital data into digital data in electronic form. Similar to optical beacon receiver optical signal receiver and or combined optical receiver may include one or more optical detectors or detector arrays one or more collection optics and control electronics with associated software and or firmware . In the case of combined optical receiver the component parts of optical beacon receiver may be adapted to also operate as an optical signal receiver. The optical detectors can detect optical flux in the waveband and at the bit rates used by optical transmitters to transmit optical signals and or optical beacons it is designed to receive. Each collection optic may collect incident in band flux over its entrance pupil and within its specified FOV and utilize refraction reflection and or diffraction to concentrate it onto one or more of the optical detectors. A spectral filter may also be included in each receiver optic to increase communication range by reducing the out of band flux incident on the detectors to lower levels.

It should be noted that one or more of the aforementioned optics and or detectors or detector arrays that in part make up optical beacon receiver optical signal receiver and or combined optical receiver may be custom manufactured and or commercially available. For example one or more refractive optics may be customized with respect to one or more optical characteristics or properties such that its operation may be optimized for use in optical receiver assembly . For example one or more optical detectors or detector arrays may be commercially available near IR detectors or detector arrays.

The electronics and associated software and or firmware of optical signal receiver and or combined optical receiver can perform one or more of the following functions receive and if necessary modify timing pulses and electrical power sent by the optical receiver assembly receive and properly interpret various control signals sent to it by optical receiver assembly and transfer digital data received from one or more optical transmitters e.g. optical signal transmitter and or combined optical transmitter to optical receiver assembly . In some embodiments the electronics and associated software and or firmware may be customized to provide appropriate electrical power to operate the optical detectors. Moreover it should be noted that electronics hardware and or software may continuously monitor the output of the optical detectors determining when an output therefrom may represent a signal sent by an optical transmitter as opposed to for example flux received from artificial or manmade illumination sources.

Once an optical beacon has been detected optical receiver assembly may receive a related optical signal and store it as a data file in its memory. For example optical receiver assembly may buffer its detector outputs using one or more memory units or memory partitions to permit at least a portion of a given optical signal to be received prior to it being recognized as an actual optical signal. Alternatively optical transmitter assembly may transmit an optical signal that contains at its beginning a short alert pulse sequence. This alert pulse sequence may inform optical receiver assembly that transmission of an optical signal dataset has begun thereby allowing it to store the entire dataset in its memory without the need for buffering. That is optical beacon transmitter of optical transmitter assembly may transmit an optical beacon followed by an optical signal that begins with an alert pulse sequence. These operations may be continuously repeated by optical transmitter assembly . In some embodiments each transmitted optical beacon may end with an alert pulse sequence rather than having an alert pulse sequence be included at the beginning of each transmitted optical signal.

In some embodiments optical narrowcasting system elements such as optical receiver assemblies may be integrated into a device e.g. user device . That is user device may have resident optical receiver functionality. Alternatively optical receiver assemblies may be operatively and communicatively connected to user device . In this case an optical receiver assembly may be added to user device as an attachment or enhancement. The same can be true for optical transmitter assemblies although in some cases optical transmitter assemblies may be stand alone elements that are fixed at a particular location.

As alluded to previously a user may utilize a device to interact with an optical receiver assembly to input operating parameters receive transmitted data control the optical receiver assembly etc. The software software applications may be utilized by the user to manage messages received optically. In addition if the user is a subscriber of a social media service the controlling software may allow the user to access all of the capabilities of that service such as posting optically received messages images videos or other information on a social media page viewing and responding to posts on other users pages sharing posts etc. in the usual manner in which such tasks are performed within the context of social media services.

To that end illustrates that user device case may also include one or more communications elements that allow user device and optical receiver assembly to communicate and or interact. For example as described above user device may be utilized by a user to input operating parameters for optical receiver assembly etc. As illustrated in one such communications element may be a Bluetooth transceiver an NFC transceiver or other communications element. If needed a power supply e.g. a compact battery an energy harvesting sensor or other appropriate power source may be provided to energize communications element . Here communications element and power supply may embedded in or located on the device facing side of case for aesthetics and or to gain closer operating proximity to user device . It should be noted that power supply may also provide power to optical receiver assembly or optical receiver assembly may have its own power source that can be used to power communications element . In some embodiments optical receiver assembly and or communications element may be integrated into a single unit or device that may be attached to an input output port such as a micro USB or Lightning port of user device .

In the case of user device a user may control optical receiver assembly and or perform the above noted functions and or interactions via a hardwired connection between optical receiver assembly and one or more processors memory units and or other applicable components of user device which may be an embodiment of a computing component illustrated in .

Optical receiver assembly may include an optical beacon receiver and an optical signal receiver as well as any electronics and or software and or firmware e.g. the aforementioned control electronics data interface etc. utilized in operating optical receiver assembly and or communicating with e.g. media and or information systems resident in a vehicle such as a vehicle s navigation system media system heads up display etc. It should be noted that the electronics and software firmware are not visible in the frontal view depicted in but are nevertheless present in optical receiver assembly and or in an associated component s . In some embodiments optical beacon receiver and optical signal receiver may share some or all of their optical components and optical detectors or detector arrays.

In some embodiments unmodified user devices may be utilized in an optical narrowcasting system. For example an existing camera of user device may be utilized as an optical receiver assembly. As another example software may be used to generate a modulated optical beam comprising optical beacons and or optical signals by modulating the output from one or more LEDs designed for use as photographic flash units e.g. LED of user device .

In some embodiments optical receiver assemblies and or may incorporate high bit rate near IR optical detectors. High bit rate optical detectors can receive data at higher bit rates than may be possible using existing hardware of a user device e.g. camera

Referring back to various operations may be performed by an optical receiver assembly to detect the presence of optical beacons determine the angular position of optical beacons receive identifying information from optical beacons and ultimately receive information transmitted via an optical signal. From a user s perspective interactions with an optical narrowcasting system aside from e.g. controlling the operation of an optical receiver assembly can involve selecting visual representations of sources of one or more optical beacons that have been detected and receiving and or interacting with information received from one or more optical signals.

In some embodiments augmented reality functionality resident in or available through a user device e.g. user device see may be utilized to facilitate the above noted user interactions with one or more aspects of optical narrowcasting system . illustrates a user device which can be one embodiment of user device that is operatively and or communicatively connected to an optical receiver assembly which can be one embodiment of optical receiver assembly .

User device may comprise an augmented reality component one or more cameras a display which may be a touchscreen or non touchscreen display one or more speakers and or one more sensors . User device may in part embody an augmented reality device that is capable of displaying a real time view of a physical real world environment while altering elements within the displayed view of the environment. As such unlike a virtual reality device which displays a view of an entirely computer generated world an augmented reality device displays a view of the real world but augments e.g. adds or modifies elements using computer graphics technology. Such an augmented reality device may include and or be communicatively coupled to a camera device or multiple camera devices used to capture a view of the real world environment and may further include computer software and or hardware configured to augment elements of the captured scene. For example and as will be described in greater detail herein an augmented reality device could capture a series of images or a scene representative of a user s view of a street city or other location modify the series of images so that detected optical beacons appear as overlaid selectable items or icons in real time to a user. As such the user can be presented with an augmented view of the physical real world environment in which the user is located.

The one or more cameras may include cameras for capturing the visual scene. The one or more cameras may be an existing camera s of user device which may be for example a smartphone. As used herein a visual scene refers to one or more views of the real world environment in which user device is being used and in which one or more optical beacons and or optical signals are being transmitted in an optical narrowcasting system .

For example video imagery captured by one or more cameras and presented on display may be a live feed of an urban scene viewed from the perspective of a user who is utilizing user device to explore a particular city. An icon representative of an optical beacon detected by optical receiver assembly may be overlaid on the scene commensurate with the location of a source of the optical beacon. As previously discussed optical beacons may be transmitted by optical transmitter assemblies and optical receiver assembly may detect the optical beacon and extract identifying information therefrom. For example the overlaid icon may be representative of a hotel in the line of sight of the user that is transmitting descriptive or advertising information. There may be accompanying text that indicate the name and location of the source of the optical beacon e.g. the name and address of the hotel.

One example of one or more sensors may be an accelerometer capable of measuring the physical acceleration of user device e.g. when manipulated by the viewer as the user scans the urban scene to obtain information about one or more businesses points of interest etc. . User device may use the accelerometer to determine when the position of user device is changing for example which could indicate that the position of user device is changing relative to one or more transmitted optical beacons and or the scene itself. Augmented reality component may also on its own or with assistance from the accelerometer determine the positioning of an optical beacon relative to user device . It should be noted that other sensors such as GPS receivers compasses gyroscopes and or other sensors may be utilized to more accurately characterize or further enhance one or more aspects of an augmented reality experience provided by augmented reality component

Augmented reality component may control aspects of presenting the augmented reality view of the urban scene on display such as how optical beacon derived information may be presented e.g. via static icons animated elements. Augmented reality component may control the incorporation of position or location aiding cues or visuals as well as the presentation of information extracted from one or more optical signals associated with the optical beacons reacting to user inputs and or selections among other aspects.

For example information received by an optical beacon receiver of optical receiver assembly may be cached after it has been received. Caching may occur immediately after receipt. Icons markers used to represent detected optical beacons can be located in the augmented reality visual scene such that the location of each of the icons markers may coincide with the corresponding optical transmitter assemblies actual location within one or more cameras s FOV. The icons markers may stay in their correct locations as one or more cameras is zoomed panned or otherwise moved resulting in a location accurate augmented reality experience.

For example a user may select an icon representative of a particular optical beacon by touching or otherwise actuating the icon and as described above information regarding the source of the optical beacon may be presented e.g. via a pop up window. It should be noted that touching different areas of the pop up window may bring up different types of additional information regarding the source of the optical beacon. In some embodiments the additional information may be considered identifying information associated with the source of the optical beacon that can extracted from the optical beacon. In some embodiments the additional information may be information that has been extracted from an optical signal transmitted by the same source as that of the optical beacon or a related optical signal source. For example the additional information may comprise advertising multimedia that can be presented to the user via display and or the one or more speakers

In some embodiments one or more boxes or other representative graphic overlaid on the display of live imagery from the camera s may be used in an augmented reality experience where the size and position of each of the boxes can represent the size and position of an FOV associated or commensurate with each optical signal receiver of optical receiver assembly . A user may take advantage of such FOV representations by e.g. tilting user device such that an icon marker representing a detected optical beacon may be moved within one of the FOV representative boxes. The user may select the icon marker to initiate optical receiver assembly s receipt of one or more optical signals corresponding to the detected optical beacon.

The augmented reality experience comprising at least the augmented reality scene which include one or more selectable representations and or associated information of one or more detected optical beacons and or signals may be thought of an optical narrowcasting graphical user interface GUI .

In some embodiments augmented reality component may permit recording of the augmented reality scene and embedding any optical beacon extracted information angular positioning information as well as optical signal extracted information in the resulting media file. If desired the user may disseminate the recorded scene via e.g. social media outlets to be accessed by others. This embedding technique can allow optically transmitted information to be accessed in a non real time manner not only by the user e.g. at a later time but by social media subscribers or others e.g. on social media sites which may provide an enhanced social media experience for social media subscribers and may significantly increase the number of viewers of optically narrowcast information e.g. advertisements as well as provide new opportunities for social media services to generate online advertising revenue.

At operation optical receiver assembly may detect the presence of an optical beacon that can be transmitted by an optical transmitter assembly of an optical narrowcasting system. As previously discussed an optical beacon may be an optical beam comprising information identifying a source of the optical beacon.

At operation the horizontal and vertical angular position of the optical beacon is determined by measuring the propagation direction of the optical beacon relative to the FOV of one or more optical beacon receivers that are part of the optical receiver assembly . Because a plurality of optical beacons and or optical signals may be transmitted within an optical narrowcasting system the angular position of an optical beacon transmission may be utilized to point or focus one or more optical signal receivers of optical receiver assembly in the direction of a source from where the optical beam and an associated optical signal may originate. In addition knowledge of angular positions of optical beacons may be useful in helping the user determine the locations of and or navigate to optical transmitter assemblies from which optical beacons have been received.

At operation the identification information may be extracted from the optical beacon the identification information being indicative of or otherwise identifying the source of the optical beacon. As noted previously the source of the optical beacon may be an optical transmitter assembly a source device and or a user or entity utilizing the source device to transmit optical beams via the optical transmitter assembly.

At operation the live scene captured at operation may be augmented with an augmented reality representation of the beacon s position and identification data may be presented. As discussed angular positioning and identifying information may be obtained from or in relation to an optical beacon and presented by augmented reality component alone or in accordance with information obtained by one or more sensors . The augmented reality representation may include one or more graphical representations of at least the identifying information as well as representations of the positions of received optical beacons e.g. by utilizing symbols or icons overlaid on the displayed live camera imagery at the locations of optical beacons relative to that imagery . The augmented reality representation may be presented on display

At operation one or more selections regarding the augmented reality representation may be received. A user of user device may utilize display if for example display is a touchscreen or some other input device or mechanism to select the augmented reality representation. There may be multiple augmented reality representations presented on display and the user may select one that is of interest.

At operation descriptive data or information from an optical signal sent by the source of the optical beacon or by an optical signal source associated with the source of the optical beacon may be extracted. Again the optical signal source and the beacon source may be one in the same e.g. a source device or optical transmitter assembly or alternatively a user or entity utilizing the source device to transmit optical beams via the optical transmitter assembly.

At operation the extracted descriptive data may be presented to the user. In some embodiments the extracted descriptive data may be presented in a manner that further augments the live scene or augmented reality experience. In some embodiments the extracted descriptive data may be presented in or via another application or using other software such as a media player a web browser etc. In some embodiments the extracted descriptive data may be a universal resource locator URL that can be used to direct a web browser to display a particular webpage or website.

It should be noted that the example applications and use case scenarios described herein are not limiting and that an optical narrowcasting system may be utilized in many other applications or scenarios. For example an optical narrowcasting system may be used to enhance merchandise displays in stores or store windows where information regarding one or more products for sale may be presented to consumers through an augmented reality experience that leverages the information exchange made possible by an optical narrowcasting system. For example the optical narrowcasting system may be used to optically transmit not only product information but other information such as store hours and or other information of interest to potential customers. Billboards and other locations where out of home advertising is utilized may leverage optical narrowcasting to make visual aspects of the advertising more appealing and or viewable from farther away while also providing much more information than can currently be provided via e.g. a billboard image text.

New social media sites and or applications may be based on the sharing of content obtained via optical narrowcasting and if desired generating income though online ads appearing on these sites and applications. For example a social media application may allow individuals to use smartphones and other portable devices to create and share videos and photos containing embedded optically transmitted content.

In various embodiments optical narrowcasting may be considered highly localized in nature where the term localized can refers to the ability to transmit data from one location to another with a sufficiently small path length to prevent excessive bit errors. This characteristic can be leveraged in a social media context to obtain information that might otherwise be difficult or impossible to obtain regarding the location of people sending the information. For example one or more optical receiver assemblies may be mounted in the ceiling of a store to collect customer feedback. The optical receiver assemblies respective FOVs can be designed to only pick up information optically transmitted by people actually in the store. In addition optical information does not pass through walls floors or ceilings as WiFi signals may often do. Using an array of optical receiver assemblies detailed information about where people are within the store could also be obtained. This could be used to provide accurate navigation within the store with a search feature to help people locate specific products they re interested in.

The localized nature of the optical narrowcasting may also be used to motivate people to visit a particular geographic location e.g. by encouraging people to transmit contact information to an optical receiver assembly found in a store for example using an optical transmitter assembly controlled by a social media application on a user device. Optical narrowcasting may provide superior localization relative to what could be achieved using WiFi or built in location sensors. A network of optical receiver assemblies may be created at certain locales allowing users to share information about the surrounding area share relevant text photos videos etc.

Security privacy and or anonymity can be achieved through the use of an optical narrowcasting system. Unlike e.g. WiFi networks that require users to log into the network in order to obtain service a user may receive an optical beam without disclosing any sensitive information or any information for that matter . Moreover the optical beam transmitted by an optical transmitter assembly can be made quite narrow if desired to limit the receipt of the optical beam to only those optical receiver assemblies in line with the narrow width of the optical beam.

An appealing characteristic of optical narrowcasting is that the transmittal of information is unobtrusive indeed invisible. That is only people that are interested in obtaining optically transmitted information can see e.g. via an augmented reality experience the information.

In various embodiments the OTA is a device including electronics software and or firmware and one or more optical transmitters OTs described herein that transmit optical beacons and or optical signals as part of an optical narrowcasting system ONS . The OTA may be capable of long communication range providing sufficient information at long distances for streaming video with low correctable error rates. In one example the modulated optical beams provided by the OTA may be received by an ORA described herein. The ORA may include or be attached to a digital computing device such as a smartphone media tablet laptop camera game device wearable device e.g. smartwatch or the like.

The OTA may generate and transmit optical beacons and or optical signals in the visible near infrared IR or other optical bands produced using incoherent optical sources e.g. LEDs coherent optical sources e.g. lasers or the like. An optical beam is a beam of electromagnetic waves in the spectral region from the extreme ultraviolet UV to the far IR which may include wavelengths in the range of 10 to 10nm. It will be appreciated that the OTA may generate and transmit optical beams at any wavelength or range of wavelengths in the aforementioned spectral region. For example the OTA may generate and transmit optical signals in the visible or near infrared IR bands.

The OTA may generate optical beam s that transmit information to another location through air water transparent solids e.g. glass windows and or space i.e. a vacuum . The propagation path of a beam transmitted by an optical transmitter may be direct i.e. line of sight or indirect. In an example of an indirect path the beam may reflect and or scatter off of one or more liquid and or solid objects before being received by an ORA.

In various embodiments a single OTA may produce optical beams having different intensity distributions as a function of horizontal and vertical angular coordinates. In some embodiments two or more different OTAs may each produce two or more different optical beams having different intensity distributions.

The OTA s electronics and associated software and or firmware perform various useful functions such as but not limited to providing an interface between the OTA and one or more of its user s or users computing devices supplying timing pulses and electrical power to its OT s controlling the operation of its OT s e.g. turning them on and off setting their data transmission rate or the like transferring digital data to one or more of the OTs for them to output as one or more digitally modulated optical beams and controlling one or more tilt actuators to alter the pointing direction s of the output optical beam s .

The OTA may be compact as depicted in . For example the OTA may be 2 inches in length or be shorter than 2 inches. Various example components of the OTA are described herein. It will be appreciated that the OTA may be any length including longer than 2 inches or shorter than 2 inches. In some embodiments length of the OTA may produce different performance characteristics e.g. communication range bit rate beam width or the like .

The OTA may be mobile or stationary. For example a dedicated OTA may be stationary and installed on various structures e.g. buildings and billboards or it may be mobile due to it being installed on vehicles e.g. buses automobiles and aircraft . In addition it may be mobile due to it being a portable or wearable device or due to it being a component of or attachment to a portable or wearable device.

Although depicts an OTA for optical communication it will be appreciated that a smartphone or other digital device may perform one or more functions of the OTA . For example an LED flash unit built into a smartphone may be utilized as an OT e.g. without a collimator and a smartphone application may produce the necessary digital modulation of the flash unit s optical output. In some embodiments a smartphone may be coupled to a smartphone case with one or more elements of the OTA e.g. integrated IR emitter and beamforming optics firmware and or software interface .

Utilizing optical communications has many advantages for users of smartphones and or other digital computing devices. For example optical communications may provide long range and high bandwidth capabilities even in the absence of cellular coverage or WiFi. Further optical transmissions are not regulated by the FCC. Optical communications also have low power requirements and high energy efficiency. Users may also prefer to utilize optical communication because they are not necessarily required to provide location information through the personal devices e.g. smartphone or provide location information by utilizing cellular towers that triangulate position.

Optical communications may provide an additional degree of security relative to radio wave based communications. For example due to the ease with which optical beams having narrow beam widths may be produced in some embodiments transmitted optical signals are only received by optical receivers located within a narrow angular zone. It will be appreciated that receiving or transmitting information optically may not require that users utilize any of the limited cellular data provided by their cell phone service plan.

A user may utilize a computer smartphone or other digital computing device to provide data files of streaming video or other data to OTA by means of the data input electronics . The data input electronics may accept data via a hardwired data connection e.g. a USB port a wireless data connection e.g. Bluetooth or both. As an example a user may upload one or more data files via the data input electronics from local storage e.g. hard drive or SSD network storage or memory within his computing device. In various embodiments the data input electronics may include an interface port antenna or the like to receive information from another digital device. The data input electronics may receive information over a hardwired data connection e.g. USB Ethernet cable SATA cable or the like and or wirelessly e.g. Bluetooth WiFi or the like .

The user may also utilize a computing device to input commands via the control input electronics to control any number of operations of the data format converter the light source driver e.g. commands specifying the bit rate of the optically transmitted data optical output intensity and optical pulse duty cycle and or the tilt actuator e.g. commands specifying horizontal and vertical pointing direction of the optical beam .

The control input electronics may also allow the user to input commands controlling the operation of the data preprocessor as well as the data storage e.g. commands to delete files from storage or to transfer one or more specified stored files to the OT which may transmit the file s . The control input electronics may accept such control command inputs from one or more computing devices via a hardwired data connection e.g. a USB connection a wireless data connection e.g. Bluetooth or both. In various embodiments the data input electronics and control input electronics may share one or more data connections. In various embodiments control commands may be received by the control input electronics over the data input electronics . In various embodiments the control input electronics may retrieve or receive control commands from software executing on the OTA .

The OTA may optionally preprocess the input data by means of the data preprocessor . The preprocessor may be any physical or virtual processor. In some embodiments the data may be organized filtered compressed combined with other data and the like to prepare it for transmission in the form of a modulated optical beam output by the OT . One or more users may utilize computing devices to specify by means of control commands input via the control input electronics desired preprocessing to be performed by the data preprocessor on different types of data files.

In various embodiments the OTA may accept 720p video files as input data to be optically transmitted at bit rates in the range of 300 500 kb s. It will be appreciated that any video format may be accepted as input data and then optically transmitted including standard or high definition formats. It will also be appreciated that the OTA may optically transmit any file or combination of files including video images audio text files or the like.

The data storage in the OTA may store data that has been input via the data input electronics and preprocessed by the data preprocessor . The data storage may be any storage including hard drive SSD network storage or the like. One or more users may utilize computing devices to control the operation of the data storage by means of control commands input via the control input electronics . For example commands may be issued to delete data files from the data storage . Additionally commands may be issued to transfer files that have been stored in data storage to the OT so that the information in the files can be optically transmitted.

In various embodiments the OTA may provide the preprocessed input data stored in data storage to the data format converter . Commands to provide such input data may be issued to the data storage by the control input electronics based on commands received from one or more computing devices. The purpose of the data format converter may be to convert data into an appropriate format for optical transmission. The conversion process may include data segmentation in which the data to be transmitted are broken up into segments such as forward error correction FEC segments. Such FEC segments may be of any size and may assist in recovery e.g. instant recovery using a protocol e.g. TCP . In one example if a segment is not properly received the next segment provides recovery information. It will be appreciated that different data segmentation methods may be used. In some embodiments the data may not be segmented at all or the segmentation procedure may be an optional step dependent on control inputs received from the user s .

In other embodiments the data format converter may apportion the data for error correction e.g. based on Vandermonde matrices to allow for recovery . Such data apportionment may also be an optional step dependent on control inputs received from the user s . The data format converter may also perform parallel to serial conversion of the data in preparation for transmitting it optically.

In some embodiments the data format converter may convert the data to an appropriate format for optical transmission. In one example the data format converter may convert the data into a return to zero on off keying RZ OOK format which provides a clock signal to the optical receiver. The data format converter may incorporate transmit and receive first in first outs FIFOs into the data in order to prevent overflow errors and improve data optimization. The specific set of procedures performed by the data format converter on data from a given data file may depend on what specific data format converter commands have been input via the control input electronics and transferred to the data format converter via the OT control electronics . These data format converter commands may alter the nature of specific procedures performed by the data format converter . For example a particular command may cause the number of bits in each segment produced by the data segmentation procedure to be changed from a previous value or another command may eliminate the data segmentation procedure from the data format conversion processing for one or more specific data files or files of a certain type or types.

The light source driver accepts data to be optically transmitted from the data format converter and outputs the appropriate modulated electrical signals to drive the light source using power supplied by power supply . The operation of the light source driver is controlled by user commands input via the control input electronics and transferred to the light source driver via the OT control electronics . For example characteristics of the modulated output optical beam such as the bit rate optical output power level and optical pulse duty cycle may be controlled in this manner.

In some embodiments the OT may be equipped with a tilt actuator . The tilt actuator may include any number of actuators that may alter the horizontal and vertical pointing direction of the output optical beam. The specific pointing direction used at any given time may be controlled by user commands input via the control input electronics and transferred to the tilt actuator via the OT control electronics . In various embodiments the tilt actuator may include any number of actuators to move the beamforming optics and or the light source .

The OT control electronics provides a means of transferring user commands received via the control input electronics to different components of the OT including the data format converter the light source driver and or the tilt actuator . In some embodiments the OT control electronics may control all three of the aforementioned components while in other embodiments it may control only one or two of these components.

In various embodiments the beamforming optics may include custom or commercially available reflective and refractive optics.

In various embodiments the light source may consist of one or more custom or commercially available optical emitters. For example the light source may incorporate at least one commercially available near IR emitter.

In a particular implementation the light source may output optical radiation with a spectrum having a centroid wavelength of 850 nm and a peak power of 1.4 W e.g. during a 1 bit output pulse . It will be appreciated that the light source may produce optical radiation having any wavelength spectrum. Similarly the light source may produce optical radiation at any output power level.

The light source may be any light source. For example the light source may be or include any incoherent optical emitters e.g. LEDs and or coherent optical emitters e.g. lasers . In some embodiments the light source may be mounted on a Berquist thermal Clad LED substrate for heat dissipation. The light source may be an IR emitter having a die size and or active emitter area of 1 mm 1 mm. It will be appreciated that the light source may have any size. In some embodiments the light source may comprise one or more OSRAM SFH 4235 Platinum Dragon high power IR emitters. While the OSRAM SFH 4235 IR emitter has a maximum transmitted bit rate of 24 MHz it will be appreciated that the light source may have any transmission rate. In one example the active emitter area of light source may be a 1 mm square and its maximum transmitted bit rate may be 24 MHz.

In various embodiments the electrical power for the light source to produce 1 W of optical output power is 3.579 W. It will be appreciated that the light source may utilize any amount of electrical power e.g. more or less electrical power to produce 1 W of optical output power.

The light source driver may utilize the formatted data provided by the data format converter to drive the light source . In some embodiments the light source driver may include a high speed MOSFET that drives the light source . The MOSFET may be selected to provide high current while maintaining the desired data bandwidth.

The light source may generate one or more modulated optical beams that are provided to the beamforming optics . The beamforming optics receives each beam produced by the light source and transforms it into an output beam having a desired intensity distribution as a function of horizontal and vertical angular coordinates. As discussed herein the light source may output optical radiation in the near IR wavelength range.

The beamforming optics may be or include for example collimator homogenizer optics discussed herein. In various embodiments the beamforming optics uses a reflective wineglass collimator further discussed herein and at least one pair of lenslet arrays e.g. K hler lenslet arrays also further discussed herein to produce an output beam that is highly uniform within a square angular region.

It will be appreciated that there may be different OTAs for different purposes. For example an OTA designed to be used outdoors may include electronics emitters transmitters and the like capable of long distance optical transmission while an OTA designed to be used indoors may include electronics emitters and transmitters designed for indoor use and shorter distance optical transmission.

The OTA may receive the data from any computing device or combination of computing devices. In some embodiments a remote computing device i.e. a computing device that is remote to the OTA may provide any or all of the data to the OTA via a data input electronics using a wired or wireless network. For example a server may provide any number of files to any number of OTAs over one or more networks. The server may provide the same files or different files to a number of OTAs .

In various embodiments the server may coordinate and or manage delivery of digital content to any number of OTAs for an entity or user. For example a retail store may have any number of different outlets one or more of which includes any number of OTAs . The server may send different or the same data to any number of OTAs located at any number of the different outlets. The server may be controlled or configured to provide updates or changes to content among the different OTAs . It will be appreciated that a centralized server may provide consistent and or organized messaging through any number of OTAs at one or more locations thereby allowing the entity or user to provide consistent messaging and or branding.

Similarly it will be appreciated that a centralized server may provide consistent and or organized messaging through any number of OTAs at any number of locations on behalf of any number of entities. For example the same centralized server may receive files e.g. video images audio text or the like from two different retailers. The centralized server may provide different files to one or more different OTAs based on instructions or configurations of the first retailer. Similarly the centralized server may provide other files to one or more other OTAs based on instructions or configurations of the second retailer. In this way the centralized server may be used by any number of entities to coordinate and provide optical narrowcasting content over any number of OTAs to stores restaurants landmarks facilities private residences government offices and or the like.

In step the OTA preprocesses the received data. For example the data preprocessor may organize filter compress combine with other data and or the like to prepare the data for transmission in the form of a modulated optical beam output by the OT . It will be appreciated that the data may include a combination of video text and or images. It will also be appreciated that different types of data may be preprocessed in different ways. Video data for example may be transformed into a compressed video file using a video codec while other types of data may be compressed in a different manner or may not be compressed at all. In step the data storage may store the preprocessed data in memory e.g. hard disk SSD network memory or RAM .

In step the data format converter within the OT converts the stored data into an appropriate format for optical transmission. The conversion process may include data segmentation parallel to serial conversion and or conversion into a signal format suitable for optical transmission such as an RZ OOK format which provides a clock signal to the optical receiver. As part of step the data format converter may also incorporate transmit and receive FIFOs into the data to prevent overflow errors and improve data optimization. The data may be apportioned for error correction e.g. based on Vandermonde matrices to allow for recovery . It will be appreciated that one or more of the aforementioned data format conversion processes may be optional or may not be used at all. For example in some embodiments step may not include a data segmentation process. It will also be appreciated that in one or more embodiments one or more data format conversion procedures other than the aforementioned procedures may be performed as part of the complete data format conversion process.

In step the OTA may convert the data formatted in step into a modulated optical beam by means of the light source driver and the light source . The light source driver may accept as input the data output from the data format converter . The light source driver may subsequently output appropriate modulated electrical signals to drive the light source using electrical power supplied by the power supply . These modulated electrical signals may cause the light source to output the data in the form of a modulated optical beam.

In step the modulated optical beam produced in step may be transformed into a modulated optical beam having a required intensity distribution. This step may be accomplished by passing the modulated optical beam produced by the light source through the beamforming optics which transforms the beam into a beam having a required intensity distribution as a function of horizontal and vertical angular coordinates. In some embodiments the modulated optical beam produced by the light source may already have the desired or required intensity distribution in which case the beamforming optics may not be included as part of the OTA . In some embodiments the beamforming optics may include a reflective wineglass collimator further discussed herein and at least one pair of lenslet arrays e.g. K hler lenslet arrays also further discussed herein to produce an output beam that is highly uniform within a square angular region.

The modulated data may have a modulation duty cycle of the value of which is less than unity. In one example of the modulation duty cycle the modulation duty cycle may be defined as

In various embodiments bit error probability Pis defined as the probability that noise in the system will cause any given optically transmitted bit to be incorrectly interpreted by an optical receiver i.e. will cause a 1 bit to be interpreted as a 0 bit or vice versa . In some embodiments the system may utilize a single optical channel with a center wavelength of and wavelength range . For systems with multiple optical channels using different optical wavebands the performance analysis must be done separately for each channel.

The beamforming optics comprise a reflective wineglass collimator and two identical lenslet arrays and . The wineglass collimator which may comprise three separate reflective components and may be coupled with and or receive an optical beam from the light source . An interior portion of an inner surface of each of the separate reflective components and may be at least partially reflective. The outer surface of the separate reflective components and may not be reflective.

The separate reflective components and may be coupled together to form the wineglass collimator . As discussed herein the wineglass collimator may be or include an ellipsoidal portion and a paraboloidal portion. Components and may be coupled to form the ellipsoidal portion. In some embodiments the components and are coupled at the broadest diameter of the ellipsoidal portion e.g. in the middle of the broad middle body further described herein . Component may be coupled to a side of the component that is opposite that of the component . Component may include the paraboloidal portion of the wineglass collimator. In some embodiments the components and position and align the ellipsoidal portion and a paraboloidal portions of the wineglass collimator such that the optical axis of the wineglass collimator is aligned with the light source.

The reflective optical surface of the wineglass collimator may be rotationally symmetric about an optical axis substantially centered on the light emitting element of the light source . In some embodiments the reflective surface of the wineglass collimator may include the reflective surfaces of the two reflective components and which may have a shape that is close to being ellipsoidal but yet which may deviate substantially from being ellipsoidal in order to reduce or minimize the horizontal and vertical beamwidth of the collimated beam produced by the wineglass collimator . A second portion of the reflective surface of the wineglass collimator including the reflective surface of reflective component may have a shape that is close to being paraboloidal but yet which may deviate substantially from being paraboloidal in order to reduce or minimize the horizontal and vertical beamwidth of the collimated beam produced by the wineglass collimator .

The output optical beam produced by the wineglass collimator without the lenslet arrays and in place may have an intensity distribution as a function of horizontal and vertical angular coordinates that is somewhat uniform within a square angular region. The pair of lenslet arrays and may improve or substantially improve the uniformity of the intensity distribution of the optical beam output by the beamforming optics thereby providing a communications range for receivers that may be substantially the same for any two or more identical ORAs lying within that square angular region. In some embodiments the pair of lenslet arrays and may convert the output beam produced by the wineglass collimator into a beam having an intensity distribution that is highly uniform within a rectangular or hexagonal angular region rather than a square angular region.

The lenslet arrays and may for example comprise a pair of K hler lenslet arrays. The lenslet arrays are further discussed herein. The lenslet arrays and may be spaced apart and or positioned by structure unit where the spacing distance between the two lenslet arrays is substantially equal to the focal length of each lenslet in each array. The lenslet arrays and may be positioned in front of the exit pupil of the wineglass collimator where this exit pupil is the larger aperture of the reflective component i.e. the rightmost aperture of in the cross sectional view of .

In various embodiments the beamforming optics which may include the wineglass collimator and the pair of lenslet arrays and are capable of converting the optical output of the light source into an output optical beam that has a highly uniform intensity distribution within an 8 square angular region. It will be appreciated that the beamforming optics in various embodiments may convert the output of the light source into an output optical beam having an intensity distribution that is highly uniform within any square rectangular or hexagonal angular region.

Because of its uniform square output optical beam multiple copies of this design of beamforming optics each having its own light source may be used together within a single OTA that produces an output optical beam wider than 8 in a horizontal direction and or a vertical direction. As discussed herein the optical source e.g. light source of may be a 1 W near IR solid state emitter with a peak output wavelength of 860 nm. The beamforming optics may have a clear aperture diameter of 18.5 mm and a total length of 30.5 mm.

In various embodiments when used with the appropriate ORA the OTA may allow for information transfer over distances in excess of 400 m during the day and 1200 m at night with a bit rate of 1 MHz and a bit error probability of 10. This data rate permits transmission of livestreamed HD video.

The ellipsoidal portion may be rotationally symmetric. The ellipsoidal portion may include a narrow entrance pupil a broader middle body and a narrow circular exit. The narrow entrance pupil may be circular with a diameter that is smaller than the greatest diameter of the middle body. The narrow entrance pupil may be positioned to receive light from the light source. The diameter of the broad middle body may flare from the narrow entrance pupil to a diameter that is greater than that of the narrow entrance pupil and then diminish to the narrow circular exit.

The paraboloidal portion may also be rotationally symmetric. The paraboloidal portion may include a narrow circular entrance and a broad exit pupil. The diameter of the paraboloidal portion flare from the narrow circular entrance to the diameter of the broad exit pupil. The diameter of the exit pupil of the paraboloidal portion may be the greatest diameter of the reflective surface of the wineglass collimator. The narrow circular entrance may be or be coupled to the narrow circular exit of the ellipsoidal portion . As such the diameter of the narrow circular entrance of the paraboloidal portion may be the same as the diameter of the narrow circular exit of the ellipsoidal portion .

In a second view depicts a different perspective view of the beamforming optics with rays traced from the light source . In various embodiments the length of the wineglass collimator is less than 1 inch.

In some embodiments the wineglass collimator re images the emitting surface of the light source to infinity to produce a collimated output beam. The collimated beam may propagate through the pair of lenslet arrays and and exit as an optical beam having a highly uniform intensity distribution within an 8 square angular region. Lenslet arrays and may homogenize the beam such that it has a flat i.e. uniform intensity distribution within this square angular region providing uniform or near uniform signal strength for two or more identical ORAs at the same distance from the OTA and located within the aforementioned square angular region. It will be appreciated that in various embodiments the angular region over which the output optical beam is highly uniform may be rectangular or hexagonal rather than square.

In the collimator has a length of slightly less than 22 mm and an exit pupil diameter of 18.5 mm. It will be appreciated that the collimator may be longer than or shorter than 22 mm and may have an exit pupil diameter that is greater than or less than 18.5 mm e.g. 20 mm 18 mm or the like . In one example the collimator may have an exit pupil diameter of 18.511 mm and a total length of 21.50 mm. The central obscuration of the collimator may have a diameter of 6.536 mm.

While measurements are depicted in millimeters it will be appreciated that the collimator may be any length including fractions of millimeters.

The reflective components and may be fabricated in any number of ways. For example they may be fabricated in a three part fabrication process whereby each is turned from aluminum to near net shape such that the optical surface is within 0.010 of its shape. The components may then be diamond turned to produce the required optical surface shape. The optical surface of each of component may then be coated with a reflective coating that is highly reflective in the optical waveband of the light source .

In one example each lenslet array may be made of Schott B270 glass. Each array may be 1.2 mm thick with a 20 20 square array of lenslets which has been truncated to a clear aperture diameter of 20 mm. Each lenslet in the array has a 1 mm square aperture. The refractive index of B270 glass is 1.51555 for a wavelength of 850 nm. The focal length of each lenslet may be 7.17 mm. The separation between the planar surfaces of the two lenslet arrays may be 7.5 mm. In one example the total length of the beamforming optics including the wineglass collimator and the K hler lenslet arrays is 30.50 mm.

It will be appreciated that each lenslet array may be made of any transparent refractive optical material be of any thickness and have any refractive index for any wavelength. The focal length may be greater than or less than 7.17 mm and the separation between lenslet arrays may be any distance. The length of the beamforming optics may have any value.

Performance of an example OTA is discussed as follows. In this example the OTA includes an IR emitter with a centroid wavelength of 850 nm a full width at 5 of peak optical bandwidth of 75 nm and a peak optical output power of 1.4 W e.g. during 1 bit pulse . The active emitter region may be a square 1 mm of a side and the maximum transmitted bit rate may be 24 MHz. The beamforming optic may include the wineglass collimator and lenslet arrays and which are K hler lenslet arrays as described herein.

In computing the performance for this example the optical efficiency of the beamforming optic is assumed to be 0.80. The beamforming optic for use in the example OTA is designed to efficiently transfer flux from a 1 mm square source into an 8 square output beam with a high degree of intensity uniformity. The efficiency in transferring flux from an idealized light source defined as a 1 mm square uniform Lambertian emitter into the 8 square output beam may be about 82.2 . However in some embodiments the light emitting element of the light source may be mounted at the bottom of a shallow hole in the base of the light source e.g. the IR emitting die mounted at the bottom of a shallow hole in the base of the OSRAM SFH 4235 IR emitter such that a portion of light is scattered by the materials in the walls of the hole before it can be collected by the beamforming optic. As a result the flux transfer efficiency for such a non idealized light source may be 49.8 . This significantly increases the tendue of the source preventing much of the light from being transferred into the desired 8 square angular region.

As can be seen from the intensity is approximately 36 W sr within the aforementioned 8 square angular region of high uniformity. At the edges of this region i.e. the vertical edges at 4 from the center of the region the intensity is approximately 25 W sr.

As can be seen from the intensity is approximately 44 W sr along the vertical beamwidth near the center of the aforementioned 48 by 8 rectangular angular region of high uniformity. Along vertical slices taken through horizontal coordinates 4 from the center the intensity within this rectangular angular region is approximately 42 W sr.

As can be seen from the intensity is approximately 36 W sr within the aforementioned 8 square angular region of high uniformity. Near the edges of this region i.e. at vertical coordinates 3.95 relative to the center of the region the intensity is approximately 35 W sr. It will be appreciated that the horizontal and vertical angular widths of the output optical beam may have any values and that the intensity level may have any value within the horizontal and vertical extent of the beam.

As can be seen from the intensity is approximately 44 W sr along the horizontal centerline of the beam between 9.5 and 9.5 horizontally relative to the center of the aforementioned 48 by 8 rectangular angular region of high uniformity. Along horizontal slices taken through horizontal coordinates 3.95 from the center the intensity within this rectangular angular region between 9.5 and 9.5 horizontally is approximately 42 W sr.

In various embodiments software e.g. from a user s computing device may provide files to transfer to control electronics e.g. electronics within the OTA of . The control electronics may convert the information in these files into appropriate electrical signals for driving the light sources 

Each light source may generate a modulated optical beam in which the modulations represent the information contained in the aforementioned files. The modulated optical beam from each of the light sources is converted into a modulated output optical beam having a required intensity distribution by each one of the multiple beamforming optics e.g. a wineglass collimator and a pair of lenslet arrays and . Although depicts control of three light sources and three beamforming optics it will be appreciated that there may be any number of light sources and any number of beamforming optics.

The light sources may be driven by identical synchronized electrical drive signals so that their modulated optical outputs as a function of time are identical. Although depicted as refractive in the optics could utilize refraction reflection and or diffraction. The beams output by the beamforming optics may combine to produce a combined output beam having a desired intensity distribution over a desired two dimensional angular zone referred to as the angular output region.

In the example illustrated in each 8 square angular region of each respective optical beam may abut each other to generate a tiled combined optical beam. It should further be appreciated that one or more of the OTs generating the combined optical beam can be aimed and or positioned such that the respective optical beams output from each of the multiple OTs can result in the illustrated combined optical beam. That is one or more angular offsets may be used when positioning one or more of the OTs e.g. horizontal and or vertical angular coordinates within the angular output region. Hence the aforementioned intensity distribution may be a function of such angular coordinates. For example the light rays comprising each of optical beams may be output generally in direction z but offset by some angle. Here the OTs generating optical beams and may be positioned such that optical beams and are not angled with respect to the direction but are offset from each other by 8 in the x direction to create a 32 wide angular region. The OTs outputting optical beams and may be offset in the x direction by 8 relative to each other to create a 32 wide angular region and further offset in the y direction by 8 relative to optical beams and . Optical beams and may also be offset in the y direction by 8 relative to optical beams and . The resulting combined optical beam output from the multiple OTs is a 32 by 24 rectangular optical beam.

It should be noted that an OTA which includes multiple OTs can have one or more of its OTs oriented in any desired manner. For example an OTA may have a first OT oriented 90 with respect to a second OT. Such an arrangement may allow an OTA to be used to output optical beams along two different paths while being situated at the convergence of those two different paths e.g. along two streets where the OTA is located at the corner of those two streets . Other orientations are possible and contemplated herein.

It should be further noted that one or more of the optical beams output in such a tiled manner may be optical beacons optical signals or some combination thereof. For example optical signals and optical beacons may be temporally interleaved for transmission. For example optical signals and optical beacons may be appropriately identified e.g. with a first identifier indicating that optical beams or portions of optical beams are optical signals contain signal information and a second identifier indicating that optical beams or portions of optical beams are optical beacons contain beacon information. For example the optical beams may comprise an optical signal that is modulated by the optical beacon e.g. the modulation representative of an optical signal is itself modulated by the modulation representative of the optical beacon. Data rates used to transmit optical signals may be different from those used to transmit optical beacons. For example an optical signal data rate may be higher than an optical beacon data rate. Different optical wavelength bands may be used to transmit optical signals and optical beacons the respective optical wavelength bands may be different and non overlapping.

In various embodiments an OTA may transmit two different types of modulated optical beams optical beacons and optical signals. These two types of modulated optical beams are discussed herein in terms of their functions. For optical beacons and optical signals to serve their respective purposes in an ONS it is necessary that an effective method of differentiating between the two types of modulated optical beams be adopted. Otherwise an ORA could incorrectly interpret an optical beacon or a portion of an optical beacon as being an optical signal or a portion of an optical signal. Similarly an ORA could incorrectly interpret an optical signal or a portion of an optical signal as being an optical beacon or a portion of an optical beacon.

Possible methods of distinguishing between optical beacons and optical signals are now discussed. It will be appreciated that there may be any number of effective methods other than those presented herein for producing optical beacons that are distinguishable from optical signals. Methods discussed herein include 1 spectral separation 2 temporal separation and 3 double modulation.

A straightforward method of enabling ORAs to distinguish between optical beacons and optical signals is to use spectral separation. In one example the optical waveband which can also be referred to as an optical wavelength band used for optical beacons is separate from the optical waveband used for optical signals. For example an OTA may produce optical beacons by modulating an optical source that outputs near IR radiation having a wavelength spectrum in the 800 900 nm range. The OTA may also produce optical signals by modulating an optical source that outputs near IR radiation having a wavelength spectrum in the 900 1000 nm range. ORAs for receiving optical beams transmitted by such an OTA may use OBRs discussed herein having significant sensitivity only to wavelengths in the 800 900 nm range and OSRs discussed herein having significant sensitivity only to wavelengths in the 900 1000 nm range. As long as the sensitivities of OBRs and OSRs to optical radiation having wavelengths in each other s bands are sufficiently low the probability of an optical beacon being confused with an optical signal and vice versa may be negligible.

Further if the bit rate used for optical beacons is significantly different than that used for optical signals electronic bandpass filtering can further reduce the likelihood of optical beacons and optical signals being confused with each other. It will generally not be a problem for optical beacons to use significantly lower bit rates than optical signals because the amount of information contained in an optical beacon will typically be far lower than that contained in an optical signal. In some embodiments separate transmitter optics and optical sources may be used in an OTA to enable production of optical beacons and optical signals with spectral separation. Similarly separate receiver optics and detectors or detector arrays may be required in ORAs to enable them to receive both optical beacons and optical signals.

A second method of enabling optical beacons that are distinguishable from optical signals is temporal separation. As the name implies this method separates optical beacons from optical signals temporally rather than spectrally. In this example at any given time an OTA will output either an optical beacon or an optical signal but will not output both simultaneously. Such an OTA may alternate between sending optical beacons and optical signals. In some embodiments ORAs can determine whether they are currently receiving an optical beacon or an optical signal from such an OTA by looking for the presence of a header at the beginning of an optical beacon. Such a header may include a unique series of transmitted 1 bits and 0 bits that marks the beginning of an optical beacon. A different header may be used to mark the beginning of a transmission of optical signals or alternatively each transmitted optical beacon may include a standard number of pulses such that ORAs would always know when transmission of an optical beacon has ended and transmission of an optical signal has begun. Because optical beacons will typically include very small amounts of information relative to optical signals the amount of time devoted by an OTA to transmitting optical beacons may typically be very small e.g. 2 relative to the amount of time devoted to transmitting optical signals assuming the bit rate is the same for both . One advantage of the temporal separation method is that an OTA may use a single optical source and a single transmitter optic operating in a single waveband to produce both optical beacons and optical signals. Similarly an ORA may be able to use a single receiver optic and a single detector or detector array to receive both optical beacons and optical signals. That is the same receiver optic and detector or detector array may be able to serve as both an OBR and an OSR in an ORA designed to receive temporally separated optical beacons and optical signals.

The third method discussed herein of enabling optical beacons to be distinguished from optical signals is double modulation. In this method an OTA transmits a single modulated optical beam having the relatively low bit rate modulation of an optical beacon combined with a relatively high bit rate modulation of an optical signal. In this way an optical beacon and an optical signal are combined into a single beam. This allows the double modulation method to be implemented using an OTA operating in a single optical waveband using a single optical source and a single transmitter optic.

The memory system is any memory configured to store data. Some examples of the memory system are storage devices such as RAM or ROM. The memory system may comprise the RAM cache. In various embodiments data is stored within the memory system . The data within the memory system may be cleared or ultimately transferred to the storage system .

The storage system is any storage configured to retrieve and store data. Some examples of the storage system are flash drives hard drives optical drives and or magnetic tape. In some embodiments the digital device includes a memory system in the form of RAM and a storage system in the form of flash data. Both the memory system and the storage system comprise computer readable media which may store instructions or programs that are executable by a computer processor including the processor .

The communications network interface comm. network interface may be coupled to a network via the link . The communication network interface may support communication over an Ethernet connection a serial connection a parallel connection or an ATA connection for example. The communication network interface may also support wireless communication e.g. 802.11 a b g n WiMax . It will be apparent to those skilled in the art that the communication network interface may support many wired and wireless standards.

The optional input output I O interface is any device that receives input from the user and output data. The optional display interface is any device that is configured to output graphics and data to a display. In one example the display interface is a graphics adapter.

It will be appreciated that the hardware elements of the digital device are not limited to those depicted in . A digital device may comprise more or less hardware elements than those depicted. Further hardware elements may share functionality and still be within various embodiments described herein. In one example encoding and or decoding may be performed by the processor and or a co processor located on a GPU i.e. NVIDIA .

The ORA may include electronics software and or firmware and one or more optical receivers ORs described herein that receive data i.e. information in the form of modulated optical beams as part of an optical narrowcasting system ONS . The ORA may be capable of long communication range receiving sufficient information at long distances for streaming video with low correctable error rates. In one example the signals received by the ORA may be transmitted by an optical transmitter assembly e.g. OTA described herein.

A modulated optical beam output by an OTA may be of two different types as described herein optical beacons and optical signals. In some cases a single modulated optical beam may simultaneously be both an optical beacon and an optical signal. A detailed discussion of optical beacons and optical signals is discussed herein. In some embodiments an optical receiver that is designed to receive optical beacons is referred to as an optical beacon receiver OBR . An OR that is designed to receive optical signals may be referred to as an optical signal receiver OSR . In various embodiments an ORA may include at least one OSR and one OBR. In some embodiments a single optical receiver may function as both an OBR and an OSR.

The ORA may include or be attached to a digital computing device such as a smartphone media tablet laptop camera game device wearable device e.g. smartwatch automobile central computer or the like. In various embodiments any or all components of the ORA are within a case e.g. a smartphone case that is coupled to a digital device such as a smartphone. In one example the digital device may be coupled to a smartphone case equipped with an ORA that incorporates one or more OSRs and one or more OBRs . Such a smartphone case may also be equipped with an OTA not depicted in to facilitate two way communications.

The ORA may receive modulated optical beams in the visible near infrared IR or other optical bands produced using incoherent optical sources e.g. LEDs coherent optical sources e.g. lasers or the like. For example the ORA may receive modulated optical beams in the spectral region from the extreme ultraviolet UV to the far IR which may include wavelengths in the range of 10 to 10nm. It will be appreciated that the ORA may receive modulated optical beams at any wavelength or range of wavelengths in the aforementioned spectral region. For example the ORA may receive modulated optical beams in the visible or near IR bands.

The ORA may receive modulated optical beams transmitted through air water transparent solids e.g. glass windows and or space i.e. a vacuum . As previously discussed the ORA may include a digital device case e.g. a smartphone case . The digital device case may include or be coupled to one or more OSRs and one or more OBRs . The OSR may include for example a detector array e.g. a 6 6 array of detectors . The detector array is further discussed herein.

In some embodiments if the OSR utilizes a single lens having a 16.5 mm square aperture or similarly sized aperture the total thickness of the OSR may be required to be greater than 16.5 mm. As a result an OSR utilizing a single lens may be impractical for smartphones or other personal digital devices due to the inability to fit it into the available space in a typical device e.g. a smartphone or device case e.g. a smartphone case .

Alternately an OSR may include an array of lenslets having smaller apertures e.g. a 6 6 array of 36 lenslets having 2.75 mm square sub apertures with a combined 16.5 mm square aperture with each lenslet in each sub aperture being paired with a separate detector which may enable designs that are significantly less than 16.5 inches thick. For example there may be a separate detector located in the focal plane of each lenslet in each of the 36 2.75 mm square sub apertures of the 6 6 lenslet array such that the total thickness of the lenslet array and detector array may be less than 0.20 inches. In this example a single 0.2 mm square high speed silicon photodetector may be placed in the focal plane of each lenslet. The total thickness of the receiver optics measured from the photosensitive surface of each detector to the outermost surface of each lenslet may be approximately 4 mm. As a result the OSR including lenses and detectors may fit into a smart phone or digital device case.

It will be appreciated that the ORA may be or include a separate ORA that is coupled to a digital device in any number of ways may be or include a digital device case or may be or include a digital device e.g. the smartphone may internally include the ORA . In one example the ORA may include an OSR having a 6 6 array of lenslets with a combined 16.5 mm square aperture with each lenslet having an f near 1.0. In some embodiments the total thickness of the lenslet array and the detector array may be less than 0.20 inches. It will be appreciated that with 36 detectors in the OSR all summed into a single amplifier the detector shot noise may be reduced allowing for higher signal to noise ratio SNR and longer range than could be obtained using only the signal from any one of the 36 detectors or using the summed signal from fewer than 36 of the detectors. In the same example the ORA may also include an OBR consisting of a single imaging lens with a detector array in its focal plane where said detector array is designed as for use in video cameras.

In various embodiments the detectors in OSR operate at a high bit rate which may provide the capability of receiving data at much higher bit rates than would be possible using the camera built into the digital device as an OSR. This is because freed from the requirement to produce video imagery the high bit rate OSR may be designed to operate at a much higher frame rate than could be achieved using the built in camera .

The high bit rate OSR may include optics e.g. the previously discussed 6 6 lenslet array that concentrate flux collected over its entrance pupil within a relatively narrow FOV e.g. 3.6 3.6 onto one or more detectors discussed further herein capable of operating at the bit rate used by optical transmitters e.g. OTA . In some embodiments the high bit rate OSR is a multi channel receiver in which case it may have at least one detector dedicated to receiving flux within the optical waveband corresponding to each of the channels. The optical channels may be in the visible and or near IR but could also be in other spectral regions.

In various embodiments an optical spectral filter may be used to reduce to low levels the out of band flux incident on each detector thereby reducing background noise and increasing the operational range. The aperture size of the high bit rate OSR may be in some embodiments significantly larger than that of video cameras built into typical portable devices which may significantly enhance its achievable operational range at a given bit rate relative to using the video cameras as optical receivers. It will be appreciated that the high bit rate OSR may have fewer pixels and a higher frame rate than a visible band camera because the high bit rate OSR may not need to produce high resolution video imagery but rather provide a means of receiving optical signals.

The optical receiver e.g. ORA may work both with stand alone optical transmitters not contained within any existing portable devices as well as with transmitters based on LED flash units in portable devices. The ORA may also provide part of the capability i.e. the capability of receiving information in the form of modulated optical beams for two way optical communication between portable devices.

It will be appreciated that the ORA may include or be coupled to a device including electronics software firmware one or more OBRs and one or more number of OSRs. In some embodiments the ORA may contain one or more tilt actuators allowing for control of the pointing direction s of OBRs and or OSRs. An ORA s electronics and associated software and or firmware perform various functions including but not limited to providing an interface between the ORA and its user s or its users devices controlling operation of the OBRs and OSRs e.g. turning them on and off setting their data sampling rate or the like receiving and transferring to users or to users devices information such as identifying information and angular position obtained by OBRs regarding optical beacons they have detected receiving and transferring to users or to users devices data extracted from optical signals received by OSRs and or controlling one or more tilt actuators to alter the pointing direction s of one or more OBRs and one or more OSRs.

The ORA control electronics may accept control inputs from a user device via the control input port e.g. a physical or virtual port which may receive information from any number of digital devices . The ORA control electronics outputs to a user device via the OSR data output port e.g. a physical or virtual port which may provide information to any number of digital devices information it has received from optical signals sent by one or more OTAs and or other relevant information related to optical signals e.g. estimates of SNR of received optical signals .

The ORA control electronics may also output to a user device via the OBR data output port e.g. a physical or virtual port which may output information from any number of digital devices information retrieved from optical beacons sent by one or more OTAs . Said information extracted from optical beacons and output via the OBR data output port may include but is not limited to such information as the number of optical beacons that have been detected and that currently fall within the OBR s FOV the current estimated horizontal and vertical angular positions within the OBR s FOV of OTAs associated with detected optical beacons and or identifying information extracted from optical beacons that have been detected by the OBR. In one example information retrieved from optical beacons may identify entities e.g. business organizations or individuals associated with the OTAs that sent said optical beacons.

The OSR detector s or detector array s may be capable of detecting optical flux in wavebands and at bit rates used by optical transmitters e.g. OTA to transmit optical signals. Similarly the OBR detector array s may be capable of detecting optical flux in wavebands and at bit rates used by optical transmitters e.g. OTA to transmit optical beacons. Each OSR receiver optic may collect incident in band flux over its entrance pupil and within its specified FOV and utilize refraction reflection and or diffraction to concentrate flux onto one or more of the OSR detectors or detector arrays . Similarly each OBR receiver optic may collect incident in band flux over its entrance pupil and within its specified FOV and utilize refraction reflection and or diffraction to concentrate flux onto one or more of the OBR detector arrays .

In some embodiments one or more optical spectral bandpass filters may be included as part of each OSR optic and or each OBR optic to reduce to low levels the out of band flux incident on the OSR detector s or detector array s and or the OBR detector array s . Each such spectral bandpass filter may be a separate component e.g. a flat refractive plate coated with a spectral bandpass coating or may include a spectral bandpass coating on an optical surface of one of the optical components e.g. a lens or reflective concentrator of OSR optic or OBR optic used to concentrate flux onto detectors or detector arrays.

In various embodiments a single OSR may comprise multiple optical detectors or detector arrays each paired with its own OSR optic . Similarly in various embodiments a single OBR may comprise multiple optical detector arrays each paired with its own OBR optic . Said use of multiple detectors or multiple detector arrays paired with multiple OSR optics in a single OSR and or multiple detector arrays paired with multiple OBR optics in a single OBR may provide a means of increasing the FOV and or increasing the OSR s and or OBR s sensitivity in certain solid angular regions while maintaining a sufficiently small thickness of the OSR and or OBR so that they may fit into user devices e.g. smartphones or device cases e.g. smartphone cases .

For example depicts a simplified schematic diagram of an example ORA utilizing multiple OSR detectors or detector arrays and OSR optics . OSR detectors or detector arrays may be identical or at least similar to each other. OSR optics may have optical axes that are parallel to each other. It should be noted that multiple OSR detectors or detector arrays along with their respective OSR optics may be configured in a variety of ways one example of which may be similar the manner in which multiple OTs are configured in e.g. a two dimensional array.

The ORA control electronics and ORA software and or firmware may enable the user to adjust via control commands input via the control input port various operational settings and or provide electrical power and control signals for operation of the OSR detector s or detector array s and or the OBR detector arrays s . In addition the ORA control electronics and ORA software and or firmware may receive and amplify modulated signals from the OSR detector s or detector array s and the OBR detector array s optionally decrypt the information received optically in the form of optical signals and optical beacons convert the received information into a format suitable for display and or internal storage and store the received information in internal storage i.e. memory within the ORA control electronics . The ORA control electronics and ORA software and or firmware may also enable the user to transfer information received from OTAs as well as other relevant data from internal storage within the ORA control electronics to another electronic device or computer via the OSR data output port and the OBR data output port .

In some embodiments the ORA control electronics and ORA software and or firmware may be used to control the direction from which optical signals and optical beacons are received by tilting one or more of the OSR and or OBR assemblies. In such cases tilt actuators may perform the tilting movement. For example when tilt actuators are used the tilting could be based on user inputs or be controlled automatically by the ORA control electronics and ORA software and or firmware . In some embodiments the tilting may be based on information received from the OBR regarding the horizontal and vertical angular positions of operating optical transmitters e.g. OTA or from pointing commands received via the control input port . In the case of ORAs in handheld and wearable devices the direction from which signals are received may be controlled manually by the user by means of hand and or body motion.

In some embodiments a function of the OBR may be to provide information to the ORA allowing it to detect the presence of optical beacons transmitted by OTAs distinguishing them from incident in band radiation produced by radiation sources other than optical transmitters e.g. natural and artificial illumination sources . Further the OBR may provide information to the ORA allowing it to determine the horizontal and vertical angular positions of received optical beacons and therefore of the OTAs that are transmitting said received optical beacons within said OBR s FOV. The OBR may also provide information extracted from optical beacons to the ORA allowing it to identify entities e.g. businesses organizations or private individuals operating or otherwise associated with OTAs . In some embodiments the OBR may share some or all of its optics and detector arrays with one or more OSRs or it could be a separate unit.

In some embodiments as discussed herein the LED flash unit built into a smartphone may be utilized as an OTA e.g. without a collimator to transmit optical signals and or optical beacons to other smartphones cameras or to an ORA e.g. a smartphone or smartphone case equipped with an ORA . To transmit optical information a smartphone application may produce the necessary digital modulation of the flash unit s optical output.

In some cases some or all of the information output by ORA via the OSR data output port and or the OBR data output port may be combined with sensed data other than information obtained from optical transmitters. This could include information received by other sensors. For example the digital device e.g. a smartphone in which an ORA is installed or with which it is interfaced may store photographic or video imagery collected concurrently by any number of cameras or by one or more co located cameras. The device in which an ORA is installed or with which it is interfaced might also include one or more microphones or accept audio inputs from one or more co located microphones for the purpose of recording ambient sounds to accompany any information received e.g. photographic imagery videos text or the like from one or more OTAs . In another example the device in which the ORA is installed may include GPS information information received from applications or other digital devices e.g. over a cellular or data network . It will be appreciated that the device may include any or all of the information discussed above with information retrieved from optical beams and or sensors.

The digital device e.g. a smartphone in which an ORA is installed or with which it is interfaced may create a single dataset in a standardized format that combines such photographic video and or audio data with information the ORA has received in the form of optical signals and or optical beacons from one or more OTAs as well as with relevant associated information such as the estimated horizontal and vertical positions of OTAs within the FOV of the OBR . Optionally other data could be included such as a timestamp and the latitude longitude and altitude of the device in which the receiver and signal detector are located. Such a combined dataset could be uploaded or live streamed to other devices or onto the internet via WiFi or other data connections and or stored as a file for later use.

In some embodiments the digital camera e.g. camera in in a user s device may serve as either an OBR an OSR or both. The bit rate for receiving optical beacons or optical signals may be relatively low however due to the frame rate limitations of user device e.g. smartphone cameras. In one example the bit rate may be approximately 30 bits per second. In some embodiments useful information in the form of short messages could still be received by a smartphone using one or more of its cameras as one or more OBRs and or one or more OSRs.

OTAs may in addition to transmitting high bit rate e.g. 1 Mbit per second optical signals to OSRs transmit optical beacons at bit rates sufficiently low that they could be temporally resolved by typical video cameras e.g. camera in in portable user devices to which information is to be optically transmitted. Also OBR in may itself be a video camera capable of receiving such low bit rate optical beacons. Video cameras used to receive optical beacons may operate in the visible light waveband or some other optical waveband e.g. a near IR band . In some embodiments low bit rate optical beacons may provide characteristic signals that a video camera in a portable device could use to detect the presence of optical transmitters and determine their horizontal and vertical angular positions within the camera s FOV. Said low bit rate optical beacon s could be transmitted in one or more optical wavelength channels that are completely separate from the channel s used to transmit information in the form of optical signals to the OSR see and . Alternatively the optical beacon s could share one or more of the wavelength channels used to transmit optical signals. In the latter case the optical beacon could take the form of a low bit rate modulation of the high bit rate optical signal or transmission of the high bit rate optical signal could be paused periodically to provide time intervals during which the low bit rate optical beacon could be transmitted.

In one example the material of which the lenslet array of the OSR optic is made may be polycarbonate with a refractive index for wavelength 850 nm of 1.5710. Dimensions of the entrance pupil for each lenslet in the array may be 2.75 mm square. Dimensions of the combined entrance pupil of the lenslet array may be 16.5 mm square. The full width of the FOV of the OSR with OSR detectors having 0.203 mm square light sensitive regions may be 3.6 square when said detectors are located in the focal planes of the aforementioned lenslets. In some embodiments the lens thickness at center is 1.850 mm. The focal length of each lens in a 6 6 lens array may be 3.230 mm. Distance from an outer surface of lens to focal plane may be 4.000 mm and in band optical efficiency of uncoated lens which may or may not include narrowband optical filter losses may be 0.8939.

The OSR detectors or detector arrays may convert the concentrated optical signals provided by the OSR optic into electrical signals. The OSR power and clock signal electronics may provide the electrical power and or clock signals necessary for the OSR detectors or detector arrays to function properly. The electrical power and clock signals provided by the OSR power and clock signal electronics are controlled by the control input electronics based on inputs received from the user or user s device via the control input port see . The output of the OSR detector or detector array may be amplified and filtered by the OSR amplifier and filter . Said filtering may include for example bandpass filtering to improve the SNR. The amplified and filtered signal may have its format converted into a convenient form by the OSR format converter . For example the OSR format converter may convert the electrical signal pulses into a digital form suitable for storing in digital memory as well as perform error correction.

The OSR format converter may also perform decryption if received optical signals are encrypted. The OSR memory may accept the data from the OSR format converter and store the data in digital memory. Data stored in OSR memory may be output via the OSR data output port with said output being controlled by the control input electronics based on commands received via the control input port . The control input electronics also controls the operation of the OSR amplifier and filter as well as the OSR format converter based on commands received via the control input port .

The OBR in may receive optical beacons sent by one or more OTAs e.g. OTA and convert said beacons into electrical signals. By analyzing the electrical signals the ORA may detect the presence of optical beacons estimate the horizontal and vertical angular positions relative to the OBR s FOV of OTAs sending said optical beacons and extract information identifying entities operating or otherwise associated with said OTAs. As discussed herein the OBR may include one or more OBR optics which concentrate optical beacon flux i.e. increase the flux density of optical beacons from OTAs onto one or more OBR detector arrays . The OBR optic may consist of one or more imaging lenses each of which has a single OBR detector array in its focal plane. One or more narrowband optical filters may be included in the OBR optic . Each such narrowband optical filter may be for example a multi layer thin film interference filter coating on a transparent flat substrate located on the side of an OBR imaging lens opposite the detector array with which it is associated e.g. each detector array may be on one side of its associated imaging lens and the optical filter may be on the other side of the imaging lens or it may comprise one or more multi layer thin film interference filter coatings on one or more of the optical surfaces of OBR optic e.g. one or more optical surfaces of each of the aforementioned imaging lenses . The substrate material used for the narrowband filter may be glass with high transmittance throughout the 800 900 nm waveband. It will be appreciated that the transmittance of the substrate material may be high for any waveband. In some embodiments the substrate for each narrowband optical filter has a 6 mm diameter circular aperture and a thickness of 0.5 mm. It will be appreciated that the narrowband optical filter may be of any size and shape e.g. not necessarily square and have any thickness. In one example the narrowband optical filter may include a center wavelength of the passband of 850 nm and the width of the passband for 0 angle of incidence may be 75 nm.

With reference to the OBR detector array may convert the concentrated optical beacons provided by the OBR optic into electrical signals. The OBR power and clock signal electronics may provide the electrical power and or clock signals necessary for the OBR detector array to function properly. The electrical power and clock signals provided by the OBR power and clock signal electronics may be controlled by the control input electronics based on inputs received from the user or user s device via the control input port .

The output of the OBR detector array may be amplified and filtered by the OBR amplifier and filter . Said filtering may include for example bandpass filtering to improve the SNR. The amplified and filtered signal may then be input into the OBR data processor which may perform the processing necessary to detect optical beacons determine the horizontal and vertical angular positions within the OBR s FOV of the OTAs that sent the optical beacons and extract the identifying information from the beacons.

The OBR data processor may be or include any number of processors e.g. physical or virtual . The OBR data processor may detect optical beacons for example by searching the electrical signal output as a function of time produced by each detector in the OBR detector array for a beacon header code which is a specific binary sequence of 1 bit and 0 bit pulses e.g. 0010110001000011101 included in optical beacons for the purpose of allowing OBRs to detect them.

In some embodiments once an optical beacon has been detected the OBR data processor may estimate the horizontal and vertical angular position of said optical beacon within the FOV of the OBR optics from the location in the OBR detector array of the electrical signal said beacon produces. Since the OBR optic is an imaging optic there may be a straightforward mapping between the horizontal and vertical position where an electrical signal is produced in the OBR detector array and the horizontal and vertical angular position within the OBR s FOV of the optical beacon that produced said electrical signal. The OBR data processor may extract identifying information from a detected optical beacon by receiving and storing in digital form the sequence of 1 bit and 0 bit pulses that follow the beacon header code in the electrical signal corresponding to said detected optical beacon. When the identifying information has been encrypted the OBR data processor may decrypt the identifying information. The OBR data processor may also perform error correction on the identifying information as well as convert it into a convenient format for storage in digital memory. The results produced by the OBR data processor may be stored in digital form in the OBR memory . Data stored in OBR memory may be output via the OBR data output port with said output being controlled by the control input electronics based on commands received via the control input port . The control input electronics also controls the operation of the OBR amplifier and filter as well as the OBR data processor based on commands received via the control input port .

In some embodiments the identifying information and horizontal and vertical positioning information obtained from optical beacons that have been detected and received by the ORA may allow its user to select one or more OTAs of interest and then receive optical signals from those OTAs but not from other OTAs which are not of interest to the user. In such cases the received identifying information may provide the user with sufficient knowledge of the OTAs that have been detected e.g. by a display of information regarding OTA s detected to allow the user to select one or more of interest.

An optical signal from a given OTA of interest may then be received by first tilting the ORA either manually or by means of tilt actuators until the associated OTA is located within the FOV of the OSR where the positioning information previously obtained from said OTA s optical beacon may be used to tilt the ORA by the correct horizontal and vertical amounts to put the OTA within the OSR s FOV. Once an OTA of interest has been positioned within the OSR s FOV a command issued by the user via the control input port may cause the ORA to extract and store information from the optical signal transmitted by that OTA which may then be output via the OSR data output port .

Like the OTA the ORA may be interfaced with a computing device e.g. a notebook computer or smartphone by means of a wired or wireless connection that provides inputs to the ORA via the control input port and accepts outputs from the ORA via the OSR data output port and the OBR data output port . Software installed in this computing device may allow a user to operate and or control the ORA . For example the user may be able to download received data files as well as specify the signal filtering parameters error correction methods to be used and various other receiver operating parameters.

In some embodiments the computing device interfaced with the ORA may be any digital device. As discussed herein a digital device is any device with a processor and memory. The computing device may receive data from the ORA e.g. via a USB port .

In step the OSR detector or detector array converts the concentrated optical signal into an electrical signal.

In step the OSR amplifier and filter amplifies and or filters the electrical signal output from the OSR detector or detector array . The filtering may include for example bandpass filtering to remove electrical noise that is outside of the signal band.

In step OSR format converter converts the amplified and filtered signal into a convenient digital format. During this step error correction may be performed and the signal may be decrypted if the original optical signal was encrypted.

In step the OSR memory may store the formatted optical signal data output from the OSR format converter .

In step the OSR data output port may output the formatted optical signal data stored in the OSR memory to a digital device.

In step the OBR detector array converts the concentrated optical beacon into an electrical signal. This electrical version of the optical beacon is referred to herein as an electrical beacon signal.

In step the OBR amplifier and filter amplifies and filters the electrical beacon signal output from the OBR detector array . The filtering may include for example of bandpass filtering to remove electrical noise that is outside of the signal band.

In step the OBR data processor may process the amplified and filtered electrical beacon signal to detect the optical beacon determine the horizontal and vertical angular positions within the OBR s FOV of the OTA that sent the optical beacon and or extract the identifying information from the beacon. During this step error correction may also be performed and the signal may be decrypted if the original optical beacon was encrypted.

In step the OBR memory may store the beacon information obtained from the electrical beacon signal by the OBR data processor .

In step the OBR data output port outputs the beacon information stored in the OBR memory to the digital device.

It will be appreciated that many different optical assemblies e.g. combinations of one or more lenses reflectors filters and or other types of optical components as well as one or more optical detectors or optical detector arrays may be utilized in conjunction with embodiments described herein. depict one example of a combination of lenslets and optical detectors comprising an OSR as well as possible performance measures for this example.

In one example each lenslet may include a square entrance pupil 2.75 mm on a side so that the entrance pupil area of each lenslet may be 2.75 mm 7.5625 mm

It will be appreciated that the entrance pupil of each lenslet may be any shape e.g. circular oblong rectangular polygonal or the like and any size. As such the receiver optic may include any entrance pupil area.

In various embodiments the ORA uses a 6 6 array of axisymmetric aspheric lenslets each with a single near IR detector in its focal plane. Thus the total number of receiver optics in this example is 36 It will be appreciated that there may be any number of receiver optics and that the array may not necessarily be square. Further although in this example all of the lenslets and detectors may be of the same type i.e. each having the same properties and capabilities it will be appreciated that there may be any number of lenslets including different combinations of different types of lenslets. Similarly there may be any number of detectors including different combinations of different types of detectors.

The array of lenslets may be any size. In one example the array of lenslets may be 0.5 inch per side. In this example each lenslet of the array of lenslets may be about 0.083 inch in width.

In this example the combined entrance pupil of the array of lenslets is 16.5 mm square. The lenslet thickness measured parallel to the z axis of is 1.85 mm at the center and 0.718 mm at a corner of the square lenslet aperture. The distance along the optical axis from the outer optical surface of the lenslet to the focal plane is approximately 4.0 mm. The focal length of the lens may be 3.23 mm

The in band optical efficiency of the OSR optic is defined as the fraction of collected optical power in the operational waveband of the OSR that is lost due to reflection transmission and or absorption losses in the optical materials and at the optical surfaces. The in band optical efficiency of the example lenslet array OSR optic design with uncoated optical surfaces may be 0.894 for a collimated beam incident on the OSR optic parallel to the optical axis. The optical efficiency value provided in the above formula could be significantly higher with AR coatings on the lenslet surfaces. The optical efficiency may be substantially the same for all incident propagation directions within the FOV of the OSR.

The maximum bit rate of this particular photodiode is 800 MHz and quantum efficiency is 0.740. The specific detectivity is 4.06 10cm HzW.

It will be appreciated that other detectors may be used such as but not limited to OSI Optoelectronics PIN HR020 high speed Si photodiodes. Other detectors used in conjunction with some embodiments may have any maximum bit rate quantum efficiency specific detectivity and active area.

Substitution of the detector width and the focal length of the receiver into the previous formula then gives 

The optics in an OSR optic and in an OBR optic may include any number of optical components. The optical components in an OSR optic and in an OBR optic receiver may utilize refraction reflection and or diffraction.

An tendue analysis of an example OSR comprising the lenslet array of where each lenslet has a detector in its focal plane as depicted in is as follows. The tendue of a single detector in the detector array is given by the formula sin where ais the area of a single detector nis the refractive index of the material in which the detectors are immersed and is the maximum incidence angle of rays incident on the detector relative to its surface normal. In this example the OSR s FOV corresponding to a single detector is square with angular width FOV. Since this angle is sufficiently small relative to 90 the small angle approximation may be used in computing the solid angle. In this example the solid angle corresponding to the single detector receiver FOV is therefore FOV Because of the small angle approximation the projected solid angle is equal to the solid angle FOV

The tendue of one of the lenslets of the OSR lenslet array is FOV where ais its entrance pupil area. Setting the detector tendue equal to the lenslet tendue and solving for agives the result 

The quantity arepresents the maximum allowable entrance pupil area of one of the receiver optics for which it will be possible to obtain efficient flux transfer. The maximum allowable total combined receiver entrance pupil area is 

The signal intensity in W sr produced at the entrance pupil of the OSR optic during a transmitted 1 bit from an OTA located a distance r from the OSR optic is where Iis the ideal loss free i.e. not including reflection transmission and absorption losses due to non ideal coatings and optical materials used in the OTA optics output intensity produced by the OTA along the line of sight from the OTA to the OSR optic. The ideal loss free intensity Iis used in the above formula because the losses due to non ideal optical materials and coatings are accounted for via the optical efficiency of the OTA optics. The function T r in the above formula is the in band atmospheric transmittance along the propagation path. Characterizing the atmospheric transmittance in terms of the atmospheric extinction coefficient the above formula becomes exp 

When the OTA is within the FOV of the OSR the optical power incident on one of the OSR detectors during transmission of a single 1 bit may be where nis the optical efficiency of the OSR optic which includes the effects of non ideal optical materials and coatings. The aberrations of the OSR optic may be sufficiently low that all of the transmitted power incident on the entrance pupil of a single lenslet falls on a single OSR detector when the angular position of the OTA lies within the OSR s FOV. The total signal energy deposited on this detector during transmission of a single 1 bit may simply be the optical power times the bit duration r 

The standard deviation of the photon noise produced in a single detector due to the 1 bit signal electrons is the square root of the number of signal electrons. In this example this photon noise standard deviation may be 

The optical power incident on a single OSR detector due to background radiation may be where Lis the spectral background radiance is the optical waveband and is the solid angle corresponding to the OSR s FOV. The corresponding energy collected during one integration time may be 

The corresponding number of electrons produced by background radiation in one detector during one integration time may be 

The standard deviation of the photon noise due to background radiation is obtained by taking the square root of e 

Detector noise may be characterized by a D star value. The electrical bandwidth of the detector is half the bit rate 2

The three noise sources discussed above are all statistically independent. Thus the combined noise variance equals the sum of the variances of the separate noise sources. For a 1 bit the combined noise produced in one detector may be 

The corresponding combined noise produced during a 0 bit is the same as for a 1 bit except that there is no contribution from photon noise produced by the transmitted signal since no optical power is transmitted during a 0 bit. Thus the combined noise in one detector during a 0 bit may be 

Invoking the statistical independence of the noise in each detector in the OSR the combined noise in these Ndetectors may be 

The software in the optical receiver may use a threshold to determine whether or not a given bit is a 0 bit or a 1 bit. The following threshold level may be used for this purpose 

In various embodiments when the combined signal received during one integration time by the optical receiver is greater than or equal to this threshold value the received bit is assumed to be a 1 bit. Otherwise the received bit is assumed to be a 0 bit. Using the threshold level herein may ensure that the bit error probability is the same for 0 bits as for 1 bits and that the overall bit error probability is as low as possible. The bit error probability is Thresh where P x is the cumulative normal probability distribution with mean and standard deviation . This equation may be solved numerically to obtain the communication range r I as a function of ideal i.e. loss free intensity for which the bit error probability equals a desired value.

As previously noted the technology disclosed herein may be used to transmit and receive information within an ad hoc network which is a type of communications network established directly between two or more devices without relying on a base station or central access point. As such two devices may directly communicate over long ranges at high bandwidths without any access to conventional radio wave based communications systems such as cellular networks satellite networks WiFi networks Bluetooth networks and the like. In some instances the ad hoc network may include an internet gateway device that shares its RF data connection with one or more optical narrowcasting devices that do not have access to RF data networks.

In ad hoc environment mobile devices A and B e.g. smartphones directly communicate by transmitting digitally modulated optical beams through space or some other propagation medium. Each device respectively includes an optical transmitting element e.g. an element of an OTA and an optical receiving element e.g. an element of an ORA including one or more lenses or lenslet arrays and one or more optical detectors . Although bidirectional communication is illustrated in this example in some instances the ad hoc network may be unidirectional. For example a transmitting element of mobile device B may broadcast a digitally modulated optical beam that is received by receiving element of mobile device A. Additionally although the ad hoc network in this exemplary environment is established between mobile devices A and B in other implementations the ad hoc network may be established using fixed devices configured with OTAs ORAs vehicles configured with OTAs ORAs and other devices.

Modulated optical beams and may include information such as text information voice information audio information video information application information and other information that may be shared over the ad hoc network. For example the devices may use optical narrowcasting in accordance with the disclosure to share photographs a live video stream a voice conversation or documents. Additionally as further described below modulated optical beam may include information to be sent over RF communication network by device B and modulated optical beam may include information retrieved by mobile device B over RF communication network . In implementations mobile devices may initialize an optical narrowcasting application further described below that may be used to control various parameters of the ad hoc network connection such as device trust device permissions what received information is stored in volatile or non volatile memory etc.

In the example environment of device A has no access or limited access to RF communication networks. For example device A may be a smartphone located in an area without WiFi network availability and where the user s cellular carrier does not offer coverage. By contrast mobile device B has access to one or more RF communication networks over an RF communication network . For example device B may access one or more WiFi networks through one or more Wifi access points e.g. routers a satellite network through one or more satellites and an outdoor indoor satellite unit and a cellular network through one or more cellular or radio stations . The RF communication network may use any suitable RF communication protocols such as cellular telecommunications protocols e.g. GSM LTE CDMA2000 etc. WiFi communications protocols e.g. 802.11g 802.11n 802.11ac etc. etc.

As such in this environment mobile device B may be configured as an optical narrowcasting hotspot that shares an RF connection e.g. a connection to the Internet a LAN and or a WAN with devices e.g. mobile device A that do not have access to or cannot access RF networks. In other words mobile device A may be tethered to mobile device B using an ad hoc optical narrowcasting connection. A variety of benefits may be realized by this implementation.

By way of example ad hoc optical narrowcasting network environment may be used to provide or extend Internet access to devices that are located in remote locations without RF signal availability and or devices that do not have the necessary hardware chipsets for forming cellular satellite WiFi or other like connections. For instance consider a rural area residence that relies on a fixed satellite outdoor unit for providing Internet access. In this scenario a wireless RF gateway e.g. a WiFi router may broadcast wireless access to the satellite connection that is available provided that residents are within a close proximity of the gateway. However if a resident moves a substantial distance from the gateway e.g. greater than 50 m the gateway s signal may be too weak for a mobile device of the resident to access the network. The aforementioned problem may be addressed by deploying an OTA and ORA at the residence that may broadcast and receive modulated optical beams at distances of 200 m 400 m or even greater. For instance the satellite outdoor unit may be retrofitted with a OTA and ORA. As another example ad hoc optical narrowcasting networks may be used to provide or extend Internet access in disaster relief zones in military zones and other zones that do not readily have access to RF communication networks.

In some implementations before an optical narrowcasting ad hoc network is established directly between mobile devices A and at least one of the devices may first confirm that the other device is a trusted device to which it will transmit optical beacons and or optical signals containing information other than identifying information e.g. voice messages text messages document files advertisements etc. and or a trusted device from which it will demodulate and decode received optical beacons and or optical signals containing information other than identifying information. In implementations trust may be established by reviewing the source identifying information contained in an optical beacon transmitted by a device. For example the beacon transmitted by a device may contain source identifying information such as a unique optical narrowcasting ID assigned to the device a unique media access control MAC address assigned to the device or some other type of identification information. In some instances trust may be established by transmitting a code or password in an optical beacon or optical signal. Alternatively the information contained in an optical beacon or optical signal may be encrypted using a key that was previously made available to trusted users. As would be appreciated by one having skill in the art a variety of methods may be implemented to establish trust and or secure communications between devices on an optical narrowcasting ad hoc network.

Alternatively in some instances there may be no need to establish trust. For example where the information transmitted by an OTA is intended to be publically received by any device within the modulated optical beam s path e.g. advertising information or where an ORA is configured to accept all optical signals a device may forego the trust process.

As illustrated by the graphical user interface may present a user with a control e.g. a radio box button toggle slider etc. for enabling or disabling optical narrowcasting. When optical narrowcasting is enabled the mobile device s OTA and or ORA may be configured to transmit and or receive modulated optical beams. As such the mobile device may form an optical narrowcasting ad hoc network with other devices. Conversely when optical narrowcasting is disabled the mobile device s OTA and or ORA may not transmit receive modulated optical beams and may be powered off to conserve battery life. In the example of optical narrowcasting is enabled. As such the mobile device is configured to transmit a modulated optical beacon that makes the device discoverable e.g. as John s Phone by other devices equipped with an ORA. For example an OTA of the mobile device may transmit a beacon including mobile device identifying information within a certain angular region.

The example graphical user interface also displays a list of stored trusted devices that includes devices with which the mobile device has previously established an optical narrowcasting ad hoc network. In this manner graphical user interface may permit a user of the mobile device to specify trusted devices with which to automatically form ad hoc networks. For example if the mobile device s ORA receives a beacon from a device on the trusted device list an ad hoc network may be automatically established. The trusted device list may also display an indication of which trusted devices are currently connected to the mobile device and other information associated with trusted or untrusted devices. For example in a trusted device identified as John s Home Tx is currently connected to the mobile device via an optical narrowcasting ad hoc network.

As another example the trusted device list may display a short visual indication of a trusted device s position relative to the mobile device e.g. distance and absolute orientation in a north east south west plane . This visual indication of the trusted device s position may be supplemented by for example an AR representation of the device s position relative to the mobile device s ORA FOV a navigational map interface showing the trusted device s position or some other indication. This visual indication may be particularly useful in the case of fixed devices such as Internet gateway devices. The visual indication may provide a quick means of locating the device and establishing optical narrowcasting ad hoc networks such as connections to optical narrowcasting hotspots that provide access to an RF network.

The graphical user interface also displays a list of other devices that are not on a trusted device list. For example this may include devices with which the mobile device has not previously formed an optical narrowcasting ad hoc network devices that were not added to a trusted device list after forming an optical narrowcasting ad hoc network or devices with which the user does not wish to form an ad hoc optical narrowcasting ad hoc network. In the example of a beacon is received from a device identified as a Dan s Phone a device with which the mobile has not previously formed an ad hoc network.

With reference now to the device identified as Dan s Phone may send an optical signal or other modulated optical beam including a request to form an ad hoc network. The optical signal may be received at an ORA of the mobile device which demodulates the beam and causes graphical user interface to display to the user a prompt that Dan s Phone would like form an ad hoc network. In the example of a user of the device may either accept the request and form an ad hoc network deny the request or block future communications with the device e.g. ignore future optical signals received from the device .

With reference now to assuming the mobile device accepts the request from Dan s Phone to form an optical narrowcasting ad hoc network the graphical user interface may present options to the user for configuring communications between the user s mobile device and Dan s Phone over the optical narrowcasting ad hoc network. In the example of the user is presented with a control for adding Dan s Phone to the trusted device list and controls for setting permitted optical narrowcasting ad hoc network communications between the user s device and Dan s Phone. For example permissions may be set for initiating voice and or video calls over the optical narrowcasting ad hoc network e.g. Opti Call sending text messages over the optical narrowcasting ad hoc network e.g. Opti Text transferring document video audio or other files over the optical narrowcasting ad hoc network File Transfer communicating using particular applications installed on the mobile device e.g. App and App or other permissions. Additionally using a permission control a user of the mobile device may choose whether to allow Dan s Phone to use the user s device as an optical narrowcasting hotspot e.g. tethering that provides a gateway to an RF connection e.g. an Internet gateway .

At operation the device is enabled as an optical narrowcasting hotspot. For example a user of mobile device B may use a GUI e.g. similar to GUI described with reference to to select a control that authorizes the device to share its RF connection e.g. a connection to the Internet over an ad hoc optical narrowcasting network. As another example a user may deploy a fixed Internet gateway device at a residence remote location or other location to extend or create access to the Internet to devices that do not otherwise have access to RF networks. In this example a user may configure the fixed Internet gateway device in advance such that only trusted devices and or devices having a private encryption key may access the gateway s Internet connection over the optical narrowcasting ad hoc network.

At operation the device uses an OTA to broadcast a beacon or other modulated optical beam identifying the device as an optical narrowcasting hotspot source. In implementations the beacon may be broadcast over a fixed angular region. For example the beacon may be broadcast in a same angular region as the optical narrowcasting hotpot source broadcasts an optical signal or other modulated optical beam carrying information retrieved over an RF network. In some implementations multiple beacons may be broadcast to increase the angular region of the signal. Alternatively in some implementations the beacon may be swept over a horizontal and or vertical angular direction e.g. using one or more tilt actuators of an OTA to increase the probability of a device receiving the beacon identifying the optical narrowcasting hotspot source.

At operation the device receives at an ORA a modulated optical beam from a device requesting access the optical narrowcasting hotspot source. In implementations the requesting device may transmit an optical beacon identifying the device and an optical signal requesting access to the optical narrowcasting hotspot. As previously noted the optical beacon and optical signal may be transmitted on the same modulated optical beam or separate modulated optical beams.

At decision it is determined if the device requesting access to the optical narrowcasting hotspot is a trusted device. For example the device requesting access may transmit a beacon including identifying information e.g. a unique optical narrowcasting ID that the optical narrowcasting hotspot device compares against a stored trusted device list to determine if the device is trusted. As another example the device requesting access may transmit an optical signal including an encryption key or other information that the optical narrowcasting hotspot device may use to determine if the device is trusted. If the device is trusted at operation the optical narrowcasting hotspot may permit the device to access the RF network connection of the optical narrowcasting hotspot. In some implementations the optical narrowcasting hotspot may transmit an optical signal authenticating or otherwise confirming the connection with the requesting device.

If at decision the optical narrowcasting hotspot is unable to determine that the requesting device is trusted the optical narrowcasting hotspot may ignore optical signals from the requesting device until the requesting device can establish it is trusted e.g. by transmitting a modulated optical beam including a private key . Alternatively in some implementations all devices that can receive modulated optical beams from the optical narrowcasting hotspot e.g. all devices configured with an ORA having a FOV within the optical signal path of the optical narrowcasting hotspot may be permitted to access the optical narrowcasting hotspot. In such implementations operations may be skipped.

At operation the optical narrowcasting hotspot device receives an optical signal at an ORA from the device permitted to access the hotspot. The optical signal in implementations is a modulated optical beam including information to be sent over the RF communication network made available by the optical narrowcasting hotspot device. Depending on the destination node and application e.g. a web browser request of the information to be sent over the RF communication network the information carried by the optical beam may be encapsulated by the requesting device using suitable headers and trailers.

At operation the optical narrowcasting hotspot device may extract the information from the optical signal e.g. using the systems and methods disclosed herein for demodulating and otherwise receiving a modulated optical beam . The information may then be transmitted over the RF network to a node using an RF connection interface of the device e.g. by modulating the information onto an RF carrier signal . For example with reference to the example of optical narrowcasting hotspot device B may receive an optical beam from device A extract information intended for RF communication network from the optical beam encapsulate and or remodulate the information in preparation for transmission over RF communication network and transmit the information over RF communication network .

At operation in response to transmitting the information over the RF communication network the optical narrowcasting hotspot device receives a response e.g. a modulated RF signal including information. At operation the information retrieved over the RF network is modulated onto an optical signal and transmitted by the hotspot s OTA to an ORA of the requesting device e.g. using the systems and methods disclosed herein for modulating and otherwise transmitting a modulated optical beam .

At operation the device may modulate information to be transmitted over the hotspot s RF network connection onto an optical signal. At operation the device s OTA may transmit to the hotspot s ORA the modulated optical beam including the information to be transmitted over the hotspot s RF network connection. At operation the device receives at an ORA a modulated optical signal from an OTA of the hotspot including information retrieved over the RF network by the hotspot.

In various embodiments a computing system may be configured to provide graphical user interfaces GUIs for optical narrowcasting in accordance with the present disclosure. For example GUIs may be provided for presenting and selecting OTAs and or sources of OTAs information extracted from modulated optical beams produced by the OTAs and graphical representations thereof. In some embodiments for sake of illustrative clarity reference to an OTA may refer to a physical OTA and or graphical representation thereof.

As used herein to describe a UI or GUI the term user input generally refers to any user action that generates data that triggers one or more actions at the UI e.g. the retrieval of optical signal information the display of optical signal information the selection of graphical controls the movement of an ORA etc. . A user input may include for example a touch user interface gesture e.g. taps holds swipes pinches etc. vocal input e.g. voice commands that are digitized and translated into a corresponding action a keyboard input e.g. pressing a keyboard key a mouse input e.g. clicking and or moving a mouse pointer and the like. User input may include a sequence of inputs such as a particular sequence of touch gestures voice commands and or key presses. User input may select modify or otherwise manipulate a displayed graphical control element such as for example buttons checkboxes menus windows sliders navigational control elements and the like.

In the example of the presentation and selection system includes a device interface engine an optical receiver interface engine a location engine an augmented reality control engine a filtering engine a third party interface engine a notification engine a context aware OTA sensing engine a signal information enhancement engine a graphical user interface engine and a datastore .

The device interface engine facilitates interaction between the presentation and selection system and one or more associated user devices. For example user devices may include mobile devices e.g. smartphones cell phones smartwatches head mounted displays tablet computers or laptop computers computing devices of vehicles such as automobiles e.g. on board automobile computing devices and sensors and the like. In some embodiments the device interface engine may access or otherwise control functionality of content capture devices e.g. cameras and microphones presentation devices e.g. displays and speakers and sensors e.g. location and orientation sensors of one or more user devices. The device interface engine may include one or more application programming interfaces APIs or communication protocols for interacting with user devices.

The optical receiver interface engine facilitates interaction between the presentation and selection system and one or more ORAs. For example the optical receiver interface engine may access an ORA included in or coupled to the user device. The optical receiver interface engine may utilize one or more APIs or communication protocols for interacting with any number of ORAs simultaneously or otherwise.

In some embodiments the optical receiver interface engine obtains optical information e.g. identification data and descriptive data from one or more ORAs. The optical receiver interface engine may obtain optical information automatically e.g. without requiring user input or manually e.g. in response to user input . For example the optical receiver interface engine may automatically obtain optical information from an ORA once it begins extracting optical information from a received modulated optical beam or after the ORA finishes extracting all optical information from a received modulated optical beam.

In some embodiments the optical receiver interface engine stores optical information. For example the optical receiver interface engine may persistently store or temporarily store e.g. cache or buffer optical information in a datastore e.g. datastore . This may allow the presentation and selection system to access optical information after an OTA s modulated optical beam is no longer within the FOV of an OBR or OSR of an ORA. In some embodiments rules may define conditions for determining when to store optical information what optical information to store an amount of time to store optical information when to purge stored optical information and other conditions for storing received optical information. For example the rules may define that optical information may be stored for a threshold number of OTAs. For example a FIFO structure may store optical information for twenty OTAs and as optical information is stored for additional OTAs the optical information associated with the first in OTA may be purged.

In some embodiments the optical information rules define a geographic proximity condition for storing optical information. For example if an ORA or associated user device is within a threshold geographic proximity e.g. 1 km of an OTA or a location the optical information was received the optical information may be stored. As follows if the user device exceeds the geographic proximity the optical information may be purged. This may help ensure for example that stored optical information is current and that resources e.g. memory are not unnecessarily consumed.

The location engine functions to determine a location of an ORA or associated user device relative to one or more OTAs. In some embodiments the location engine may determine the relative location from a current location and orientation of the user device e.g. as indicated by one or more sensors of the user device and a current location and orientation of an OTA. As the user device changes location e.g. user operating the user device is walking or orientation e.g. a user tilts or rotates the user device the location engine may update the relative location between the user device and the OTA.

In the example of the augmented reality control engine functions to provide augmented reality features for presenting selecting and otherwise interacting with OTAs and optical information. The augmented reality control engine may receive user input and otherwise control augmented reality features of the presentation and selection system . For example augmented reality actions may include selecting an augmented reality object generating a request for optical information associated with a selected augmented reality object and removing augmented reality objects.

In some embodiments the augmented reality control engine may capture content e.g. images pictures video or audio and overlay augmented reality objects on the content at the same or substantially same time as the content is being captured. Augmented reality objects may include visual objects e.g. graphics icons text images pictures or video audio objects e.g. songs or other audio tracks and metadata objects such as URI links e.g. hyperlinks or instructions to execute one or more third party systems e.g. web browser or mobile application . In some embodiments augmented reality objects may represent OTAs or a source of an OTA. For example an augmented reality object representing an OTA may comprise an icon representing an OTA text and images representing optical information and the like.

In some embodiments the augmented reality control engine renders a field of view FOV augmented reality object that provides a visual representation of the boundaries of a FOV in which optical receivers e.g. an OBR and or an OSR associated with an ORA may receive modulated optical beams. For example the FOV augmented reality object may be visually rendered as a square rectangle circle or other geometric object. If a visual representation of an OTA or source of an OTA is within the boundaries of the FOV augmented reality object an optical receiver of an ORA may be able to receive optical information from the visually represented OTA because at least a portion of a modulated optical beam transmitted by the OTA is within the optical receiver s FOV. Conversely if the visual representation of the OTA is outside of the FOV boundaries the ORA may be moved e.g. by tilt actuators and or user movement of the user device so that the visual representation of the OTA is within the boundaries of the FOV augmented reality object. In some embodiments the FOV augmented reality object is scalable and or maintains a relative location on a display e.g. a centered location . For example as a user zooms in or zooms out the FOV augmented reality object can change sizes and when a user pans in a direction e.g. left or right the field of view augmented reality object may maintain the same relative location on the display.

In some embodiments some or all augmented reality objects are interactive. For example the augmented reality control engine may select an augmented reality object in response to user input and perform one or more actions in response to the selection. For example selection of an augmented reality object such as a visual representation of an OTA or source of an OTA may trigger the presentation of optical information received from the OTA.

The filtering engine functions to select or remove or collectively filter one or more subsets of OTAs from a set of OTAs. The filtering engine may filter OTAs based on one or more filter parameters and corresponding tags associated with a modulated optical beam. Filter parameters and tags may indicate a source of an OTA e.g. a location one or more entities associated with an OTA e.g. name or other identifier of a person company or organization one or more categories associated with an OTA e.g. merchant music venue or real estate agent and one or more subcategories associated with an OTA e.g. jewelry merchant or residential real estate agent . Filter parameters and tags may be predetermined or user defined. In some embodiments a tag may be included in optical information e.g. a header of the optical information of a beacon signal . The filtering engine may match or otherwise compare filter parameters and tags to filter OTAs.

In the example of the third party interface engine functions to facilitate interaction between the presentation and selection system and one or more third party systems. The third party systems may include mobile application systems e.g. Google Maps social media systems e.g. Facebook or Twitter and the like and they may comprise local or remote systems. For example the third party interface engine may present visual indicators of OTAs on a map generated by a third party system and allow users to select and otherwise interact with OTAs using the third party system. In some embodiments the third party interface engine comprises one or more APIs or communication protocols.

In the example of the notification engine functions to generate and provide messages or alerts associated with OTAs. For example the notification engine may trigger notification messages in response to satisfaction of one or more notification trigger conditions or based on notification parameters. Notification trigger conditions may include detection of OTAs signal strength or signal quality OTA connection status and the like and may be predetermined or user defined. The messages may be provided to a user through a component of the presentation and selection system and or the user device and the messages may comprise augmented reality objects or other visual indicators sounds or haptics.

In some embodiments the notification engine functions to provide indicators for orientating an OTA and or user device. For example the notification engine may generate visual indicators e.g. graphical arrows or audio indicators e.g. speech instructions for orienting an ORA relative to an OTA in order to receive a modulated optical beam or improve a strength and or quality of a modulated optical beam. The indicators may be generated in response to user input e.g. a user requesting orientation instructions or automatically e.g. a connection drops or signal strength and or quality falls below a threshold value .

In the example of the context aware OTA sensing engine functions to recommend OTAs. In some embodiments the context aware OTA sensing engine detects whether an OTA may be of interest to a user. For example ten OTAs may be available at a particular location and the context aware OTA sensing engine may categorize each available OTA based on a predicted interest level of a user e.g. low medium or high . The context aware OTA sensing engine may select which OTAs may be presented based on the interest level. For example the context aware OTA sensing engine may select medium and high interest level OTAs for display and ignore low interest level OTAs. This may help ensure for example that users are not unnecessarily inundated with information received from OTA.

In some embodiments the context aware OTA sensing engine may generate an OTA interest vector for some or all available OTAs. As used herein available OTAs may include OTAs currently transmitting to an ORA OTAs currently capable of transmitting to an ORA OTAs capable of transmitting to an ORA with limited location or orientation change and or OTAs with available stored e.g. cached optical information. The interest vector may include an OTA identifier and a history of previous user interactions. The interest vectors may be compared with each other or a threshold value to determine OTAs to present to a user and or determine OTAs to emphasize to a user. For example if an interest vector indicates that an associated user has previously interacted with a particular OTA or OTAs transmitting particular categories or subcategories of signal information e.g. merchant jewelry merchant and the like a threshold number of times or frequency the context aware OTA sensing engine may categorize a predicted interest level as high . Similarly if an interest vector indicates user interaction below a particular threshold the context aware OTA sensing engine may categorize a predicted interest level as low .

In the example of the optical information enhancement engine functions to provide enhanced signal information. As used herein enhanced signal information may include enhanced signal information obtained from a supplemental communication connection e.g. WiFi . As used herein a supplemental communication connection may be any communication connection other than the communication connection providing the optical information. For example enhanced signal information may include a detailed description of an entity s business videos pictures online retail features and the like. This may allow for example additional information to be provided that may not be reasonably transmitted through a modulated optical beam. In some embodiments the signal information enhancement engine may automatically detect and or access supplemental communication connections and or automatically obtain enhanced signal information upon accessing a supplemental communication connection.

The graphical user interface engine functions to provide a graphical user interface for presenting selecting and otherwise interacting with one or more OTAs. For example the graphical user interface engine may be implemented as a mobile application desktop application web application or the like. In some embodiments the graphical user interface engine provides functionality for interacting with OTAs as described elsewhere herein albeit in a non augmented reality environment. For example the graphical user interface engine may present a list of available OTAs e.g. a filtered or non filtered list receive user selections regarding OTAs present optical information from selected OTAs present notifications present enhanced signal information and so forth.

The datastore functions to store data persistently and or temporarily. For example the datastore may store communications received from other systems optical and enhanced signal information rules and filters.

At operation the presentation and selection system obtains optical information associated with one or more OTAs. In some embodiments an optical receiver interface engine e.g. optical receiver interface engine obtains the optical information.

At operation the presentation and selection system stores the optical information at least temporarily. For example the presentation and selection system may cache the optical information in a datastore e.g. datastore and or persistently store the optical information in a datastore e.g. datastore . In some embodiments the presentation and selection system stores the optical information based on one or more optical information rules.

At operation the presentation and selection system identifies one or more available OTAs. In some embodiments the optical receiver interface engine identifies the one or more available OTAs. In various embodiments a filtering engine e.g. filtering engine may filter the one or more available OTAs. For example ten OTAs may be available although only five OTAs may be of interest to the user. The filtering engine may filter the available OTAs such that only the OTAs of interest to the user are identified. Example filtering methods are discussed further below.

At operation the presentation and selection system presents one or more graphical representations of the one or more available OTAs. In some embodiments an augmented reality control engine e.g. augmented reality control engine a third party interface engine e.g. third party interface engine or a graphical user interface engine e.g. graphical user interface engine presents the graphical representations. For example the augmented reality control engine may generate one or more augmented reality objects representing at least a portion of the available OTAs and overlay the one or more augmented reality objects on the content. By way of further example the third party interface engine may generate and overall one or more graphical icons on a third party system e.g. Google Maps indicating locations of the corresponding OTAs. By way of further example the graphical user interface engine may present a list of the available OTAs.

At operation the presentation and selection system graphically renders a representation of the one or more OTAs. In some embodiments the augmented reality control engine the third party interface engine and or the graphical user interface engine renders the graphical representation in response to user input.

At operation the presentation and selection system presents additional optical information in response to the selection. For example the additional information may include additional identification data additional descriptive data and the like. In various embodiments the augmented reality control engine the third party interface engine or the graphical user interface engine presents the particular graphical representation.

At operation a presentation and selection system e.g. presentation and selection system obtains a set of filter parameters. The set of filter parameters may correspond to OTA parameters e.g. source category sub category and the like . Filter parameters may be obtained in real time e.g. at the same time or substantially same time an associated user device is capturing content of an environment or otherwise. In some embodiments a filtering engine e.g. filtering engine obtains the set of filter parameters automatically e.g. based on predetermined filter rules or based on user input received by an augmented reality control engine e.g. augmented reality control engine or a graphical user interface engine e.g. graphical user interface engine .

At operation the presentation and selection system identifies a set of available OTAs. For example the presentation and selection system may identify the set of available OTAs based on one or more tags or other optical information of one or more beacon signals. The one or more tags and or other optical information of the one or more beacon signals may be active e.g. currently being received by an associated ORA and or stored e.g. cached or persistently stored . Accordingly an available OTA may be an OTA transmitting or capable of transmitting a modulated optical beam to an associated ORA and or an OTA that is not currently transmitting or currently unable to transmit to an associated ORA. In some embodiments the filtering engine identifies the set of available OTAs.

At operation the presentation and selection system filters a subset of OTAs from the set of available OTAs based on the set of filter parameters. The subset of OTAs may indicate which if any of the available OTAs to present. In various embodiments the presentation and selection system filters the subset of OTAs from the set of available OTAs based on the set of filter parameters and one or more corresponding tags of a modulated optical beam. For example if a source of a modulated optical beam matches a corresponding source parameter of the set of filter parameters the OTA associated with that modulated optical beam may be filtered. Similarly if the set of filter parameters indicates that a first particular category e.g. real estate is of interest to a user while a second particular category e.g. jewelry is not of interest to the user the set of available OTAs may be filtered such that the subset of OTAs includes OTAs associated with the first particular category and does not include OTAs associated with the second particular category. Filtering may be performed based on any number of filter parameters and may indicate parameters of interest to a user and or not of interest to a user. In some embodiments the filtering engine filters the one or more subsets of OTAs.

In various embodiments physical OTAs as well as graphical representations thereof may be filtered. More specifically the user device and or associated ORA s may deny e.g. ignore transmissions from OTAs based on the set of filter parameters. For example a first optical beam from a particular OTA may include one or more tags indicating parameters of the OTA e.g. source category sub category and the like . Based on the set of filter parameters the user device and or associated ORA s may deny subsequent transmissions the particular OTA. For example subsequent transmissions may be denied for a particular period of time e.g. an hour a day a month and so forth for the particular OTA.

In various embodiments filtering may be based on context and or predicted interest level s for a user with respect to available OTAs. Filtering based on context may be performed by the filtering engine and or a context aware OTA sensing engine e.g. context aware OTA sensing engine . An example filtering method based on context is discussed below.

At operation the presentation and selection system presents graphical representations of one or more OTAs of the set of available OTAs based on the filtering. For example the presentation and selection system may present the subset of OTAs. It will be appreciated that in some examples the filtering may indicate that none of the available OTAs are to be presented to a user. In some embodiments the augmented reality control engine or the graphical user interface engine presents the graphical representations.

At operation a presentation and selection system e.g. presentation and selection system obtains notification parameters. For example the notifications parameters may comprise filter parameters or other notification parameters. In some embodiments a notification engine e.g. notification engine obtains the notification parameters.

At operation the presentation and selection system identifies a set of available OTAs. In some embodiments the notification engine identifies the set of available OTAs.

At operation the presentation and selection system identifies a subset of OTAs from the set of available OTAs based on the notification parameters. In some embodiments the notification engine performs the determination.

At operation one or more notification messages are provided regarding the identified OTAS. For example a notification message may indicate the set of available OTAs or the subset of available OTAs. In some embodiments the notification engine provides the one or more notification messages to a user through an augmented reality control engine e.g. augmented reality control engine a third party interface engine e.g. third party interface engine or a graphical user interface engine e.g. graphical user interface engine .

At operation a presentation and selection system e.g. presentation and selection system obtains a history of prior user actions. In some embodiments a context aware OTA sensing engine e.g. context aware OTA sensing engine identifies the subset of OTAs.

At operation the presentation and selection system identifies a set of available OTAs. In some embodiments the context aware OTA sensing engine identifies the set of available OTAs.

At operation the presentation and selection system identifies a subset of OTAs from the available OTAs based on the history of prior actions. In some embodiments the context aware OTA sensing engine identifies the subset of OTAs.

At operation the presentation and selection system presents an enhanced graphical representation for at least a portion of the subset of OTAs. For example enhanced graphical representations can include modified colors sizes and or shapes. In some embodiments an augmented reality control engine e.g. augmented reality control engine third party interface engine or graphical user interface engine provides the enhanced graphical representations.

At operation a presentation and selection system e.g. presentation and selection system obtains optical information associated with a set of available OTAs. In some embodiments an optical receiver interface engine e.g. optical receiver interface engine obtains the optical information.

At operation the presentation and selection system presents the optical information. In some embodiments an augmented reality control engine e.g. augmented reality control engine a third party interface engine e.g. third party interface engine or a graphical user interface engine e.g. graphical user interface engine provides the graphical representations.

At operation the presentation and selection system determines whether a supplemental connection is available. In some embodiments a signal information enhancement engine e.g. signal enhancement engine determines available supplemental connections.

At operation the presentation and selection system obtains enhanced information using the supplemental connection if such a supplemental connection is available. Otherwise the method may terminate or wait for a supplemental connection to become available. In some embodiments the signal information enhancement engine obtains the enhanced information if the supplemental connection is available or waits for a supplemental connection to become available.

At operation the presentation and selection system enhances the graphical representation with the enhanced information. In some embodiments the augmented reality control engine the third party interface engine or the graphical user interface engine enhances the graphical representations with the enhanced information obtained by the signal information enhancement engine.

Mobile device includes optical receiver assembly optical transmitter assembly motion sensor position determination device display camera storage and processing modules .

As illustrated in the example of ORA and OTA are integrated into mobile device e.g. inside the casing of mobile device . However in alternative implementations ORA and or OTA may instead be communicatively coupled to mobile device e.g. using a smartphone case with a built in ORA . Additionally in the example of camera is a separate component from ORA . However as discussed with reference to in some instances camera may be utilized as an ORA to receive optical beacons and or optical signals. In such implementations camera may be used in place of or in addition to ORA . Example implementations of ORA and OTA are described in greater detail with reference to .

Storage may include non volatile memory e.g. flash storage volatile memory e.g. RAM or some combination thereof. In the example of storage stores an optical narrowcasting application that when executed by a processing module e.g. a digital signal processor provides an optical narrowcasting GUI on display e.g. a touchscreen display of a smartphone or a head mounted display . Additionally storage may store information retrieved or created by using optical narrowcasting application . For example storage may store application settings e.g. filters notifications OTA ORA settings information extracted from optical beacons and optical signals and other information.

Motion sensor generates electronic input signals representative of the orientation of mobile . These electronic input signals may be received and processed by circuity of processing modules to determine a relative orientation of mobile device e.g. an orientation in the north east south west NESW and up down planes . In embodiments motion sensor may include one or more gyroscopes accelerometers and magnetometers.

Position determination device includes a device for retrieving geographical positional information over an RF communication medium. For example position determination device may include a cellular receiver a global positioning system receiver a network interface card an altimeter or some combination thereof. The positional information retrieved by device may be processed by processing modules to determine the geographical coordinates of mobile device . For example a GPS receiver may acquires time signals from three or more satellites and determine mobile device s position using three dimensional trilateration. As another example the geographical coordinates of mobile device may be determined relative to one or more WiFi access points using fingerprinting received signal strength indication RSSI angle of arrival AoA time of flight ToF or other techniques known in the art.

As further described below the determined orientation e.g. absolute orientation in an NESW direction and geographical position e.g. geographical coordinates of mobile device may assist in generating an optical narrowcasting GUI display. For example a GUI of optical narrowcasting application may render an augmented reality display of the location of one or more OTAs relative to a FOV of an optical receiver of ORA e.g. an OBR or OSR based at least in part on the determined orientation and or geographical position of the mobile device.

Camera captures a video stream of the user s real world environment that may be presented on display . In implementations further described below an optical narrowcasting application may overlay augmented reality objects such as FOV augmented reality objects and visual representations of OTAs over the display of the video stream captured by camera .

At operation an optical narrowcasting application is initialized on the mobile device . For example a user operating a smartphone or tablet device may tap or otherwise touch an icon corresponding to an optical narrowcasting application. As another example the optical narrowcasting application may be automatically initialized after the mobile device is powered on. In some implementations the optical narrowcasting application may be initialized within another application installed on the device. For instance a camera application of mobile device may include an option for initializing an optical narrowcasting mode.

At operation a camera and ORA of the mobile device may be activated e.g. from a powered off or idle state . In some instances camera and ORA may be activated in response to initialization of the optical narrowcasting application. Once activated camera may capture a live feed of the user s real world environment that is displayed on a display and ORA may receive optical beacons and or optical signals from one or more OTAs.

Following activation of the ORA and camera at operation a visual representation of the FOV of an optical receiver of the ORA e.g. a FOV of an OBR and or OSR overlaid over a live display of the camera s FOV is shown on a GUI. illustrates one such example of an AR GUI showing a FOV AR object overlaid over a live camera feed. FOV AR object provides a visual representation of the boundaries of a FOV in which optical receivers e.g. an OBR and or an OSR of ORA receive optical signals. As the FOV of the optical receiver depends on an angular region in which it receives optical beacons or optical signals the displayed FOV AR object may be sized relative to the displayed FOV of the camera. For example if a 16 by 8 angular region is displayed on AR GUI and the FOV of the optical receiver receives signals within angular region of 4 by 4 the area of FOV AR object may cover of the area of the display of AR GUI .

It should be noted that in various embodiments the FOV of the OBR may coincide with or may even extend somewhat beyond the FOV of the camera to facilitate the process of finding beacons. In such embodiments the FOV AR object represents a smaller FOV of an OSR as illustrated in and . In such implementations once beacons have been detected the smaller field of view of the OSR may be positioned so that an optical signal can be received by moving and or tilting the mobile device to bring an optical signal transmitted by an OTA within the FOV of the OSR.

In some instances the boundaries of FOV AR object may be based on an area of the receiver s FOV that receives optical beacons or optical signals at a threshold SNR and or threshold bit rate. As shown in this example the FOV AR object is rendered as a square. However depending on the configuration of the one or more receivers within ORA e.g. a rectangular array or circular array configuration in some instances FOV AR object may instead be rendered as a rectangle or other polygon a circle or other ellipse or some other geometric shape. In other words FOV AR object may be rendered as a cross section of an angular region in which an optical receiver may receive optical beacons or optical signals.

In embodiments illustrated by FOV AR object is displayed as a semi transparent object to avoid obstruction of a user s view of the live environment and or other AR objects e.g. visual representations of OTA . Alternatively FOV AR object may be displayed as an outline of the receiver s FOV. In yet further embodiments GUI may provide a control for modifying the appearance of FOV AR object or hiding FOV AR object from view.

In embodiments FOV AR object stays fixed to a relative location of a display or GUI e.g. a centered location as illustrated by as the mobile device and correspondingly the ORA is moved i.e. tilted or panned in different directions. For example as a user tilts the mobile device in a direction e.g. left or right the FOV AR object maintains the same relative location on the display.

At operation a camera of the mobile device is zoomed in or out. In implementations the camera may be zoomed optically and or digitally. As zooming in or out changes the angular region of the user s environment that is displayed by GUI at operation the visual representation of the FOV of the optical receiver of the ORA e.g. FOV AR object is resized. For example as illustrated in the example of FOV AR object is increased in response to the camera zooming in. Conversely if the camera zoomed out the size of AR object is decreased.

At operation a beacon transmitted by an OBT of an OTA is detected within the FOV of an OBR of an ORA . For example as a user moves a mobile device in an environment optical beacons transmitted by OBTs in the environment may come into the FOV of the OBR. Upon detection of the optical beacon at operation ORA may estimate the horizontal and vertical angular positions of the received beacon relative to the OBR s FOV. For example the angular position of the optical beacon may be detected by mapping between the horizontal and vertical position where an electrical signal is produced in a detector array of the OBR and the horizontal and vertical angular position within the OBR s FOV of the optical beacon that produced an electrical signal.

At operation ORA extracts identifying information from the received beacon. The identifying information may identify the name of the source or entity e.g. business name device name individual name etc. associated with the OTA that sent the optical beacon. In some instances the identifying information may further identify the category and or type of the source. For example the identifying information may specify whether the source is an individual business organization landmark product or object. In the case of businesses the identifying information may specify for example whether the business is a restaurant a hotel a department store a supermarket a warehouse store a gas station a movie theater etc.

The extracted identifying information may be temporarily cached or permanently stored in a memory of ORA and or another storage of mobile device e.g. storage . Once extracted the identifying information is made available to an optical narrowcasting application .

At operation the extracted identifying information and estimated angular positions of the received beacon may be used by optical narrowcasting application to render a visual representation of the beacon s source overlaid over a live display of the camera s FOV. The visual representation in various implementations may identify the source of the beacon e.g. based on the extracted identifying information and visually represent the location of the source OTA relative to the display of the live feed from the camera e.g. based on the estimated angular positions of the received beacon . One such implementation is illustrated by which shows an AR GUI displaying an icon or marker associated with a business e.g. Business A transmitting a beacon that was detected by an ORA of the mobile device. In this example icon is overlaid over a live display of a FOV of the mobile device s camera. The location of icon in this example represents the estimated location of Business A relative to the displayed live feed of camera imagery based on the estimated angular position of the received beacon. For example as a user moved the mobile device in the urban environment a beacon transmitted by Business A came into the FOV of the OBR of the mobile device s ORA where the FOV of said OBR coincides substantially with the FOV of the mobile device s camera identifying information was extracted from the received beacon and a graphical representation of Business A was rendered on the GUI.

In some implementations the visual representation of the beacon s source may include an icon indicating the category or type of source in addition to the source s name. For example the icon may indicate if the source is a restaurant a hotel a department store a supermarket a warehouse store a gas station a movie theater and the like. In such instances a predetermined set of icons may be used by the optical narrowcasting application to represent the different types of entities.

At operation the mobile device s camera may move e.g. pan tilt or roll and or the displayed imagery produced by the camera may be zoomed in or out. In response to the change this produces in the size and or orientation of the camera s FOV the visual representation of the source of the beacon may be updated such that its position relative to the displayed live feed imagery is always an accurate representation of the actual location relative to the real world scene of the OTA that transmitted said beacon. In some instances this may be implemented by overlaying an AR visual layer over the displayed live feed of the camera output. The AR visual layer may store the positions of AR objects representing beacons relative to each other. As the camera is moved and or zoomed AR objects representing beacons may remain anchored to this layer which is kept properly registered or aligned with the camera s live feed imagery as the camera is moved and or zoomed. In some instances the size of the displayed visual representation of the source may be increased as the camera zooms in and decreased as the camera zooms out.

In some embodiments a motion sensor may be used to determine the mobile device s absolute orientation in the direction of the optical receiver s FOV e.g. in the NESW and up down planes and a position determination device may be used to determine the mobile device s geographical position e.g. latitude longitude and altitude upon detecting a beacon. This additional information along with the beacon s estimated angular position may be stored in memory and used to map the relative position of the beacon such that it may be rendered by a GUI of an optical narrowcasting application when the beacon is no longer within the FOV of OBR or even when the optical narrowcasting application is closed and reinitialized at a later time.

As further discussed below a user may take advantage of these AR representations of sources of beacons along with a FOV AR representation of an OSR to retrieve additional descriptive information associated with each of the sources of the beacons. For example a user may tilt a mobile device such that icons representing a previously detected optical beacon are moved within an FOV AR object such that the user may select an icon corresponding to an ORA to initiate receipt of one or more optical signals corresponding to the ORA. Such example use cases are further described below.

At decision it is determined if descriptive information associated with the selected OTA source has previously been stored in an available data storage. For example it may be determined if the descriptive information is persistently stored or temporarily cached in a storage or a memory of ORA assembly . This descriptive information may have been stored during a prior user session with optical narrowcasting application . If the descriptive information is stored the information may be retrieved from storage and presented at operation .

On the other hand if the descriptive information for the OTA source is not available for retrieval from storage the mobile device may instead receive the data using an OSR of an ORA . As such at decision it is determined if an optical signal transmitted by the OTA i.e. an OST of the source is within the FOV of an OSR of the ORA. It should be noted that in most cases an optical signal associated with an entity will be transmitted from the same or substantially the same angular position as a beacon e.g. the OST and OBT are the same device or are integrated into the same OTA . For instance in the example of as Business A is within the FOV of an OSR as represented by AR FOV object it may be determined that an optical signal transmitted by the OTA associated with Business A is within the FOV of the OSR. Conversely in the example of none of the optical signals transmitted by the represented entities are within the FOV of the OSR.

If the optical signal is not within the FOV of the OSR at operation a GUI of the optical narrowcasting application may display a prompt to the mobile device s user to position e.g. tilt the mobile device such that the ORA may receive optical signals transmitted by the selected OTA. For instance in the example of if a user selects Business A the GUI may prompt the user to position the mobile device such that icon is within the FOV of FOV AR object . Additionally at operation control electronics and ORA software and or firmware may be used to control the direction from which optical signals are received by the OSR by tilting one or more tilt actuators such that the FOV of the OSR falls within the path of the desired optical signal.

In some implementations GUI may provide a control for zooming camera such that FOV AR object fits or exceeds the FOV of the camera . Such a configuration may provide an intuitive way of detecting and selecting an OTA within the aforementioned AR GUI as all visual representations of OTAs sources of OTAs displayed on the GUI will immediately be within the OSR s FOV ready for optical signal acquisition.

At operation the optical signal is received from the OTA and at operation descriptive information is extracted from the received optical signal. Particular systems and methods for receiving optical signals and extracting information from received optical signals are described in greater detail with reference to . The extracted descriptive information may include a variety of information generated by the source of the OTA. For example the extracted information may include source contact information photographic imagery videos text product listings advertisements and other information generated by the source of the OTA. In some implementations further described below the descriptive information extracted from the detected optical signal may be stored in a persistent storage for later access.

At operation the extracted descriptive information is presented to the user using a GUI of the optical narrowcasting application. In implementations extracted descriptive information may be presented using windows window controls menus icons or some combination thereof. For example in cases where different types of descriptive information are extracted e.g. video information contact information shopping information etc. the different types of descriptive information may be organized by icons or menu items that when selected present a window including the type of selected information. illustrates one such example of a GUI displaying descriptive data extracted from an optical signal received from an OTA of an entity. In this example a user may have selected the icon corresponding to Business A e.g. by a touch user interface gesture and positioned FOV AR object such that an optical signal transmitted by an OST of Business A is within a FOV of the mobile device s OSR. In this example the descriptive data extracted from the optical signal is displayed in a window and includes contact information for Business A including a physical address phone number and web address.

Although example method illustrates an example GUI method through which a user may manually retrieve optical signal information from OTA sources by selecting the OTA sources it should be noted that in alternative implementations an optical narrowcasting application may be configured such that optical signal information is automatically retrieved for all or a subset of OTAs e.g. as determined by user defined filters that transmit an optical signal that falls within the FOV of the OSR of the mobile device. For example the optical narrowcasting application may present the user with a GUI controller for enabling or disabling automatic retrieval of optical signal information as the mobile device is moved around the environment.

In some cases optical signals may carry descriptive data that takes a non trivial amount of time to retrieve e.g. a few seconds several seconds a minute a few minutes or longer . For example optical signals may carry high fidelity image data video data audio data documents with large file sizes or some combination thereof. In such cases it may be desirable to dynamically present e.g. stream data extracted from an incident optical signal while the ORA receives the optical signal and extracts remaining data. Additionally it may be desirable to provide an indication to the user that data is being downloaded or retrieved from an optical signal to ensure that the user keeps the FOV of a mobile device s OSR in place.

At decision it is determined if sufficient descriptive data has been extracted for presentation on the GUI. For example in the case where different types of data are extracted e.g. contact information video photographs etc. the extracted descriptive data may be ready for presentation if one type of data e.g. contact information has been completely extracted. As another example video data may be ready for presentation if a sufficient buffer of video data has been created such that the video data may be streamed.

If sufficient descriptive data has been extracted for presentation at operation one or more icons markers or menu items associated with the types of extracted descriptive data may be made available for presentation. For instance in the example of a video icon signal e.g. square with symbol of video camera is displayed next to the icon of the associated Business. In this example the appearance of the icon may indicate that video data is available for viewing. In some instances the icon may initially be displayed to indicate the type of data that is being retrieved even before such data is ready for presentation. For example video icon may be grayed out until enough video data is available for presentation. As also illustrated in the example GUI of a user may be presented with a control e.g. a save icon for saving or archiving data that has already been received and a control e.g. an exit icon for pausing or stopping data receipt. Alternatively all received data may be automatically archived.

At operation the mobile device receives data corresponding to user input selecting an object corresponding to a type of extracted descriptive data available for presentation. For instance in the example of a user may tap video icon or provide some other user input for selecting the video information extracted from the optical signal transmitted by the OTA of Business A. At operation the type of extracted descriptive data is presented on the GUI.

By way of example illustrates the GUI displaying a window with an advertising video for Business A that may be presented after a user touches video icon . In this case the video is overlaid on the GUI in a window and begins playing after the user selects a playback control. During video playback icon may continue blinking or the GUI may provide some other indication that data is still being retrieved from the optical signal transmitted by an OTA of Business A.

As would be appreciated by one having skill in the art the navigational controls illustrated with reference to need not be implemented in the precise form illustrated therein and in some instances other user interface inputs such as touch user interface gestures and or voice commands may be used in place of the controls. For instance in the example of photo galley window swipe user interface gestures may be used in place of controls to navigate the photograph collection.

As illustrated by the example GUI of as part of the process of presenting the optical signal information received from an OTA of an entity the GUI may also present controls for communicating with the entity associated with the OTA e.g. the Order control of . As such selection of one or more of these controls may cause the mobile device to generate information through the optical narrowcasting application that is modulated onto an optical beacon and or an optical signal that is transmitted from the mobile device s OTA to an ORA of the entity.

In response to the user input data requesting additional data from the source of the OTA may be generated at operation . For example by creating a product order request a mobile device may generate a secure transaction request to be transmitted to an ORA associated with the source of the OTA. At operation the generated data may be transferred to an OTA of the mobile device in preparation for outputting an optical signal to an ORA of the source.

At decision it is determined if the source s ORA is within the transmitting path of an optical transmitter of the mobile device. In implementations this decision may be based on the assumption that the source s ORA is located in the same or substantially the same location as the source s OTA. If the source s ORA is not within the transmitting path of the OST at operation OTA hardware software and or firmware may be used to control the pointing direction of the optical signal output by the OST by tilting one or more tilt actuators. Additionally at operation a prompt may be displayed to a user of the mobile device to position the mobile device such that the OTA may transmit optical signals to the source s ORA.

In implementations a GUI of an optical narrowcasting application of the mobile device may display an AR object corresponding to a transmitting emitting region covered by an optical transmitter of the mobile device. The displayed AR object may be displayed in a similar manner as described above with respect to example FOV AR object . Assuming the source s ORA is located in the same or substantially the same location as the source s OTA the GUI may display a prompt to the user to position the mobile device such that the visual representation of the source on the GUI is within the AR object corresponding to the optical transmitter s emitting region.

At operation the mobile device transmits the optical signal to the source s ORA. At operation the mobile device receives a response optical signal from the source s OTA. For example the mobile device may transmit an optical signal including a secure transaction request to purchase a product and receive a response optical signal including confirmation of the secure transaction request.

In some instances method may be implemented by establishing an optical narrowcasting ad hoc network between the mobile device and one or more devices of the entity including an OTA and ORA. Systems and methods for creating optical narrowcasting ad hoc network are described in greater detail in .

In the remaining examples it is assumed that the FOVs of all OBRs and OSRs are all at least as large as the FOV of the camera providing the live feed imagery for the AR display of information received from optical beacons and optical signals. When this is the case it is not necessary to utilize AR objects in the GUI to represent the FOVs of OBR or OSRs e.g. FOV AR object for the purpose of indicating to the user the angular region within which an OTA must be located in order to receive optical beacons and or optical signals from it.

As in the examples described above touching one of the icons on the mobile device s display may retrieve additional information from an OST and bring up additional graphical information and or text describing the merchandise. For example touching an icon representing the men s watch may render a pop up box with the price and detailed specifications of that watch as well as photos and videos. Additionally a magnified 3D representation of the watch could be overlaid on the live scene. This 3D representation could be manipulated using one s fingers on the mobile device s touchscreen display to zoom in or out and rotate it to any desired orientation.

As shown an optical transceiver is integrated or attached to an aircraft seat back positioned in front of the passenger above the passenger s tray table. Placement of optical transceiver in this position may facilitate reception of optical beacons and optical signals in instances where the FOV of an ORA of the mobile device is positioned on the backside of the mobile device i.e. on the same side as the mobile device s forward facing camera . Similarly it may facilitate transmission of optical signals from an OTA of the mobile device to optical transceiver . For example the passenger may hold the mobile device in his her hand such that the mobile device s display is visible while the ORA of the mobile device receives optical signals from transceiver . However in other implementations the transceiver may alternatively be integrated into an armrest of the passenger s seat overhead in the ceiling above the passenger or some other location.

As illustrated in the example of a live camera feed of the mobile device is overlaid with a visual representation e.g. icon and or text representing optically transmitted information provided by the airline to the passenger during the flight using optical transceiver . For example icon and text illustrated in as in flight information may be displayed as a result of the transceiver using its OBT to transmit to the ORA in the mobile device an optical beacon containing identifying information associated with said transceiver. In this example the portion of the identifying information displayed in the form of the visual representation identifies the transceiver as a source of in flight information. Selecting e.g. by a touch user interface gesture may cause the mobile device to download and display via GUI additional information received from the optical signal transmitted by transceiver . In the example of selection of the in flight information icon causes the GUI to display a window including menu options available for selection. For example the menu options may include an in flight entertainment option an in flight meals option a connecting flight information option a restaurants at destination airport option and other options. In the example of selection of the connecting flight information option may display information on connecting flights received from the optical signal. A user may subsequently cancel this option and bring back the previous menu. For example a user may navigate to the previous menu and select the restaurants at destination airport option to bring up a series of menus pertaining to airport restaurants.

In some instances an optical narrowcasting ad hoc network may be established between the user s mobile device and transceiver installed on seat back . This may be particularly advantageous for example where the passenger transmits commands to transceiver requesting transmission of particular content e.g. movies over an optical signal.

Use of optical narrowcasting in this example environment may be particularly advantageous as the passenger s mobile device may transmit and receive optical signal information even when it is placed in airplane mode to comply with FAA regulations relating to RF signal interference. In addition to using optical narrowcasting to receive and present optical beacon and optical signal information from an optical transceiver installed in the airplane s seatback a passenger may use optical narrowcasting to receive optical beacons and optical signals e.g. from businesses from the ground through an airplane window.

As noted above in addition to mobile devices the optical narrowcasting technology disclosed herein may be implemented using vehicles such as buses and automobiles. GUI methods of implementing this technology in automobiles are further discussed below. is a flow diagram illustrating an example of one such GUI method of implementing optical narrowcasting in a vehicle. Method in various embodiments may be implemented by a vehicle equipped with an ORA as discussed above with reference to . The vehicle may additionally include a dashboard system including the necessary hardware e.g. camera display GPS storage etc. software and or firmware to visually present an optical narrowcasting GUI to the vehicle occupants. In some instances the optical narrowcasting GUI may be provided as a component of a navigational map interface of the vehicle.

Following the method of an ORA of the vehicle may automatically retrieve and filter information received from multiple OTAs. The filtered information of interest may be presented by a display on the vehicle s dashboard. The information of interest may be filtered during extraction and storage e.g. received optical signal information is only extracted and stored for OST that transmit information of interest during presentation e.g. a subset of stored information is made available for presentation or some combination thereof. will be described with reference to which illustrate example displays of an optical narrowcasting GUI that may be provided by a vehicle to a driver and or passenger interested in purchasing real estate.

At operation a display of the vehicle s dashboard system presents an optical narrowcasting GUI including controls for setting filters for extraction and storage of data received from OTA by the vehicle s ORA. At operation the vehicle s dashboard system receives data corresponding to user input at the GUI selecting filters for extraction and storage of information received from OST. For example a user may select controls for specifying categories and subcategories of information that are of interest and or not of interest to the user. For example a user may specify that only restaurants gas stations and houses for sale are of interest to the user. As such in this example only optical signal information that falls into one of these categories e.g. as determined by the ORA s extraction of identifying information from an optical beacon may be stored by the vehicle s dashboard system. As a further example for a given category of information e.g. restaurants a user may specify additional filters e.g. pricing cuisine hours etc. such that only optical signal information satisfying these parameters is stored by the vehicle s dashboard system. Alternatively in some embodiments operations may be skipped all information transmitted by OSTs may be extracted and stored and the filtering of information of interest may occur during presentation of the information to the user.

At operation the ORA of the vehicle receives information transmitted by OTAs. For example the ORA of the vehicle may receive optical beacons and or optical signals containing information about businesses houses for sale and the like. At operation the ORA of the vehicle extracts identifying data from received optical beacons and optionally other data from optical signals. For example the identifying data may specify a business name and business category. Depending on the extracted identifying data at decision it may be determined by software on the vehicle s dashboard system whether or not the data transmitted by the OTA satisfies the filters specified by the user during operation . If the data transmitted by the OTA does not satisfy the specified filters the ORA of the vehicle may disregard e.g. not extract or store data received from the OTA. In some implementations it may be necessary to extract optical signal data in addition to optical beacon data from an OTA to make a determination of whether the data transmitted by the OTA complies with the filters specified by the user during operation . In such implementations operation includes the vehicle ORA extracting data from the optical signal and decision includes comparing the extracted optical signal data against the filters.

At operation all or a subset of the stored optical beacon data and optical signal data is presented on the display of the vehicle s dashboard. illustrates one such example presentation of an optical narrowcasting GUI on a display of a vehicle s dashboard. In this example information is retrieved from OTAs broadcasting for sale information relating to homes or other real estate. For example prior to the drive a user may have set filters for retrieving and storing for sale information and other information broadcast by OTAs meeting the filters. For example along with specifying that homes for sale were of interest the user may have specified additional criteria such as pricing criteria bedroom number criteria bathroom number criteria square footage criteria location criteria or other criteria. As such during the drive detailed information may have been received and stored for each house meeting the user specified criteria.

As illustrated in the example of the GUI shown on the dashboard display overlays AR objects and associated with respective homes over a live camera feed of the vehicle. In this example each AR object is a visual representation of optical beacon and or optical signal information extracted from an OTA associated with a home for sale and is overlaid based on the respective angular positions e.g. in the direction of the home from which they were received by the vehicle s ORA from each home s OTA. Additionally the AR objects display extracted information of interest such as price and number of rooms. Although in the example of an AR GUI is illustrated for presenting the received optical beacon data and optical signal data in some instances alternative GUIs may be used to present the data. For example the extracted data may instead by presented as an overlay of a virtual representation of a street view or as an overlay of an overhead map view of the car s position e.g. as generated using a navigational map interface of the vehicle dashboard system .

With reference again to method during or before presentation of the optical beacon and or optical signal data on the display of the vehicle dashboard the user may select filters for specifying what stored data is presented. As such at operation data may be received corresponding to user input at the GUI selecting filters presenting the stored data. In response at operation the GUI may present a subset of the stored data based on the selected filters.

Referring now to the example of a user may select price and or room filters such that the home for sale represented by AR icon is filtered out of view. For example the user may filter out homes with a price greater than 600 k and or homes having more than four bedrooms.

In the example of a user in the vehicle selects an icon associated with a home for sale. In response more detailed information associated with the home is presented to the user in a window including a menu of options.

Although example method has been described with reference to vehicles it should be appreciated that in other implementations some or all of the steps of method may be implemented in mobile devices or other devices. For example a user of a smartphone may run an optical narrowcasting application that may be used to set filters for extraction and storage of data extracted from optical beacons and or optical signals automatically store extracted data satisfying filter parameters and set filters for specifying what data is presented by a GUI. In addition in some instances the optical beacon data and or optical signal data extracted and stored by the user s vehicle may be transferred to the user s mobile device e.g. via Bluetooth or other suitable connection for similar presentation using an optical narrowcasting application installed on the user s mobile device.

Although the example of illustrate one exemplary use case in which the disclosed optical narrowcasting technology may be utilized with vehicles a variety of other uses are possible. For example in some implementations vehicles may receive optical transmissions from advertising billboards equipped with OTAs associated with businesses such as restaurants. Following the GUI methods described above for example receipt of optical beacon and or optical signal information from the OTA installed on the advertising billboard may cause a GUI on the vehicle s dashboard to display icons windows or other information associated with the business. In some instances an ad hoc network may be established.

In some implementations road signs such as guide signs e.g. route markers warning signs e.g. left turn ahead sign regulatory signs e.g. stop signs and yield signs and other signs may be equipped with an OTA that transmits optical beacon and or optical signal information to oncoming traffic. This information may be received by vehicles equipped with an ORA and presented to a user via the vehicle s dashboard. For example an optical transmission from a road sign may warn of upcoming road repairs. This optically transmitted information may be made available to a navigational map interface presented by the vehicle s dashboard to adjust estimated travel times and or remap routes.

Referring again to and as alluded to previously augmented reality component may permit recording of the augmented reality scene and embedding in a resulting media file any optically narrowcast content i.e. information received by one or more ORAs from one or more OTAs. Such embedded content received by ORAs from OTAs may include identifying information extracted from one or more optical beacons information extracted from one or more optical signals and or horizontal and or vertical position coordinates within a recorded scene of one or more of the OTAs that sent the embedded optically transmitted content. If desired the user may disseminate the resulting recorded scene containing embedded optically narrowcast content via e.g. social media outlets to be accessed by others. This embedding technique can allow optically narrowcast information to be accessed in a non real time manner not only by the user e.g. at a later time but by social media subscribers or others e.g. on social media sites which may provide an enhanced social media experience for social media subscribers. It may also significantly increase the number of viewers of optically narrowcast information e.g. advertisements and new opportunities for social media services to generate online advertising revenue may result. Accordingly augmented reality component may be thought of as an enhanced media component. In some embodiments a separate and or distinct enhanced media component may be utilized to embed optically narrowcast information into one or more media files. In some embodiments control electronics of an ORA e.g. control electronics of may be used to effectuate the embedding of information or data.

At operation at least one media representation e.g. video imagery digital photographic imagery and or recorded audio of a real world scene may be received. Receipt of such a media representation can occur at an augmented reality enhanced media component or at control electronics of an ORA. Referring again to user device may comprise one or more cameras and or one more sensors . The one or more cameras may be used to capture a media representation of the real world environment such as one or more images of said real world environment. In some embodiments the one or more images may be still images photographs. In some embodiments a series of images may comprise frames of a video or animated image of the real world scene. In some embodiments audio or other media representation of the real world environment may be captured using at least one of the one or more sensors . For example one of one or more sensors may be a microphone adapted to capture sound audio sensed in conjunction with the capture of the at least one image representative of the real world scene. In some embodiments content from other sensors with which ORA and or user device may be interfaced can be received and used to contribute content to the media representation of the real world scene. For example user device may accept audio transmitted via one or more audio input ports from one or more co located or remotely located microphones or audio transducers. In some embodiments the aforementioned media representation of the real world environment may be captured during substantially the same time interval as that during which the optical narrowcasting content that will be embedded in it is captured. In some embodiments in which the aforementioned media representation of the real world environment is captured by a camera the camera imagery may be captured during substantially the same time interval as that during which the optical narrowcasting content that will be embedded in it is captured. Moreover the propagation directions from which said camera can receive light to form imagery may coincide substantially with the propagation directions from which optically narrowcast content can be received by the ORA that provides the optically narrowcast content to be embedded. As such the horizontal and vertical location within the captured imagery corresponding to the horizontal and vertical location in the real world scene of each OTA that contributes optically narrowcast content i.e. to be embedded may be accurately computed e.g. based on a location mapping function or lookup table from the OTA location data provided for that OTA by the ORA.

At operation optically narrowcast content may be embedded within or as part of at least one media representation to generate an enhanced media dataset. An augmented reality enhanced media component or control electronics of an ORA may perform this embedding of optically narrowcast content. Various methods of embedding such information data can be utilized in accordance with embodiments of the present disclosure. For example steganography techniques may be used where optically narrowcast content may be embedded in a cover medium which can be image s video s and or audio captured by the one or more cameras and or one or more sensors . In some embodiments digital watermarking techniques may be used to insert a digital signal or pattern representing optically narrowcast content into digital media content such as captured image s and or audio representing an associated real world scene. Still other techniques such as least significant bit insertion discrete wavelet or cosine transformation or other techniques may be used. In some embodiments a combination of techniques may be used. For example digital watermarking techniques may be utilized to embed identification information into captured video. As digital watermarking may be typically used for identifying an owner of a work embedded identification information such as source information GPS coordinates and the like may be appropriately addressed by digital watermarking. For data received or extracted from an optical signal e.g. data that may include other media itself that may be more comprehensive or voluminous than data received or extracted from optical beacons steganography techniques may be utilized where the media representation of the real world environment e.g. a video itself may be temporally modulated. It should be noted that embedded information may be broken up between two or more images or sets of captured media representations.

By virtue of embedding optically narrowcast content into captured media content a single combined dataset can be generated that combines photographic video and or audio representations of the real world environment with data that has been received from optical beacons and or optical signals concurrently received from one or more OTAs including information regarding horizontal and vertical positions of detected OTAs within an FOV of an ORA. In some embodiments this single dataset may be generated in a standardized format. Optionally other data can be received and or sensed and embedded such as a timestamp a latitude longitude and or altitude of a device in which an ORA is located or with which it is associated such as user device . Such a combined dataset could be uploaded or live streamed to other devices or onto a data network such as the Internet via WiFi or other data connections and or stored as a file for later use. The aforementioned dataset can be referred to generally as signal enhanced media SEM particular examples of which may be referred to as a signal enhanced photo SEP a signal enhanced video SEV and signal enhanced audio SEA depending on the type of media with which the optically transmitted signal beacon information is combined. It should be noted that while new modified audio image and or video formats may be developed and utilized to include embedded optical beam information existing formats may be utilized as well. It should be noted that enhanced media component may be existing software hardware resident in user device for generating audio image s and or video s captured by the one or more cameras and or the one or more sensors

At operation an enhanced media dataset such as the aforementioned SEM may be received by a user device. The user device may be any device capable of rendering or presenting media content such as a smartphone laptop PC tablet PC etc. The enhanced media dataset may be received from a server data repository and or any mechanism device or system used to receive and or store an enhanced media dataset. For example software or applications used to view photos and videos and or listen to audio could be upgraded to provide the capability to conveniently view the full content of one or more SEMs. At operation the existence of optically narrowcast content embedded within or as part of the enhanced media dataset may be detected. At operation some or all of the optically narrowcast content may be extracted. At operation some or all of the optically narrowcast content may be presented e.g. displayed in conjunction with a presentation of some or all of the media representation portion e.g. the media representation of the real world environment of the enhanced media dataset. It should be noted that the manner of presentation can vary. For example a user may be presented with the option of viewing a photo or video captured by a camera of a real world scene by itself or with symbols and or identifying text imagery superimposed on the locations in said photo or video corresponding to the actual locations relative to horizontal and or vertical locations in the photographic or video imagery of OTAs from which information was received and embedded in said captured photo or video. In some embodiments a symbol may be presented as a selectable icon or control that may be selected by a viewer to bring up a pop up window or other graphic containing information transmitted by a particular OTA associated with that symbol. In some embodiments such a selectable icon may be presented in conjunction with the presentation of audio that was captured during substantially the same time interval as that during which embedded optically narrowcast content was captured.

It should be noted that if media captured by a user device e.g. a camera or a microphone has been stored as a media file a media player utilized to present the media to the user of the user device can allow any and all standard or non signal enhanced functions to be performed when playing back the media. It should be noted that the captured media can be presented e.g. as streaming media or non real time media. Additionally the media player can provide the ability for the user to pan zoom or otherwise move around within a captured photographic or video media representation of a real world environment to bring overlaid i.e. superimposed embedded optically narrowcast content received from one or more OTAs into view commensurate with the horizontal and vertical location s of said OTAs relative to said captured photographic or video representation. Software to perform these functions could also be installed on any other devices to be used to view live streamed and or pre recorded media containing embedded optically narrowcast content successfully received from one or more OTAs whether or not the device used to consume the SEM itself actually produced the SEM itself. That is any information received by ORAs in the form of optical beacons and or optical signals may be embedded in media datasets produced by user devices other than ORAs e.g. cameras and microphones and would be available to anyone who receives such media datasets either in the form of a live stream or as a pre recorded media file.

It should be noted that the embedding of optically narrowcast content into media can be automatically accomplished. For example operation of may occur automatically upon detecting the existence of optically narrowcast content within the FOV of an optical receiver during presentation of an augmented reality experience presented to a user see . In some embodiments augmented reality component may present an option to a user of user device to embed optically narrowcast content rather than automatically embedding such content in one or more media representations of the real world scene captured in the augmented reality experience. In some embodiments a user may set parameters regarding what information to embed and under what conditions to embed the information. For example user device may present a GUI to a user setting forth one or more options or filters that specify conditions or parameters defining conditions under which optically narrowcast content is embedded in an image or video. For example parameters may specify that information may be embedded when an OTA is within a specified distance from the user user device if the information is identified as being a particular type of information if an OTA is identified as being a particular type or associated with a specified retailer business etc.

Some example applications highlighting the uses and advantages of SEM are discussed herein. As a first example consider a retail business that uses optical narrowcasting to provide information to customers and potential customers in the vicinity of its brick and mortar store. The retail business may use one or more OTAs inside and or outside its brick and mortar store to provide information such as the name street address and phone number of the retail business store as well as advertising media links to its website Twitter page Facebook page etc. In the event that a user utilizes an ORA equipped smartphone to take a video either inside or outside the store with one or more of the store s OTAs located within the FOV of the ORA the optically narrowcast information received by the ORA can be embedded into the video to produce a SEV. When this SEV is shared via social media e.g. uploaded to YouTube Facebook or Instagram the store can benefit from an increase in the number of people who have access to the information transmitted by the brick and mortar store which may encompass additional information not discoverable available absent being present at the brick and mortar store .

Consider another example where an SEV is uploaded to YouTube . A YouTube server can be configured to detect the presence of optically narrowcast content embedded in an uploaded SEV file and would provide convenient means for people viewing the SEV to display this embedded content. It should be noted that the embedding of optically narrowcast content need not prevent the addition embedding of other information to a SEM. For example a SEM creator may also embed additional information into the SEV such as links to the SEM creator s own social media accounts. The latitude and longitude of the location at which an SEM was recorded may also be automatically embedded thereby allowing people to find that location online using a location based search. The SEM creator s name or other identifier such as a social media account name associated with the creator may be included in the SEM allowing other SEMs the SEM creator has uploaded to YouTube to be conveniently accessed. For SEMs that become extremely popular i.e. go viral any embedded information can be accessed by a large number of viewers. This represents a powerful form of advertising for the store or any other person or organization whose information has been embedded in the SEM. Embedded information which can also be considered a form of metadata may further be encoded with identifying information that can be used to search for and or identify SEM associated with a particular source of embedded optically narrowcast content e.g. a retail business source entity person etc. that who owns or is otherwise associated with one or more OTAs . In this way such a source can search for and access popular e.g. viral SEMs that are associated with itself himself herself for use in enhancing their own advertising for use in an advertising campaign etc. To that end such metadata may be associated with one or more forms of digital media rights DRM . For example a SEM creator can institute DRM in a SEM that he she creates. For example an information source can embed DRM information mechanisms in transmitted information such that e.g. usage of a video recording made within the confines a brick and mortar store can be controlled by the brick and mortar store associated business entity.

As another example of the social media related benefits of embedding optically transmitted information in media consider the use of SEM by individuals for business and or social networking purposes. For example two persons who have met may wish to exchange contact information but neither have business cards. However each person may have a smartphone equipped to send and receive information optically e.g. each person s respective smartphone may have an OTA and an ORA. In order to connect on a social media platform the first person may activate his her OTA and configure it to transmit his her contact information including one or more of his her social media usernames. The second person may capture a video or photo of the first person with his her smartphone s ORA activated and capable of detecting and receiving the first person s optical beacons and or optical signals. The second person s smartphone may generate a SEM e.g. a SEV or SEP of the first person which incorporates or embeds the first person s contact information e.g. name phone numbers social media usernames etc. into the SEM.

In some embodiments the SEM may be uploaded to the second person s social media platform server s database s for storage. In some embodiments the second person s smartphone e.g. an augmented reality enhanced media component can extract the first person s contact information and upload that contact information to the second person s social media platform server s database s . As evidenced by this example the entirety of the SEM need not be uploaded stored. In some embodiments a user may wish to locally store identification and or descriptive data without the corresponding media content while storing the SEM i.e. the optically narrowcast content along with the captured media to a social media platform server database or other data repository.

In some embodiments tagging media with information regarding known subjects can be accomplished using optical narrowcasting. For example an optical narrowcasting enabled device may simultaneously record information transmitted optically by each member of a group of people by taking a single photo or video of the group with each person using his or her OTA equipped user device e.g. a smartphone to transmit desired information into the ORA of the person taking the picture or video. An important advantage of this method is that the horizontal and vertical position of each OTA within the recorded imagery would also be captured so that the each person s recorded video or photographic image s could be correctly associated with the information he or she transmitted optically.

For example illustrates a scenario in which a user may utilize a user device e.g. smartphone to capture an image or video of a group of individuals e.g. persons and . Each of persons and may transmit his her respective identification and or descriptive data such as his her name contact information or other data using his her respective OTA equipped user device e.g. user devices and . Each of user devices and may have respective OTAs and or ORAs one example of which is . For clarity other respective OTAs ORAs are not labeled in but are understood to be present. The OTAs may transmit one or more optical beacons and or optical signals that can be received by an ORA of user device not shown here but illustrated for example in . User device may present a media capture GUI to the user of user device on display . The media capture GUI may be presented in accordance with usage of one or more cameras not shown here but illustrated for example in or as an augmented reality experience with a real world scene captured using one or more cameras and created via augmented reality enhanced media component . The media capture GUI augmented reality experience may provide the user with options to capture one or more types of media e.g. a photo video and or audio. The media capture GUI augmented reality experience may provide the user with one or more options to capture a SEM set an operating parameter such as flash etc. In some embodiments the capturing of one or more types of media can automatically include capturing optically narrowcast content without the need to specify an option to capture a SEM. Upon capturing an image in this example a photo all or selectable filterable information transmitted optically by one or more OTAs e.g. the four OTAs operated by the four persons depicted in may be embedded in the resulting SEP. Such information may maintained in the SEP extracted for use storage apart from the SEP etc.

In this way a new dimension to social networking may be created that may likely have great appeal to many users. Information about people in photographs and videos could be conveniently received optically and automatically stored in image and video files without the need for extra processing and or errors associated with visual facial recognition methods. After sharing these files using a social media service the embedded information could be conveniently accessed by users. Additionally information received from OTAs mounted on nearby fixed structures e.g. shops restaurants billboards and homes and vehicles e.g. buses trucks and cars could also be automatically incorporated into shared photos and videos. The social media service can also provide a search capability allowing users to search for shared media with embedded content relating to persons businesses geographical locations of interest etc. If desired any user could use privacy settings to limit the ability of strangers to perform searches for information regarding the user create DRM associated with created SEM etc.

For example illustrates an example view of a SEP taken in accordance with example scenario illustrated in . As illustrated in the resulting SEP may be displayed on a social media platform webpage presented to a user on e.g. a user device such as a smartphone. An appropriate user interface of the social media platform webpage may include options to download media alone without embedded optically narrowcast content e.g. an option to download media . The user interface may provide an option to download the entirety of SEP vis vis SEM download option . The user interface may provide an option to tag each of the persons in the SEP using one or more aspects of the embedded information e.g. the embedded name information associated with each person and transmitted by each person s respective OTA. This can be accomplished via an ID option . The user interface may provide an option to download solely the embedded optically transmitted information in this case name and contact information of each person in the SEP via OPTI INFO option . Such embedded information may be extracted and stored locally e.g. in a digital address book.

Still another example may involve utilization of embedded optically narrowcast content as a pointer or bookmark to additional and or other information or content such as narrowcast content. As previously discussed optical beacon information as well as optical signal information may be transmitted by an OTA and received by an ORA. In some embodiments optical beacon information may be embedded as optically narrowcast content into SEM such that a user viewing the SEM in the same or proximate location to that in which the optically narrowcast content was obtained may at that time receive optical signal information transmitted by e.g. the OTA that transmitted the embedded optically narrowcast content. In some embodiments the additional and or other information or content may be content associated with and or available due to proximity to the location in which the embedded optically narrowcast content was obtained. Such additional and or other information or content may be received by the user via another communication channel e.g. WiFi or Bluetooth channel. In this way a user may filter and or otherwise experience the ability to selectively receive information or content. In this way memory of a user device may be reserved.

Additional example applications of the optical narrowcasting technology disclosed herein are discussed below.

In various embodiments the optical narrowcasting technology disclosed herein may be applied to a variety of business environments including but not limited to 

Selling or leasing optical narrowcasting hardware and software directly to businesses and other organizations for use in their marketing campaigns. For example a company could purchase optical narrowcasting hardware and software to be installed at their brick and mortar retail stores. This could be used to optically transmit product information store hours and other information of interest to potential customers.

Selling or leasing optical narrowcasting hardware and software to out of home advertising companies or partnering with such companies to sell or lease such hardware and software to other businesses for use in their marketing campaigns. For example a billboard company could supply optical narrowcasting hardware to companies for use on billboards storefront displays and other locations where out of home advertising is used.

Selling portable device based optical narrowcasting hardware directly to individual consumers or to companies selling smartphones and similar devices to consumers. For example smartphone cases with optical receivers and or optical transmitters built into them could be sold directly to consumers. Or optical narrowcasting equipment could be sold to manufacturers to be incorporated into smartphones and other portable devices e.g. tablet computers e book readers etc. .

Charging fees to sellers of various products for optically transmitted ads that direct traffic to the sellers websites. For example optical narrowcasting equipment could be set up in various outdoor locations. Ads could be transmitted from these locations which could be received by individuals using portable device based optical receivers. These ads could contain links that when clicked on may direct the portable device user to product related websites where he could obtain product information and or purchase specific products. The sellers of such products could for example be charged an advertising fee for each instance of traffic being directed to their websites or for each product sale resulting from such traffic. Additionally optically transmitted ad content could be embedded in videos and photos recorded by portable device users and then uploaded or livestreamed to one or more social media websites. Other individuals viewing such videos or photos online may have the opportunity to click on such embedded ads to view the ad content and or be redirected to sellers websites. Companies advertising their products via such embedded ads could be charged advertising fees on a pay per click pay per sale or similar basis.

Creating new social media sites and apps based on the sharing of content obtained via optical narrowcasting and then generating income though online ads appearing on these sites and apps. For example a social media app could be created that may allow individuals to conveniently use their smartphones and other portable devices to create and share videos and photos containing embedded optically transmitted content. Companies selling various products could be charged fees in exchange for ads viewed by users of the social media app.

The optical narrowcasting technology disclosed herein may also be applied to a variety of social media environments.

In various embodiments the presently disclosed optical narrowcasting technology provides a new way to disseminate digital information. Its unique characteristics make important contributions to social media and therefore offer great opportunities.

In various embodiments the presently optical narrowcasting technology is its highly localized nature. The term localized here refers to the fact that for this technology to successfully transmit data from one location to another it utilizes on some embodiments a direct or indirect e.g. diffusely reflected optical path between the transmitter and receiver with a sufficiently small path length to prevent excessive bit errors. This characteristic can be taken advantage of in a social media context to obtain information that might otherwise be difficult or impossible to obtain regarding the location of people sending the information.

For example consider the case of a store in a shopping mall that wants to use a social media app to collect feedback from customers regarding various products it s selling. But it only wants people who are currently inside the store to be able to leave feedback because such people are much more likely to be customers who are interested in and knowledgeable about the store s products. One potential solution is to use the location sensing feature available in most smartphones and other portable devices. However the information provided by the location sensing feature may not be sufficiently accurate to reliably determine whether people leaving feedback are actually in the store. They may for example be just outside the store or in a different store directly above or below the store that is collecting the feedback. Another potential problem is that many people may not have the location sensing feature activated in their portable device. Or even if they do have it activated they may not wish to give the store s feedback collection app permission to access their location information. Similar problems would prevent WiFi from being used to limit feedback collection to in store customers. WiFi signals pass through walls floors and ceilings. Additionally many customers may not be willing to log into the store s WiFi system.

These problems could be eliminated by using one or more optical receivers mounted in the ceiling of the store to collect customer feedback. The field of view FOV of the receivers can be designed to only pick up information optically transmitted by people actually in the store. In addition optical information does not pass through walls floors or ceilings. Using an array of receivers detailed information about where people are within the store could also be obtained. This could be used to provide accurate navigation within the store with a search feature to help people locate specific products they re interested in.

The localized nature of the optical narrowcasting technology in some embodiments could also be used to motivate people to visit a particular geographic location for business purposes or otherwise. For example a chain of retail stores could use social media to advertise a contest with valuable prizes. But to enter the contest a person may be required to visit one of the chain s store and transmit his or her contact information to one of the store s optical receivers using the optical transmitter controlled by a social media app in his or her smartphone or other portable device. As in the previous example the optical narrowcasting technology may provide superior localization relative to what could be achieved using WiFi or built in location sensors.

As another example of an application taking advantage of the localized nature of optical narrowcasting consider a new form of travel related social media service that may allow people to easily document trips they ve taken and share that information with their online friends. The service itself may be given a descriptive name such as Placebook. The company providing the service may establish a worldwide network of optical receivers at convenient locations such as parks museums restaurants hotels airports train stations etc. A subscriber could use his smartphone or other portable device to find nearby receivers. Once they ve found one they could to go to its location and use their smartphone to optically transmit their identifying information to it. This could be done without the need for either a cellular network or WiFi. Besides their identifying information users could also transmit relevant text photos and or video imagery. The optical receiver could also be equipped with a camera which it may use to record photographs or video of subscribers while they are transmitting their information.

In various embodiments all of this information including any photos or videos recorded by the Placebook receiver may be stored on the subscriber s Placebook page along with the location of the receiver and a timestamp providing a record of the subscriber s travels. This information could be shared with the subscriber s Placebook friends and or with other subscribers so travelers could compare notes on different travel destinations. The information may be fully searchable by date location key words etc. The Placebook receivers could be installed and paid for by the company providing the service. Additionally other companies organizations or communities could benefit by sponsoring receivers which may attract Placebook subscribers to their locations. Revenue could also be generated via ads viewable by users of the social media service.

Another characteristic of the presently disclosed optical narrowcasting technology is that in some embodiments it can more easily provide privacy and anonymity to its users than other forms of digital communication currently in use. Many current users of social media are sufficiently concerned about privacy that they have a strong preference for social media technology that preserves as much privacy as possible.

Consider a person who is simply interested in receiving information. Using a smartphone equipped with an optical receiver she will be able to receive information from any nearby optical transmitter as long as there is an unobstructed line of sight or indirect diffuse propagation path between the transmitter and the receiver and the range from the transmitter to the receiver is low enough to provide a sufficiently high signal to noise ratio. She will be able to receive such signals without needing to log in to a WiFi network or use his cellular connection. In fact She will be able to receive data even when his phone in airplane mode . Thus people who only want to receive data can do this while remaining anonymous. Even for someone who also wants to send data a high degree of privacy can be achieved. The primary reason for this is that the beam transmitted by an optical transmitter can be made quite narrow if desired. Thus only receivers within this narrow beam width will be capable of receiving information. This is in contrast to signals sent using wireless service WiFi and Bluetooth which are omnidirectional. If an even higher level of security in transmitting data is desired encryption can be used.

An appealing characteristic of the optical narrowcasting technology disclosed herein is that it can serve as an effective substitute for conventional signage and as a new medium for personal expression. A homeowner can install an optical narrowcasting transmitter on the side of his house. He could then transmit information regarding his business to passersby without violating local ordinances. People could be interested in installing optical transmitters on their homes for such non business purposes as uncensored personal expression declaring support for particular political candidates advertising free kittens announcing a neighborhood barbecue transmitting a new music composition or a personal video.

A characteristic of the optical narrowcasting technology as it relates to social media in some embodiments is the capability it provides to automatically embed information received from an optical transmitter into videos or photographs captured by smartphones or other portable devices. This capability could add a new and powerful dimension to social media by greatly increasing the potential audience size for any given message transmitted via optical narrowcasting. The best way to understand this is to discuss some examples.

As an example of the social media related benefits of embedding optically transmitted information in videos and photographs we consider the use of this technology by individuals for business or social networking purposes. Suppose two strangers Bob and Susan are seated next to each other on a commercial airliner and have struck up a conversation during their flight. At the end of the flight they agree to keep in touch. Neither of them have business cards but they both have smartphones equipped to send and receive information optically. To connect with Susan on social media Bob may simply activate his optical transmitter setting it up to transmit his contact information including one or more of his social media usernames. Susan could then take a video or photo of Bob with her phone s optical receiver activated and with his phone s optical transmitter within the receiver s FOV. Her phone may then create an SEV or a signal enhanced photograph SEP of Bob which may incorporate Bob s contact information e.g. name phone numbers social media usernames etc. into the image file.

All of this information including the video or photo itself could then be automatically uploaded to Susan s account on a social media service providing the capability of storing and sharing SEPs and SEVs. The same method could be used to simultaneously record information transmitted optically by each member of a group of people by taking a single photo or video of the group with each person using his or her smartphone to transmit the desired information into the optical receiver of the person taking the picture or video. An advantage of this method is that in some embodiments the horizontal and vertical position of each optical transmitter within the recorded imagery may also be captured so that the each person s recorded video or photographic images could be correctly associated with the information he or she transmitted optically.

In some embodiments the above features may be implemented in a new social media service rather than utilize existing social media platforms e.g. Facebook . For example a new social media service could be created that may be devoted to sharing SEPs and SEVs rather than conventional photos and videos.

In some embodiments the new social media service discussed above could be given an appropriate name such as Optigram and could be capable of displaying and extracting embedded information from SEPs and SEVs. This may provide a new dimension to social networking having great appeal to many users. For the first time information about people in photographs and videos could be conveniently received optically and automatically stored in image and video files. After sharing these files using the social media service the embedded information could be conveniently accessed by users. Additionally information received from optical transmitters mounted on nearby fixed structures e.g. shops restaurants billboards and homes and vehicles e.g. buses trucks and cars could also be automatically incorporated into shared photos and videos. The social media service may also provide a search capability allowing users to search for shared media with embedded content relating to persons businesses geographical locations of interest etc. If desired any user could use privacy settings to limit the ability of strangers to perform searches for information regarding himself. 

Advertising revenue could be generated by existing methods and or by optically transmitted ads embedded in uploaded photos and videos. The latter category of ads could gain further exposure and therefore generate further revenue whenever users provide links to them on other social media sites or re upload them to such sites.

As used herein the term module might describe a given unit of functionality that can be performed in accordance with one or more embodiments of the present application. As used herein a module might be implemented utilizing any form of hardware software or a combination thereof. For example one or more processors controllers ASICs PLAs PALs CPLDs FPGAs logical components software routines or other mechanisms might be implemented to make up a module. In implementation the various modules described herein might be implemented as discrete modules or the functions and features described can be shared in part or in total among one or more modules. In other words as would be apparent to one of ordinary skill in the art after reading this description the various features and functionality described herein may be implemented in any given application and can be implemented in one or more separate or shared modules in various combinations and permutations. Even though various features or elements of functionality may be individually described or claimed as separate modules one of ordinary skill in the art will understand that these features and functionality can be shared among one or more common software and hardware elements and such description shall not require or imply that separate hardware or software components are used to implement such features or functionality.

Where components or modules of the application are implemented in whole or in part using software in one embodiment these software elements can be implemented to operate with a computing or processing module capable of carrying out the functionality described with respect thereto. One such example computing module is shown in . Various embodiments are described in terms of this example computing module . After reading this description it will become apparent to a person skilled in the relevant art how to implement the application using other computing modules or architectures.

Referring now to computing module may represent for example computing or processing capabilities found within desktop laptop notebook and tablet computers hand held computing devices tablets PDA s smart phones cell phones palmtops etc. mainframes supercomputers workstations or servers or any other type of special purpose or general purpose computing devices as may be desirable or appropriate for a given application or environment. Computing module might also represent computing capabilities embedded within or otherwise available to a given device. For example a computing module might be found in other electronic devices such as for example digital cameras navigation systems cellular telephones portable computing devices modems routers WAPs terminals and other electronic devices that might include some form of processing capability.

Computing module might include for example one or more processors controllers control modules or other processing devices such as a processor . Processor might be implemented using a general purpose or special purpose processing engine such as for example a microprocessor controller or other control logic. In the illustrated example processor is connected to a bus although any communication medium can be used to facilitate interaction with other components of computing module or to communicate externally.

Computing module might also include one or more memory modules simply referred to herein as main memory . For example preferably random access memory RAM or other dynamic memory might be used for storing information and instructions to be executed by processor . Main memory might also be used for storing temporary variables or other intermediate information during execution of instructions to be executed by processor . Computing module might likewise include a read only memory ROM or other static storage device coupled to bus for storing static information and instructions for processor .

The computing module might also include one or more various forms of information storage mechanism which might include for example a media drive and a storage unit interface . The media drive might include a drive or other mechanism to support fixed or removable storage media . For example a hard disk drive a solid state drive a magnetic tape drive an optical disk drive a CD or DVD drive R or RW or other removable or fixed media drive might be provided. Accordingly storage media might include for example a hard disk a solid state drive magnetic tape cartridge optical disk a CD DVD or Blu ray or other fixed or removable medium that is read by written to or accessed by media drive . As these examples illustrate the storage media can include a computer usable storage medium having stored therein computer software or data.

In alternative embodiments information storage mechanism might include other similar instrumentalities for allowing computer programs or other instructions or data to be loaded into computing module . Such instrumentalities might include for example a fixed or removable storage unit and an interface . Examples of such storage units and interfaces can include a program cartridge and cartridge interface a removable memory for example a flash memory or other removable memory module and memory slot a PCMCIA slot and card and other fixed or removable storage units and interfaces that allow software and data to be transferred from the storage unit to computing module .

Computing module might also include a communications interface . Communications interface might be used to allow software and data to be transferred between computing module and external devices. Examples of communications interface might include a modem or softmodem a network interface such as an Ethernet network interface card WiMedia IEEE 802.XX or other interface a communications port such as for example a USB port IR port RS232 port Bluetooth interface or other port or other communications interface. Software and data transferred via communications interface might typically be carried on signals which can be electronic electromagnetic which includes optical or other signals capable of being exchanged by a given communications interface . These signals might be provided to communications interface via a channel . This channel might carry signals and might be implemented using a wired or wireless communication medium. Some examples of a channel might include a phone line a cellular link an RF link an optical link a network interface a local or wide area network and other wired or wireless communications channels.

In this document the terms computer readable medium computer usable medium and computer program medium are used to generally refer to non transitory media volatile or non volatile such as for example memory storage unit and media . These and other various forms of computer program media or computer usable media may be involved in carrying one or more sequences of one or more instructions to a processing device for execution. Such instructions embodied on the medium are generally referred to as computer program code or a computer program product which may be grouped in the form of computer programs or other groupings . When executed such instructions might enable the computing module to perform features or functions of the present application as discussed herein.

Although described above in terms of various exemplary embodiments and implementations it should be understood that the various features aspects and functionality described in one or more of the individual embodiments are not limited in their applicability to the particular embodiment with which they are described but instead can be applied alone or in various combinations to one or more of the other embodiments of the application whether or not such embodiments are described and whether or not such features are presented as being a part of a described embodiment. Thus the breadth and scope of the present application should not be limited by any of the above described exemplary embodiments.

Terms and phrases used in this document and variations thereof unless otherwise expressly stated should be construed as open ended as opposed to limiting. As examples of the foregoing the term including should be read as meaning including without limitation or the like the term example is used to provide exemplary instances of the item in discussion not an exhaustive or limiting list thereof the terms a or an should be read as meaning at least one one or more or the like and adjectives such as conventional traditional normal standard known and terms of similar meaning should not be construed as limiting the item described to a given time period or to an item available as of a given time but instead should be read to encompass conventional traditional normal or standard technologies that may be available or known now or at any time in the future. Likewise where this document refers to technologies that would be apparent or known to one of ordinary skill in the art such technologies encompass those apparent or known to the skilled artisan now or at any time in the future.

The presence of broadening words and phrases such as one or more at least but not limited to or other like phrases in some instances shall not be read to mean that the narrower case is intended or required in instances where such broadening phrases may be absent. The use of the term module does not imply that the components or functionality described or claimed as part of the module are all configured in a common package. Indeed any or all of the various components of a module whether control logic or other components can be combined in a single package or separately maintained and can further be distributed in multiple groupings or packages or across multiple locations.

Additionally the various embodiments set forth herein are described in terms of exemplary block diagrams flow charts and other illustrations. As will become apparent to one of ordinary skill in the art after reading this document the illustrated embodiments and their various alternatives can be implemented without confinement to the illustrated examples. For example block diagrams and their accompanying description should not be construed as mandating a particular architecture or configuration.

While various embodiments of the present disclosure have been described above it should be understood that they have been presented by way of example only and not of limitation. Likewise the various diagrams may depict an example architectural or other configuration for the disclosure which is done to aid in understanding the features and functionality that can be included in the disclosure. The disclosure is not restricted to the illustrated example architectures or configurations but the desired features can be implemented using a variety of alternative architectures and configurations. Indeed it will be apparent to one of skill in the art how alternative functional logical or physical partitioning and configurations can be implemented to implement the desired features of the present disclosure. Also a multitude of different constituent module names other than those depicted herein can be applied to the various partitions. Additionally with regard to flow diagrams operational descriptions and method claims the order in which the steps are presented herein shall not mandate that various embodiments be implemented to perform the recited functionality in the same order unless the context dictates otherwise. It should be understood that the steps may be reorganized for parallel execution or reordered as applicable.

