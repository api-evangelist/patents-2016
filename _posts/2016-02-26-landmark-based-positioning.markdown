---

title: Landmark based positioning
abstract: Disclosed are devices, methods and storage media for use in determining position information for imaging devices or mobile devices. In some implementations, a landmark is identified in an image which is obtained from an imaging device which in turn is positioned at a location and in a pose. A virtual two-dimensional image that would be visible from the landmark is determined based, at least in part, on the pose. The location or position information is based, at least in part, on the virtual two-dimensional image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09483826&OS=09483826&RS=09483826
owner: QUALCOMM Incorporated
number: 09483826
owner_city: San Diego
owner_country: US
publication_date: 20160226
---
This application is a continuation of and claims the benefit of priority from U.S. patent application Ser. No. 14 494 484 entitled Landmark Based Positioning filed Sep. 23 2014 which such application is incorporated by reference herein.

Embodiments described herein are generally directed to landmark based positioning techniques including in some embodiments techniques for estimating the position of mobile devices.

Global Positioning Systems GPS and other satellite positioning systems SPS have enabled navigation services for mobile handsets in outdoor environments. Since satellite signals may not be reliably received or acquired in an indoor environment different techniques can be employed to enable navigation services. For example mobile devices can typically obtain a position fix by measuring ranges to three or more terrestrial wireless access points which may be positioned at known locations. These ranges can be measured for example by obtaining a MAC ID address from signals received from the access points and measuring one or more characteristics of signals received from the access points such as for example received signal strength indicator RSSI round trip delay RTT just to name a few examples.

Broadly speaking certain embodiments of the claimed subject matter relate to the conversion of a two dimensional map of a region or venue into a three dimensional map or model. In a first embodiment using the three dimensional map certain areas may be color coded. They are the areas on which an imaging device including a mobile imaging device being held by a user potentially could be located such as for example floors escalators etc. The lens of the imaging device may be pointed in the direction of a landmark having a known location such as a store front or a store sign for example while the corresponding pose of the imaging device e.g. its elevation and or azimuth is recorded. Using the pose information a selected view or portion of the three dimensional venue map may be rendered into a virtual two dimension image according to an implementation. This selected view may correspond to a line of sight visible area where the imaging device could be located and as would be viewed theoretically from the perspective of the landmark in the direction of the imaging device. According to an implementation the color coding may be used to derive or estimate an area on a map where the imaging device and by inference its user may be located.

In a second embodiment a method for determining a location comprises identifying a first landmark in a first image obtained from an imaging device positioned at a first location. The imaging device is in a first pose during the time that the first image is obtained. Using a processor a first virtual two dimensional image of a first view from a first viewpoint at the first landmark is determined based at least in part on the first pose. The first location is estimated based at least in part on the determined first virtual two dimensional image.

In an aspect of the second embodiment a second landmark in a second image is identified. The second image was obtained from the imaging device positioned at the first location. The imaging device is in a second pose during the time that the second image is obtained. The second pose is different from the first pose. A second virtual two dimensional image of a second view from a second viewpoint at the second landmark is determined based at least in part on the second pose. The estimating of the first location includes estimating the first location based at least in part on a matching of portions of the determined first virtual two dimensional image with portions of the second virtual two dimensional image.

In a third embodiment an apparatus comprises a memory and one or more processors in communication with the memory. The one or more processors are configured to identify a first landmark in a first image. The first image was obtained by the apparatus positioned at a first location. The apparatus is in a first pose during the time that the first image is obtained. The one or more processors are further configured to determine a first virtual two dimensional image of a first view from a first viewpoint at the first landmark based at least in part on the first pose. The one or more processors are further configured to estimate the first location based at least in part on the first virtual two dimensional image.

In an aspect of the third embodiment the one or more processors are further configured to identify a second landmark in a second image. The second image was obtained by the apparatus positioned at the first location. The apparatus is in a second pose during the time that the second image is obtained. The second pose is different from the first pose. The one or more processors are further configured to determine a second virtual two dimensional image of a second view from a second viewpoint at the second landmark based at least in part on the second pose. The estimating of the first location includes estimating the first location based at least in part on a matching of portions of the first virtual two dimensional image with portions of the second virtual two dimensional image.

In a fourth embodiment a non transitory computer readable storage medium comprises machine readable instructions stored thereon which are executable by a special purpose computing apparatus to identify a first landmark in a first image. The first image was obtained by the special purpose computing apparatus positioned at a first location. The special purpose computing apparatus is in a first pose during the time that the first image is obtained. The instructions are further executable by the special purposed computing apparatus to determine a first virtual two dimensional image of a first view from a first viewpoint at the first landmark based at least in part on the first pose. The instructions are further executable by the special purposed computing apparatus to estimate the first location based at least in part on the first virtual two dimensional image.

In an aspect of the fourth embodiment the instructions are further executable by the special purpose computing apparatus to identify a second landmark in a second image. The second image was obtained by the special purpose computing apparatus positioned at the first location. The special purpose computing apparatus is in a second pose during the time that the second image is obtained. The second pose is different from the first pose. The instructions are further executable by the special purpose computing apparatus to determine a second virtual two dimensional image of a second view from a second viewpoint at the second landmark based at least in part on the second pose. The estimating of the first location includes estimating the first location based at least in part on a matching of portions of the first virtual two dimensional image with portions of the second virtual two dimensional image.

There are additional aspects to claimed subject matter. It should therefore be understood that the preceding is merely a brief summary of some embodiments and aspects of the claimed subject matter. Additional embodiments and aspects are referenced below. It should further be understood that numerous changes to the disclosed embodiments can be made without departing from the spirit or scope of the claimed subject matter. The preceding summary therefore is not meant to limit the scope of the claimed subject matter. Rather the scope of the claimed subject matter is to be determined by appended claims and their equivalents.

The following description is of the best mode presently contemplated for carrying out claimed subject matter. Moreover in the following description details are set forth by way of example to enable a person of ordinary skill in the art to practice the claimed subject matter without undue experimentation. Reference will be made in detail to embodiments of the present claimed subject matter examples of which are illustrated in the accompanying drawings wherein like reference numerals refer to like elements throughout. It is understood that other embodiments may be used and structural and operational changes may be made without departing from the scope of the present claimed subject matter.

GPS and other satellite positioning systems have enabled navigation services for mobile devices in outdoor environments. Since satellite signals may not be reliably received or acquired in an indoor environment different techniques may be employed to enable navigation services. Other mobile positioning techniques include recognition of objects in features in an image obtained at an imaging device e.g. in a camera phone . For example locations of visual landmarks may be known a priori. Recognition of a visible landmark in an image obtained at an imaging device can suggest that the device is in visual proximity of or located in some relation to the landmark. In landmark based positioning one method for estimating a user s location is based on a visible region of a landmark. For example in a shopping mall venue for a given storefront that is observed by a camera the camera s location may be inversely estimated based on the floor area from which this storefront is visible or in a line of sight. An intersection of areas observable from multiple landmark locations can improve the accuracy of a position estimation.

Some methods of estimating a location of an imaging device may be straightforward and enable a quick computation of a location estimate in a particular case of a two dimensional map e.g. the camera and landmarks are located on the same vertical elevation level or floor . However this technique can become more complicated and require significantly more computational resources in a multi level environment where visible landmarks of interest are located on a floor or vertical level different from each other or from that of the imaging device. Techniques such as ray tracing can be used to project rays from identified landmarks. Intersections of rays projected from identified landmarks may at least in part define an area or region where the imaging device may be located. Unfortunately ray tracing in three dimensions can be computationally complex.

However in a particular alternative implementation certain computational complexities may be reduced for the generation of position estimates especially in environments having landmarks located on different levels or elevations. According to an implementation a three dimensional map is used which includes certain areas that are uniquely coded such as for example color coded i.e. coded according to a color scheme. Alternative coding schemes may include a numerical coding of the selected areas of the map. In one implementation the coded areas of the three dimensional map are limited to those on which an imaging device potentially could be located such as for example floors escalators etc. as opposed to walls or ceilings for example. However in other implementations the coded areas of the map may include all areas of the map.

The lens of the imaging device may be pointed in the direction of one of the landmarks having a known location such as a store front or a store sign for example while the corresponding pose parameters of the imaging device are recorded. An image that includes the landmark is captured by the imaging device. A selected view or portion of the three dimensional map including at least some of its coded areas is rendered into two dimensions using the pose parameters. This selected view corresponds to a line of sight visible area as would be viewed from the perspective of the landmark where the imaging device could be located. According to an implementation the coded areas are used to derive or estimate a location or area where the imaging device may be located.

In certain implementations as shown in a system may include a mobile device that can receive or acquire satellite positioning system SPS signals from SPS satellites . In some embodiments the SPS satellites may be from one global navigation satellite system GNSS such as the GPS or Galileo satellite systems. In other embodiments the SPS Satellites may be from multiple GNSS such as but not limited to GPS Galileo Glonass or Beidou Compass satellite systems. In other embodiments the SPS satellites may be from any one several regional navigation satellite systems RNSS such as for example Wide Area Augmentation System WAAS European Geostationary Navigation Overlay Service EGNOS Quasi Zenith Satellite System QZSS just to name a few examples.

Mobile device may transmit radio signals to and receive radio signals from a wireless communication network. In one example mobile device may communicate with a cellular communication network by transmitting wireless signals to or receiving wireless signals from a base station transceiver over a first wireless communication link . Similarly mobile device may transmit wireless signals to or receive wireless signals from a local transceiver over a second wireless communication link .

In a particular implementation local transceiver may be configured to communicate with mobile device at a shorter range over second wireless communication link than at a range enabled by the base station transceiver over first wireless communication link . For example local transceiver may be positioned in an indoor environment. Local transceiver may provide access to a wireless local area network WLAN e.g. IEEE Std. 802.11 network or wireless personal area network WPAN e.g. Bluetooth network . In another example implementation local transceiver may comprise a femto cell transceiver capable of facilitating communication on the second wireless link according to a cellular communication protocol. Of course it should be understood that these are merely examples of networks that may communicate with a mobile device over a wireless link and claimed subject matter is not limited in this respect.

In a particular implementation base station transceiver and local transceiver can communicate with any one or more of a plurality of servers comprising a first server a second server and a third server over a network through links . Here network may comprise any combination of wired or wireless links. In a particular implementation network may comprise Internet Protocol IP infrastructure capable of facilitating communication between mobile device and servers or through local transceiver or the base station transceiver . In another implementation network may comprise cellular communication network infrastructure such as for example a base station controller or master switching center not shown to facilitate mobile cellular communication with mobile device .

In particular implementations and as discussed elsewhere herein mobile device may have circuitry and processing resources capable of computing a position fix or estimated location of mobile device . For example mobile device may compute a position fix based at least in part on pseudorange measurements to four or more SPS satellites . Here mobile device may compute such pseudorange measurements based at least in part on pseudonoise code phase detections in signals acquired from four or more SPS satellites . In particular implementations mobile device may receive from one or more of servers positioning assistance data to aid in the acquisition of signals transmitted by the SPS satellites including for example almanac ephemeris data Doppler search windows just to name a few examples.

In other implementations mobile device may obtain a position fix by processing signals received from terrestrial transmitters fixed at known locations e.g. such as base station transceiver using any one of several techniques such as for example advanced forward trilateration AFLT and or observed time difference of arrival OTDOA . In these particular techniques a range from mobile device may be measured to three or more of such terrestrial transmitters fixed at known locations based at least in part on pilot signals transmitted by the transmitters fixed at known locations and received at mobile device . Here the one or more of servers may be capable of providing positioning assistance data to mobile device including for example locations and identities of terrestrial transmitters to facilitate positioning techniques such as AFLT and OTDOA. For example servers or may include a base station almanac BSA which indicates locations and identities of cellular base stations in a particular region or regions.

In particular environments such as for example indoor environments outdoor stadiums or urban canyons mobile device may not be capable of acquiring signals from a sufficient number of SPS satellites or perform AFLT or OTDOA to compute a position fix. Alternatively mobile device may be capable of computing a position fix based at least in part on signals acquired from local transmitters e.g. WLAN access points femto cell transceivers Bluetooth devices etc. positioned at known locations . For example mobile devices may obtain a position fix by measuring ranges to three or more indoor terrestrial wireless access points which are positioned at known locations. Such ranges may be measured for example by obtaining a MAC ID address from signals received from such access points and obtaining range measurements to the access points by measuring one or more characteristics of signals received from such access points such as for example received signal strength RSSI or round trip time RTT .

In alternative implementations mobile device may obtain an indoor position fix by applying characteristics of acquired signals to a radio heatmap indicating expected RSSI and or RTT signatures at particular locations in an indoor area. In particular implementations a radio heatmap may associate identities of local transmitters e.g. a MAC address which is discernible from a signal acquired from a local transmitter expected RSSI from signals transmitted by the identified local transmitters an expected RTT from the identified transmitters and possibly standard deviations from these expected RSSI or RTT. It should be understood however that these are merely examples of values that may be stored in a radio heatmap and that claimed subject matter is not limited in this respect.

In a particular implementation mobile device may also apply signals received from a magnetometer to signatures in a magnetic heatmap indicating expected magnetic signatures at particular locations in an indoor area. In particular implementations for example a magnetic heatmap may associate expected magnetic signatures or compass deviations with locations in an indoor area allowing a mobile device to estimate its location based at least in part on an association of magnetic heatmap values with compass or magnetometer measurements obtained at the mobile device.

In particular implementations mobile device may receive positioning assistance data for indoor positioning operations from one or more of the servers . For example such positioning assistance data may include locations and identities of transmitters positioned at known locations to enable measuring ranges to these transmitters based at least in part on a measured RSSI and or RTT for example. Other positioning assistance data to aid indoor positioning operations may include radio heatmaps magnetic heatmaps locations and identities of transmitters routeability graphs just to name a few examples. Other assistance data received by mobile device may include for example local maps of indoor areas for display or to aid in navigation. Such a map may be provided to mobile device as it enters a particular indoor area. The map may show indoor features such as doors hallways entry ways walls etc. points of interest such as bathrooms pay phones room names stores etc. By obtaining and displaying such a map mobile device can overlay its current location and therefore that of its user over the displayed map to provide the user with additional context.

In one implementation a routeability graph and or digital map assist mobile device in defining feasible areas for navigation within an indoor area and subject to physical obstructions e.g. walls and passage ways e.g. doorways in walls . Here by defining feasible areas for navigation mobile device can apply constraints to aid in the application of filtering measurements for estimating locations and or motion trajectories according to a motion model e.g. according to a particle filter and or Kalman filter . In addition to measurements obtained from the acquisition of signals from local transmitters according to a particular embodiment mobile device can further apply a motion model to measurements or inferences obtained from inertial sensors e.g. accelerometers gyroscopes magnetometers etc. and or environment sensors e.g. temperature sensors microphones barometric pressure sensors ambient light sensors camera imager etc. in estimating a location or motion state of mobile device .

According to an embodiment mobile device accesses indoor navigation assistance data through one or more servers by for example requesting the indoor assistance data through selection of a universal resource locator URL . In one implementation the indoor navigation assistance data may be on server and the position assistance data referred to above may reside on a different server such as for example server . In another implementation however the indoor navigation assistance data as well as the position assistance data may reside on a single server such as server for example. Alternatively the indoor navigation assistance data may reside on mobile device initially so that this data need not be retrieved from one or more servers .

In particular implementations one or more servers may be capable of providing navigation assistance data to cover many different indoor and or outdoor areas including for example floors of buildings wings of hospitals terminals at an airport portions of a university campus portions of a stadium areas of a large shopping mall just to name a few examples. Also memory resources at mobile device and data transmission resources may make receipt of indoor navigation assistance data for all areas served by servers impractical or infeasible. A request for indoor navigation assistance data from mobile device may indicate a rough or course estimate of a location of mobile device . Mobile device can then be provided with indoor navigation assistance data covering areas including and or proximate to the rough or course estimate of the location of mobile device .

In one particular implementation a request for indoor navigation assistance data from mobile device specifies a location context identifier LCI . Such an LCI may be associated with a locally defined area such as for example a particular floor of a building or other indoor area which is not mapped according to a global coordinate system. In one example upon entry of an area mobile device may request a server such as first server for example to provide one or more LCIs covering the area or adjacent areas. Here the request from mobile device may include a rough location of mobile device such that the requested server can associate the rough location with areas covered by known LCIs and then transmit those LCIs to mobile device . Mobile device can then use the received LCIs in subsequent messages with a different server such as second server for example for obtaining navigation assistance data relevant to an area identifiable by one or more of the LCIs as discussed above e.g. digital maps locations and identities of beacon transmitters radio heatmaps or routeability graphs .

In another implementation first server may be configured to render or generate a three dimensional model or map of an indoor or outdoor environment based on a two dimensional map of the environment having one or more landmarks at known locations. In an alternative implementation mobile device may be configured to render the three dimensional model based on the two dimensional map. First server and or mobile device may be configured to access the two dimensional map of the environment from a navigation database or receive the two dimensional map from a navigation server. In yet another implementation the three dimensional model or map already exists and accordingly it need not be rendered from a two dimensional map.

A two dimensional map of the environment may be analyzed to derive or render the three dimensional model. Basic structural components of the indoor environment can be identified such as walls doors windows floors and ceilings. Some basic assumptions can be made about the structure of the environment if the two dimensional map of the environment does not provide information to the contrary. For example assumptions can be made that the floors and ceilings are parallel to the ground unless otherwise specified. As another example the system may be configured to recognize that the environment includes a ramp or escalator at a particular location and could render that portion of the floor to be sloped rather than perpendicular to a ground plane. As another assumption the walls and doors can be assumed to be placed perpendicular to the floor unless otherwise specified by the two dimensional map. According to an implementation first server or mobile device may be further configured to selectively render certain portions of the three dimensional model so that these portions are tessellated into graphic primitives each one of which is uniquely marked or coded. The portions of the model that are selectively rendered may include floors ramps and escalators for example but not walls or ceilings. In an implementation graphic primitives may be uniquely coded with a color scheme or code.

In one implementation a two dimensional map of a region or venue may be converted to a three dimensional model or map using one or more assumptions such as for example that the walls are disposed perpendicularly to the floors. Using a three dimensional map certain areas may be tessellated into graphic primitives and are uniquely coded. They are the areas on which a mobile imaging device potentially could be located such as for example the floors escalators etc. Other areas such as walls or ceilings for example are not uniquely coded. The lens of the imaging device are pointed in the direction of one of the landmarks at the venue such as a store front or a store sign for example and an image is taken while the corresponding pose or view of the device e.g. its elevation and or azimuth and its viewing angle toward the landmark is estimated and recorded. This information represented as the range of rotation and distance to the landmark may be estimated based on the appearance of the landmark and or the surrounding structure in the image more specifically by comparing the visual feature key points in the current image to ones in the reference image or by finding the vanishing points of the lines in the image that present the edges of the walls floors and the doors etc.

Using the pose parameters a selected view or portion of the three dimensional venue map may be rendered into two dimensions. This selected view may be from a viewpoint at the landmark looking in the opposite direction when the opposite view of the pose parameter is used e.g. a view that corresponds to a line of sight visible area where the imaging device could be located as would be viewed from the perspective of the landmark and looking in the direction of the imaging device. The color coding and graphic primitives are used to derive or estimate the location or region on the map where the imaging device and by inference its user in some embodiments may be located.

In another implementation a location of the imaging device can be estimated with improved accuracy by using a second landmark having a known location. While remaining at the same position where the device was pointed at the first landmark the imaging device can be pointed in the direction of the second landmark while the corresponding second pose of the device is recorded. Using the second pose parameters a selected second view of the three dimensional venue map is rendered into two dimensions. This second view may be from a viewpoint at the second landmark e.g. a view that corresponds to a line of sight visible area where the imaging device and by inference its user could be located as would be viewed from the perspective of the second landmark and looking in the direction of the user s imaging device. The color coding and graphic primitives are used to correspond to derive or estimate a second location or region on the map where the imaging device could be located. Now having identified a first region based upon the first landmark and first pose parameters and a second region based upon the second landmark and second pose parameters the two regions can be compared. The area where they match or overlap according to the coding of the respective graphic primitives may correspond to a refined estimation of the location where the imaging device and by inference its user may be located.

A second cone of visibility extends from second landmark and also encompasses a portion of escalator and a portion of third floor . Thus if the imaging device lens is pointed in the direction of second landmark while the device is located on any area within second cone of visibility second landmark would appear in a perspective view which is similar to that shown in at reference numeral . Imaging device or camera pose parameters generated and recorded while pointing the imaging device in the direction of second landmark is used to derive second cone of visibility in a manner similar to that described above with respect to the first cone of visibility .

An overlap region i.e. the region where the first and second cones of visibility overlap represents a refined or more accurate estimate of the location of the imaging device and by inference its user. As explained elsewhere herein embodiments are described showing how an overlapping area can be identified in a three dimensional model in a rapid manner including in some implementations at a speed that approaches real time.

While the implementation of describes the use of two landmarks appearing in two images in an alternative implementation the two landmarks may appear in a single image captured by a mobile imaging device. A selection or identification of each of the two landmarks may occur automatically. Accordingly a single set of pose parameters associated with the single image may be used to derive first and second virtual two dimensional images associated with first and second views at the respective two landmarks.

In an implementation the determination of first and second virtual two dimensional images may include rendering them based at least in part on a three dimensional representation of a region. In an implementation the three dimensional representation of the region may include a plurality of graphic primitives wherein each one of the primitives has an attribute. In an implementation the three dimensional representation of the region is color coded and the attribute is based at least in part on a value corresponding to the color coding. In other implementations other attributes of the graphic primitives that are not based upon color coding may be used as well. One example of an alternative attribute may be the assignment of an attribute number to each primitive so that no two primitives have the same number. These attribute numbers may be computer generated or derived on the basis of other than color coding.

The first location of the imaging device is estimated based at least in part on a matching of portions of the first virtual two dimensional image with portions of the second virtual two dimensional image. Block In an implementation this matching may include matching the attribute of at least one of the graphic primitives in the first virtual two dimensional image with the attribute of at least one of the graphic primitives in the second virtual two dimensional image.

In an alternative implementation shows a three dimensional representation of a region or model of a venue which in this case also is an indoor shopping mall. This three dimensional model is generated or rendered from a two dimensional map of the mall having one or more landmarks with known locations. The three dimensional model includes a first floor a second floor and a third floor which are disposed at different elevations or levels from one another. The model further includes a first plurality of walls extending upwardly from first floor a second plurality of walls extending upwardly from second floor and a third plurality of walls extending upwardly from third floor . As shown in certain areas or features of three dimensional model are color coded. These color coded areas correspond to locations where a mobile imaging device could potentially be located which in this case would be first second and third floors . In other words the walls may not be color coded since they are locations where a mobile imaging device likely could not be located. In an alternative implementation however all areas and features of three dimensional model may be color coded.

In the illustrated implementation however these floors are not color coded with uniform coloring. Moreover each of the floors is colored differently from one another. For example third floor is color coded so that as the floor extends from right to left the coloring begins as a relatively dark solid orange color and then phases into progressively lighter shades of orange and then into a light orange lime hue and then into progressively darker shades of lime or light green. Second floor is color coded so that as the floor extends from right to left the coloring begins as a solid blue and then phases into progressively lighter shades of blue and then into a light blue pink hue and then into progressively darker shades of pink. First floor is color coded so that as the floor extends from right to left the coloring begins as a light aquamarine color and then phases into progressively lighter shades of aquamarine and then into a light red hue and then into progressively darker shades of red.

The foregoing is merely one implementation other color selections may be used in other implementations so that a mixture and or blending of various hues tones primary colors tints shades intensity levels saturations brightness value and or luminance lightness values is applied to each floor so that there is not a uniformity of color throughout each floor. As previously mentioned in the illustrated implementation the first second and third pluralities of walls are not color coded since they typically represent areas where a mobile imaging device typically could not physically be located. In some implementations the walls are in greyscale or in one bit bi tonal black and white. In other implementations the walls are in a color but in one that is different than the colors used for the floors and moreover may be a color that is uniform throughout the walls so that they do not have the shadings and variations etc. as previously described for the floors.

As shown in a first area of visibility in the three dimensional model encompasses a portion of the third floor and portions of the second and third pluralities of walls . This first area of visibility is derived by receiving imaging device or camera pose parameters from an imaging device not shown located somewhere within first area of visibility while the imaging device is pointed toward a landmark . First area of visibility a portion of which may be color coded as previously described is rendered from the three dimensional model into a virtual two dimensional image not shown using a graphics program or language such as for example the OpenGL Open Graphics Library application programming interface API e.g. using a first virtual camera in OpenGL mode. In an implementation this rendering is accomplished using a frame buffer. However because only the floor portion of first area of visibility is color coded it is determined by this coding that the user and his her imaging device would be located somewhere on the color coded floor area of third floor within first area of visibility and not on the walls which are not color coded.

As shown in a first area of visibility in the three dimensional model includes a portion of the third floor and portions of the second and third pluralities of walls . The first area of visibility may be derived from a first virtual camera at a first landmark having a known location. This first area of visibility may be generated from pose parameters provided by an imaging device not shown while the device is located somewhere in first area of visibility and while pointing the device in the direction of first landmark . The first area of visibility includes a portion of the third floor which is color coded and portions of the second and third pluralities of walls which are not color coded.

As also shown in a second area of visibility in the three dimensional model includes a portion of third floor and portions of the second and third pluralities of walls . The second area of visibility is derived from a second virtual camera at a second landmark having a known location that is different than the known location of first landmark . Second area of visibility may be generated from pose parameters provided by the imaging device not shown while the device is located somewhere in second area of visibility and while the imaging device is pointed in the direction of second landmark . Second area of visibility includes a portion of the third floor which is color coded and portions of the second and third pluralities of walls which are not color coded.

In both the first and second areas of visibility the color coding of third floor may not be uniform according to the illustrated implementation. Rather variations in colors and shadings are used throughout third floor for reasons discussed elsewhere herein. A determination is made where the coloring of the third floor in first area of visibility matches the coloring of the third floor in second area of visibility . Those areas that correspond to a color match may represent an improvement in the accuracy of the estimated location of the imaging device and by inference its user. This is illustrated by a superimposed or overlap area as shown in where the first and second areas of visibility are illustrated to be within the larger three dimensional map of the mall venue. Overlap area may be smaller than either one of the first or second areas of visibility and therefore represents a refined or improved estimated location of the imaging device. However in some implementations it is not necessary to conduct an overlay like that shown at reference numeral of . For example overlap may be determined from virtual images of the individual first and second views of which have been color coded and rendered into two dimensions and then color matched to identify the smaller region i.e. the overlap area where the imaging device may be located.

In order to use OpenGL according to an implementation the aspect ratio r of the camera or imaging device and the second angle of can be provided to the OpenGL API. On the other hand the view angle of can be obtained from the pose data of the imaging device. Therefore the second angle of can be mathematically derived from expressions 1 2 and 3 so that the second angle can be expressed as a function of the view angle and the aspect ratio r in expression 4 as follows tan 2 tan 2 1 4 Thus the second angle of can be determined based upon the imaging device view angle and the aspect ratio r so that the second angle of and the aspect ratio r can be used to set up a virtual perspective camera in OpenGL in order to render the three dimensional model into a two dimensional virtual image and in order to determine an area or cone of visibility for the imaging device location. The foregoing is an example of one use of OpenGL however and alternative implementations may use other features of OpenGL or use other API s.

Graphic primitives have attributes for use in identification of a selected one or more of graphic primitives as described in more detail elsewhere herein. In the implementation of the attributes are based at least in part on values corresponding to a color coding of the graphic primitives . Accordingly first and second floors are color coded. However the color coding of the floors may not be uniform. That is each floor may be colored so that a mixture and or blending of various hues tones primary colors tints shades intensity levels saturations brightness value and or luminance lightness values is applied to the floor so that there is not a uniformity of color throughout the floor. Accordingly a graphic primitive may be assigned a unique color or mix of colors which in turn may be used to determine an identification of graphic primitive such as for example an identification number. While the floors may be color coded as previously described the walls partitions and other areas may not be colored at all or alternatively may be colored so that they all have the same color that is different than the color coding of the floors. Three dimensional model further includes a plurality of walls extending upwardly from middle portions of first and second floors . According to the illustrated implementation the plurality of walls may not be tessellated but may be color coded so that they all have the same color which is uniform and which is different than the colors of the floors.

According to an implementation when the three dimensional model is rendered into two dimensions it may be a flat rendering without any lighting or shading effects. Moreover if this is rendered based upon an imaging device view and pose parameters an identity of only those parts of the first and second floors on which an imaging device may be visible from the perspective of the landmark can be identified. According to an implementation the uniform coloring of the plurality of the walls may be used to determine portions of the first and second floors e.g. those specific graphic primitives that are disposed behind the walls with respect to the virtual camera located at the landmark such that they may block the view of any imaging device that otherwise would be located behind them. This in turn may be an identification of certain areas of the first and second floors where an imaging device would not be located.

According to an implementation the attributes of the graphic primitives may be based at least in part on a plurality of RGB triplet values according to the RGB color model. These values may be converted to an index for the graphic primitives in a three dimensional model which corresponds to a physical location in the real world. Thus RGB triplet values can be used to generate a unique identification number for each graphic primitive. By examining an RGB color value for a pixel this can be losslessly converted back to integers which can be a basis for an index for the graphic primitive. Thus in some implementations graphics hardware is used to find visible graphic primitives or polygons in a scene. As previously mentioned only the features in the scene where an imaging device potentially can be located are color coded. Color coding is advantageous in that some implementations employ the OpenGL API and a graphics pipeline which is a combination that can be configured to perform this color coding relatively easily and rapidly. One goal is to render a three dimensional image and this graphics pipeline can easily use color. For example in three dimensions it normally is relatively easy to determine which parts of a scene constitute the floors but in some two dimensional images it can be more difficult to distinguish floors from walls. In three dimensions therefore it often is useful to assign colors to floors that are different than the colors or lack of color used for walls so that if a three dimensional scene is rendered into two dimensions it may be easier to differentiate walls from floors in the two dimensional scene.

Still referring to a second group of pixels may be color coded with a blue color having a highest intensity of blue and having no other color components thus corresponding to a RGB triplet value of 0 0 255. Again using expression 5 an identification number for this second group may be 0 0 256 255 256 256 or 0 0 16 711 680 or 16 711 680. Thus pixels in the second group may be assigned the identification number 16 711 680. Finally a third group of pixels may be color coded with a white color corresponding to a RGB triplet value of 255 255 255 in the RGB model. Using expression 5 an identification number for this third group may be 255 255 256 255 256 256 or 255 65 280 16 711 680 or 16 777 215. Thus pixels in the third group may be assigned the identification number 16 777 215. While the foregoing illustrates a method for generating an identification number using expression 5 alternative implementations may use other formulas expressions or methods for generating identification numbers based upon RGB triplet values.

The embodiment of illustrates pixel block having first second and third groups of pixels which comprise respectively 15 pixels 16 pixels and 33 pixels. However alternative embodiments may include one or more pixel blocks each one of which has a greater or lesser number of groups of pixels. Each of those groups of pixels in turn may include a greater or lesser number of individual pixels. For example an alternative embodiment may include a pixel block comprised of only one group of pixels all of which are of a particular color. In yet another alternative embodiment a pixel block may include only one pixel having a particular color while the pixel block further includes one or more groups of pixels having other different colors than the color of the single pixel.

A graphic primitive in a frame buffer may comprise a plurality of contiguous pixels each of which can have an identification value that can be determined as described above or that can be determined by other formulas expressions or methods. A plurality of pixel identification values that correspond to the plurality of pixels in a graphic primitive in turn can be used to generate an identification value for the overall graphic primitive using any one or more mathematical operations or formulas operating on the individual pixel identification values. Accordingly a graphic primitive in the frame buffer may be assigned an identification value which can be indexed to its corresponding graphic primitive. Because areas in a scene where a mobile imaging device may be located e.g. the floors are color coded with non uniform coloring as described elsewhere herein an identification value of a graphic primitive may be unique to that graphic primitive.

In still further alternative implementations the generating of identification numbers based upon attributes of the graphic primitives need not be performed according to the RGB model but instead can be based upon other color models color systems or color spaces wherein colors can be represented by numbers. The RGBA model the CYMK model the CIE XYZ color space and the YUV color space are a few such examples. Moreover alternative implementations need not be color based at all. Rather other methods or systems that generate graphic primitive attributes or identification numbers for assignment to the graphic primitives may be used as well.

Digital signal processor s DSP s are connected to the bus by a bus interface not shown . Similarly general purpose processor s can be connected to the bus by a bus interface not shown . Alternatively the bus interface may be integrated with the DSP s or the general purpose processor s . In various embodiments functions may be performed in response to the execution of one or more machine readable instructions stored in a memory such as on a computer readable storage medium such as RAM ROM FLASH or disc drive just to name a few example. The one or more instructions may be executable by the general purpose processor s specialized processors not shown or the DSP s . The memory may comprise a non transitory processor readable memory and or a computer readable memory that stores software code programming code instructions etc. that are executable by the processor s and or the DSP s to perform functions described herein.

Also shown in is a user interface that may comprise any one of several devices such as for example a speaker microphone display device vibration device keyboard touch screen just to name a few examples. In a particular implementation the user interface may enable a user to interact with one or more applications hosted on mobile device . For example devices of the user interface may store analog or digital signals on the memory to be further processed by the DSP s or the general purpose processor in response to an action from a user. Similarly applications hosted on mobile device may store analog or digital signals on the memory to present an output signal to a user. In another implementation mobile device may comprise touch sensors responsive to touching or pressure on a keyboard or touch screen device.

Mobile device also comprises a dedicated camera device for capturing still or moving imagery. The camera device may comprise for example an imaging sensor e.g. charge coupled device or CMOS imager lens analog to digital circuitry frame buffers just to name a few examples. In one implementation additional processing conditioning encoding or compression of signals representing captured images may be performed at the general purpose application processor or the DSP s . Alternatively a dedicated video processor may perform conditioning encoding compression or manipulation of signals representing captured images. Additionally the video processor may decode decompress stored image data for presentation on a display device not shown on mobile device .

Mobile device also comprises sensors coupled to the bus which may include for example inertial sensors and environment sensors. Inertial sensors may comprise for example accelerometers e.g. collectively responding to acceleration of mobile device in three dimensions one or more gyroscopes or one or more magnetometers e.g. to support one or more compass applications . Environment sensors of mobile device may comprise for example temperature sensors barometric pressure sensors ambient light sensors camera imagers microphones just to name few examples. Sensors may generate analog or digital signals that may be stored in the memory and processed by the DPS s or the general purpose application processor in support of one or more applications such as for example applications directed to positioning or navigation operations. Moreover sensors may provide signals from which pose parameters may be derived for mobile device .

In a particular implementation a two dimensional digital map of an indoor area may be stored in a particular format in the memory . The digital map may have been obtained from messages containing navigation assistance data from a remote server. In one implementation a mobile device may further apply crowd sourced data e.g. obtained from a location server to confirm an inference of an egress segment. For example if there is a history of mobile devices moving through a feature presumed to be an egress segment the feature may be confirmed as providing an egress segment. A three dimensional model or map of the indoor area may be rendered from the two dimensional map. Certain portions of the three dimensional model may be selectively rendered so that these portions are tessellated into graphic primitives having attributes such as for example attributes that are based at least in part on a color coding of the primitives. These portions of the three dimensional model may be rendered into a virtual two dimensional image for use in estimating a position of mobile device as described in more detail elsewhere herein.

Mobile device of or mobile device of can comprise an imaging device that may be used for estimating its position using one or more landmarks having a known position. Alternatively the imaging device may comprise a dedicated camera or any other device having a lens device for capturing images and having a processor. The estimation of a position using one or more landmarks pursuant to embodiments of claimed subject matter may be especially useful in venues where the landmarks are located on different levels floors or elevations from each other or from the location of the imaging device. Examples of such venues include buildings such as for example shopping malls hotels hospitals and office structures having atriums as well as airport terminals sports stadiums and live entertainment arenas just to name a few examples.

In some implementations two dimensional or three dimensional images are produced or rendered rapidly which in some instances can approach real time speed. Commands are sent to a graphics accelerator using a library or API such as OpenGL for example. A graphics driver can translate those commands to instructions for a graphics processing unit GPU . The GPU uses those instructions to compute rasterized results which are transformed to a frame buffer as a rectangular block of pixels. A signal from the frame buffer is then produced as an output signal to a video display.

The methodologies described herein may be implemented by various means depending upon applications according to particular examples. For example such methodologies may be implemented in hardware firmware software or combinations thereof. In a hardware implementation for example a processing unit may be implemented within one or more application specific integrated circuits ASICs digital signal processors DSPs digital signal processing devices DSPDs programmable logic devices PLDs field programmable gate arrays FPGAs processors controllers micro controllers microprocessors electronic devices other devices units designed to perform the functions described herein or combinations thereof.

Some portions of the detailed description included herein are presented in terms of algorithms or symbolic representations of operations on binary digital signals stored within a memory of a specific apparatus or special purpose computing device or platform. In the context of this particular specification the term specific apparatus or the like includes a general purpose computer once it is programmed to perform particular operations pursuant to instructions from program software. Algorithmic descriptions or symbolic representations are examples of techniques used by those of ordinary skill in the signal processing or related arts to convey the substance of their work to others skilled in the art. An algorithm is here and generally considered to be a self consistent sequence of operations or similar signal processing leading to a desired result. In this context operations or processing involve physical manipulation of physical quantities. Typically although not necessarily such quantities may take the form of electrical or magnetic signals capable of being stored transferred combined compared or otherwise manipulated.

It has proven convenient at times principally for reasons of common usage to refer to such signals as bits data values elements symbols characters terms numbers numerals or the like. It should be understood however that all of these or similar terms are to be associated with appropriate physical quantities and are merely convenient labels. Unless specifically stated otherwise as apparent from the discussion herein it is appreciated that throughout this specification discussions utilizing terms such as processing computing calculating determining or the like refer to actions or processes of a specific apparatus such as a special purpose computer special purpose computing apparatus or a similar special purpose electronic computing device. In the context of this specification therefore a special purpose computer or a similar special purpose electronic computing device is capable of manipulating or transforming signals typically represented as physical electronic or magnetic quantities within memories registers or other information storage devices transmission devices or display devices of the special purpose computer or similar special purpose electronic computing device.

Wireless communication techniques described herein may be in connection with various wireless communications networks such as a wireless wide area network WWAN a wireless local area network WLAN a wireless personal area network WPAN and so on. The term network and system may be used interchangeably herein. A WWAN may be a Code Division Multiple Access CDMA network a Time Division Multiple Access TDMA network a Frequency Division Multiple Access FDMA network an Orthogonal Frequency Division Multiple Access OFDMA network a Single Carrier Frequency Division Multiple Access SC FDMA network or any combination of the above networks and so on. A CDMA network may implement one or more radio access technologies RATs such as cdma2000 Wideband CDMA W CDMA to name just a few radio technologies. Here cdma2000 may include technologies implemented according to IS 95 IS 2000 and IS 856 standards.

A TDMA network may implement Global System for Mobile Communications GSM Digital Advanced Mobile Phone System D AMPS or some other RAT. GSM and W CDMA are described in documents from a consortium named 3rd Generation Partnership Project 3GPP . Cdma2000 is described in documents from a consortium named 3rd Generation Partnership Project 2 3GPP2 . 3GPP and 3GPP2 documents are publicly available. 4G Long Term Evolution LTE communications networks may also be implemented in accordance with claimed subject matter in an aspect. A WLAN may comprise an IEEE 802.11x network and a WPAN may comprise a Bluetooth network an IEEE 802.15x for example. Wireless communication implementations described herein may also be used in connection with any combination of WWAN WLAN or WPAN.

In another aspect as previously mentioned a wireless transmitter or access point may comprise a femto cell utilized to extend cellular telephone service into a business or home. In such an implementation one or more mobile devices may communicate with a femto cell via a code division multiple access CDMA cellular communication protocol for example and the femto cell may provide the mobile device access to a larger cellular telecommunication network by way of another broadband network such as the Internet.

Techniques described herein may be used with an SPS that includes any one of several GNSS and or combinations of GNSS. Furthermore such techniques may be used with positioning systems that utilize terrestrial transmitters acting as pseudolites or a combination of SVs and such terrestrial transmitters. Terrestrial transmitters may for example include ground based transmitters that broadcast a PN code or other ranging code e.g. similar to a GPS or CDMA cellular signal . Such a transmitter may be assigned a unique PN code so as to permit identification by a remote receiver. Terrestrial transmitters may be useful for example to augment an SPS in situations where SPS signals from an orbiting SV might be unavailable such as in tunnels mines buildings urban canyons or other enclosed areas. Another implementation of pseudolites is known as radio beacons. The term SV as used herein is intended to include terrestrial transmitters acting as pseudolites equivalents of pseudolites and possibly others. The terms SPS signals and or SV signals as used herein is intended to include SPS like signals from terrestrial transmitters including terrestrial transmitters acting as pseudolites or equivalents of pseudolites.

The terms and and or as used herein may include a variety of meanings that will depend at least in part upon the context in which it is used. Typically or if used to associate a list such as A B or C is intended to mean A B and C here used in the inclusive sense as well as A B or C here used in the exclusive sense. Reference throughout this specification to one example or an example means that a particular feature structure or characteristic described in connection with the example is included in at least one example of claimed subject matter. Thus the appearances of the phrase in one example or an example in various places throughout this specification are not necessarily all referring to the same example. Furthermore the particular features structures or characteristics may be combined in one or more examples. Examples described herein may include machines devices engines or apparatuses that operate using digital signals. Such signals may comprise electronic signals optical signals electromagnetic signals or any form of energy that provides information between locations.

In view of the above it will be appreciated that certain embodiments overcome many of the long standing problems in the art by providing a system method and product for estimating the location of an imaging device. Using a three dimensional map or model of a venue certain areas of the venue are color coded and tessellated into graphic primitives according to one implementation. They are the areas on which the imaging device potentially could be located such as for example floors escalators etc. The lens of the imaging device are pointed in the direction of one of the landmarks at the venue having a known location such as a store front or a store sign for example while the corresponding pose of the imaging device is recorded. Using the pose parameters a selected view or portion of the three dimensional venue map is rendered into a virtual two dimension image according to an implementation. This selected view corresponds to a line of sight visible area where the imaging device could be located. According to an implementation the color coding of the graphic primitives is used to derive or estimate an area on the map where the imaging device and by inference its user may be located.

While there has been illustrated and described what are presently considered to be example features it will be understood by those skilled in the art that various other modifications may be made and equivalents may be substituted without departing from claimed subject matter. Additionally many modifications may be made to adapt a particular situation to the teachings of claimed subject matter without departing from the central concept described herein. Therefore it is intended that claimed subject matter not be limited to the particular examples disclosed but that such claimed subject matter may also include all aspects falling within the scope of the appended claims and equivalents thereof.

