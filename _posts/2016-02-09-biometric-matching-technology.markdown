---

title: Biometric matching technology
abstract: Biometric matching technology, in which a watch list is managed, multiple images of a potential suspect are accessed, and parallel pre-processing of the multiple images is controlled. Based on the pre-processing, an image of the potential suspect to use in matching against the watch list is determined and the determined image is used to search sorted biometric data included in the watch list. A subset of persons from the watch list is identified based on the search and parallel analysis of the determined image of the potential suspect against detailed biometric data associated with the subset of persons in the watch list is controlled. Based on the parallel analysis, it is determined whether the potential suspect matches a person in the watch list and a result is outputted based on the determination.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09390338&OS=09390338&RS=09390338
owner: Accenture Global Services Limited
number: 09390338
owner_city: Dublin
owner_country: IE
publication_date: 20160209
---
The present application is a continuation of U.S. application Ser. No. 14 882 552 filed Oct. 14 2015 which is a continuation of U.S. application Ser. No. 14 585 480 filed Dec. 30 2014 now U.S. Pat. No. 9 195 893 issued Nov. 24 2015 which is a continuation of U.S. application Ser. No. 13 598 819 filed Aug. 30 2012 now U.S. Pat. No. 8 948 465 issued Feb. 3 2015 which claims the benefit of Indian Patent Application No. 1400 CHE 2012 filed on Apr. 9 2012 which are incorporated herein by reference in their entirety for all purposes.

A typical biometric matching system includes a database of biometric information e.g. fingerprints retina scans facial images etc. about individuals. To identify or authenticate a sample of biometric information the typical biometric matching system compares the sample with entries in the database one by one until a match is found. As a result the time to find a matching entry grows linearly and may be time consuming when the database includes many entries.

In one aspect a system includes at least one processor and at least one memory coupled to the at least one processor having stored thereon instructions which when executed by the at least one processor causes the at least one processor to perform operations. The operations include managing a watch list that includes sorted biometric data for persons in the watch list and associations to additional biometric data for persons in the watch list and accessing multiple images of a potential suspect. The operations also include controlling parallel pre processing of the multiple images of the potential suspect determining an image of the potential suspect to use in matching against the watch list based on the pre processing and using the determined image of the potential suspect to search the sorted biometric data included in the watch list. The operations further include identifying a subset of persons from the watch list based on the search of the sorted biometric data included in the watch list and controlling parallel analysis of the determined image of the potential suspect against biometric data associated with the subset of persons in the watch list. In addition the operations include determining whether the potential suspect matches a person in the watch list based on the parallel analysis of the determined image of the potential suspect against biometric data associated with the subset of persons in the watch list and outputting a result based on the determination of whether the potential suspect matches a person in the watch list. In another aspect a method may include one or more of the operations described above. In yet another aspect a computer readable storage medium may be operable to cause a processor to perform one or more of the operations described above.

Implementations may include one or more of the following features. For example the operations may include maintaining numeric index values for persons in the watch list sorted in the watch list and maintaining blobs of images of the persons in the watch list stored on different partition servers.

In some implementations the operations may include creating in relational database storage a table for the watch list accessing biometric data for a person to include on the watch list and determining an index value from the accessed biometric data. In these implementations the operations may include storing the index value with an identifier for the person at an appropriate location in the table and determining whether blob data for the accessed biometric data of the person meets a threshold storage size. Based on a determination that the blob data for the accessed biometric data of the person does not meet the threshold storage size the blob data may be stored in the table with the identifier. Based on a determination that the blob data for the accessed biometric data of the person meets the threshold storage size the blob data may be stored in non relational storage and a link to the blob data may be stored in the table with the identifier.

In addition the operations may include creating the table for the watch list in a relational database included in a storage account provided by a cloud service provider storing the blob data in a non relational storage included in the storage account provided by the cloud service provider and controlling the blob data to be stored on a different partition server than all other blob data stored for persons on the watch list. The operations also may include determining at least one criterion relevant to the multiple images of the potential suspect based on at least one of sensor and camera data selecting a number of images to use in pre processing based on the at least one criterion and controlling parallel pre processing of the selected number of images of the potential suspect. The operations further may include determining at least one criterion relevant to the multiple images of the potential suspect based on at least one of sensor and camera data selecting types of operations to perform in pre processing based on the at least one criterion and controlling parallel pre processing of the multiple images of the potential suspect using the selected types of operations to perform in pre processing.

In some examples the operations may include determining at least one criterion relevant to the multiple images of the potential suspect based on at least one of sensor and camera data and selecting a number of images to use in pre processing based on the at least one criterion. In these examples the operations may include selecting types of operations to perform in pre processing based on the at least one criterion and controlling parallel pre processing of the selected number of images of the potential suspect using the selected types of operations to perform in pre processing.

In some implementations the operations may include accessing a reference image computing a similarity score that represents similarity between the determined image of the potential suspect and the reference image based on the accessed reference image and searching the watch list using the computed similarity score. In these implementations the operations may include identifying a subset of persons in the watch list having a similarity score within a threshold of the computed similarity score for the potential suspect.

Further the operations may include determining at least one criterion relevant to the multiple images of the potential suspect based on at least one of sensor and camera data selecting from among multiple reference images a reference image based on the at least one criterion and accessing the selected reference image. The operations may include evaluating distribution of similarity scores in the watch list selecting from among multiple reference images a reference image based on the evaluation of the distribution of similarity scores in the watch list and accessing the selected reference image. The operations also may include determining at least one criterion relevant to the multiple images of the potential suspect based on at least one of sensor and camera data evaluating distribution of similarity scores in the watch list selecting from among multiple reference images a reference image based on the at least one criterion and the evaluation of the distribution of similarity scores in the watch list and accessing the selected reference image.

In some implementations the operations may include determining a quality measure for the determined image of the potential suspect and images of persons in the watch list and setting a score threshold based on the determined quality measure for the determined image of the potential suspect and images of persons in the watch list. In these implementations the operations may include identifying a subset of persons in the watch list having a similarity score within the set score threshold of the computed similarity score for the potential suspect.

In some examples the operations may include determining a number of matches within a set of matches representative of the subset of persons in the watch list and determining whether the number of matches within the set of matches is within a match threshold. In these examples the operations may include using the set of matches as the subset of persons in the watch list for which to perform additional processing based on a determination that the number of matches within the set of matches is within the match threshold.

Based on a determination that the number of matches within the set of matches is not within the match threshold the operations may include selecting a new reference image that is different than the accessed reference image identifying a new set of matches within the score threshold for the new reference image determining the number of matches within each of the set of matches and the new set of matches and determining whether the number of matches within each of the set of matches and the new set of matches is within the match threshold. Based on a determination that the number of matches within each of the set of matches and the new set of matches is within the match threshold the matches in each of the set of matches and the new set of matches may be used as the subset of persons in the watch list for which to perform additional processing. Based on a determination that the number of matches within each of the set of matches and the new set of matches is not within the match threshold an additional reference image may be used in continuing to narrow potential matches.

In some implementations the operations may include determining a context of a situation associated with the determined image of the potential suspect setting a batch size based on the determined context of the situation and selecting a batch of images from the subset of persons in the watch list based on the batch size. In these implementations the operations may include controlling parallel analysis of the determined image of the potential suspect against the batch of images and controlling parallel analysis of the determined image of the potential suspect against additional batches of images until images of all of the subset of persons in the watch list have been analyzed.

In some examples the operations may include determining a criticality of the situation associated with the determined image of the potential suspect setting a batch size based on the determined criticality of the situation and selecting a batch of images from the subset of persons in the watch list based on the batch size. In these examples the operations may include controlling parallel analysis of the determined image of the potential suspect against the batch of images and controlling parallel analysis of the determined image of the potential suspect against additional batches of images until images of all of the subset of persons in the watch list have been analyzed.

In some implementations the operations may include determining a context of a situation associated with the determined image of the potential suspect determining a criticality of a situation associated with the determined image of the potential suspect setting a batch size based on the determined context of the situation and the determined criticality of the situation and selecting a batch of images from the subset of persons in the watch list based on the batch size. In these implementations the operations may include controlling parallel analysis of the determined image of the potential suspect against the batch of images and controlling parallel analysis of the determined image of the potential suspect against additional batches of images until images of all of the subset of persons in the watch list have been analyzed.

In addition the operations may include determining whether the number of unprocessed persons in the subset of persons in the watch list is greater than a batch size and based on a determination that the number of unprocessed persons in the subset is less than or equal to the batch size performing a comparison of the determined image of the potential suspect against all remaining unprocessed persons in the subset of persons in the watch list. The operations also may include selecting a batch of persons from the subset of persons in the watch list based on a determination that the number of unprocessed persons in the subset is greater than the batch size and performing a comparison of the determined image of the potential suspect against all persons in the selected batch of persons. The operations further may include determining whether a match is found within the selected batch based on the comparison of the determined image of the potential suspect against all persons in the selected batch. Based on a determination that a match is found within the selected batch processing may end and the match may be output. Based on a determination that a match is not found within the selected batch one or more additional batches of images may be processed in parallel until all of the subset of persons in the watch list have been processed or a match is found.

In some examples the operations may include identifying a person of interest from the watch list determining a profile for the identified person of interest from the watch list accessing one or more images of a crowd that includes multiple potential suspects and comparing the profile for the identified person of interest from the watch list to profiles of the multiple potential suspects included in the one or more images of the crowd. In these examples the operations may include selecting from among the multiple potential suspects included in the one or more images of the crowd the potential suspect for further processing based on the comparison revealing that the profile for the identified person of interest from the watch list matches a profile of the potential suspect. In these examples the operations of accessing multiple images of the potential suspect controlling parallel pre processing of the multiple images of the potential suspect determining the image of the potential suspect to use in matching against the watch list using the determined image of the potential suspect to search the sorted biometric data included in the watch list identifying the subset of persons from the watch list controlling parallel analysis of the determined image of the potential suspect against biometric data associated with the subset of persons in the watch list determining whether the potential suspect matches a person in the watch list and outputting the result based on the determination of whether the potential suspect matches a person in the watch list may be conditioned on the selection of the potential suspect for further processing.

The details of one or more implementations are set forth in the accompanying drawings and the description below. Other potential features of the disclosure will be apparent from the description and drawings and from the claims.

In some implementations a multi dimensional approach that leverages facial recognition technology is used to identify a suspect in a crowd in real time. The approach converts a sequential face matching process to a parallel process leveraging flexible computing and storage resources in the cloud for parallel processing while constraining the number of resources to be used in the cloud to optimize expenses without sacrificing performance.

After the multiple images of the potential suspect are captured pre processing is performed on each of the captured images in parallel . The pre processing includes any types of operations that enhance the quality of each of the captured images such as blur removal contrast enhancement brightness adjustment and skin tone enhancement. The pre processing is performed in parallel using flexible computing resources provided by a cloud service provider. For instance an amount of computing resources needed to pre process all of the captured images in parallel are requisitioned from the cloud service provider and used to pre process all of the captured images in parallel.

After the captured images have been pre processed and enhanced the enhanced versions of the captured images are analyzed and the best image of the potential suspect is selected for use in matching. The selected image is compared against a reference image to obtain an index value that reflects how similar the selected image is to the reference image. The index value of the selected image is then used to search a watch list of persons of interest . The watch list includes index values for all of the persons of interest in the watch list. The index values in the watch list were computed using the same reference image and the same process used to compute the index value for the selected image. The index values in the watch list also are sorted in ascending or descending order. When the watch list is searched using the index value of the selected image the index values in the watch list are compared to the index value of the selected image and a subset of the index values within the watch list that are within a threshold value of the index value of the selected image are identified based on the comparison.

Because the index values in the watch list are sorted in ascending or descending order all index values in the watch list do not need to be compared to the index value of the selected image. Rather knowledge of how the index values are sorted in the watch list is leveraged to search in the watch list in a more efficient manner. For example a binary search process may be used in which half the list of index values in the watch list may be discarded with each comparison performed. In this example the index value of the selected image is compared to a central index value in the list of index values. If the index values are sorted in ascending order and the index value of the selected image is less than the central index value the bottom half of the list is discarded because all the index values within the bottom half of the list are now known to be greater than the index value of the selected image. The binary search continues to compare the index value of the selected image to the central index value of the remaining index values in the watch list and discard half of the remaining index values with each comparison until the subset of index values within the threshold of the index value of the selected image is identified. By using a binary search process that leverages knowledge of how the index values are sorted in the watch list the subset of index values within the threshold may be identified relatively quickly.

After identifying the subset of index values in the watch list that are within the threshold of the index value of the selected image detailed face images e.g. blobs storing face images for the persons in the subset is accessed a detailed face image e.g. a blob storing a face image for the potential suspect is accessed and a parallel matching process is performed using the detailed face images for the persons in the subset and the detailed face image for the potential suspect . The detailed matching process is performed in parallel using flexible computing resources provided by a cloud service provider. For instance an amount of computing resources needed to perform matching of all of the detailed face images for the persons in the subset against the detailed face image for the potential suspect in parallel are requisitioned from the cloud service provider and used to matching in parallel. The parallel matching is possible because each of the detailed face images for the persons in the subset are stored on a separate partition server within non relational storage provided by the cloud service provider. Because the detailed face images for the persons in the subset are stored on different partition servers the detailed face images for the persons in the subset may all be accessed in parallel and then compared against the detailed face image for the potential suspect in parallel.

In addition as shown in the detailed face images for the persons in the subset may be divided into batches and processed in batches rather than processing all of the detailed face images for the persons in the subset in a single parallel process. Because requisitioning computing resources from a cloud service provider may be expensive a decision may be made to sacrifice some performance benefits and divide the detailed face images into batches instead of processing all of the detailed face images at the same time. After the images have been divided into batches all of the images in the first batch are matched against the detailed face image for the potential suspect in parallel. If a match is found in the first batch the match is returned and processing of subsequent batches of images is omitted. However if a match is not found in the first batch all of the images in a second batch are matched against the detailed face image for the potential suspect in parallel. The batches of images are continued to be processed until a match is found or all of the batches of images have been processed without finding a match.

Using the techniques described in a potential suspect may be matched against a watch list relatively quickly and a crowd of people may be scanned for persons of interest in the watch list in a relatively short period of time e.g. real time . In addition because resources in the cloud are leveraged in scanning the crowd of people for persons of interest in the watch list the processing is flexible and the cost of scanning the crowd quickly may be balanced against the desire to locate a person of interest in the crowd quickly.

The image processor processes the one or more images to determine attributes of the images and or persons within the one or more images. For instance the image processor may compute the distance between a person within an image and the camera based on an analysis of the captured image. The image processor also may determine the angle gender ethnicity and any other detectable attributes of a person within the one or more images based on an analysis of the one or more images. The image processor also may determine general characteristics e.g. blurriness etc. of the one or more images based on an analysis of the one or more images.

The sensor data processor processes the sensor data sensed by the one or more sensors to determine attributes related to the one or more images captured by the one or more cameras . For instance the sensor data processor may compute darkness and or brightness levels related to the one or more images based on output from the one or more sensors e.g. one or more light intensity sensors . The sensor data processor may determine any attributes related to the one or more images captured by the one or more cameras that are capable of determination by the one or more sensors .

The adaptation engine receives output from the image processor and the sensor data processor and based on the output determines to allocate a certain number of processors and a certain amount of storage to processing including pre processing images of the target. The adaptation engine sends the determined allocation of the number of processors and the amount of storage to the cloud provisioning system . The cloud provisioning system interfaces with the cloud service provider and requests the cloud service provider to allocate the number of processors and the amount of storage. The cloud service provider performs actual provisioning of the number of processors and the amount of storage based on the request from the cloud provisioning system . The cloud service provider confirms allocation of the number of processors and the amount of storage to the cloud provisioning system and the cloud provisioning system in turn confirms allocation of the number of processors and the amount of storage to the adaptation engine .

After receiving confirmation of the allocation of the number of processors and the amount of storage the adaptation engine instructs the Face in the Crowd system to use the allocated number of processors and the amount of storage for processing images of the target. Based on the instructions from the adaptation engine the Face in the Crowd system starts the Face in the Crowd application with the allocated number of processors and the amount of storage. The Face in the Crowd application processes one or more images of the target in parallel in attempting to determine whether the target matches any of the persons in the watch list. As described throughout this disclosure multiple targets may be processed in parallel and the Face in the Crowd application may process images of multiple different targets from a crowd in parallel.

In some examples the data store may be a relational database that logically organizes data into a series of database tables. Each database table in the data store may arrange data in a series of columns where each column represents an attribute of the data stored in the database and rows where each row represents attribute values . In some implementations the data store may be an object oriented database that logically or physically organizes data into a series of objects. Each object may be associated with a series of attribute values. In some examples the data store may be a type of database management system that is not necessarily a relational or object oriented database. For example a series of XML Extensible Mark up Language files or documents may be used where each XML file or document includes attributes and attribute values. Data included in the data store may be identified by a unique identifier such that data related to a particular process may be retrieved from the data store .

The processor may be a processor suitable for the execution of a computer program such as a general or special purpose microprocessor and any one or more processors of any kind of digital computer. In some implementations the system includes more than one processor . The processor may receive instructions and data from the memory . The memory may store instructions and data corresponding to any or all of the components of the system . The memory may include read only memory random access memory or both.

The I O devices are configured to provide input to and output from the system . For example the I O devices may include a mouse a keyboard a stylus or any other device that allows the input of data. The I O devices may also include a display a printer or any other device that outputs data.

The system manages a watch list . For instance the system manages a watch list of persons of interest that includes biometric data e.g. a face image for each of the persons of interest. The watch list may include criminals that a government agency is trying to locate missing persons persons blacklisted from an establishment or any type of persons of interest that an organization would like to locate.

The system creates in relational database storage a table for the watch list . For instance the system creates a relational database table that includes columns for information collected in the watch list. The relational database table may include a column that stores a unique identifier for each person in the watch list a column that stores an index value of biometric data for each person in the watch list and a column for detailed biometric data for each person in the watch list. The index value of biometric data is a representation of biometric data that is capable of being sorted and may include a similarity score that represents how similar biometric data e.g. a facial image for the person in the watch list is to a reference image. The column for detailed biometric data may store the detailed biometric data itself e.g. blob data of a facial image or may store a link to the detailed biometric data stored in another location.

The system accesses biometric data for a person to include on the watch list . For example the system receives a biometric image of a person s face. In this example the system may include or communicate with one or more devices that capture biometric images of a person. The one or more devices may include cameras or any other type of device capable of capturing a biometric image of a person. The system may access the output of any of the one or more devices as the biometric image in a traditional image format such as bmp jpeg tiff png etc.

In some examples the system accesses the biometric image from electronic storage. In these examples biometric images may be captured over time at a location separate from the system and stored for later processing and identification. The system also may receive the biometric image over a network.

The system determines an index value from the accessed biometric data . For instance the system determines a representation of the accessed biometric data that may be sorted. The system may determine the index value as a numeric representation of a facial image of the person being added to the watch list.

In some implementations to determine the index value the system uses a reference image to compute a similarity score that represents similarity between the accessed biometric image and the reference image. In these implementations the system accesses the reference image from electronic storage. The reference image may be an image of a face of a reference person. The reference image may be of any reference person as long as the reference image is used in calculating similarity scores for all similarity scores stored in the watch list and then used in searching the similarity scores.

After accessing the reference image the system compares the accessed facial image with the reference facial image and generates a numeric value that reflects similarity between the accessed facial image and the reference facial image. In these examples the system may compute the similarity scores between two templates extracted from the two images. The resulting score reflects the similarity between the accessed facial image and the reference facial image in that the score is closer to zero depending how similar the accessed biometric image is to the reference image i.e. the score would be zero for same images and near to zero for identical images .

Any type of process for computing a similarity score e.g. numeric value that reflects similarity between two images may be used. For example to compute a similarity score between two images a method for facial matching using zero crossings of a one dimensional Discrete Cosine Transform DCT may be used to perform feature extraction for later classification. This coding method is based on differences of discrete cosine transform DCT coefficients of overlapped angular patches from normalized facial images. The DCT of a series of averaged overlapping angular patches are taken from normalized facial images and a small subset of coefficients is used to form subfeature vectors. Feature codes are generated as a sequence of many such subfeatures and classification is carried out using a weighted Hamming distance metric. This technique is described in more detail in DCT based iris recognition by D. M. Monro S. Rakshit and D. Zhang published in IEEE Transactions on Pattern Analysis and Machine Intelligence Vol. 29 No. 4 pp. 586 595 April 2007.

In addition other face matching techniques may be used in determining an index value e.g. computing a similarity score that reflects similarity between two images . For example the system may employ face matching techniques that use Singular Value Decomposition and Radial Basis Function using Neural Networks. These techniques are described in more detail in Face Verification Based on Singular Value Decomposition and Radial Basis Function Neural Network by Yunhong Wang Tieniu Tan and Yong Zhu National Laboratory of Pattern Recognition Institute of Automation Chinese Academy of Sciences Beijing P. R. China 100080 published at http www.cbsr.ia.ac.cn publications yhwang Face 20Verification 20Based 20on 20Singular 20Value 20Decomposition 20and 20Radial 20Basis 20Function 20Neural 20Network.pdf. The system also may employ face matching techniques that perform Face Verification using locally adaptive regression kernel LARK representation. These techniques are described in more detail in Face Verification Using the LARK Representation by Hae Jong Seo Student Member IEEE Peyman Milanfar Fellow IEEE published at http users.soe.ucsc.edu milanfar publications journal TIFS Final.pdf.

In some examples the system may access multiple biometric images of the face of the person being added to the watch list and compute for each of the multiple biometric images a similarity score that represents similarity between the corresponding biometric image and the reference image. In these examples the system may determine an average similarity score or median similarity score based on the similarity scores computed for the multiple biometric images. Using multiple biometric images of the face of the person may provide a more accurate similarity score and may account for slight differences in position when capturing biometric images of the person as compared to position in the reference image.

In some implementations the system may use one or more image similarity processes to generate a similarity measure between the accessed biometric image and the reference image. In these implementations the system may normalize the similarity measure to a similarity score between zero and one. Normalization allows the system to use a similarity process that produces a measure outside of a desired scale. In addition normalization may allow different similarity processes with different output ranges to be used and may allow for changes in the similarity process as long as the normalization is adjusted to compute similarity scores within the desired range e.g. zero to one .

The system stores the index value with an identifier for the person at an appropriate location in the table . For example the system identifies an appropriate row in the table created in the relational database storage based on the index value. In this example the appropriate row in the table is the row that maintains the index values within the table in a sorted manner. The system may compare the index value with other index values already sorted in the watch list table if any and based on the comparison finds the row where the index value belongs in the sorted list. If the index values are numeric and sorted in ascending order the system identifies the first row as the appropriate row when the system determines that the index value is lower than all of the other index values in the table identifies the last row as the appropriate row when the system determines that the index value is higher than all of the other index values in the table or identifies a row where the index value falls between two adjacent index values in the sorted list. If the index values are numeric and sorted in descending order the system identifies the first row as the appropriate row when the system determines that the index value is higher than all of the other index values in the table identifies the last row as the appropriate row when the system determines that the index value is lower than all of the other index values in the table or identifies a row where the index value falls between two adjacent index values in the sorted list.

After identifying the appropriate location e.g. row within the table the system stores a unique identifier of the person at the appropriate location e.g. row in a field e.g. column used to store unique identifiers. The system also stores the index value at the appropriate location e.g. row in a field e.g. column used to store index value. Because the system stores the unique identifier and the index value at the same location e.g. the same row the unique identifier and the index value are associated with one another.

The system determines whether blob data for the person meets a threshold storage size . For instance the system accesses blob data for the person and determines an amount of storage needed to store the accessed blob data. The accessed blob data may represent the facial image of the person and may be the accessed biometric data used to determine the index value for the person. After determining the storage size of the blob data as the amount of storage needed to store the accessed blob data the system accesses the threshold storage size compares the determined storage size of the blob data to the threshold storage size and determines whether the blob data meets the threshold storage size based on the comparison. The threshold storage size may be a pre set value e.g. one megabyte or may be dynamically determined based on the current storage and access characteristics of the one or more databases being used to store blob data.

Based on a determination that the blob data for the person does not meet the threshold storage size the system stores the blob data in the table with the identifier . For instance the system stores the blob data for the person at the appropriate location e.g. row in the table in a field e.g. column used to store blob data or links to blob data. In storing the blob data in the table the system converts the blob data from an object representation to a data representation needed for storage in the relational database table. In this regard the system serializes the blob data for storage in the relational database table and then deserializes the stored data representation back to the object format when extracting the blob data from the relational database table. Although the serialization and deserialization of the data takes processing the performance impact is not significant because the data size is relatively small and lower than the threshold storage size. In fact the processing needed for serialization and deserialization of the data may be more efficient than the processing needed to access a link from the relational database table and then use the accessed link to access the blob data in an object format directly from another non relational storage system. Accordingly the system sets the threshold storage size based on the processing time needed for the serialization and deserialization of the data as compared to the processing time needed to access a link from the relational database table and then use the accessed link to access the blob data in an object format directly from another non relational storage system. The system sets the threshold storage size such that blob data is stored in the relational database table unless the storage size of the blob data causes the serialization and deserialization of the blob data to impact performance as compared to the processing time needed to access a link from the relational database table and then use the accessed link to access the blob data in an object format directly from another non relational storage system. Because the system stores the unique identifier and the blob data at the same location e.g. the same row the unique identifier and the blob data are associated with one another.

Based on a determination that the blob data for the person meets the threshold storage size the system stores the blob data in non relational storage and stores a link to the blob data in the table with the identifier . For instance the system stores the blob data for the person in a non relational storage system and determines an address at which the blob data is stored in the non relational storage system. In storing the blob data in the non relational storage system the system causes the blob data to be stored on a separate partition server from all other instances of blob data that are in the watch list and that are stored in the non relational storage system. By maintaining all instances of blob data on separate partition servers the system ensures that all instances of blob data can be accessed simultaneously in parallel which enables true parallel processing to be performed on the images in the watch list.

The system may ensure that all instances of blob data are stored on separate partition servers by controlling naming conventions for each instance of blob data in a manner that causes the cloud service provider providing the non relational storage system to store each instance of blob data on a different partition server. For instance the system may assign each blob a unique key which is composed of its container name and blob name. This key is used as a partitioning key which assigns the blob to one partition server. The access to each partition server is load balanced and all the partition servers use a common distributed file system. With this approach concurrent access to all of the images at the same time is possible as they are on different partition servers and the system may run parallel matching processes for same suspect as well as for different suspects in parallel. This concurrent parallel matching cannot be performed by using of relational databases. Any other techniques to control storage of each instance of blob data on a different partition server may be used.

Another aspect of a cloud storage system that provides non relational storage is that it allows blobs to be divided into blocks and these blocks are stored and retrieved in parallel from the blob storage. In this regard the system may retrieve each blob in a faster way by retrieving blocks in parallel.

After storing the blob data for the person in the non relational storage system and determining the address at which the blob data is stored in the non relational storage system the system stores a link to the address at which the blob data is stored at the appropriate location e.g. row in the table in a field e.g. column used to store blob data or links to blob data. Because the system stores the unique identifier and the blob data at the same location e.g. the same row the unique identifier and the blob data are associated with one another.

The system determines whether another person needs to be added to the watch list . Based on a determination that another person needs to be added to the watch list the system repeats the process of storing an index value and blob data for the person as described above with respect to reference numerals to . The system continues to add additional persons to the watch list until all persons have been added to the watch list.

Based on a determination that another person does not need to be added to the watch list the system updates the watch list while maintaining index values sorted in the watch list and maintaining all blobs stored on different partition servers . For instance when a new person is added to the watch list the system performs the operations described at reference numerals to to add the new person at the appropriate location in the watch list and to if the threshold storage size is met store blob data for the new person on a separate partition server from partition servers used to store all other instances of blob data for persons in the watch list. The system may routinely verify that the watch list remains sorted in a proper manner and that all instances of blob data are stored on different partition servers. To the extent the verification reveals that the watch list is not properly sorted or that all instances of blob data are not stored on different partition servers the system corrects any issues by re sorting the watch list and redistributing the blob data within the non relational storage system.

The storage account includes table storage and blob storage . The table storage supports massively scalable tables in the cloud which may include billions of entities and terabytes of data. Given the vast amount of storage the system may efficiently scale out by automatically scaling to thousands of servers as traffic grows. The table storage is used to store the index table for the watch list. The index table includes a set of entities . Table names are scoped by the account. An application may create many tables within a storage account. A table does not have a fixed schema allowing tables to store entities with different type of properties.

The entities which are analogous to rows in a table are the basic data items stored in a table. An entity contains a set of properties. Each table has two properties that form the unique key for the entity. An entity is dissimilar from a row in a relational database like a structured query language SQL database as it need not have a fixed structure. Each entity in a table can be different with other entity in terms of the structure of properties. A property which is analogous to a column in a table represents a single value in an entity. Property names are case sensitive and a rich type set is supported for property values.

A PartitionKey is the first key property of every table. The system uses the PartitionKey to automatically distribute the table s entities over many storage nodes. The entities having the same partition keys are stored on the same node. In some examples the face images of similar group type will be assigned the same partition key. To be more specific each index profile is assigned a different partition key. For instance the watch list of a particular country or region may be assigned the same partition key.

A RowKey is the second key property for the table. The RowKey is the unique ID of the entity within the partition it belongs to. The PartitionKey combined with the RowKey uniquely identifies an entity in a table. In some examples the index values e.g. similarity scores are considered as the RowKey.

Every entity has a version maintained by the system and includes a timestamp related to the entity s creation and or updates. A Partition includes a set of entities in a table with the same partition key value. The sort order is a single index where all entities in a table are sorted by PartitionKey and then RowKey. In this regard queries specifying these keys are more efficient and all results are returned sorted by PartitionKey and then by RowKey.

As shown illustrates an example set of entity properties for the index table. The entity properties include a PartitionKey as a string in which the database category is considered as the PartitionKey. The entity properties also include a RowKey where the computed index value of an image is considered as the RowKey. The entity properties further include a RecordID which is a field that assigns a unique RecordID for each identity and an ImageURL which is a field that stores the uniform resource locator URL for the corresponding blob. The ImageURL is the property used to link the table and the blob images.

The blob storage enables applications to store large objects up to 50 GB each in the cloud. The blob storage supports a massively scalable blob system where hot blobs are served from many servers to scale out and meet the traffic needs of the application. A container in the blob storage provides a grouping of a set of blobs . The container name is scoped by the account. Sharing policies are set at the container level. Public READ and Private are supported. When a container is Public READ all of its contents may be read by anyone without requiring authentication. When a container is Private only the owner of the corresponding account may access the blobs in that container with authenticated access. Containers also may have metadata associated with them. Metadata may be in the form of pairs and may be up to 8 KB in size per container. The ability to list all of the blobs within the container is also provided.

Blobs are stored in and scoped by Blob Containers. Each blob may be up to 50 GB. A blob has a unique string name within the container. Blobs may have metadata associated with them which may be pairs and may be up to 8 KB in size per blob. The blob metadata may be retrieved and set separately from the blob data bits.

As shown illustrates an example blob format for blobs stored in the blob storage . The blob format includes an ImageURL as a string which is the URL for the image stored as a blob. The blob format also includes a RecordID as a string which is a field stored as a metadata with a blob. All access to a blob is done through a standard HTTP REST PUT GET DELETE interface. Blobs may be accessed via PUT and GET by using the appropriate URL. Together the container name and the blob name form a unique partition key which causes each blob to be stored on a different partition server. By setting the container name and the blob name to cause each blob to be stored on a different partition server the system is able to concurrently access each blob and perform parallel accessing of each blob.

Referring again to the system accesses multiple images of a potential suspect . For example the system receives multiple biometric images of a person s face. In this example the system may include or communicate with one or more devices that capture biometric images of a person. The one or more devices may include cameras or any other type of device capable of capturing a biometric image of a person. The system may access the output of any of the one or more devices as the biometric image in a traditional image format such as bmp jpeg tiff png etc.

In some implementations the multiple images of the potential suspect may be multiple images of a crowd with many potential suspects taken successively in time e.g. images of the crowd taken about every second . In these implementations the system analyzes the multiple images of the crowd to identify a single potential suspect within each of the images of the crowd. After the system identifies the single potential suspect within each of the images of the crowd the system extracts a portion of each of the multiple images of the crowd that includes the single potential suspect and accesses the extracted portions of the multiple images as the multiple images of the potential suspect.

In some examples the system accesses the multiple biometric images from electronic storage. In these examples biometric images may be captured over time at a location separate from the system and stored for later processing and identification. The system also may receive the multiple biometric images over a network.

The system controls parallel pre processing of the multiple images . For example the system takes each of the multiple images and performs pre processing of each of the multiple images in parallel. In this example the system may requisition processing resources from a cloud service provider and control the processing resources from the cloud service provider to pre process the multiple images in parallel.

In some situations the number of multiple images may be too large to justify pre processing all of the multiple images in parallel. In these situations the system determines to pre process the multiple in multiple batches. In this regard the system divides the multiple images in several batches selects a first batch of images for pre processing controls pre processing of the images in the first batch in parallel and after completion continues to iteratively perform parallel pre processing of images in the remaining batches until all of the multiple images have been pre processed.

The system may perform any types of pre processing operations. For instance system may use any type of image processing technique in an attempt to enhance the quality of the images to enhance the quality of the images and achieve the best images to use in facial matching. The system also may consider aspects of several of the multiple images and derive an enhanced representation of the potential suspect based on features captured in several different images. For example the system may fill in a shadow on an otherwise good image of the potential suspect s face using a portion of another image of the potential suspect s face. In pre processing the system attempts to enhance the quality of the facial images of the potential suspect and generate the best possible representation of the potential suspect s face by selecting the best image from among the enhanced versions of the multiple images or using a combination of the enhanced versions of the multiple images. The stages of pre processing the system may use in attempting to enhance the quality of the facial images of the potential suspect include contrast enhancement blur removal brightness adjustment increase decrease as appropriate skin tone enhancement or any other type of pre processing that enhances quality of a facial image.

The system determines criteria relevant to the multiple images of the potential suspect based on sensor and or camera data . For example the system may access sensor data captured in conjunction with capturing of the multiple images and analyze the accessed sensor data to determine criteria relevant to the captured images. In this example the sensor data may be sensor data captured by a light level sensor and or a proximity sensor that senses distances of objects from the camera capturing the image e.g. a time of flight sensor . The system may analyze the light level sensor and or the proximity sensor data and determine a light level at a time when the multiple images were captured and or a distance of one or more objects e.g. persons within the multiple images based on the analysis.

In some implementations the system may analyze the camera data e.g. the multiple images and determine criteria relevant to the captured images based on the analysis. In these implementations the system may analyze the camera data to determine a distance of one or more objects e.g. persons within the multiple images. The system also may analyze faces detected within the multiple images and determine whether features of the detected faces have characteristics that suggest the face is of a female or a male. In this regard the system may determine the gender of the detected faces within the multiple images. The system further may perform skin tone processing of faces detected within the multiple images and determine ethnicity of persons within the multiple images based on the skin tone processing.

In some examples the system may consider a combination of the sensor data and the camera data in determining criteria relevant to the multiple images of the potential suspect. In these examples the system may determine a distance of one or more objects e.g. persons within the multiple images based on sensor data from a proximity sensor and then confirm the measured distances or that the objects are in fact persons based on analysis of the camera data. Based on the sensor data and or the camera data the system may determine lighting conditions distance of persons in the multiple images camera angle with respect to persons in the multiple images gender of persons in the multiple images ethnicity of persons in the multiple images and any other criteria relevant to the multiple images of the potential suspect that assists in informing processing needed on the multiple images.

The system selects a number of images to use in pre processing based on the criteria . For example the system considers the criteria determined e.g. lighting conditions distance camera angle gender ethnicity etc. and selects the number of images to use in pre processing based on the criteria determined. In this example the system selects the number of images that are needed or would be beneficial in determining an image to use in matching based on the criteria determined. For instance when the lighting conditions are relatively poor and the distance of the person is relatively far from the camera the system selects a relatively high number of images to use in pre processing because the criteria suggests that determining an image of sufficient quality will be relatively difficult and a large number of images would be beneficial. When the lighting conditions are relatively good and the distance of the person is relatively near the camera the system selects a relatively low number of images to use in pre processing because the criteria suggests that determining an image of sufficient quality will be relatively easy and a sufficient image is likely to be determined in the low number of images. To determine the number of images to use in pre processing the system may reference a look up table that stores a number of images to use in pre processing for the various possible values or value ranges for the criteria used by the system to select the number of images. The system may store the look up table in electronic storage based on user input provided by an operator of the system .

The system references the first data structure and or the second data structure in selecting a number of images to use in pre processing. For example the system determines lighting conditions of the images based on output from a light sensor positioned at a location where the images were captured or based on analysis of the images themselves. In this example the system determines whether the images were taken with no noticeable light were taken at night with dim light were taken indoors or were taken in daylight. Based on the determination the system references the first data structure and selects the number of images to use in pre processing defined by the first data structure . For instance the system selects fifty images based on determining that the images were taken with no noticeable light selects twenty images based on determining that the images were taken at night with dim light selects ten images based on determining that the images were taken indoors and selects five images based on determining that the images were taken at in daylight.

In another example the system determines a distance of the potential suspect from the camera in the images based on output from a distance sensor positioned at the camera or based on analysis of the images themselves. In this example the system determines whether the potential suspect is more than two hundred yards away from the camera between one hundred to two hundred yards away from the camera between fifty to one hundred yards away from the camera or less than fifty yards away from the camera. Based on the determination the system references the second data structure and selects the number of images to use in pre processing defined by the second data structure . For instance the system selects fifty images based on determining that the potential suspect is more than two hundred yards away from the camera selects twenty images based on determining that the potential suspect is between one hundred to two hundred yards away from the camera selects ten images based on determining that the potential suspect is between fifty to one hundred yards away from the camera and selects five images based on determining that the potential suspect is less than fifty yards away from the camera.

The system selects types of operations to perform in pre processing based on the criteria . For example the system considers the criteria determined e.g. lighting conditions distance camera angle gender ethnicity etc. and selects the types of operations to perform in pre processing based on the criteria determined. In this example the system selects the stages of pre processing to perform from among stages including contrast enhancement blur removal brightness adjustment increase decrease as appropriate skin tone enhancement or any other type of pre processing that enhances quality of a facial image.

The system selects the types of operations that are needed or would be beneficial in determining an image to use in matching based on the criteria determined. For instance when the lighting conditions are relatively poor and the distance of the person is relatively far from the camera the system selects a relatively large number of operations to use in pre processing because the criteria suggests that determining an image of sufficient quality will be relatively difficult and a large amount of pre processing would be beneficial. When the lighting conditions are relatively good and the distance of the person is relatively near the camera the system selects a relatively low number of operations to use in pre processing because the criteria suggests that determining an image of sufficient quality will be relatively easy and a sufficient image is likely to be determined without a large amount of pre processing. To determine the types of operations to use in pre processing the system may reference a look up table that stores operations to use in pre processing for the various possible values or value ranges for the criteria used by the system to select the number of images. The system may store the look up table in electronic storage based on user input provided by an operator of the system . For instance the system may use data structures similar to the data structures and discussed above with respect to to determine the operations to use in pre processing.

The system controls parallel pre processing of the selected number of images using the selected types of operations . For instance the system accesses e.g. captures the selected number of images of the potential suspect and performs the selected types of pre processing operations e.g. one or more of contrast enhancement blur removal brightness adjustment skin tone enhancement etc. on the accessed images. The system may control the pre processing of the accessed images in parallel using processing resources requisitioned from a cloud service provider.

Referring again to the system determines an image of the potential suspect to use in matching against the watch list . For example the system analyzes the enhanced versions of the multiple images that result from pre processing and for each image determines a quality score that reflects the quality of the corresponding image of the potential suspect s face. In this example the system compares the determined quality scores and selects the image having the highest quality score to use in matching against the watch list.

In some examples the system may consider aspects of several of the multiple images and derive an enhanced representation of the potential suspect based on features captured in several different images. In these examples the system may fill in a shadow on an otherwise good image of the potential suspect s face using a portion of another image of the potential suspect s face. The system may attempt to generate the best possible representation of the potential suspect s face using a combination of the enhanced versions of the multiple images that result from pre processing. For instance the system may take small portions of several of the images and generate a new image that reflects a combination of the information captured in the several images. In this regard the system may generate a new composite image of the potential suspect that is better than any of the captured images alone.

In some implementations the system may determine whether to perform processing of a combination of the enhanced versions of the multiple images that result from pre processing based on whether any of the enhanced versions of the multiple images are of sufficient quality. In these implementations the system may identify the image having the highest quality score as discussed above and determine whether the image having the highest quality score is of sufficient quality. For instance the system may compare the highest quality score to a quality threshold and based on the comparison determine whether the highest quality score meets the quality threshold. Based on a determination that the highest quality score meets the quality threshold the system determines that the image having the highest quality score is of sufficient quality and omits processing of a combination of the enhanced versions of the multiple images. Based on a determination that the highest quality score does not meet the quality threshold the system determines that the image having the highest quality score is of insufficient quality and performs processing of a combination of the enhanced versions of the multiple images in an attempt to generate a new image that is of better quality.

The system uses the determined image to search the watch list and identifies a subset of persons from the watch list based on the search . For example the system computes an index value of the determined image and uses the computed index value to search the sorted list of index values in the watch list in a manner that leverages knowledge of how the index values are sorted e.g. ascending or descending order . In this example the system may discard multiple potential matches perhaps many potential matches with a single comparison based on the knowledge of how the index values are sorted. A binary search process or any other search process described throughout this disclosure may be used.

Based on results of the searching the system identifies a subset of persons in the watch list that are each associated with an index value within a threshold of the computed index value. The system may identify the subset of persons by identifying index values whose absolute difference from the computed index value is less than or equal to the threshold. If the index values were not sorted the system would have to compare the computed index value against all of the index values to ensure each appropriate person is found. However because the index values are sorted the system may find the subset of people more quickly by discarding multiple index values using a single comparison and knowledge of how the index values are sorted. As described throughout this disclosure the system may compute the index value as a similarity score that reflects similarity of the determined image to a reference image used to generate the sorted similarity scores within the watch list.

The system accesses a reference image . For instance the system accesses the reference image from electronic storage. The reference image may be an image of a face of a reference person. The reference image may be of any reference person as long as the reference image is used in calculating similarity scores for all similarity scores being searched.

The system determines criteria relevant to the multiple images of the potential suspect based on sensor and or camera data . For example the system may access sensor data captured in conjunction with capturing of the multiple images and analyze the accessed sensor data to determine criteria relevant to the captured images. In this example the sensor data may be sensor data captured by a light level sensor and or a proximity sensor that senses distances of objects from the camera capturing the image e.g. a time of flight sensor . The system may analyze the light level sensor and or the proximity sensor data and determine a light level at a time when the multiple images were captured and or a distance of one or more objects e.g. persons within the multiple images based on the analysis.

In some implementations the system may analyze the camera data e.g. the multiple images and determine criteria relevant to the captured images based on the analysis. In these implementations the system may analyze the camera data to determine a distance of one or more objects e.g. persons within the multiple images. The system also may analyze faces detected within the multiple images and determine whether features of the detected faces have characteristics that suggest the face is of a female or a male. In this regard the system may determine the gender of the detected faces within the multiple images. The system further may perform skin tone processing of faces detected within the multiple images and determine ethnicity of persons within the multiple images based on the skin tone processing.

In some examples the system may consider a combination of the sensor data and the camera data in determining criteria relevant to the multiple images of the potential suspect. In these examples the system may determine a distance of one or more objects e.g. persons within the multiple images based on sensor data from a proximity sensor and then confirm the measured distances or that the objects are in fact persons based on analysis of the camera data. Based on the sensor data and or the camera data the system may determine lighting conditions distance of persons in the multiple images camera angle with respect to persons in the multiple images gender of persons in the multiple images ethnicity of persons in the multiple images and any other criteria relevant to the multiple images of the potential suspect that assists in informing processing needed on the multiple images.

The system evaluates distribution of similarity scores in the watch list . For instance the system analyzes how spread out the similarity scores in the watch list and determines whether the similarity scores are evenly distributed throughout the watch list or clustered in one or more groups based on the analysis. When the similarity scores are evenly distributed throughout the watch list the reference image is relatively good for the images of the persons in the watch list and the similarity scores allow the system to narrow down to a relatively small number of potential matches by searching the similarity scores. When the similarity scores are clustered in one or more groups the reference image is relatively poor for the images of the persons in the watch list and the similarity scores may leave the system with a relatively large number of potential matches based on the similarity score of the potential suspect falling within a group of similarity scores.

The system selects a reference image based on the criteria and the evaluation . For example the system considers the criteria determined e.g. lighting conditions distance camera angle gender ethnicity etc. and selects a reference image appropriate for the criteria determined. In this example the system uses multiple reference images and the watch list stores multiple index profiles e.g. a sorted list of similarity scores for each reference image . Each reference image may be stored with metadata that defines the criteria for which is reference image provides better performance. For instance when the lighting conditions are relatively poor and the distance of the person is relatively far from the camera the system selects a first reference image that provides relatively good performance for images of a potential suspect that are captured in relatively poor lighting conditions when the potential suspect is relatively far from the camera. When the lighting conditions are relatively good and the distance of the person is relatively near the camera the system selects a second reference image that provides relatively good performance for images of a potential suspect that are captured in relatively good lighting conditions when the potential suspect is relatively near the camera. To determine the reference image to use in searching the watch list the system may reference a look up table that stores an indication of which one or more reference images provide good performance for the various possible values or value ranges for the criteria used by the system to select the reference image. The system may store the look up table in electronic storage based on user input provided by an operator of the system .

In some implementations the system considers the distribution of similarity scores within the watch list in selecting the reference image. In these implementations the system may determine that similarity scores in the watch list for a particular reference have become clustered and based on the determination change the reference image being used for the watch list. When the system uses multiple reference images and the watch list stores multiple index profiles e.g. a sorted list of similarity scores for each reference image the system may select the reference image for which the similarity scores are most evenly distributed throughout the list.

In some examples the system selects the reference image using a combination of the criteria determined e.g. lighting conditions distance camera angle gender ethnicity etc. and the distribution of similarity scores within the watch list. In these examples the system may first narrow down the potential reference images to a subset of reference images that provide relatively good performance for the criteria determined. After narrowing down the potential reference images to the subset of reference images the system analyzes the distribution of similarity scores within the lists of similarity scores for each of the subset of reference images and selects the reference image that corresponds to the most evenly distributed list of similarity scores. The system also may first consider the distribution of similarity scores to arrive at the subset of reference images and then select the reference image from the subset of reference images that provides the best performance for the criteria determined.

As shown in a first reference image and a first index list includes metadata that indicates that the first reference image provides relatively good performance for distances greater than two hundred yards and dim lighting conditions. The first reference image and the first index list also include metadata that indicates that the distribution of similarity scores within the first index list is excellent. A second reference image and a second index list include metadata that indicates that the second reference image provides relatively good performance for distances between one hundred and two hundred yards and no light. The second reference image and the second index list also include metadata that indicates that the distribution of similarity scores within the second index list is of medium quality e.g. some clustering of similarity scores within the second index list . A third reference image and a third index list includes metadata that indicates that the third reference image provides relatively good performance for distances less than fifty yards and day light conditions. The third reference image and the third index list also include metadata that indicates that the distribution of similarity scores within the third index list is excellent. A fourth reference image and a fourth index list includes metadata that indicates that the fourth reference image provides relatively good performance for distances between fifty and one hundred yards and indoor lighting conditions. The fourth reference image and the fourth index list also include metadata that indicates that the distribution of similarity scores within the fourth index list is excellent. An nth reference image and an nth index list includes metadata that indicates that the nth reference image provides relatively good performance for distances greater than two hundred yards and dim lighting conditions. The nth reference image and the nth index list also include metadata that indicates that the distribution of similarity scores within the nth index list is of poor quality e.g. significant clustering of similarity scores within the nth index list .

The system uses the metadata associated with the reference images and corresponding index lists shown in to determine which reference image to use. For example the system determines that the distance of the potential suspect is greater than two hundred yards from the camera and dim lighting conditions exist. In this example the system determines that the first reference image and the first index list and the nth reference image and the nth index list meet the criteria of greater than two hundred yards from the camera and dim lighting conditions. The system then considers the distribution of the similarity scores within the first index list and the nth index list and selects the first reference image and the first index list because the distribution in the first index list is excellent and the distribution in the nth index list is poor. In this regard the system uses the first reference image and the first index list to perform a search based on the image of the potential suspect and only consults the nth reference image and the nth index list as a secondary option if the system cannot determine a satisfactory result using the first reference image and the first index list . In some implementations the system may discard the nth reference image and the nth index list based on a determination that the distribution of similarity scores in the nth index list is poor.

Referring again to the system computes a similarity score based on the accessed reference image . For example the system computes a similarity score that represents similarity between the accessed biometric image and the reference image. In this example the system may compare the accessed biometric image with the reference image and generate a numeric value that reflects similarity between the accessed biometric image and the reference image. The system may compute the similarity scores between the two templates extracted from the two images. The resulting score reflects the similarity between the accessed biometric image and the reference image in that the score is closer to zero depending how similar the accessed biometric image is to the reference image i.e. the score would be zero for same images and near to zero for identical images . Any type of process for computing a similarity score e.g. numeric value that reflects similarity between two images may be used. For example to compute a similarity score between two images a method for matching using zero crossings of a one dimensional Discrete Cosine Transform DCT may be used to perform feature extraction for later classification.

In some examples the system may access multiple biometric images of the person e.g. multiple face images and compute for each of the multiple biometric images a similarity score that represents similarity between the corresponding biometric image and the reference image. In these examples the system may determine an average similarity score or median similarity score based on the similarity scores computed for the multiple biometric images. Using multiple biometric images of the person may provide a more accurate similarity score and may account of slight differences in position when capturing biometric images of the person as compared to position in the reference.

In some implementations the system may use one or more image similarity processes to generate a similarity measure between the accessed biometric image and the reference image. In these implementations the system may normalize the similarity measure to a similarity score between zero and one. Normalization allows the system to use a similarity process that produces a measure outside of a desired scale. In addition normalization may allow different similarity processes with different output ranges to be used and may allow for changes in the similarity process as long as the normalization is adjusted to compute similarity scores within the desired range e.g. zero to one .

The system searches the watch list using the computed similarity score . For instance the system compares the computed similarity score to the sorted similarity scores in the watch list and identifies one or more matches based on the comparison. The system may identify a closest match to the computed similarity score and or may identify a group of people having similarity scores within a threshold of the computed similarity score. Searching based on a similarity score may improve the speed of searching biometric data over traditional techniques that search based on a comparison of more detailed data.

In some implementations the system may search the sorted similarity scores in a manner that leverages knowledge of how the similarity scores included in the watch list are sorted. In these implementations the system may perform a binary search of the sorted similarity scores using the computed similarity score. For example the similarity scores included in the biometric data may be sorted in a list in descending order. In this example the system compares the computed similarity score to a similarity score at a central point in the sorted list. If the comparison reveals that the computed similarity score is more than a threshold greater than the similarity score at the central point in the sorted list the system discards a bottom half of the sorted list and moves to a similarity score at a central point in the remaining portion e.g. upper half of the sorted list. If the comparison reveals that the computed similarity score is more than the threshold less than the similarity score at the central point in the sorted list the system discards an upper half of the sorted list and moves to a similarity score at a central point in the remaining portion e.g. bottom half of the sorted list. The system continues to search the sorted list in half intervals until one or more matches that are within the threshold of the computed similarity score are located. Because the system knows that the similarity scores are sorted in a list in descending order the system is able to discard relatively large portions of the sorted list with a single comparison and without the need to compare the computed similarity score to all of the similarity scores included in the biometric data. Any type of search process that leverages knowledge of how data is sorted may be used by the system to search the sorted similarity scores. For example a binary search method can be used that is based on the linear ordering of keys such as alphabetic order or numeric order. In some examples the numeric order may be used when searching a list of similarity scores which are numbers. In this example a given input argument K e.g. a similarity score is compared to a middle key Kx in the sorted list and the result of this comparison tells which half of the table should be searched next. The result can be one of the three possible scenarios KKx. In case K Kx a match is identified. If KKx all of the elements in the table with keys less than Kx are discarded. Thus in each iteration of the search half of the table is eliminated and hence the search is completed in log N time. A more detailed explanation of the binary search process is given in The Art of Computer Programming Volume 3 Sorting and Searching Third Edition. Addison Wesley 1997. ISBN 0 201 89685 0. Section 6.2.1 Searching an Ordered Table pp. 409 426 by Donald Knuth .

The system identifies a subset of persons in the watch list having a similarity score within a threshold . For example the system identifies a subset of persons that are each associated with a similarity score within a threshold of the computed similarity score based on the searching. The system may identify the subset of people by identifying similarity scores whose absolute difference from the computed similarity score is less than or equal to the threshold. If the similarity scores were not sorted the system would have to compare the computed similarity score against all of the similarity scores to ensure each appropriate person is found. However because the similarity scores are sorted the system may find the subset of persons more quickly by discarding multiple similarity scores using a single comparison and knowledge of how the similarity scores are sorted.

The system determines image quality . For instance the system determines a quality of the image of the potential suspect. The quality may be determined as a number of pixels a level of clarity or lack of blurriness or any other measure of quality of captured images. The system also may determine a quality of images of persons included in the watch list. The system further may determine a quality of the reference image used to compute a similarity score for the image of the potential suspect and similarity scores for the images of persons included in the watch list.

The system sets a score threshold based on the image quality . For example the system sets a score threshold used in determining a subset of matches in searching the similarity scores in the watch list based on a level of the determined quality of the images. In this example the system sets a relatively low threshold based on a determination that the image quality is relatively good and the system sets a relatively high threshold based on a determination that the image quality is relatively poor. A low threshold is used when the image quality is good because the matching process is more accurate with high quality images. A high threshold is used when the image quality is poor because the matching process is less accurate with low quality images.

The system identifies a set of matches within the score threshold . For example the system uses a reference image to compute a similarity score for the image of the potential suspect and uses the computed similarity score to search the sorted list of similarity scores in the watch list in a manner that leverages knowledge of how the similarity scores are sorted e.g. ascending or descending order . Based on results of the searching the system identifies a subset of persons in the watch list that are each associated with a similarity score within the score threshold of the computed similarity score. The system may identify the subset of persons by identifying similarity scores whose absolute difference from the computed similarity score is less than or equal to the score threshold. If the similarity scores were not sorted the system would have to compare the computed similarity score against all of the similarity scores to ensure each appropriate person is found. However because the similarity scores are sorted the system may find the subset of people more quickly by discarding multiple similarity scores using a single comparison and knowledge of how the similarity scores are sorted.

The system determines a number of matches within the set of matches . For instance the system counts the number of matches included in the set of matches that have similarity scores within the score threshold of the similarity score of the potential suspect.

The system determines whether the number of matches within the set of matches is within a match threshold . For instance the system accesses the match threshold compares the determined number of matches within the set of matches to the match threshold and determines whether the determined number of matches within the set of matches is less than the match threshold based on the comparison. The match threshold may be a pre set value e.g. one hundred matches or may be dynamically determined based on the current context and or criticality of the situation.

Based on a determination that the number of matches within the set of matches is within the match threshold the system uses the set of matches as the subset . For example based on the system determining that the number of matches within the set of matches is less than the match threshold the system determines that additional narrowing of the set of matches is unnecessary and the system begins detailed comparison and processing of the images of the persons included in the set of matches.

Based on a determination that the number of matches within the set of matches is not within the match threshold the system selects a new reference image . For instance based on the system determining that the number of matches within the set of matches is more than the match threshold the system determines that additional narrowing of the set of matches is needed to avoid excess costs. To perform the additional narrowing of the set of matches the system selects a new reference image to use in narrowing the set of matches. The new reference image is different than the reference image used to arrive at the set of matches. The system may select a new reference image using the techniques described above with respect to reference numeral and .

The system identifies a new set of matches within the score threshold for the new reference image . For example the system uses the new reference image to compute a similarity score for the image of the potential suspect and uses the computed similarity score to search the sorted list of similarity scores in the watch list associated with the new reference image in a manner that leverages knowledge of how the similarity scores are sorted e.g. ascending or descending order . Based on results of the searching the system identifies a subset of persons in the watch list that are each associated with a similarity score within the score threshold of the similarity score computed using the new reference image. The system may identify the subset of persons by identifying similarity scores whose absolute difference from the similarity score computed using the new reference image is less than or equal to the score threshold.

The system determines the number of matches within all sets of matches . For example the system compares the matches included in the new set of matches with the matches included in the original set of matches and identifies a common set of matches included in each of the new set of matches and the original set of matches. In this example the system counts the number of matches included in the common set of matches which includes all of the matches found in both the new set of matches and the original set of matches. The common set of matches becomes the set of matches under consideration for further processing.

After determining the number of matches within all sets of matches the system determines whether the number of matches within all sets of matches is within the match threshold . Based on a determination that the number of matches within all sets of matches is within the match threshold the system uses the matches within all sets of matches as the subset . Based on a determination that the number of matches within all sets of matches is not within the match threshold the system repeats operations to until the number of matches within all sets of matches is within the match threshold. To the extent that the system uses all reference images and the match threshold has not been reached the system ends processing and uses the matches within all sets of matches as the subset despite the number of matches within all sets of matches falling outside of the threshold.

Referring again to the system controls parallel analysis of the determined image against detailed biometric data for the subset and determines whether the potential suspect matches a person in the watch list based on the analysis . For example the system identifies detailed biometric data linked to each of the persons in the subset and accesses the detailed biometric data identified. In this example the system may access from an index table stored in relational database storage a link to detailed biometric data e.g. blob data of a facial image for each person in the subset and use the accessed link to retrieve detailed biometric data for each person in the subset. The system further may access detailed biometric data for one or more persons in the subset directly from the index table stored in relational database storage. The system may access each instance of the detailed biometric data for the subset e.g. each blob in parallel because each instance of the detailed biometric data for the subset e.g. each blob is stored on a separate partition server in the cloud.

In some implementations the system compares the detailed biometric data for the persons in the subset to detailed biometric data for the accessed biometric image of the potential suspect. The system may use any type of technique to compare the detailed biometric data for the person to the detailed biometric data for each person in the subset. For instance the system may use any image matching process for face images to compare the detailed biometric data for the potential suspect to the detailed biometric data for each person in the subset. The system may compare each instance of the detailed biometric data for the subset e.g. each blob with the detailed biometric data for the potential suspect in parallel. Each comparison may be performed by a different processor in the cloud in parallel.

The system determines whether the potential suspect matches a person in the watch list based on the analysis. For example the system analyzes results of the detailed comparison and determines which person in the subset is the closest match. In this example the system may determine whether the closest match meets a threshold level of confidence in the match and outputs the closest match based on a determination that the closest match meets the threshold level of confidence. Based on a determination that the closest match does not meet the threshold level of confidence the system may provide output that no match exists.

The system sets a batch size based on context and or criticality of the situation . For example the system determines the context and criticality of the situation based on user input a pre defined setting and or an alert feed. In this example the system may receive user input that defines a baseline context and criticality of a particular area or location and the system sets the batch size based on the baseline context and criticality of the particular area or location. If the context and or criticality changes temporarily e.g. a threat is made or a person of interest is reported to be in the particular area or location the system receives updated user input to reflect the change and sets the batch size based on the updated context and or criticality. The system also may update the context and or criticality based on an alert feed. For instance the system may receive a threat level alert provided by a government organization or other organization and update the context and or criticality as appropriate for the threat level provided by the government organization or other organization.

The system considers the context and or criticality and sets the batch size based on the context and or criticality. The system sets the batch size as appropriate for the context and or criticality. For instance when the context is a high crime area and the criticality of the situation is relatively high the system sets a relatively large batch size because the circumstances justify the expense of processing more images in parallel. When the context is a low crime area and the criticality of the situation is relatively low the system sets a relatively small batch size because the circumstances do not justify the expense of processing more images in parallel. To determine the batch size the system may reference a look up table that stores batch sizes to use for the various possible values or value ranges for the context and or criticality used by the system to set the batch size. The system may store the look up table in electronic storage based on user input provided by an operator of the system .

The system references the data structure in setting the batch size. For example the system determines the context and criticality of the situation based on user input a pre defined setting and or an alert feed e.g. a threat level alert provided by a government organization or other organization . In this example the system determines whether the criticality of the situation is very high high medium or low. The system also determines whether the context of the situation is in a crime sensitive area or jewelry store whether the context of the situation is in an airport or railway station whether the context of the situation is in a public transport location a public park or vehicular surveillance or whether the context of the situation is in home security or school campus security. Based on the determinations the system references the data structure and sets the batch size as the number of images defined by the data structure . For instance the system selects fifty images based on determining that the criticality is very high and the context is in a crime sensitive area or jewelry store selects twenty images based on determining that the criticality is high and the context is in an airport or railway station selects ten images based on determining that the criticality is medium and the context is in a public transport location a public park or vehicular surveillance and selects five images based on determining that the criticality is low and the context is in home security or school campus security.

Referring again to the system determines whether the number of unprocessed persons in the subset is greater than the batch size . For instance the system determines a number of unprocessed persons in the subset and compares the number to the batch size. Based on comparison results the system determines whether the number of unprocessed persons in the subset is greater than the batch size.

Based on a determination that the number of unprocessed persons in the subset is less than or equal to the batch size the system performs a detailed comparison of all remaining unprocessed persons . Because the number of unprocessed persons in the subset is less than or equal to the batch size the system performs in parallel detailed biometric comparison of the image e.g. blob data of the potential suspect against each of the images e.g. blob data of the persons in the subset identified from the watch list. The parallel comparison and analysis of the image e.g. blob data of the potential suspect against each of the images e.g. blob data of the persons in the subset identified from the watch list is possible because the images e.g. blob data of the persons in the subset identified from the watch list are stored in a cloud storage system with each image e.g. instance of blob data being stored on a different partition server.

Referring again to the system selects a batch of persons based on a determination that the number of unprocessed persons in the subset is greater than the batch size . For instance because the number of unprocessed persons in the subset from the watch list exceeds the batch size the system selects less than all of the unprocessed persons in the subset for processing first. The system may select the unprocessed persons in the subset from the watch list that have the closest similarity scores to the potential suspect for the batch because the persons with the closest similarity scores are more likely to result in a match than other persons in the subset. The system may consider whether any of the persons in the unprocessed persons in the subset from the watch list are more likely results than others. For instance the system may select any of the unprocessed persons in the subset from the watch list have been reported to be an area where the multiple images were captured or are known to be geographically proximate to the area where the multiple images were captured. The system may select those persons for the batch because they may be more likely to result in a match than other persons that are thought to be in other geographic locations even though the other persons have closer similarity scores to the potential suspect than the persons selected.

The system performs a detailed comparison of all persons in the selected batch . For example the system identifies detailed biometric data linked to each of the similarity scores for the persons in the selected batch and accesses the detailed biometric data identified. In this example the system may access a user identification number for each person in the selected batch and use the accessed user identification numbers to retrieve detailed biometric data for each person in the selected batch. The system also may access from an index table stored in relational database storage a link to detailed biometric data e.g. blob data of a facial image for each person in the selected batch and use the accessed link to retrieve detailed biometric data for each person in the selected batch. The system further may access detailed biometric data for one or more persons in the selected batch from an index table stored in relational database storage. The detailed biometric data for each person in the selected batch may include data that is more descriptive of the biometric image of the face of the corresponding person than the similarity score for the corresponding person. The detailed biometric data for the persons in the selected batch also may have a greater storage size than the similarity score for the corresponding person. The detailed biometric data may include the biometric images that were used to compute the similarity scores for the subset of the people or another representation e.g. blob data for the biometric images.

In some implementations the system compares the detailed biometric data for the persons in the selected batch to detailed biometric data for the accessed biometric image of the potential suspect. For instance the system may access detailed biometric data for the potential suspect and compare the detailed biometric data for the potential suspect to the detailed biometric data for each person in the selected batch. The detailed biometric data for the person is the same type of biometric data as the detailed biometric data for the subset of the people and may be more descriptive of the biometric image of the person than the computed similarity score. The detailed biometric data for the person also may have a greater storage size than the computed similarity score. The detailed biometric data for the person may include the biometric image that was used to compute the similarity scores for the person or another representation e.g. template blob data for the biometric image.

The system may use any type of technique to compare the detailed biometric data for the person to the detailed biometric data for each person in the subset of the people. For instance the system may use any image matching process for that particular modality sub modality to compare the detailed biometric data for the person to the detailed biometric data for each person in the subset of the people. The process can be similar to the one discussed above as an example for left iris matching technique based on weighted Hamming Distance metric as described in DCT based iris recognition by D. M. Monro S. Rakshit and D. Zhang published in IEEE Transactions on Pattern Analysis and Machine Intelligence Vol. 29 No. 4 pp. 586 595 April 2007. Because the detailed biometric data is more descriptive than the similarity scores the comparison of the detailed biometric data may be more time consuming and more accurate than the comparison involving the similarity scores. However the comparison involving the similarity scores may still be useful because it narrows down the potential matches to a subset of the people prior to the more detailed and time consuming process being performed. This staged approach may speed up the search process and still provide the accuracy of traditional biometric systems that perform more detailed analysis on all possible matches from the outset.

The system determines whether a match is found within the selected batch based on the detailed comparison of all persons in the selected batch . For example the system analyzes results of the detailed comparison and determines which person in the selected batch is the closest match. In this example the system may determine whether the closest match meets a threshold level of confidence in the match and outputs the closest match based on a determination that the closest match meets the threshold level of confidence. Based on a determination that the closest match does not meet the threshold level of confidence the system may provide output that no match exists within the selected batch or may provide output identifying multiple potential matches with an indication that none of the potential matches meets the threshold level of confidence.

Based on a determination that a match is found within the selected batch the system ends processing and outputs the match . Although additional batches remain unprocessed the system ends processing because a match was found and it is unnecessary to complete processing for the remaining persons in the subset of persons identified from the watch list. Based on a determination that a match is not found within the selected batch the system moves on to process another batch of images in parallel until all of the subset of persons identified from the watch list have been processed or a match is found. Specifically the system repeats operations to until all of the subset of persons identified from the watch list have been processed or a match is found.

As shown the system determines that fifteen persons in the watch list are within the threshold. Because the system determines that the batch size is five the system determines to select three batches of images for processing. As shown the system selects a first batch of images to process a second batch of images to process and a third batch of images to process. The system selects the first batch of images as the five images having the closest similarity score to the similarity score for the potential suspect . The system selects the second batch of images as the five images having similarity scores below the first batch of images and selects the third batch of images as the five images having similarity scores above the first batch of images . The system may identify the closest match and select batches of images radiating outward from the closest match. Also the system may identify batches as the images within the batch size having the closest similarity score to the similarity score for the potential suspect . In this regard the second batch of images may include images with similarity scores above and below the similarity scores within the first batch of images.

After selecting the three batches of images the system first processes the first batch of images in parallel. If a match is not found in the first batch of images the system processes the second batch of images in parallel. If a match is not found in the second batch of images the system the system processes the third batch of images in parallel.

Referring again to the system outputs a result based on the determination of whether the potential suspect matches a person in the watch list . For instance the system displays a result of the search e.g. one or more matches identified through searching stores the result of the search in electronic storage sends the result of the search in an electronic communication e.g. an electronic mail message prints a copy of the result of the search using a printing device sends the result of the search to another process for additional processing or performs any other output operation that allows a user to perceive the result of the search and or that allows the result of the search to be used in further authentication processing. Based on a determination that the potential suspect does not match a person in the watch list the system outputs an indication that no match was found for the potential suspect. The system may display a result that indicates no match was found for the potential suspect stores an indication that no match was found for the potential suspect in electronic storage sends an indication that no match was found for the potential suspect in an electronic communication e.g. an electronic mail message prints a copy of the indication that no match was found for the potential suspect using a printing device sends the indication that no match was found for the potential suspect to another process for additional processing or performs any other output operation that allows a user to perceive the result that no match was found for the potential suspect and or that allows the result that no match was found for the potential suspect to be used in further authentication processing.

For example as shown in the system selects potential suspects to process in parallel . In this example the system selects three suspects to process in parallel. However in other implementations the system may process more or fewer potential suspects in parallel.

In some implementations the system dynamically determines a number of potential suspects to process in parallel. In these implementations the system may set the number of potential suspects to process in parallel based on context and or criticality of the situation. The system may use similar techniques to those discussed above with respect to setting the batch size reference numeral in setting the number of potential suspects to process in parallel. For instance as shown in the data structure defines a number of potential suspects to process in parallel based on the context and the criticality of the situation. The system may use the data structure to set the number of potential suspects to process in parallel based on the context alone the criticality alone or a combination of the context and the criticality.

The system references the data structure in setting the number of potential suspects to process in parallel. For example the system determines the context and criticality of the situation based on user input a pre defined setting and or an alert feed e.g. a threat level alert provided by a government organization or other organization . In this example the system determines whether the criticality of the situation is very high high medium or low. The system also determines whether the context of the situation is in a crime sensitive area or jewelry store whether the context of the situation is in an airport or railway station whether the context of the situation is in a public transport location a public park or vehicular surveillance or whether the context of the situation is in home security or school campus security. Based on the determinations the system references the data structure and sets the number of potential suspects to process in parallel defined by the data structure . For instance the system selects fifty potential suspects based on determining that the criticality is very high and the context is in a crime sensitive area or jewelry store selects twenty potential suspects based on determining that the criticality is high and the context is in an airport or railway station selects ten potential suspects based on determining that the criticality is medium and the context is in a public transport location a public park or vehicular surveillance and selects five potential suspects based on determining that the criticality is low and the context.

After determining the number of potential suspects to process in parallel the system selects which potential suspects to process in parallel first. For example the system captures images of large crowds with many potential suspects. In this example the system only processes a subset of the potential suspects in the crowd even though the system processes multiple potential suspects in parallel.

To determine the subset of potential suspects to process first the system considers one or more of several factors. For instance the system may consider the quality of the images of the faces of the potential suspects in selecting the subset of potential suspects to process first. In this regard the system may select potential suspects where the image of the face is of relatively high quality e.g. faces where a clear front view is present in the images . The system may process a first potential suspect where the image of the face of the first potential suspect is a front view prior to processing a second potential suspect where the image of the face of the second potential suspect is a side view.

In addition to the view of the face the system also may consider the quality of the image of the face in selecting the subset of potential suspects to process first. For example portions of an image of a crowd may have better lighting than other portions of the image of the crowd. In this example the system may select potential suspects located in the portions of the image of the crowd that have better lighting prior to potential suspects located in the other portions of the image of the crowd with inferior lighting characteristics.

The system further may consider other image quality characteristics in selecting the subset of potential suspects to process first. For instance some potential suspects in the image of the crowd may be moving and other potential suspects in the image of the crowd may be stationary. The system may determine that the faces of the persons in the image of the crowd that are moving are blurrier than the faces of the persons in the image of the crowd that are stationary. Based on that determination the system may select the potential suspects that are stationary and less blurry prior to the potential suspects that are moving and blurrier .

In some implementations the system may be attempting to identify a particular person on the watch list based on other information that indicates the particular person may be within the area monitored by the system . In these implementations the system may consider similarity of the faces in the image of the crowd to the image of the particular person in selecting the subset of potential suspects to process first. For example the particular person on the watch list may have known gender and ethnicity characteristics. In this example the system may scan the faces in the image of the crowd to locate potential suspects in the crowd that have the same gender and ethnicity characteristics as the particular person on the watch list and select the potential suspects that have the same gender and ethnicity characteristics for initial processing. The system also may compute similarity scores for faces in the image of the crowd and select the potential suspects that have similarity scores that are closest to the similarity score of the particular person on the watch list.

After selecting the potential suspects to process in parallel the system accesses multiple images of each suspect and invokes parallel pre processing cores for each suspect . The system controls the parallel pre processing cores to pre process the multiple images of each suspect in parallel. The system may control pre processing for each suspect in parallel using the techniques described above with respect to reference numeral and .

Based on results of pre processing the system determines a selected image for each suspect . The system may arrive at the selected image for each suspect at the same time or may arrive at the selected image for each suspect at staggered times based on how long pre processing takes for each suspect. The system determines the selected image for each suspect as the best image from the multiple images of the corresponding suspect or as an aggregate of information from the multiple images of the corresponding suspect that provides the best representation of the corresponding suspect.

After determining the selected image for each suspect the system matches each of the selected images with a reference image and generates a suspect index profile that includes a similarity score for each of the potential suspects being processed in parallel. The system may match each of the selected images with the reference image in parallel or at staggered times based on when the selected image of each potential suspect is determined. The system may use the techniques described above with respect to reference numerals and to generate the suspect index profile .

After generating the suspect index profile as shown in the system accesses the selected image for each suspect and invokes parallel matching threads or processes for performing detailed comparison of the selected image for each suspect with different batches of images of persons from the watch list . The system may determine the different batches of images of persons from the watch list to use in the detailed comparison by using the similarity scores in the suspect index profile to search the similarity scores in the watch list. The system may search the watch list in parallel for each potential suspect using the techniques described above with respect to reference numerals and .

For example as shown in the system computes a similarity score for a first potential suspect as 0.886745 a similarity score for a second potential suspect as 0.970045 and a similarity score for a third potential suspect as 0.848745. The system compares in parallel the similarity score for each of the first potential suspect the second potential suspect and the third potential suspect to a watch list database that includes sorted similarity scores for persons in the watch list. Based on the comparison the system identifies all persons in the watch list database that have a similarity score that is within a threshold above or below of the similarity score for each of the first potential suspect the second potential suspect and the third potential suspect . As shown the system determines a separate batch of five persons in the watch list for each of the first potential suspect the second potential suspect and the third potential suspect .

After identifying the batches of images the system processes the separate batch of images for each of the potential suspects in parallel . The parallel processing of the separate batches of images is possible because as shown in the system compares the images of each potential suspect and to detailed facial images e.g. blob data of persons in the watch list that are stored in a watch list database on different partition servers. The system may process the separate batch of images for each of the potential suspects in parallel using the techniques described above with respect to reference numeral and .

After completing parallel matching for a batch of images for each of the potential suspects the system determines for each of the potential suspects whether a match was found in the batch . Based on a determination that a match was found in the batch for a potential suspect the system outputs the match result for the potential suspect. Based on a determination that a match was not found in the batch for a potential suspect the system determines whether another batch of images remains for the potential suspect . Based on a determination that another batch of images does not remains for the potential suspect the system outputs an indication that a match result was not found for the potential suspect. Based on a determination that another batch of images remains for the potential suspect the system continues to process the additional batches of images that remain for the potential suspect until all of the batches of images have been processed. The system continues to process the additional batches of images in parallel and continues to process the multiple potential suspects in parallel.

In addition as the system completes processing for a potential suspect e.g. a match is found or an indication of no match result is determined the system selects a new potential suspect and begins processing of the new potential suspect in parallel with processing of the potential suspects for which processing has not completed. The system may select the new potential suspect using the techniques described above with respect to and reference numeral . The system continues to select new potential suspects and processes the new potential suspects in parallel until all of the potential suspects in the crowd have been processed.

The system includes a processor a memory a storage device and an input output device . Each of the components and are interconnected using a system bus . The processor is capable of processing instructions for execution within the system . In one implementation the processor is a single threaded processor. In another implementation the processor is a multi threaded processor. The processor is capable of processing instructions stored in the memory or on the storage device to display graphical information for a user interface on the input output device .

The memory stores information within the system . In one implementation the memory is a computer readable medium. In one implementation the memory is a volatile memory unit. In another implementation the memory is a non volatile memory unit.

The storage device is capable of providing mass storage for the system . In one implementation the storage device is a computer readable medium. In various different implementations the storage device may be a floppy disk device a hard disk device an optical disk device or a tape device.

The input output device provides input output operations for the system . In one implementation the input output device includes a keyboard and or pointing device. In another implementation the input output device includes a display unit for displaying graphical user interfaces.

The features described can be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations of them. The apparatus can be implemented in a computer program product tangibly embodied in an information carrier e.g. in a machine readable storage device for execution by a programmable processor and method steps can be performed by a programmable processor executing a program of instructions to perform functions of the described implementations by operating on input data and generating output. The described features can be implemented advantageously in one or more computer programs that are executable on a programmable system including at least one programmable processor coupled to receive data and instructions from and to transmit data and instructions to a data storage system at least one input device and at least one output device. A computer program is a set of instructions that can be used directly or indirectly in a computer to perform a certain activity or bring about a certain result. A computer program can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment.

Suitable processors for the execution of a program of instructions include by way of example both general and special purpose microprocessors and the sole processor or one of multiple processors of any kind of computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The elements of a computer are a processor for executing instructions and one or more memories for storing instructions and data. Generally a computer will also include or be operatively coupled to communicate with one or more mass storage devices for storing data files such devices include magnetic disks such as internal hard disks and removable disks magneto optical disks and optical disks. Storage devices suitable for tangibly embodying computer program instructions and data include all forms of non volatile memory including by way of example semiconductor memory devices such as EPROM EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in ASICs application specific integrated circuits .

To provide for interaction with a user the features can be implemented on a computer having a display device such as a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device such as a mouse or a trackball by which the user can provide input to the computer.

The features can be implemented in a computer system that includes a back end component such as a data server or that includes a middleware component such as an application server or an Internet server or that includes a front end component such as a client computer having a graphical user interface or an Internet browser or any combination of them. The components of the system can be connected by any form or medium of digital data communication such as a communication network. Examples of communication networks include e.g. a LAN a WAN and the computers and networks forming the Internet.

The computer system can include clients and servers. A client and server are generally remote from each other and typically interact through a network such as the described one. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly other implementations are within the scope of the following claims.

